

# 项目反应理论 [u](https://github.com/nababasky/IRT) 



全部知识点的综合掌握程度 = 能力 = 潜在特质（latent traits）



**计算机自适应测验中RASCH模型稳健性的模拟研究** [u](https://wenku.baidu.com/view/8fe865eb856a561252d36fd7.html)

> **基于pytorch的单参模型代码** [u](https://github.com/jplalor/py-irt)
>
> > **pyro** [u](https://github.com/pyro-ppl/pyro)
> >
> > **SVI 随机变分推断** [u](https://causalai.github.io/pyro_zh_tutorial/svi_part_i.html)
> >
> > **Pyro简介：产生式模型实现库（一），模型** [u](https://www.jianshu.com/p/b7267ce2d763)
> >
> > **Pyro 从入门到出门** [u]()
> >
> > > 搞机器学习的同学大部分在线性代数、矩阵论、微积分上没什么问题，**但是概率论、信息论的知识还是有很大空白的**。因此，这里给大家推荐一个现成的库 Pyro
> > >
> > > ```python
> > > m = Bernoulli(torch.tensor([0.3])) # 二项（伯努利）分布
> > > m.sample()
> > > # tensor([ 0.])
> > > # 有 30% 可能性出现 1，70% 可能性出现 0
> > > ```
> > >
> > > ```python
> > > m = Normal(torch.tensor([0.0]), torch.tensor([1.0])) # 正态（高斯）分布
> > > m.sample()
> > > # tensor([ 0.1046])
> > > ```
> > >
> > > ```python
> > > m = Poisson(torch.tensor([4])) # 泊松分布
> > > m.sample()
> > > # tensor([ 3.])
> > > ```
> > >
> > > 只需要记住，在**增强学习中要调用 sample，在 VAE 中要调用 rsample** 就可以了

> y = np.random.binomial(1, expit(real_theta[i] - real_diff[j])) 
>
> \# The expit function, also known as the logistic sigmoid function, is defined as expit(x) = 1/(1+exp(-x)). 



- **许多学术论文将术语“变量”、“分布”、“密度”，甚至“模型”互换使用**。这种做法本身不一定导致错误，因为X、P(X)和p(X)都可以通过一对一的对应关系相互指代。



**变分贝叶斯初探** [u](https://www.jianshu.com/p/86c5d1e1ef93)

**Rasch model By Pyro** [u](https://forum.pyro.ai/t/rasch-model/1224)

> https://colab.research.google.com/drive/1SZDm5ppWBFIpowO8KIATfoYZXEVbuVGr

**pip install girth** --upgrade [u](https://github.com/eribean/girth)

- **非常非常好**



**python机器学习笔记：EM算法** [u](https://www.cnblogs.com/wj-1314/p/12856388.html)

> $p(x|\theta)$ 对分布采样，分布是生产者，它会按一定概率生产不同的产品

**手把手教你实现一个高斯混合模型** [u](https://developer.ibm.com/zh/technologies/analytics/articles/ba-lo-machine-learning-hands-on7-gmm/)

> **求得**男生身高和女生身高这两个**高斯分布的参数**

> **当我们只有身高数据的时候，如何将身高数据聚成男女生两个簇？这就是高斯混合分布可以解决的问题**。高斯混合分布首先将该问题转换为包含隐变量（即每条样本属于不同类别的概率）和模型参数（即男女生两个高斯分布的参数）的极大似然估计问题。由于该极大似然估计问题中包含隐变量和模型参数，所以无法用传统的求偏导的方法求得。这时，需要利用EM算法，即期望最大化算法求解参数。



**项目反应理论参数的EM估计** [u](https://blog.csdn.net/Zoe_Su/article/details/84761812)

> 　　将EM算法应用到IRT模型中来，则E步和M步可以描述为：
>
> 　　E步：即在给定缺失数据的分布，观察数据和参数初值时，求完全数据的对数似然函数的条件期望。
>
> 　　M步：即使用E步计算出的完全数据充分统计量的条件期望值，极大化完全数据的对数似然函数的条件期望求解参数的值。
>
> 　　不断的循环迭代E步和M步，直到参数估计收敛。
>
> 　　在IRT模型当中，我们通常认为能力参数 θθ 是连续随机变量，故可以取任意值。在EM算法估计参数的过程中，我们是能力参数 θθ 为离散分布。能力值只能取 q1,q2,......,qKq1,q2,......,qK, K个值中的一个，且 P(θ=qk)=πkP(θ=qk)=πk 。



**最大后验推断**(Maximum A Posteriori) ，**MAP 推断**





自适应考试系统的分级组卷模板实现.doc



我们最终目的是要根据学生的做题对错情况来评估这个学生的当前能力值，也就是公式中的“θ”参数。其实问题就转化为**当我们看到观测数据（学生做题对错），确定该学生的能力值是多少才能得到这样的做题对错序列**。这样我们可以使用极大似然估计方法来估计“θ”的值，因为极大似然估计的目标就是找出一组参数，使得模型产生出观测数据的概率最大。







![image-20201124145430607](项目反应理论.assets/image-20201124145430607.png)



<img src="项目反应理论.assets/image-20201124150142395.png" alt="image-20201124150142395" style="zoom: 50%;" />







**剑桥专家为你一键解锁计算机自适应考试** [u](http://www.jzlt100.com/question/2385)

> 人工智能赋能英语学习”在线系列讲座是2020剑桥英语节的重要主题之一，由剑桥大学英语考评部首席研究经理徐兢博士作为主讲嘉宾，为大家深度解读英语测评的基本概念和人工智能在英语测评领域中的应用。



自适应测试：让定制化测试成为现实”(Building personalised assessment via Computer Adaptive Testing)

- **高效精准**：水平高的考生无需回答过多简单试题，水平有限的考生也不会遇到太多难题，从而可以确保在短时间内获得较为精确的测评结果。
- **安全便捷**：由人工智能加持，通过远程监考，并配合计算机自动评分，可以实现随时随地进行考试。
- **降低考生焦虑情绪**：每位考生遇到的题目难度不会超出其承受水平，这可以有效降低考生的焦虑情绪，让考生在考试中充分发挥其语言水平。



项目反应理论(Item Response Theory, 简称 IRT)，又称为隐性特征理论。该理论构建了一整套数学模型来描述**考生能力(test taker ability) 、题目特性 (task difficulty) 与考生答对率 (probability of correct answer)**之间的关系。



Rasch模型规定，当某个题目的难度和考生的能力相当，那么考生能够答对该题的概率为50%。这个数值也可以通过以下公式推导得出：

<img src="项目反应理论.assets/image-20201124141908328.png" alt="image-20201124141908328" style="zoom: 80%;" />

Rasch模型基本公式

在Rasch模型中，当一道题目难度中等，我们将该题赋值为0；当某位考生水平中等，则该考生水平也赋值为0，那通过以上公式可推导出该考生答对该题概率为50%。计算过程见下图。



<img src="项目反应理论.assets/image-20201124142553296.png" alt="image-20201124142553296" style="zoom: 67%;" />



<img src="项目反应理论.assets/image-20201124142702391.png" alt="image-20201124142702391" style="zoom: 80%;" />



<img src="项目反应理论.assets/image-20201124143148678.png" alt="image-20201124143148678" style="zoom: 67%;" />



由此可见，以上公式可以通过题目难度和考生能力，计算出考生答对题目的概率。但在计算机自适应考试中，计算机能够实时获取考生的答题结果。**因此通过将该公式反向推导，计算机可以根据每位考生对一系列考题的答题对错与否和相应考题的难易程度，反向估算出考生最有可能的语言能力水平。考生答题越多，能力估算就越精确。考试在达到预设的精确度后就会自动停止，给出最终结果。**





在经典测试理论(Classic Testing Theory)中，对于一整份考卷，**每个考生的答题表现可以总结到一个表格中**(如下图)。其中，顶部横项为题目，左侧纵向为考生名字（化名），数字1代表考生答对该题，数字0代表考生答错该题。经典测试理论通过累计考生答对题目的总数量来计算考生的水平。

![image-20201124144124096](项目反应理论.assets/image-20201124144124096.png)









**计算机自适应测试(Computer Adaptive Test，简称CAT)**

- 以项目反应理论（Item Response Theory）为基础

- 应用：托福留学外语考试（TOEFIE）、研究生资格考试（GRE）、护士资格证书等

- 模型计分的方式有两种，一种是多级计分，另一种1、0计分（正确记为1，错误记为0），本研究仅介绍1、0计分的逻辑谛斯克模型

- 项目选择 - **选题策略**是CAT一个非常重要的环节，它**直接影响测验的效率**问题
  
- 一种是**信息函数最大化策略**，另一种提加权偏离模型（Weighted Deviation Model ,WDM）。本研究中使用信息函数最大化策略
  
- CAT施测过程

  - 能力探查阶段

    > 测验刚开始时，一般并无被试真实水平信息，故设置一批探查性项目，初步估计其水平。本研究中，设置五个项目，难度分别为－2，－1,0，1,2；二是精确估计真值阶段，适应被试的水平从题库中挑选出能提供最大信息量的项目
  - 能力精估阶段
  - 终止规则
    
    > 一是确定题数，二是确定测量标准误，三是前两者的结合：若题数已达到，但标准误不及，则仍要继续施测，直至达到指定的测量标准误为止
    >
    > **测验终止规则采用定长：分别为10、15、20题三种**

- 能力估计的准确性的评价指标

  - 均方根误差 （Root Mean Square Error，简称RMSE）
  - 平均差异（Average Difference, 简称 AD）

  

- 选择项目反应模型

- **利用已有答题数据估计出题目参数与被试参数**
  
  - **运用概率与统计的方法来估计参数**







**Rasch模型**

Rasch模型 丹麦学者拉希（Rasch）是最早独立研究项目反应并获得巨大成功的学者，Rasch模型通常也叫单参逻辑什谛克模型，指的是被试的能力与项目难度两者关系的数学模型，它只有一个项目难度参数而没有区分度参数。拉希认为，用一批项目去测试被试，就是要在一个线性系统上去确定被试的特质水平，除了项目难度之外，应该维持所有项目的相同性质。拉希公式如下：
$$
a
$$










模型计分的方式有两种，一种是多级计分，另一种1、0计分（正确记为1，错误记为0），本研究仅介绍1、0计分的逻辑谛斯克模型。



项目反应理论 Rasch 实现 观测数据

**什么是Rasch模型？**[u](https://www.zhihu.com/question/394197045)

> IRT三参数模型的方法是使用更多参数去使“模型适应数据”, 而 **Rasch 模型却要求“数据符合模型”**
>
> 但 Rasch 模型却能**提供更稳定、更精确的题目难度参数**, 以及更好的题目和测验信度。
>
> 基于项目反应理论上的评估模型提供了数据驱动技术，用于为学习者选择适合当前知识水平的学习资源，并可用于不断地更新学习者的知识水平



基于多面Rasch模型的评分效应分析 [u](https://wenku.baidu.com/view/eea5393dad02de80d5d84058.html)

> 可以实现在同一个**洛基量尺（Logit scale）**上分析主观试题中**考生的能力、试卷的难度**、阅卷老师的宽严度以及评分量表的准确度等方面的表现以及他们之间的交互作用

基于Rasch 模型的英语阅读能力测试与评估



三参模型

b：代表项目难度系数，理论上可以取（-∞,+∞）,典型值在[-3,3]之间
a：代表项目区分度系数，理论上可以取（-∞,+∞），典型值在[-2.8,2.8]之间
c：代表猜测参数，猜测参数取值范围是[0,1]，典型值通常超过0.35
θ：代表能力值



计算机自适应考试（Computer-Adaptive Test, CAT）

> GRE考试的自适应模式算法
>
> 虽然dao官方没有公布du自适应算法，但zhi根据模考和大量dao考生数据可以推理出如专下模型：
> 第一套属算分的section一定是medium难度的，然后如果你对0-6个，下一个同类型section就会进入easy模式；7-13个，进入median模式；14-20个，进入hard模式。
> easy模式并不代表好拿分，因为得分不仅和正确题数有关，还和这个部分的难度系数有关。
> ETS没有公布官方的算分方式，但是根据多方信息汇总，大致可以得出如下数据：
> easy模式的题以难度系数1，2，3为主；
> medium模式的题以难度系数3，4为主；
> hard模式的题以难度系数4，5为主。
> 比如第一个section对了14题，那么第二个section=就进入到了hard模式，但这时只对了7题，最后的分数大概是155；
> 如果第一个section对了8题，那么第二个section进入到了medium模式，这时需要对16题才能拿到155分。
> 如果第一个section对了6题，那么第二个section进入到了easy模式，这时哪怕第二个section全对，也只有151分。



**基于认知诊断的个性化试题推荐方法 - 中国科学技术大学**

- 知识点的掌握程度  **知识点能力**





## 自适应考试目的

> 试题精准匹配考生能力，减少刷题量。让高能力考生少刷低难度题，低能力考生少刷高难度题
>
> 根据考点考频确定出题优先级



我们自已的考点考频：高、中、低



**基于IRT的计算机自适应测评系统** [u](http://www.fengjunchen.com/cat/)

> 不可观察的学生能力和可观察的解题结果之间的不确定性是学习数据分析的根本问题



**Python与项目反应理论：基于EM和MCMC的参数估计算法** [u](https://zhuanlan.zhihu.com/p/29887184)

> **基于pytorch的单参模型代码** [u](https://github.com/jplalor/py-irt)
>
> **基于Tensorflow 的Rasch代码** [u](https://www.kaggle.com/mlarionov/the-rasch-model)
>
> **Rasch 英文教材(有matlab代码)** [u](Bayesian Reasoning and Machine Learning by David Barber (z-lib.org).pdf p.425)
>
> **人人都懂EM算法** [u](https://zhuanlan.zhihu.com/p/36331115)
>
> > 概率统计的思想，根据样本估算总体
> >
> > 正态分布(normal distribution) = 高斯分布(Gaussian distribution)
>
> **项目反应理论 EM估计** [u](https://blog.csdn.net/zoe_su/article/details/84761812?utm_medium=distribute.pc_relevant.none-task-blog-baidulandingword-2&spm=1001.2101.3001.4242)
>
> **IRT模型的参数估计方法**（EM算法和MCMC算法） [u](https://www.cnblogs.com/jiangxinyang/p/9621997.html)
>
> **什么是Rasch模型？**[u](https://www.zhihu.com/question/394197045)

**变分自编码器，神经网络应用于计量心理学模型的初探**  [u](https://zhuanlan.zhihu.com/p/141742408)

> **SVD分解(一)：自编码器与人工智能** [u](https://kexue.fm/archives/4208)



**人人都懂EM算法** [u](https://zhuanlan.zhihu.com/p/36331115)

> 概率统计的思想，根据样本估算总体
>
> 正态分布(normal distribution) = 高斯分布(Gaussian distribution)



**来个例子，再解释一次 EM 算法** [u](https://blog.csdn.net/xo3ylAF9kGs/article/details/105320790)



样本集 $X = x_1, x_2, \cdots, x_N$ 表示200 个人的身高

- 假设学校**所有学生的身高服从正态分布** $N(μ, \sigma^2)$
- 期望$μ$，方差$\sigma^2$ 未知
- 目标是：**从样本估算出未知的期望和方差**



**概率密度$p(x|\theta)$ 服从高斯分布$N(μ, \sigma^2)$** 

- 未知参数是 $\theta = [\mu, \sigma]^T$
- **目标是：估算 $\theta$**

每个样本都是独立地从$p(x|\theta)$中抽取的



**正好抽到这特定的 200 个身高的概率是一个联合概率**
$$
L(\theta) = L(x_1, x_2, \cdots , x_n; \theta) = \prod^n_{i=1} p(x_i|\theta), \theta \in \Theta
$$
**当概率密度函数的参数是$\theta$ 时，得到$X$ 这组样本的概率是$L(\theta)$**



**联合概率$L(\theta)$ 表示**在不同参数$\theta$ 取值下，**正好抽到$X $ 这组样本的概率**



**联合概率$L(\theta)$** **又称为**参数$\theta$ 相对于样本集$X$ 的**似然函数**(likehood function)



为了求导方便，**对似然函数取对数**，使连乘变成连加，**就得到对数似然函数**：
$$
H(\theta) = \ln L(\theta) = \ln \prod^n_{i=1} p(x_i|\theta) = \sum^n_{i=1} p(x_i|\theta)
$$





## IRT Parameter Estimation using the EM Algorithm



**观测数据(Observed Data)**
$$
Y_{(N \times J)} = \begin{pmatrix}
y_{1,1} & y_{1,2} & \cdots & y_{1,J} \\
\vdots & \vdots   & \ddots & \vdots \\
y_{N,1} & y_{N,2} & \cdots & y_{N,J}
\end{pmatrix}
$$

- $N$ 个被试
- $J$ 道试题



$y_{i,j} = 1 \ \ \text{if 第i 被试答对第 j 道题}$ 

$y_{i,j} = 0 \ \ \text{if 第i 被试答错第 j 道题}$ 



**缺失数据(Missing Data)**



缺失数据是$N$ 个被试的**潜在能力**(unobserved latent)
$$
\theta = ( \theta_1, \theta_2, \cdots, \theta_N )
$$

- $\theta_i$ 是第$i$ 个被试的能力
- real numbers (**latent trait models**) or categories (**latent class models**).



**完全数据(Complete Data)**



完全数据是每一个被试的**观测数据加上缺失数据**
$$
[(y_1,\theta_1), (y_2,\theta_2), \cdots,(y_N,\theta_N),]
$$

- 每个被试的**答题数据加上自已的能力**








































































CTT的核心概念——信度，无法计算，这是最致命的



心理测量只是测量了一个**人对测验项目所进行的行为反应**，从而间接了解人的心理属性



**测评的本质是什么？是把不同人在同一个度量空间里区分开来**。运用IRT自适应的算法，**每个人虽然做的题目不一样**（由前一道题的答题情况决定下一道题测什么），但是测出来的知识点掌握程度是可以比较的。



IRT可以说是心理测量界的一次革命，也正是因为IRT理论的存在，SAT、ACT、雅思、托业等考试才能做到一年多次考试（其中的玄机在于**IRT等值和基于IRT的自适应测验**），同时，运用IRT的非认知测验（例如人格等），也在**处理自比数据和抵抗作假**等方面成果卓越。



假设考生在考试时**对试题的反应受某种心理潜在特质支配**，通过某种方法**估计这种心理潜在特质**

- 通过估计得到的是心理潜在特质的**观测值或观察分数**

- **真分数** = 观察分数 + 误差分数



**潜在特质空间**(能力空间)
$$
H = (\theta_1 \ \theta_2, \cdots , \ \theta_k)
$$


**双参数二级计分模型的参数估计**



试题作答正确概率为$P$：
$$
P = \frac{e^{a \theta  + b}}{ 1 + e^{a \theta  + b} }
$$

> $\theta$ 是潜在特质
>
> $z = a \theta  + b$，$z$ 是潜在特质的线性变换
>
> $a$ 是区分度（或斜率）
>
> $b$ 是阈值（或截距）
>
> $- \frac{b}{a}$ 是难度（或通俗度）



$a = 1$ 时，P函数就是**Rasch函数**

> - **如果能力和问题的难度一样，正确率是 .50**



自适应组卷

> GMAT和GRE都是自适应考试，所谓自适应考试的意思就是，当你做完了第一道题之后，系统会跟根据你这一道题回答的情况，来决定你下一道题的难度。如果你这一题答对了，那么，系统就会认为你的水平比较高，下一道题的难度就会相应高一些；如果你一直答对，你越做到后面，题目的难度就越高。相对应的，如果你这一题的答案答错了，系统就会认为你的水平稍微菜一点，那么下一题的难度，就会相对应的低一些，如果你一直答错，难度就会一直降低。当然了，因为每一题的难度系数不同，所以，分值也不一样。如果你答的题，难度系数都比较高，虽然你错的题目的数量会相对多一些，但是，你的总分可能并不低，因为，你做的全是很有难度的题。同理，如果你答的题，难度系数都很低，虽然你答对的题目数量很多，但总分可能并不高，因为，你答对的，都是一些很简单的题。

![image-20201118142656736](项目反应理论.assets/image-20201118142656736.png)





选择**与人的能力相匹配的题目**

> 题目能力与考生能力匹配



**计算机自适应测验的优势**

> 高能力考生无须回答过多的简单题，低能力考生也无须回答太多难题，通过较少题目就能对考生的能力水平做出有效的测量



**基于知识图谱的自适应推荐系统**

> 1. **减少刷题数量**
> 2. **明确刷题优先级**：尽量去掉无效刷题时间，并进一步提高学习效率
> 3. 知识点的掌握程度的定量测评





题目的覆盖面，能覆盖多少能力范围的学生

衡量哪些试题是不是没起到太大的作用，完全被其他试题覆盖了。我们就可以尝试删去这些没啥评价能力的试题



抽题具体方法
a分层将测验分为n个阶段,从每个阶段抽出若干道试题,其中第一阶段是依据难度随机抽题,不计算被试特质,其他阶段依据被试特质估计值进行抽题
第一阶段的抽题策略是:假如第一阶段需要抽出5道题,则依据难度大小把第一层次的试题分成5份,然后从这五份子试题池中抽出5道题, 从而保证随机抽题的难度均匀分布,避免发生所抽试题太简单或太难
其他阶段的抽题策略是:首先计算被试的特质估计值,依据估计值,寻找估计值与试题难度值差值绝对值最小的30道题,这30道题形成一个子试题池, 计算这30道题的总共使用次数,然后计算每道题的使用次数与总共使用次数之比,以及信息函数值, 计算前者与后者的比值, 最后抽出比值最小的题. 这样抽题的好处一个是计算上节省资源,不用计算每道题的信息函数,只需计算试题池中的题目, 既考虑了测验效率又降低了试题曝光率
参数估计方法
极大后验均值估计(MAP)

极大后验均值估计与其他流行方法比较
相比极大似然估计(MLE),极大后验均值估计对初值不敏感, 估计也比较稳健
相比期望后验均值(EAP), 极大后验均值的计算速度要慢了一倍(python的for循环非常耗时)...
经10000测试数据(每个数据包含10道题)检验, CORE M 0.8g的CPU下, 期望后验均值的时间是大约是2.4秒, 极大后验均值的时间大约是6秒





## 经典测量理论CTT

经典测量理论（Classical Test Theory，简称CTT）发端于100年前



只关心总得分，单维度

#### 仅仅以试卷总得分代表考生的能力，无法区分相同成绩考生的能力

1. 一个考生成绩越高，说明他的能力越高
2. 全体考生成绩越高，说明测验越简单



## 项目反应理论（IRT）

项目反应理论也称潜在特质理论

在测验中，**潜在特质一般是指潜在的能力**



IRT有三条基本假设，一是单维性，二是局部独立性，三是**项目反应函数假设**，但其实前两条假设可有可无（例如mirt理论打破了单维性假设，题组反应理论打破了局部独立性假设），核心的是第三个假设





答对10道难度为1的题目，获得的能力值依然是1，另一考生答对1道难度为8的题目，能力值则为8

> 低能力者很难再通过重复做对简单题拿到高分
>
> 感觉做对了题还不给分，是不是有猫腻啊？你说题目难就难，做对得分就高？我还觉得不难呢！



SAT, TOFEL, GRE等考试都是**以项目反应理论为基础构建的测验**，通过考生答对的题目的难度来确定考生的能力



**Rasch模型**就描述了考生能力、题目难度与考生是否答对之间的关系

> θ 代表考生能力，b 代表题目难度，P（θ）代表能力为θ 的考生在该题目上作答正确的概率



**根据每个学生的做答反应模式，来估算每个学生的能力值。但项目反应理论能估算每道试题的参数，比如试题的难度，区分度，猜测度等**



[如何通俗的理解项目反应理论？](https://www.zhihu.com/question/24671541)





以往的测验中（经典测量理论CTT），考试成绩就代表了某个考生的能力，考生成绩越高，说明其能力越高；群体得分也代表的某次测验的难易程度，整体得分越高，说明测验越简单。

容易发现，这种测量方式并不准确，成绩相同的考生能力真的相同吗？

不同的群体参加测验得到的分数不同，那怎样根据群体得分确定测验难度呢？

为了解决以往测验的问题，项目反应理论（IRT）不再简单的以试卷总得分代表考生的能力，只有考生答对了高能力才能答对的较难的题目时，才认为考生具有较高的能力。

也就是说，考生答对的题目难度是判断考生能力的标准。某考生答对10道难度为1的题目，获得的能力值依然是1，另一考生答对1道难度为8的题目，能力值则为8。

项目反应理论（IRT）构建了一整套数学模型来描述考生能力、题目特性与考生作答之间的关系，例如最基本的IRT模型—Rasch模型就描述了考生能力、题目难度与考生是否答对之间的关系





其中θ代表考生能力，b代表题目难度，P（θ）代表能力为θ的考生在该题目上作答正确的概率。根据该模型作图如下：横轴代表考生能力；纵轴代表正确作答概率。蓝色曲线的含义是，能力越高的考生作答正确的概率越高。（那题目难度体现在哪里呢？我们看原始公式中，当考生能力θ等于题目难度b时，P值为0.5。IRT中难度的定义就是考生答对概率为0.5时，对应的能力值。在这里可以看出这道题的难度基本是0。）

当然还有其他很多更复杂的模型适用于更精确的测量不同的题型，SAT, TOFEL, GRE等考试都是以项目反应理论为基础构建的测验，通过考生答对的题目的难度来确定考生的能力。

如果以后我国推行基于IRT的测验，能力高低会测量的更精确，低能力者很难再通过重复做对简单题拿到高分了。实际上这是更加公平的，不过对于这种测验方式，很多人还是很难接受，因为不了解背后的测量理论的科学性，就会感觉做对了题还不给分，是不是有猫腻啊？你说题目难就难，做对得分就高？我还觉得不难呢！







