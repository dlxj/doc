{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "auto_grad.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYx9V1iMADwP"
      },
      "source": [
        "# https://jax.readthedocs.io/en/latest/notebooks/autodiff_cookbook.html\n",
        "# https://jax.readthedocs.io/en/latest/jax.html#jax.jacfwd   grad 只能对标量求导，jacfwd 对向量 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4a-cg0D_uWg",
        "outputId": "e4014d55-1e86-4416-c7b7-5a3720e7ef2d"
      },
      "source": [
        "\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# from torch import tensor\n",
        "\n",
        "# from torch.autograd.functional import jacobian\n",
        "# from torch.functional import Tensor\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap\n",
        "from jax import random\n",
        "\n",
        "key = random.PRNGKey(0)\n",
        "\n",
        "\n",
        "# def exp_reducer(x):\n",
        "#     return x.exp() # .sum(dim=1)\n",
        "\n",
        "# inputs =  Tensor( [ [1, 2], [3, 4] ] ) # torch.rand(2, 2)\n",
        "# outputs = exp_reducer(inputs)\n",
        "\n",
        "# ja = jacobian(exp_reducer, inputs)\n",
        "\n",
        "\n",
        "w = jax.random.uniform(key, shape=(2, 2))   # 2*2 权重\n",
        "\n",
        "x = jnp.array(\n",
        "    [ [0, 0], \n",
        "      [0, 1] ]\n",
        "    ) \n",
        "\n",
        "b = jax.random.uniform(key, shape=(2, 2))   # 2*2 偏置\n",
        "\n",
        "def forword(w):\n",
        "\n",
        "    # 前向传播 (2,2) . (2,2) = (2,2)\n",
        "\n",
        "    a = x.dot( w ) + b\n",
        "\n",
        "    #a = np.dot(x, w) + b \n",
        "\n",
        "    return a\n",
        "\n",
        "# grad_forword = grad(forword) # grad 只能对标量求导\n",
        "\n",
        "grad_forword = jax.jacfwd(forword)  # column-by-column\n",
        "  # jacrev is row-by-row\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print( grad_forword(w) )\n",
        "\n",
        "#ja = jacobian(forword, w)\n",
        "\n",
        "#print(ja)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[0. 0.]\n",
            "   [0. 0.]]\n",
            "\n",
            "  [[0. 0.]\n",
            "   [0. 0.]]]\n",
            "\n",
            "\n",
            " [[[0. 0.]\n",
            "   [1. 0.]]\n",
            "\n",
            "  [[0. 0.]\n",
            "   [0. 1.]]]]\n"
          ]
        }
      ]
    }
  ]
}