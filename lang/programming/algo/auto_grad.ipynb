{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "auto_grad.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOsDvGgIwgyB",
        "outputId": "dacfdb88-9483-4ee3-c66a-bb13c4ff6ad5"
      },
      "source": [
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap\n",
        "from jax import random\n",
        "\n",
        "key = random.PRNGKey(0)\n",
        "\n",
        "\n",
        "w = jax.random.uniform(key, shape=(2, 2))   # 2*2 权重\n",
        "\n",
        "b = jax.random.uniform(key, shape=(2, 2))   # 2*2 偏置\n",
        "\n",
        "x = jnp.array(\n",
        "    [ [11, 12], \n",
        "      [21, 22] ]\n",
        "    ) \n",
        "\n",
        "p =  jnp.array(\n",
        "    [ [1, 0], \n",
        "      [0, 1] ]\n",
        "    ) \n",
        "\n",
        "def A(x, w, b):\n",
        "  x11 = x[0][0]\n",
        "  x12 = x[0][1]\n",
        "  x21 = x[1][0]\n",
        "  x22 = x[1][1]\n",
        "\n",
        "  w11 = w[0][0]\n",
        "  w12 = w[0][1]\n",
        "  w21 = w[1][0]\n",
        "  w22 = w[1][1]\n",
        "\n",
        "  b11 = b[0][0]\n",
        "  b12 = b[0][1]\n",
        "  b21 = b[1][0]\n",
        "  b22 = b[1][1]\n",
        "\n",
        "  a11 = x11*w11 + x12*w21 + b11\n",
        "\n",
        "  a12 = x11*w12 + x12*w22 + b12\n",
        "\n",
        "  a21 = x21*w11 + x22*w21 + b21\n",
        "\n",
        "  a22 = x21*w12 + x22*w22 + b22\n",
        "\n",
        "  a = ( (a11, a12), (a21, a22) )\n",
        "\n",
        "  return a\n",
        "\n",
        "\n",
        "jac_w = jax.jacfwd(lambda xx: A(x, xx, b) )(w)  # A 对w 的偏导（雅可比矩阵）\n",
        "jac_b = jax.jacfwd(lambda xx: A(x, w, xx) )(b) \n",
        "\n",
        "\n",
        "print(jac_w)\n",
        "print(jac_b)\n",
        "\n",
        "#a = A(x, w, b)\n",
        "\n",
        "#print(a)\n",
        "\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((DeviceArray([[11.,  0.],\n",
            "             [12.,  0.]], dtype=float32), DeviceArray([[ 0., 11.],\n",
            "             [ 0., 12.]], dtype=float32)), (DeviceArray([[21.,  0.],\n",
            "             [22.,  0.]], dtype=float32), DeviceArray([[ 0., 21.],\n",
            "             [ 0., 22.]], dtype=float32)))\n",
            "((DeviceArray([[1., 0.],\n",
            "             [0., 0.]], dtype=float32), DeviceArray([[0., 1.],\n",
            "             [0., 0.]], dtype=float32)), (DeviceArray([[0., 0.],\n",
            "             [1., 0.]], dtype=float32), DeviceArray([[0., 0.],\n",
            "             [0., 1.]], dtype=float32)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMdLbLsH6BVW",
        "outputId": "a02fe51f-22ed-4bec-931f-6c726b2d922a"
      },
      "source": [
        "# https://www.geeksforgeeks.org/jacobian-matrix-in-pytorch/\n",
        "from torch.autograd.functional import jacobian\n",
        "from torch import tensor\n",
        " \n",
        "#Defining the main function\n",
        "def f(x1,x2,x3):\n",
        "    return (x1 + x2, x3*x1, x2**3)\n",
        " \n",
        "#Defining input tensors\n",
        "x1 = tensor(3.0)\n",
        "x2 = tensor(4.0)\n",
        "x3 = tensor(5.0)\n",
        " \n",
        "#Printing the Jacobian\n",
        "print(jacobian(f,(x1,x2,x3)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "((tensor(1.), tensor(1.), tensor(0.)), (tensor(5.), tensor(0.), tensor(3.)), (tensor(0.), tensor(48.), tensor(0.)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdAyTff6D1-a",
        "outputId": "34cf9c23-dfff-4eb0-f164-959bcbaea95d"
      },
      "source": [
        "from torch.autograd.functional import jacobian\n",
        "from torch import tensor\n",
        " \n",
        "#Defining the main function\n",
        "def f(x):\n",
        "    return (x[0]+ x[1], x[2]*x[0], x[1]**3)\n",
        " \n",
        "#Defining input tensors\n",
        "x1 = tensor(3.0)\n",
        "x2 = tensor(4.0)\n",
        "x3 = tensor(5.0)\n",
        "\n",
        "x  = tensor( [3., 4. , 5.] )\n",
        " \n",
        "#Printing the Jacobian\n",
        "print(jacobian(f,x ))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([1., 1., 0.]), tensor([5., 0., 3.]), tensor([ 0., 48.,  0.]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8opmTVy6lKh",
        "outputId": "188418c5-bddf-4beb-9064-3ed3051071a6"
      },
      "source": [
        "# https://github.com/google/jax/issues/47\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap\n",
        "from jax import random\n",
        "\n",
        "def f(x1,x2,x3):\n",
        "    return (x1 + x2, x3*x1, x2**3)\n",
        "\n",
        "x1 = 3.\n",
        "x2 = 4.\n",
        "x3 = 5.\n",
        "\n",
        "jac_x1 = jax.jacfwd(lambda x: f(x,x2,x3))(x1)\n",
        "jac_x2 = jax.jacfwd(lambda x: f(x1,x,x3))(x2)\n",
        "jac_x3 = jax.jacfwd(lambda x: f(x1,x2,x))(x3)\n",
        "\n",
        "print(jac_x1)\n",
        "\n",
        "#print(jac_x2)\n",
        "\n",
        "#print(jac_x3)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(DeviceArray(1., dtype=float32), DeviceArray(5., dtype=float32), DeviceArray(0., dtype=float32))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EPXZvgzQ_SGa",
        "outputId": "c428d146-6758-4c54-c606-413c6b003785"
      },
      "source": [
        "\n",
        "from torch.autograd.functional import jacobian\n",
        "from torch import tensor\n",
        "import torch\n",
        "\n",
        "import numpy\n",
        "\n",
        "x = tensor(\n",
        "    [ [11, 12], \n",
        "      [21, 22] ]\n",
        "    ) \n",
        "\n",
        "w = tensor( numpy.random.uniform(key, size=(2, 2)) )   # 2*2 权重\n",
        "b = ( numpy.random.uniform(key, size=(2, 2)) )   # 2*2 偏置\n",
        "\n",
        "\n",
        "def A(w):\n",
        "  with torch.no_grad():\n",
        "    return tensor( numpy.dot( x, w ) + b )\n",
        "\n",
        "print(jacobian(A, w))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[0., 0.],\n",
            "          [0., 0.]],\n",
            "\n",
            "         [[0., 0.],\n",
            "          [0., 0.]]],\n",
            "\n",
            "\n",
            "        [[[0., 0.],\n",
            "          [0., 0.]],\n",
            "\n",
            "         [[0., 0.],\n",
            "          [0., 0.]]]], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMpvblx3CQsp",
        "outputId": "e51eeba5-959b-441b-d282-24fe6842ec6b"
      },
      "source": [
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap\n",
        "from jax import random\n",
        "\n",
        "key = random.PRNGKey(0)\n",
        "\n",
        "\n",
        "w = jax.random.uniform(key, shape=(2, 2))   # 2*2 权重\n",
        "\n",
        "b = jax.random.uniform(key, shape=(2, 2))   # 2*2 偏置\n",
        "\n",
        "x = jnp.array(\n",
        "    [ [11, 12], \n",
        "      [21, 22] ]\n",
        "    ) \n",
        "\n",
        "p =  jnp.array(\n",
        "    [ [1, 0], \n",
        "      [0, 1] ]\n",
        "    ) \n",
        "\n",
        "def A(w, b):\n",
        "  return x.dot( w ) + b\n",
        "\n",
        "\n",
        "jac_w = jax.jacfwd(lambda x: A(x, b))(w)\n",
        "jac_b = jax.jacfwd(lambda x: A(w, x))(b)\n",
        "\n",
        "\n",
        "print(jac_w)\n",
        "\n",
        "\n",
        "# print(jac_b)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[11.  0.]\n",
            "   [12.  0.]]\n",
            "\n",
            "  [[ 0. 11.]\n",
            "   [ 0. 12.]]]\n",
            "\n",
            "\n",
            " [[[21.  0.]\n",
            "   [22.  0.]]\n",
            "\n",
            "  [[ 0. 21.]\n",
            "   [ 0. 22.]]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTbkQD-EyzTM"
      },
      "source": [
        "\"\"\"\n",
        "{\n",
        " {\n",
        " {\n",
        "{11. ,0.},\n",
        "{12. , 0.}\n",
        "},\n",
        "{\n",
        "\t{0., 11.},\n",
        "\t{0. ,12.}\n",
        " }\n",
        "} // MatrixForm  ,\n",
        "{\n",
        "  {\n",
        "{21. ,0.},\n",
        "{22., 0.}\n",
        "},\n",
        "{\n",
        "\t{0., 21.},\n",
        "\t{0. ,22.}\n",
        "}\n",
        "} //MatrixForm\n",
        "} // MatrixForm\n",
        "\n",
        "\n",
        "In[24]:= x = {{x11, x12},{x21, x22}}; x//MatrixForm\n",
        "w = {{w11,w12}, {w21, w22}}; w//MatrixForm\n",
        "Out[24]//MatrixForm= (x11\tx12\n",
        "x21\tx22\n",
        "\n",
        ")\n",
        "Out[25]//MatrixForm= (w11\tw12\n",
        "w21\tw22\n",
        "\n",
        ")\n",
        "In[28]:= a =x.w; a//MatrixForm\n",
        "Out[28]//MatrixForm= (w11 x11+w21 x12\tw12 x11+w22 x12\n",
        "w11 x21+w21 x22\tw12 x21+w22 x22\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUVcOUFXoREz"
      },
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap\n",
        "from jax import random\n",
        "\n",
        "key = random.PRNGKey(0)\n",
        "\n",
        "\n",
        "w = jax.random.uniform(key, shape=(2, 2))   # 2*2 权重\n",
        "\n",
        "x = jnp.array(\n",
        "    [ [0, 0], \n",
        "      [0, 1] ]\n",
        "    ) \n",
        "\n",
        "p =  jnp.array(\n",
        "    [ [1, 0], \n",
        "      [0, 1] ]\n",
        "    ) \n",
        "\n",
        "# print( jnp.log( p ) )\n",
        "\n",
        "#b = jax.random.uniform(key, shape=(2, 2))   # 2*2 偏置\n",
        "\n",
        "\n",
        "def forword(w, b):\n",
        "  a = x.dot( w ) + b\n",
        "  q = jnp.exp(a - jnp.max(a))\n",
        "  \n",
        "  delta = 1e-7\n",
        "  tmp = -1 * p * ( jnp.log( q + delta ) )\n",
        "  e = jnp.sum(tmp, axis=1)\n",
        "  return e.sum() * 0.5\n",
        "\n",
        "\n",
        "#grad_forword = jax.jacfwd(forword)  # column-by-column\n",
        "  # jacrev is row-by-row\n",
        "\n",
        "\n",
        "\n",
        "for i in range(10000):\n",
        "\n",
        "  #jac_w = grad_forword(w)\n",
        "  #jac_b = grad_forword2(b)\n",
        "\n",
        "  jac_w = jax.jacfwd(lambda x: forword(x, b))(w)\n",
        "  jac_b = jax.jacfwd(lambda x: forword(w, x))(b)\n",
        "  \n",
        "  loss = forword(w, b)\n",
        "\n",
        "  w = w - 0.01 * jac_w\n",
        "  b = b - 0.01 * jac_b\n",
        "\n",
        "  #print(loss)\n",
        "  #print(jac_w)\n",
        "\n",
        "  #if i == 9999:\n",
        "  print(loss)\n",
        "\n",
        "\n",
        "a = x.dot( w ) + b\n",
        "q = jnp.exp(a - jnp.max(a))\n",
        "\n",
        "print(p)\n",
        "print(q)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYx9V1iMADwP"
      },
      "source": [
        "# https://jax.readthedocs.io/en/latest/notebooks/autodiff_cookbook.html\n",
        "# https://jax.readthedocs.io/en/latest/jax.html#jax.jacfwd   grad 只能对标量求导，jacfwd 对向量 \n",
        "\n",
        "# https://stackoverflow.com/questions/63559139/efficient-way-to-compute-jacobian-x-jacobian-t\n",
        "\n",
        "# Cross entropy  chain rule\n",
        "\n",
        "\n",
        "# https://deepnotes.io/softmax-crossentropy\n",
        "\n",
        "# https://mathematica.stackexchange.com/questions/5790/how-to-make-jacobian-automatically-in-mathematica\n",
        "\n",
        "# https://www.geeksforgeeks.org/jacobian-matrix-in-pytorch/\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4a-cg0D_uWg",
        "outputId": "136a45da-693b-4821-b138-b03d211845d3"
      },
      "source": [
        "\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# from torch import tensor\n",
        "\n",
        "# from torch.autograd.functional import jacobian\n",
        "# from torch.functional import Tensor\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap\n",
        "from jax import random\n",
        "\n",
        "key = random.PRNGKey(0)\n",
        "\n",
        "\n",
        "# def exp_reducer(x):\n",
        "#     return x.exp() # .sum(dim=1)\n",
        "\n",
        "# inputs =  Tensor( [ [1, 2], [3, 4] ] ) # torch.rand(2, 2)\n",
        "# outputs = exp_reducer(inputs)\n",
        "\n",
        "# ja = jacobian(exp_reducer, inputs)\n",
        "\n",
        "\n",
        "w = jax.random.uniform(key, shape=(2, 2))   # 2*2 权重\n",
        "\n",
        "x = jnp.array(\n",
        "    [ [0, 0], \n",
        "      [0, 1] ]\n",
        "    ) \n",
        "\n",
        "p =  jnp.array(\n",
        "    [ [1, 0], \n",
        "      [0, 1] ]\n",
        "    ) \n",
        "\n",
        "# print( jnp.log( p ) )\n",
        "\n",
        "b = jax.random.uniform(key, shape=(2, 2))   # 2*2 偏置\n",
        "\n",
        "def forword(w):\n",
        "\n",
        "    # 前向传播 (2,2) . (2,2) = (2,2)\n",
        "\n",
        "    a = x.dot( w ) + b\n",
        "\n",
        "    return a\n",
        "\n",
        "def stable_softmax(X):\n",
        "    exps = jnp.exp(X - jnp.max(X))\n",
        "    return exps / jnp.sum(exps)\n",
        "\n",
        "def crossELoss(q):\n",
        "    delta = 1e-7\n",
        "    tmp = -1 * p * ( jnp.log( q + delta ) )\n",
        "    e = jnp.sum(tmp, axis=1)\n",
        "    return e.sum() * 0.5\n",
        "\n",
        "# grad_forword = grad(forword) # grad 只能对标量求导\n",
        "\n",
        "grad_forword = jax.jacfwd(forword)  # column-by-column\n",
        "  # jacrev is row-by-row\n",
        "\n",
        "grad_softmax = jax.jacfwd(stable_softmax) \n",
        "\n",
        "grad_crossE = jax.jacfwd(crossELoss) \n",
        "\n",
        "jac_w = grad_forword(w)\n",
        "\n",
        "a = forword(w)\n",
        "\n",
        "jac_a = grad_softmax(a)\n",
        "\n",
        "q = stable_softmax(a)\n",
        "\n",
        "\n",
        "jac_q = grad_crossE(q)\n",
        "\n",
        "e = crossELoss(q)\n",
        "\n",
        "print( e )\n",
        "\n",
        "#ja = jacobian(forword, w)\n",
        "\n",
        "#print(ja)\n",
        "\n",
        "print(jac_w.shape)\n",
        "\n",
        "print(jac_a.shape)\n",
        "\n",
        "print(jac_q.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.4438475\n",
            "(2, 2, 2, 2)\n",
            "(2, 2, 2, 2)\n",
            "(2, 2)\n"
          ]
        }
      ]
    }
  ]
}