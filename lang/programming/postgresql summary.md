## Install PG

```
systemctl start postgresql.service  # ubuntu 18.04 
systemctl status postgresql-13      # centos7

pm2 save
pm2 dump // æ­¤æ—¶ä¼šå¤‡ä»½ pm2 list ä¸­çš„æ‰€æœ‰é¡¹ç›®å¯åŠ¨æ–¹å¼
pm2 resurrect // é‡å¯å¤‡ä»½çš„æ‰€æœ‰é¡¹ç›®
```



```
# alma linux 8
# https://www.postgresql.org/download/linux/redhat/
cat /etc/os-release && \
dnf -y install https://download.postgresql.org/pub/repos/yum/reporpms/EL-8-x86_64/pgdg-redhat-repo-latest.noarch.rpm && \
dnf -qy module disable postgresql && \
dnf -y install postgresql13 postgresql13-server

systemctl restart postgresql-13

vi /etc/environment
LANG=en_US.utf-8
LC_ALL=en_US.utf-8

vi /etc/environment
LANG=en_US.utf-8
LC_ALL=en_US.utf-8
	# æ·»åŠ è¿™ä¸¤é¡¹ 

source /etc/environment

export LANG="en_US.utf-8" && \
export LC_ALL="en_US.utf-8"

echo "LC_ALL=en_US.UTF-8" >> /etc/environment
echo "en_US.UTF-8 UTF-8" >> /etc/locale.gen
echo "LANG=en_US.UTF-8" > /etc/locale.conf
locale-gen en_US.UTF-8
	# ubuntu only

dnf install glibc-all-langpacks
localectl set-locale LANG=en_US.utf-8
	localectl set-locale LANG=en_US.utf8@ampm
		# æˆåŠŸ
		
en_US.utf8
en_US.utf8@ampm

echo "export LC_ALL=en_US.utf8@ampm" >> /etc/profile

source /etc/profile

locale -a

/usr/pgsql-13/bin/postgresql-13-setup initdb && \
cat /var/lib/pgsql/13/initdb.log && \
cat /var/lib/pgsql/13/data/postgresql.conf




```



### AlmaLinux 9.3

```

cat /etc/redhat-release

AlmaLinux release 9.3 (Shamrock Pampas Cat)


# Install the repository RPM:
sudo dnf install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-9-x86_64/pgdg-redhat-repo-latest.noarch.rpm

# Disable the built-in PostgreSQL module:
sudo dnf -qy module disable postgresql

# Install PostgreSQL:
sudo dnf install -y postgresql17-server

# Optionally initialize the database and enable automatic start:
sudo /usr/pgsql-17/bin/postgresql-17-setup initdb
sudo systemctl enable postgresql-17
sudo systemctl start postgresql-17


sudo -u postgres psql
select version();
\password postgres  # ä¿®æ”¹å¯†ç 
\q

postgres 	pt41
	# ç”¨æˆ·å å¯†ç 

psql -h 127.0.0.1 -p 5432 -U postgres
	# æˆåŠŸç™»å½•

mkdir /home/psqldata

chown -R postgres:postgres /home/psqldata



 systemctl stop postgresql-17

cp -R /var/lib/pgsql/17/data /home/psqldata   # åªèƒ½é€äº®æ¢æŸ±äº†

mv /var/lib/pgsql/17/data /var/lib/pgsql/17/data__link__to_home_psqldata

ln -s  /home/psqldata/data  /var/lib/pgsql/17/data
			# unlink å–æ¶ˆè½¯é“¾ç”¨è¿™ä¸ª

chown -R postgres:postgres /home/psqldata



systemctl start postgresql-17

systemctl status postgresql-17



# å…è®¸è¿ç¨‹è¿æ¥
vi /var/lib/pgsql/17/data/postgresql.conf
	listen_addresses = '*' # æ”¹æˆè¿™ä¸ª
vi /var/lib/pgsql/17/data/pg_hba.conf
hostnossl    all          all            0.0.0.0/0  md5  
	# hostnossl    all          all            0.0.0.0/0  trust  # ä»»ä½•å¯†ç éƒ½èƒ½è¿
	# åŠ åœ¨æœ€åé¢ï¼Œæ¥å—æ‰€æœ‰è¿œç¨‹IP


systemctl restart postgresql-17
systemctl status postgresql-17



yum groupinstall "Development Tools" && \
yum install llvm-toolset-7-clang && \
yum install postgresql17-devel && \
yum install postgresql17-contrib && \
yum install systemtap-sdt-devel


git clone https://github.com/postgrespro/rum && \
cd rum && \
export PATH=$PATH:/usr/pgsql-17/bin/ && \
make USE_PGXS=1 && \
make USE_PGXS=1 install

make USE_PGXS=1 installcheck && \
psql DB -c "CREATE EXTENSION rum;"



CREATE TABLE IF NOT EXISTS test_vector (
    ID integer generated always as identity,
    AppID integer NOT NULL,
    TestID integer NOT NULL,
    ChildTableID integer NOT NULL,
    S_Test text NOT NULL,
    V_Test tsvector,
    Enabled boolean,
    UNIQUE(ID),  
    PRIMARY KEY (AppID, TestID, ChildTableID) 
);

CREATE INDEX idx_appid ON test_vector (AppID);



```



### Ubuntu 22.04

```

# see huggingface/NLPP_Audio/vector.py

proxychains4 apt install -y postgresql-common && 
proxychains4 (sleep 1; echo "\n";) | bash /usr/share/postgresql-common/pgdg/apt.postgresql.org.sh

proxychains4 (sleep 1; echo "Y";) | apt install curl ca-certificates &&
install -d /usr/share/postgresql-common/pgdg && 
curl -o /usr/share/postgresql-common/pgdg/apt.postgresql.org.asc --fail https://www.postgresql.org/media/keys/ACCC4CF8.asc




sudo sh -c 'echo "deb [signed-by=/usr/share/postgresql-common/pgdg/apt.postgresql.org.asc] https://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main" > /etc/apt/sources.list.d/pgdg.list'

proxychains4 apt update && 
proxychains4 apt -y install postgresql-17 postgresql-server-dev-17 libpq-dev postgresql-contrib 



/etc/postgresql/17/main/pg_hba.conf

sudo -u postgres psql -c "ALTER USER postgres WITH PASSWORD 'post4321';"


sudo -u postgres psql
select version();
\password postgres  # ä¿®æ”¹å¯†ç 
\q

postgres 	pt41
	# ç”¨æˆ·å å¯†ç 

psql -h 127.0.0.1 -p 5432 -U postgres
	# æˆåŠŸç™»å½•


echo 'hostnossl    all          all            0.0.0.0/0  md5' >> /etc/postgresql/17/main/pg_hba.conf
	# >> è¡¨ç¤ºè¿½åŠ åœ¨æœ€å

# å…è®¸è¿ç¨‹è¿æ¥
vi /etc/postgresql/17/main/pg_hba.conf
hostnossl    all          all            0.0.0.0/0  md5  
	# hostnossl    all          all            0.0.0.0/0  trust  # ä»»ä½•å¯†ç éƒ½èƒ½è¿
	# åŠ åœ¨æœ€åé¢ï¼Œæ¥å—æ‰€æœ‰è¿œç¨‹IP

#local   all             postgres                                peer
local   all             postgres                                password
	# æ”¹æˆè¿™æ ·

see huggingface/NLPP_vector_server/Dockerfile
	# sed -i 's/\(local[[:space:]]\+all[[:space:]]\+postgres[[:space:]]\+\)peer/\1password/' /etc/postgresql/17/main/pg_hba.conf 
	# èƒ½è‡ªåŠ¨ä¿®æ”¹æˆåŠŸ

PGPASSWORD=post4321 psql -U postgres  -c "SELECT pg_reload_conf()"
	# èƒ½æ‰§è¡ŒæˆåŠŸçš„å‰ææ˜¯ä¸Šä¸€è¡Œæ”¹å¥½äº†


pg_ctlcluster 17 main restart
pg_ctlcluster 17 main status
	# æˆåŠŸé‡å¯
	# ä½†æ˜¯åœ¨ docker ä¸­ä¸çŸ¥é“æ€ä¹ˆè¿è¡Œå®ƒ

systemctl restart postgresql


http://ï½˜ï½˜.ï½˜ï½˜.ï½˜ï½˜.57:7851/wsproxy/admin
	# ali57 æ·»åŠ è¿œç¨‹ç«¯å£  54322 è½¬åˆ°ã€€wsl2 5432




// https://github.com/pgvector/pgvector å…ˆå®‰è£…

proxychains4 apt install postgresql-17-pgvector
	# å®‰è£…å‘é‡æ’ä»¶

git clone https://github.com/postgrespro/rum && 
cd rum &&
make USE_PGXS=1 PG_CONFIG=/usr/bin/pg_config &&
make USE_PGXS=1 PG_CONFIG=/usr/bin/pg_config install
$ psql DB -c "CREATE EXTENSION rum;
	# å®‰è£…ã€€RUM æ’ä»¶


CREATE DATABASE nlppvector
WITH OWNER = postgres 
ENCODING = 'UTF8' 
TABLESPACE = pg_default 
CONNECTION LIMIT = -1 
TEMPLATE template0;

CREATE EXTENSION IF NOT EXISTS rum;
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS pgroonga;
CREATE TABLE IF NOT EXISTS nlpp_vector (
    ID bigint generated always as identity (START WITH 1 INCREMENT BY 1), 
    JPMD5 CHAR(32) NOT NULL,
    name text NOT NULL,
    S_JP text NOT NULL,
    V_JP vector(1536) NOT NULL,
    S_CN text DEFAULT '' NOT NULL,
    S_EN text DEFAULT '' NOT NULL,
    metadata jsonb NOT NULL,
    AddTime timestamp DEFAULT CURRENT_TIMESTAMP,
    UpdateTime timestamp DEFAULT NULL,
    Enabled boolean DEFAULT '1',
    UNIQUE(ID),  
    PRIMARY KEY (JPMD5, name) 
);
CREATE INDEX IF NOT EXISTS index_pgvector_VJP ON nlpp_vector USING hnsw (V_JP vector_cosine_ops);
CREATE INDEX IF NOT EXISTS index_pgroonga_SJP ON nlpp_vector USING pgroonga (S_JP);



mkdir /home/psqldata

chown -R postgres:postgres /home/psqldata

```



```

# see huggingface/NLPP_Audio/vector.py

proxychains4 pip install --upgrade pip && 
proxychains4 pip install "psycopg[binary]"  


proxychains4 apt install postgresql-17-pgvector
	# å®‰è£…å‘é‡æ’ä»¶

git clone https://github.com/postgrespro/rum && 
cd rum &&
make USE_PGXS=1 PG_CONFIG=/usr/bin/pg_config &&
make USE_PGXS=1 PG_CONFIG=/usr/bin/pg_config install &&
make USE_PGXS=1 installcheck &&
$ psql DB -c "CREATE EXTENSION rum;
	# å®‰è£…  RUM æ’ä»¶

# see https://pgroonga.github.io/install/ubuntu.html
proxychains4 apt install -y software-properties-common && 
proxychains4 add-apt-repository -y universe && 
proxychains4 add-apt-repository -y ppa:groonga/ppa &&
proxychains4 apt install -y wget lsb-release && 
proxychains4 wget https://packages.groonga.org/ubuntu/groonga-apt-source-latest-$(lsb_release --codename --short).deb && 
proxychains4 apt install -y -V ./groonga-apt-source-latest-$(lsb_release --codename --short).deb && 
echo "deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release --codename --short)-pgdg main" | sudo tee /etc/apt/sources.list.d/pgdg.list && 
proxychains4 wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - && 
proxychains4 apt update && 
proxychains4 apt install -y -V postgresql-17-pgdg-pgroonga && 
proxychains4 apt install -y -V groonga-tokenizer-mecab

CREATE EXTENSION pgroonga;
	# æˆåŠŸ

see https://pgroonga.github.io/tutorial/
    # ç”¨æ³•å¾ˆè¯¦ç»†

DROP DATABASE IF EXISTS nlppvector;
CREATE DATABASE nlppvector
WITH OWNER = postgres 
ENCODING = 'UTF8' 
TABLESPACE = pg_default 
CONNECTION LIMIT = -1 
TEMPLATE template0;
    # æ•´å®Œ nvcat é‡è¿ä¸€æ¬¡ï¼Œé€‰è¿™ä¸ªåº“å†è¿è¡Œä¸‹é¢çš„è¯­å¥

# see https://github.com/pgvector/pgvector  å„ç±»å‹å‘é‡çš„é•¿åº¦è¯´æ˜
CREATE EXTENSION IF NOT EXISTS rum;
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
DROP TABLE IF EXISTS nlpp_vector;
CREATE TABLE IF NOT EXISTS nlpp_vector (
    id bigint generated always as identity (START WITH 1 INCREMENT BY 1),
    guid uuid DEFAULT uuid_generate_v4(),
    name text NOT NULL,
    s_jp text NOT NULL,
    s_zh text NOT NULL,
    v_jp tsvector NOT NULL,
    v_zh tsvector NOT NULL,
    metadata jsonb NOT NULL,
    embed_jp vector(1024) NOT NULL,
    embed_zh vector(1024) NOT NULL,
    audio bytea DEFAULT NULL,
    image bytea DEFAULT NULL,
    addtime timestamp DEFAULT CURRENT_TIMESTAMP,
    updatetime timestamp DEFAULT NULL,
    enable boolean DEFAULT '1',
    UNIQUE(ID),
    PRIMARY KEY (GUID)
);
CREATE INDEX index_halfvec_embed_jp ON nlpp_vector USING hnsw (embed_jp vector_cosine_ops);
CREATE INDEX index_halfvec_embed_zh ON nlpp_vector USING hnsw (embed_zh vector_cosine_ops);
CREATE INDEX fts_rum_v_jp ON nlpp_vector USING rum (v_jp rum_tsvector_ops);
CREATE INDEX fts_rum_v_zh ON nlpp_vector USING rum (v_zh rum_tsvector_ops);
CREATE INDEX index_btree_name ON nlpp_vector (name);
CREATE INDEX index_btree_name_section ON nlpp_vector (name, (metadata->>'section'));
```





### å…å®‰è£…é…ç½®

```
Postgresqlå…å®‰è£…é…ç½®æ–¹æ³•
ä¸€ã€ä¸‹è½½
https://www.enterprisedb.com/download-postgresql-binaries
è¿›å…¥ç½‘å€ï¼Œé€‰æ‹©é€‚åˆè‡ªå·±ç³»ç»Ÿçš„ç‰ˆæœ¬

äºŒã€ä¸‹è½½å¥½çš„zipåŒ…è§£å‹ï¼Œå¹¶åˆ›å»ºä¸€ä¸ªdataæ–‡ä»¶ç”¨æ¥å­˜æ”¾æ•°æ®

ä¸‰ã€åˆå§‹åŒ–æ•°æ®åº“
å‘½ä»¤è¡Œè¿›å…¥binç›®å½•ï¼Œæ‰§è¡Œä»¥ä¸‹ä»£ç ï¼š

cd D:\usr\postgresql-13\pgsql\bin
./initdb.exe -D E:\pgsqldata -E UTF-8 --locale=chs -U postgres -W

./pg_ctl -D E:\pgsqldata -l logfile start

æ³¨ï¼š
-D ï¼šæŒ‡å®šæ•°æ®åº“ç°‡çš„å­˜å‚¨ç›®å½•D:\tools\postgres\pgsql\data
-E ï¼šæŒ‡å®šDBçš„è¶…çº§ç”¨æˆ·çš„ç”¨æˆ·åpostgres
â€“localeï¼šå…³äºåŒºåŸŸè®¾ç½®ï¼ˆchinese-simplified-chinaï¼‰
-U ï¼šé»˜è®¤ç¼–ç æ ¼å¼chs
-W ï¼šä¸ºè¶…çº§ç”¨æˆ·æŒ‡å®šå¯†ç çš„æç¤º
æ³¨ï¼šå‘½ä»¤ä¸Šçš„åœ°å€å¦‚æœè¾“å…¥é”™è¯¯ï¼Œå†æ¬¡æ‰§è¡Œå¯èƒ½æç¤ºä¸èƒ½ç»™dataæ–‡ä»¶å¤¹æƒé™ï¼Œåˆ é™¤dataé‡æ–°åˆ›å»ºå³å¯

å››ã€å¯åŠ¨æ•°æ®åº“

pg_ctl -D D:\tools\postgres\pgsql\data -l logfile start

äº”ã€æ³¨å†Œæˆç³»ç»ŸæœåŠ¡

pg_ctl register -N PostgreSQL -D D:\tools\postgres\pgsql\data
```



## supabase

https://supabase.com/docs/guides/self-hosting/docker#securing-your-services  é…ç½®é‡è¦çš„ key

https://console.cloud.tencent.com/lighthouse/instance

https://vonng.com/pigsty/v4.0/

https://pigsty.cc/docs/setup/install/

https://pigsty.cc/docs/app/supabase/

- ```
  Supabase å¾ˆå¥½ï¼Œæ‹¥æœ‰å±äºä½ è‡ªå·±çš„ supabase åˆ™å¥½ä¸ŠåŠ å¥½ã€‚ Pigsty å¯ä»¥å¸®åŠ©æ‚¨åœ¨è‡ªå·±çš„æœåŠ¡å™¨ä¸Šï¼ˆç‰©ç†æœº/è™šæ‹Ÿæœº/äº‘æœåŠ¡å™¨ï¼‰ï¼Œä¸€é”®è‡ªå»ºä¼ä¸šçº§ supabase â€”â€” æ›´å¤šæ‰©å±•ï¼Œæ›´å¥½æ€§èƒ½ï¼Œæ›´æ·±å…¥çš„æ§åˆ¶ï¼Œæ›´åˆç®—çš„æˆæœ¬ã€‚
  
  æ¨èä½¿ç”¨ RockyLinux 9.6ã€Debian 12.11 æˆ– Ubuntu 24.04.5 ä½œä¸ºé»˜è®¤æ“ä½œç³»ç»Ÿé€‰é¡¹
  
  
  
  ```





```

console.cloud.tencent.com
	# tencent æµ·å¤–äº‘æ§åˆ¶å°
	
https://lightsail.aws.amazon.com/
	# amazon æ§åˆ¶å°

http://xx.xx.xx.xx:3000
	ç‚¹è¿›å» Dashboards -> PGSQL -> Database
		# èƒ½çœ‹åˆ°ç°æœ‰æ•°æ®åº“å’Œå·²å®‰è£…æ’ä»¶


bash -c 'version=$(lsb_release -cs) && cp /etc/apt/sources.list /etc/apt/sources.list.bak && cat << EOF > /etc/apt/sources.list
deb http://archive.ubuntu.com/ubuntu/ $version main restricted universe multiverse
deb http://archive.ubuntu.com/ubuntu/ $version-updates main restricted universe multiverse
deb http://archive.ubuntu.com/ubuntu/ $version-backports main restricted universe multiverse
deb http://security.ubuntu.com/ubuntu/ $version-security main restricted universe multiverse
EOF' \
  && apt update

	# tencent æµ·å¤–äº‘ç”¨ 4G å†…å­˜


nmap 43.xxx.xxx.xx -p 8000
	# Supabase Studio å›¾å½¢ç®¡ç†ç•Œé¢
		http://xx.xx.xx.xx:8000
		
	

apt install -y ansible python3-jmespath
	# ubuntu 
	dnf install -y ansible python3.12-jmespath python3-cryptography
		# EL 8/9 ä¼ä¸šç‰ˆ
	# å¥½åƒä¸ç”¨ï¼Œä¸€é”®å®‰è£…å·²ç»æœ‰äº†


localedef -i en_US -f UTF-8 en_US.UTF-8 \
  && localectl set-locale LANG=en_US.UTF-8
  # å¼ºçƒˆå»ºè®® ä½¿ç”¨å…¨æ–°å®‰è£…çš„æ“ä½œç³»ç»Ÿç¯å¢ƒï¼Œå¹¶å°† en_US è®¾ç½®ä¸ºä¸»è¦è¯­è¨€
  

curl -fsSL https://repo.pigsty.io/get | bash; cd ~/pigsty  # æµ·å¤–
curl -fsSL https://repo.pigsty.cc/get | bash; cd ~/pigsty  # å›½å†…
./configure -c supabase    # ä½¿ç”¨ supabase é…ç½®ï¼ˆè¯·åœ¨ pigsty.yml ä¸­æ›´æ”¹å‡­æ®ï¼‰
vi pigsty.yml              # ç¼–è¾‘åŸŸåã€å¯†ç ã€å¯†é’¥...
	# å‰é¢é‚£å‘½ä»¤è¿è¡Œå®Œå†æ”¹å¯†ç ï¼Œå› ä¸ºä¼šè¢«è¦†ç›–
./deploy.yml              # å®‰è£… pigsty
./docker.yml               # å®‰è£… docker compose ç»„ä»¶
./app.yml                  # ä½¿ç”¨ docker å¯åŠ¨ supabase æ— çŠ¶æ€éƒ¨åˆ†ï¼ˆå¯èƒ½è¾ƒæ…¢ï¼‰
vi pigsty.yml
	# è‡ªå·²å…ˆæ‰‹åŠ¨è®¾ç½®å¯†ç ï¼é™¤éå†…ç½‘ç¯å¢ƒ
	
	ä¸ç”¨ä¸‹é¢è¿™ä¸ªäº†
	./configure; ./install.yml; 
	# ç”Ÿæˆé…ç½®æ–‡ä»¶ï¼Œæ‰§è¡Œå®‰è£…å‰§æœ¬ï¼
		# é»˜è®¤å¯†ç ä¼šåœ¨ configure -g æ—¶è‡ªåŠ¨è¢«æ›¿æ¢ä¸ºéšæœºå¼ºå¯†ç 
			# å®æµ‹ -g å‚æ•°æ— æ•ˆ
			cat ~/pigsty/pigsty.yml | grep pg_admin_password

é€šè¿‡ http://<your_ip_address>:8000 è®¿é—®åˆ° Supabase Studio å›¾å½¢ç®¡ç†ç•Œé¢äº†ã€‚ é»˜è®¤çš„ç”¨æˆ·åä¸å¯†ç åˆ†åˆ«æ˜¯ï¼š supabase ä¸ pigstyã€‚

éœ€è¦ä½¿ç”¨çš„å¯¹è±¡å­˜å‚¨åŠŸèƒ½ï¼Œé‚£ä¹ˆéœ€è¦é€šè¿‡åŸŸåä¸ HTTPS è®¿é—® Supabaseï¼Œå¦åˆ™ä¼šå‡ºç°æŠ¥é”™ã€‚


Supabase éƒ¨åˆ†çš„å‡­æ®ä¿®æ”¹åï¼Œæ‚¨å¯ä»¥é‡å¯ Docker Compose å®¹å™¨ä»¥åº”ç”¨æ–°çš„é…ç½®ï¼š
./app.yml -t app_config,app_launch   # ä½¿ç”¨å‰§æœ¬
cd /opt/supabase; make up            # æ‰‹å·¥æ‰§è¡Œ



dbuser_dba	DBUser.DBA	  è¶…çº§ç”¨æˆ·	 æ•°æ®åº“ç®¡ç†
dbuser_meta	DBUser.Meta	  ä¸šåŠ¡ç®¡ç†å‘˜ åº”ç”¨è¯»å†™
dbuser_view	DBUser.Viewer åªè¯»ç”¨æˆ·	 æ•°æ®æŸ¥çœ‹
	# é»˜è®¤æ•°æ®åº“å¯†ç 
	
    #----------------------------------------------#
    # PASSWORD : https://doc.pgsty.com/config/security
    #----------------------------------------------#
    grafana_admin_password: pigstyxX
    	# admin æ˜¯è¿™ä¸ªç”¨æˆ·å xx.xx.xx.xx:3000/login
    pg_admin_password: DBUser.DBAxX
    pg_monitor_password: DBUser.MonitorxX
    pg_replication_password: DBUser.ReplicatorxX
    patroni_password: Patroni.APIxX
    haproxy_admin_password: pigstyxX
    minio_secret_key: minioadminxX

              PGADMIN_DEFAULT_EMAIL: admin@pigsty.cc
              PGADMIN_DEFAULT_PASSWORD: pigstyxX


        # define business users/roles : https://doc.pgsty.com/pgsql/user
        pg_users:
          - { name: dbuser_meta ,password: DBUser.MetaxX   ,pgbouncer: true ,roles: [dbrole_admin   ] ,comment: pigsty admin user }
          - { name: dbuser_view ,password: DBUser.ViewerxX ,pgbouncer: true ,roles: [dbrole_readonly] ,comment: read-only viewer  }


nmap 10.7.0.9 -p 5432
	# æ˜¯ä¸æ˜¯è¿™ä¸ªæ˜¯é›†ç¾¤é»˜è®¤ç»“ç‚¹ ?
	# vi pigsty.yml æ‰¾åˆ°çš„


export PGPASSWORD='DBUser.DBAxX'
psql -h 10.7.0.9 -p 5432 -U dbuser_dba -d postgres
	# è¿æ¥æˆåŠŸ
		psql è¦é€€å‡ºå®‰è£… pigsty çš„ shell é‡è¿›åæ‰å¯è§
		-d meta ä¼šæç¤ºæ²¡æœ‰è¿™ä¸ªæ•°æ®åº“
	\l	åˆ—å‡ºæ‰€æœ‰æ•°æ®åº“				  
	\c dbname  åˆ‡æ¢åˆ°æŒ‡å®šæ•°æ®åº“

	\dx                            -- psql å…ƒå‘½ä»¤ï¼Œåˆ—å‡ºå·²ç»å®‰è£…çš„æ‰©å±•
	TABLE pg_available_extensions; -- æŸ¥è¯¢å·²ç»å®‰è£…ï¼Œå¯ä»¥å¯ç”¨çš„æ‰©å±•
	CREATE EXTENSION postgis;      --  å¯ç”¨ postgis æ‰©å±•


vi /etc/nginx/nginx.conf
stream {
    upstream pg_5432 {
        server 10.7.0.9:5432;
    }

    server {
        listen 54322;
        proxy_pass pg_5432;
    }
}
nginx -t
systemctl status nginx
nginx -s reload
	# é…ç½® nginx è½¬å‘
	# navicat æˆåŠŸè¿ä¸Šäº†
	


postgres://dbuser_dba:DBUser.DBA@10.7.0.9:5432/meta
postgres://dbuser_meta:DBUser.Meta@10.7.0.9:5432/meta
postgres://dbuser_view:DBUser.View@10.7.0.9:5432/meta
	# ä½¿ç”¨ä¸‰ä¸ªä¸åŒçš„ç”¨æˆ·è¿æ¥åˆ° pg-meta é›†ç¾¤çš„ meta æ•°æ®åº“
	# https://pigsty.cc/docs/setup/pgsql/
		psql -h 10.7.0.9 -p 5432 -U dbuser_dba -d meta
			export PGPASSWORD='DBUser.DBA'
			psql -h 10.7.0.9 -p 5432 -U dbuser_dba -d meta




FATAL: no pg_hba.conf entry for host"xx.xx.xx.xx" user postgres database
	# è¿ PG æ•°æ®åº“å‡ºé”™ï¼Œåº”è¯¥æ˜¯æ²¡æœ‰å…è®¸è¿œç¨‹è¿æ¥



Ctrl+C	ä¸­æ–­æŸ¥è¯¢				Ctrl+D	é€€å‡º psql
\?	æ˜¾ç¤ºæ‰€æœ‰å…ƒå‘½ä»¤å¸®åŠ©			 \h	æ˜¾ç¤º SQL å‘½ä»¤å¸®åŠ©
\l	åˆ—å‡ºæ‰€æœ‰æ•°æ®åº“				  \c dbname	åˆ‡æ¢åˆ°æŒ‡å®šæ•°æ®åº“
\d table	æŸ¥çœ‹è¡¨ç»“æ„		   \d+ table	æŸ¥çœ‹è¡¨çš„è¯¦ç»†ä¿¡æ¯
\du	åˆ—å‡ºæ‰€æœ‰ç”¨æˆ·/è§’è‰²		     \dx	åˆ—å‡ºå·²å®‰è£…çš„æ‰©å±•
\dn	åˆ—å‡ºæ‰€æœ‰çš„æ¨¡å¼				  \dt	åˆ—å‡ºæ‰€æœ‰è¡¨


-- æŸ¥çœ‹ PostgreSQL ç‰ˆæœ¬
SELECT version();

-- æŸ¥çœ‹å½“å‰æ—¶é—´
SELECT now();

-- åˆ›å»ºä¸€å¼ æµ‹è¯•è¡¨
CREATE TABLE test (id SERIAL PRIMARY KEY, name TEXT, created_at TIMESTAMPTZ DEFAULT now());

-- æ’å…¥æ•°æ®
INSERT INTO test (name) VALUES ('hello'), ('world');

-- æŸ¥è¯¢æ•°æ®
SELECT * FROM test;

-- åˆ é™¤æµ‹è¯•è¡¨
DROP TABLE test;



Restarting services...

Service restarts being deferred:
 systemctl restart networkd-dispatcher.service
 systemctl restart unattended-upgrades.service




 å¦‚æœæ‚¨åªæ˜¯å¸Œæœ›å°å°é²œï¼Œä¸åœ¨ä¹å®‰å…¨ï¼Œå¹¶ä¸”å¸Œæœ›ä¸€åˆ‡è¶Šç®€å•è¶Šå¥½ï¼Œé‚£ä¹ˆæ‚¨å¯ä»¥ä»…å¯¹å¤–éƒ¨ç”¨æˆ·æŒ‰éœ€å¼€æ”¾ 5432 ç«¯å£ï¼ˆ PostgreSQL æ•°æ®åº“ï¼‰ ä¸ 3000 ç«¯å£ï¼ˆGrafana å¯è§†åŒ–ç•Œé¢ï¼‰ã€‚


 

```





```
https://blog.csdn.net/techshrimp/article/details/154450227
	ï¼ƒ åç«¯ä»£ç ä¸ç”¨å†™äº†ï¼Ÿå‰ç«¯æ“ä½œæ•°æ®åº“ï¼Ÿä¸€æ–‡ç²¾é€šSupabaseï¼Œå®æˆ˜æ•™ç¨‹+æœ¬åœ°éƒ¨ç½²


https://help.aliyun.com/zh/analyticdb/analyticdb-for-postgresql/user-guide/supabase/
	https://developer.aliyun.com/article/1674339?spm=a2c4g.11186623.0.0.36e373465XM2FV  
	ï¼ƒ supabase é˜¿é‡Œäº‘çš„ç‰ˆæœ¬  RDS å…¨æ‰˜ç®¡ SupabaseæœåŠ¡ï¼šå°ç™½è½»æ¾æå®šå¼€å‘AIåº”ç”¨ï¼
	

https://vonng.com/pigsty/v3.1/   Pigsty v3.1ï¼šSupabaseä¸€é”®è‡ªå»ºï¼ŒPG17ä¸Šä½ï¼ŒARMä¸Ubuntu24æ”¯æŒï¼ŒMinIOæ”¹è¿›
	Supabase çš„å£å·æ˜¯ï¼šâ€œèŠ±ä¸ªå‘¨æœ«å†™å†™ï¼Œéšä¾¿æ‰©å®¹è‡³ç™¾ä¸‡â€ã€‚åœ¨è¯•ç”¨ä¹‹åï¼Œæˆ‘è§‰å¾—æ­¤è¨€ä¸è™šã€‚ è¿™æ˜¯ä¸€ä¸ªä½ä»£ç çš„ä¸€ç«™å¼åç«¯å¹³å°ï¼Œèƒ½è®©ä½ å‡ ä¹å‘Šåˆ«å¤§éƒ¨åˆ†åç«¯å¼€å‘çš„å·¥ä½œï¼Œåªéœ€è¦æ‡‚æ•°æ®åº“è®¾è®¡ä¸å‰ç«¯å³å¯å¿«é€Ÿå‡ºæ´»äº†ï¼


https://www.ob-tutorial.org/blog/private-deploy-supabase-on-cloud-server  åœ¨äº‘æœåŠ¡å™¨ä¸Šç§æœ‰éƒ¨ç½² Supabase å®Œæ•´æŒ‡å—
	https://www.cnblogs.com/aopstudio/p/19134256  Supabaseï¼šæ— éœ€åç«¯ä»£ç çš„ Web å¼€å‘å®Œæ•´è§£å†³æ–¹æ¡ˆ
	https://pigsty.cc/blog/db/supabase/  è‡ªå»º Supabaseï¼šåˆ›ä¸šå‡ºæµ·çš„é¦–é€‰æ•°æ®åº“
	https://vonng.com/pigsty/v3.7/ Pigsty v3.7ï¼šPGä¸‡ç£ç‹ï¼ŒPG18æ·±åº¦æ”¯æŒ
	https://www.ffeeii.com/supabase.html  é˜¿é‡Œã€è…¾è®¯ã€å­—èŠ‚ã€n8néƒ½é€‰æ‹©äº†Supabaseï¼Œå¯è§Supabaseçš„æˆ˜ç•¥åœ°ä½
		https://www.ffeeii.com/trae-solo-skill.html  Trae SOLOï¼š3åˆ†é’Ÿè§£å†³Hugoåšå®¢3å¹´Githubå…¼å®¹é—®é¢˜ï¼ŒSOLOå¤ªå¼ºäº†ï¼
	https://www.zyzy.info/post/U2przPrt1a_n-y-AqeoUE  Supabase Edge Functions æœ¬åœ°å¼€å‘ä¸åŸç†è¯¦è§£
	https://vonng.com/pg/just-use-pg/  æŠ€æœ¯æç®€ä¸»ä¹‰ï¼šä¸€åˆ‡çš†ç”¨Postgres
	hangge.com/blog/cache/detail_3408.html
		# supabaseç§æœ‰åŒ–éƒ¨ç½²


https://zhuanlan.zhihu.com/p/1969746342847948293
	https://github.com/kuafuai/aipexbase
	https://blog.vonng.com/cloud/aliyun-supabase  é˜¿é‡Œäº‘â€œå€Ÿé‰´â€Supabaseï¼šå¼€æºä¸äº‘çš„ç°è‰²åœ°å¸¦
			# https://blog.vonng.com/pg/ai-db-king  PGå°†ä¸»å®°AIæ—¶ä»£çš„æ•°æ®åº“
			# https://blog.vonng.com/db/google-mcp/
				https://github.com/googleapis/genai-toolbox
					https://github.com/gemini-cli-extensions/postgres
			# https://www.zyzy.info/post/50ef5896-3b82-4bd2-b278-34deb7fc6170  ä»é›¶å¼€å§‹æ„å»ºç§äººMCPæœåŠ¡å™¨ï¼šè®©AIåŠ©æ‰‹ç›´æ¥åˆ›å»ºåšå®¢æ–‡ç« 
			# https://blog.vonng.com/db/pg-kiss-duckdb/  æ•°æ®åº“ç«æ˜Ÿæ’åœ°çƒï¼šå½“PGçˆ±ä¸ŠDuckDB
		# Supabase å¡è„–å­ï¼Ÿè¿™ä¸ªå›½äº§å¼€æºé¡¹ç›®è®© AI Coding çœŸæ­£é—­ç¯äº†

		await supabase.from(â€œusersâ€).select(â€˜*â€™).eq(â€œidâ€, userId).single()
		await pool.query(â€˜SELECT * FROM users WHERE id = $1 LIMIT 1â€™, [userId])

	æˆ‘ä¸ªäººéå¸¸å–œæ¬¢è¿™äº› BaaS é¡¹ç›®ï¼Œå¹¶ä¸”éƒ½è¯•è¿‡äº†ï¼ˆSupabase, Pocketbase, Appwrite ç­‰ï¼‰ã€‚æ¯ä¸ªéƒ½æœ‰ä¼˜ç‚¹å’Œç¼ºç‚¹

	æˆ‘æ¨èè‡ªæ‰˜ç®¡Appwriteï¼ˆMariaDBï¼‰ã€‚å®ƒæ˜¯æœ€ç›¸ä¼¼çš„æ›¿ä»£æ–¹æ¡ˆï¼Œå¹¶ä¸”æ‹¥æœ‰ç±»ä¼¼äºSupabaseè¾¹ç¼˜å‡½æ•°çš„è‡ªæ‰˜ç®¡å‡½æ•°ï¼Œè€Œä¸”æ”¯æŒä½ å–œæ¬¢çš„ç¼–ç¨‹è¯­è¨€ã€‚
```



### Trae ä»£ç†è¿è¿œç¨‹ä¸»æœº

```

Host tencent_tokyo
  HostName xx.xx.xx.xx
  Port 22
  User root
  ProxyCommand "C:\Program Files\Git\mingw64\bin\connect.exe" -H 172.22.112.93:7890 %h %p

```



### æºç æ„å»º

https://github.com/orgs/supabase/discussions/33178

- https://blog.csdn.net/m0_52537869/article/details/153853387 Supabase è‡ªéƒ¨ç½²å®Œæ•´æŒ‡å—
- https://github.com/supabase-community/supabase-mcp  

```

git clone --depth 1 https://github.com/supabase/supabase \
  && cd supabase/docker \
  && snap install docker \
  && cp .env.example .env \
  && docker compose pull


vi .env
# æ•°æ®åº“é…ç½®
POSTGRES_PASSWORD=your-super-secret-and-long-postgres-password
POSTGRES_DB=postgres

# JWT å¯†é’¥ï¼ˆè‡³å°‘ 32 ä¸ªå­—ç¬¦ï¼‰
JWT_SECRET=your-super-secret-jwt-token-with-at-least-32-characters-long

# API å¯†é’¥ï¼ˆä½¿ç”¨å®˜æ–¹å·¥å…·ç”Ÿæˆï¼‰
ANON_KEY=your-anon-key
SERVICE_ROLE_KEY=your-service-role-key

# ç«™ç‚¹ URLï¼ˆé‡è¦ï¼ç”¨äºè®¤è¯å›è°ƒï¼‰
SITE_URL=http://localhost:3000

# å…¬å¼€è®¿é—® URLï¼ˆDashboard è®¿é—®åœ°å€ï¼‰
SUPABASE_PUBLIC_URL=http://your-domain.com:8000

# Dashboard è®¤è¯
DASHBOARD_USERNAME=supabase
DASHBOARD_PASSWORD=this_password_is_insecure_and_should_be_updated

# Supavisor è¿æ¥æ± é…ç½®
POOLER_TENANT_ID=your-tenant-id

# SMTP é‚®ä»¶é…ç½®ï¼ˆç”¨äºå‘é€è®¤è¯é‚®ä»¶ï¼‰
SMTP_ADMIN_EMAIL=admin@example.com
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your-email@gmail.com
SMTP_PASS=your-email-password
SMTP_SENDER_NAME=Supabase

# å­˜å‚¨é…ç½®ï¼ˆå¯é€‰ï¼šä½¿ç”¨ S3ï¼‰
STORAGE_BACKEND=file
# å¦‚æœä½¿ç”¨ S3ï¼Œè®¾ç½®ä»¥ä¸‹é…ç½®ï¼š
# STORAGE_BACKEND=s3
# GLOBAL_S3_BUCKET=your-bucket-name
# REGION=us-east-1



docker compose up -d

docker compose ps

docker compose logs -f



å¯¼å‡ºæ¢å¤é•œåƒ

docker save supabase/studio:2025.12.17-sha-43f4f7f | gzip > supabase_studio.tar.gz

docker save supabase/logflare:1.27.0 | gzip > supabase_logflare.tar.gz 

docker save supabase/postgres-meta:v0.95.1 | gzip > supabase_postgres_meta.tar.gz

docker save supabase/storage-api:v1.33.0 | gzip > supabase_storage-api.tar.gz

docker save supabase/gotrue:v2.184.0 | gzip > supabase_gotrue.tar.gz

docker save supabase/edge-runtime:v1.70.0 | gzip > supabase_edge-runtime.tar.gz
	// docker save supabase/edge-runtime:v1.69.28 | gzip > supabase_edge-runtime.tar.gz
		// ä½ç‰ˆæœ¬æœ‰é—®é¢˜ï¼Ÿ

docker save supabase/realtime:v2.68.0 | gzip > supabase_realtime.tar.gz

docker save supabase/supavisor:2.7.4 | gzip > supabase_supavisor.tar.gz

docker save postgrest/postgrest:v14.1 | gzip > postgrest_postgrest.tar.gz

docker save supabase/postgres:15.8.1.085 | gzip > supabase_postgres.tar.gz

docker save timberio/vector:0.28.1-alpine | gzip > timberio_vector.tar.gz

docker save darthsim/imgproxy:v3.8.0 | gzip > darthsim_imgproxy.tar.gz

docker save kong:2.8.1 | gzip > kong.tar.gz




docker save -o my_images.tar image1:tag1 image2:tag2
	# æ‰¹é‡å¯¼å‡º
	
zcat /path/to/your_image.tar.gz | docker load
	# æ¢å¤


```





```

pigsty é•œåƒå¯¼å‡ºæ¢å¤

docker save supabase/studio:2025.11.10-sha-5291fe3 | gzip > supabase_studio.tar.gz \
  && docker save supabase/logflare:1.22.6 | gzip > supabase_logflare.tar.gz \
  && docker save supabase/postgres-meta:v0.93.1 | gzip > supabase_postgres_meta.tar.gz \
  && docker save supabase/storage-api:v1.29.0 | gzip > supabase_storage-api.tar.gz \
  && docker save supabase/gotrue:v2.182.1 | gzip > supabase_gotrue.tar.gz \
  && docker save supabase/edge-runtime:v1.70.0 | gzip > supabase_edge-runtime.tar.gz \
  && docker save supabase/realtime:v2.63.0 | gzip > supabase_realtime.tar.gz \
  && docker save postgrest/postgrest:v13.0.7 | gzip > postgrest_postgrest.tar.gz \
  && docker save darthsim/imgproxy:v3.8.0 | gzip > darthsim_imgproxy.tar.gz \
  && docker save timberio/vector:0.28.1-alpine | gzip > timberio_vector.tar.gz \
  && docker save kong:2.8.1 | gzip > kong.tar.gz
  
```







```

å¡åœ¨supabase-selfhostå¥½å‡ ä¸ªæ˜ŸæœŸäº†ã€‚

æ€»ç®—è¿è¡Œèµ·æ¥äº†ï¼ˆå…¬å¸YouTubeæ•…æ„ä¸æ˜¾ç¤ºç»ˆç«¯å‘½ä»¤è¡Œï¼Œè¿™å¸®å®¶ä¼™è—å¾—æŒºå·§ï¼‰ã€‚å¤šäº chatgpt å¸®æˆ‘ç”Ÿæˆäº†å‘½ä»¤è¡Œï¼Œè°¢å¤©è°¢åœ°ï¼Œç»ˆäºæˆåŠŸäº†ã€‚

è®¿é—®äº†è‡ªæ‰˜ç®¡Supabaseçš„ç®¡ç†åŒºåŸŸï¼ˆDigital Ocean EC2å®ä¾‹ï¼‰ã€‚

ç„¶åä½ çŒœæ€ä¹ˆç€â€”â€”å¥½å¤šåŠŸèƒ½éƒ½ç¼ºå¤±ï¼Œè¿æŸ¥è¯¢/å‡½æ•°éƒ½æ”¹ä¸äº†åï¼Œä¹Ÿåˆ ä¸æ‰ï¼ˆSupabaseä¸æ˜¯æœ‰è¿™ä¸ªåŠŸèƒ½å—ï¼Ÿï¼‰

æœ€åŸºæœ¬çš„APIè·å–å®Œå…¨æ²¡æ³•ç”¨ã€‚ä¸€ç›´è¶…æ—¶ï¼Œæ ¹æœ¬æ²¡åœ°æ–¹è°ƒè¯•ã€‚

é•¿è¯çŸ­è¯´ï¼šSupabaseè‡ªç§°å¼€æºï¼Œä½†ä»–ä»¬å¼€æºçš„æ˜¯ä¸ªåŠæˆå“é¡¹ç›®ï¼Œç›®çš„å°±æ˜¯ä¸ºäº†è®©ä½ ç”¨ä»–ä»¬çš„ä»˜è´¹Supabaseå¹³å°ã€‚

åˆ«æµªè´¹æ—¶é—´äº†ï¼Œæ¢å®¶å…¬å¸å§ã€‚Supabaseåªåœ¨ä¹é’±ã€‚




Supabase æ˜¯å¼€æºçš„ï¼Œä½†å®ƒçš„ Edge Functions ç®¡ç†åå°ï¼ˆFaaS Backendï¼‰å¹¶æœªå¼€æºã€‚è¿™æ„å‘³ç€ï¼š

æ‚¨å¯ä»¥åœ¨æœ¬åœ°ä½¿ç”¨ supabase start è¿è¡Œè¾¹ç¼˜å‡½æ•°ï¼ˆæ¨¡æ‹Ÿç¯å¢ƒï¼‰ï¼›

ä¹Ÿå¯ä»¥éƒ¨ç½²ä¸€ä¸ªåŒ…å« edge-runtime çš„å®¹å™¨ï¼›

ä½†æ‚¨æ— æ³•é€šè¿‡ Studio åˆ›å»ºã€ç¼–è¾‘æˆ–éƒ¨ç½²å‡½æ•°ï¼›

ä¹Ÿæ— æ³•é€šè¿‡ CLI å°†ä»£ç æ¨é€åˆ°è‡ªå»ºå®ä¾‹ï¼›

è®¸å¤šä¼ä¸šåœ¨å°è¯•è‡ªå»º Supabase æ—¶ï¼Œå‘ç° Edge Functions åŠŸèƒ½â€œä¸å¯ç”¨â€æˆ–â€œåªèƒ½é æ‰‹åŠ¨è„šæœ¬éƒ¨ç½²â€ï¼Œæœ€ç»ˆæ”¾å¼ƒä½¿ç”¨è¿™ä¸€æ ¸å¿ƒèƒ½åŠ›ã€‚



```





####  edge function å®é™…è°ƒç”¨åœ°å€

```

curl http://localhost:8000/functions/v1/hello
	# å®˜æ–¹çš„è¦è¿™æ ·, ç›´æ¥è°ƒ main å…¥å£ç‚¹ä¼šå‡ºé”™ï¼Œå®ƒåªæ˜¯ä¸€ä¸ªè·¯ç”±è½¬å‘
	
	.env å¼€å¯æˆæƒå FUNCTIONS_VERIFY_JWT=true
	{"msg":"Error: Missing authorization header"}
	
curl http://localhost:8000/functions/v1/hello \
  --header 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyAgCiAgICAicm9sZSI6ICJhbm9uIiwKICAgICJpc3MiOiAic3VwYWJhc2UtZGVtbyIsCiAgICAiaWF0IjogMTY0MTc2OTIwMCwKICAgICJleHAiOiAxNzk5NTM1NjAwCn0.dc_X5iR_VP_qT0zsiyj_I_OZ2T9FtRU2BBNWN8Bu4GE'
	
	docker compose stop functions
	
	/root/edge-runtime start --inspect=0.0.0.0:9229 --inspect-main --main-service /root/Supabase_official/docker/volumes/functions/main
		æˆåŠŸå¯åŠ¨

	huggingface_echodict\Supabase\source\supabase\edge-runtime
		edge-runtime æºç åœ¨è¿™
		
		
1. è®¾ç½®å¿…è¦çš„ç¯å¢ƒå˜é‡ (å‚è€ƒè‡ª .env å’Œ docker-compose.yml)
export JWT_SECRET="266fIWY3QlBdg0D1Juj6WUYlNQXqHoMHYT8Z4gpJ"
export SUPABASE_URL="http://localhost:8000"
export SUPABASE_ANON_KEY="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyAgCiAgICAicm9sZSI6ICJhbm9uIiwKICAgICJpc3MiOiAic3VwYWJhc2UtZGVtbyIsCiAgICAiaWF0IjogMTY0MTc2OTIwMCwKICAgICJleHAiOiAxNzk5NTM1NjAwCn0.dc_X5iR_VP_qT0zsiyj_I_OZ2T9FtRU2BBNWN8Bu4GE"
export SUPABASE_SERVICE_ROLE_KEY="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyAgCiAgICAicm9sZSI6ICJzZXJ2aWNlX3JvbGUiLAogICAgImlzcyI6ICJzdXBhYmFzZS1kZW1vIiwKICAgICJpYXQiOiAxNjQxNzY5MjAwLAogICAgImV4cCI6IDE3OTk1MzU2MDAKfQ.DaYlNEoUrrEn2Ig7tqibS-PHK5vgusbcbo7X36XVt4Q"
export SUPABASE_DB_URL="postgresql://postgres:DBUser.SupaxX@localhost:5432/postgres"
export FUNCTIONS_DIR="/root/Supabase_official/docker/volumes/functions"
/root/edge-runtime start \
  --inspect=0.0.0.0:9229 \
  --inspect-main \
  --main-service /root/Supabase_official/docker/volumes/functions/main


å¯åŠ¨æˆåŠŸåï¼Œè¯·ç›´æ¥è®¿é—® edge-runtime çš„é»˜è®¤ç«¯å£ 9000 ï¼Œå¹¶ä¸” ä¸è¦ å¸¦ /functions/v1 å‰ç¼€ï¼ˆå› ä¸ºåœ¨è¯¥æ¶æ„ä¸­ï¼ŒKong ç½‘å…³è´Ÿè´£å‰¥ç¦»è¿™ä¸ªå‰ç¼€ï¼Œç›´è¿æ—¶ä¸éœ€è¦ï¼‰ï¼š

curl http://localhost:9000/hello


curl http://localhost:8000/functions/v1/hello
  ä¸ºäº†è®© Kong èƒ½å¤Ÿè®¿é—®åˆ°å®¿ä¸»æœºä¸Šçš„æœåŠ¡ï¼Œä¿®æ”¹äº† docker-compose.yml ä¸­çš„ Kong é…ç½®ï¼Œæ·»åŠ äº† extra_hosts å­—æ®µï¼Œå°† functions åŸŸåæŒ‡å‘äº†å®¿ä¸»æœºç½‘å…³ï¼ˆ host-gateway ï¼‰ã€‚

  - ä¹‹å‰çš„é—®é¢˜ ï¼šKong å®¹å™¨å†…è§£æ http://functions:9000 æ—¶ï¼ŒDNS æŸ¥æ‰¾å¤±è´¥ï¼Œå› ä¸ºå®ƒè¯•å›¾æ‰¾åŒåçš„ Docker å®¹å™¨ï¼Œä½†é‚£ä¸ªå®¹å™¨æ²¡æœ‰è¿è¡Œï¼ˆæˆ–ä½ å¸Œæœ›å®ƒè¿å®¿ä¸»æœºï¼‰ã€‚
  - ä¿®å¤æ–¹æ¡ˆ ï¼šé€šè¿‡æ·»åŠ  extra_hosts: - "functions:host-gateway" ï¼Œå‘Šè¯‰ Docker å®¹å™¨ï¼šâ€œå½“æœ‰äººè®¿é—® functions æ—¶ï¼Œè¯·æŠŠå®ƒè½¬å‘åˆ°å®¿ä¸»æœºçš„ IP åœ°å€â€ã€‚
  - ç»“æœ ï¼šè¯·æ±‚è·¯å¾„å˜ä¸ºï¼š curl (ä¸»æœº) -> Kong (å®¹å™¨:8000) -> edge-runtime (ä¸»æœº:9000) ã€‚


	

supabase-edge-functions  | Debugger listening on ws://0.0.0.0:9229/ws/bf617c21-8443-46fe-bc74-c7eb31bc8932
supabase-edge-functions  | Visit chrome://inspect to connect to the debugger.
supabase-edge-functions  | main function started
	# ç”¨ chrome æ¥è°ƒè¯•

	chrome é‡Œä¸‹å®Œæ–­ç‚¹ curl http://localhost:8000/functions/v1/main æˆåŠŸæ–­ä¸‹æ¥äº†
		# chrome é€‰æœ¬åœ°æºç æ–‡ä»¶å¤¹ functions è¦å’Œè¿œç¨‹ä¸€æ¨¡ä¸€æ ·çš„æ–‡ä»¶æ‰è¡Œï¼Œæœ€å¥½ä»è¿œç¨‹æ‹‰ä¸‹æ¥è°ƒ
		

functions:  # è¿™ä¸ªå°±æ˜¯æœåŠ¡åç§°ï¼Œé‡å¯è¦è¿™æ ·ï¼šdocker compose restart functions
    container_name: supabase-edge-functions
    image: supabase/edge-runtime:v1.69.28
    ports:
      - "9229:9229"
    restart: unless-stopped
    volumes:
      - ./volumes/functions:/home/deno/functions:Z
    depends_on:
      analytics:
        condition: service_healthy
    environment:
      JWT_SECRET: ${JWT_SECRET}
      SUPABASE_URL: http://kong:8000
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_ROLE_KEY: ${SERVICE_ROLE_KEY}
      SUPABASE_DB_URL: postgresql://postgres:${POSTGRES_PASSWORD}@${POSTGRES_HOST}:${POSTGRES_PORT}/${POSTGRES_DB}
      # TODO: Allow configuring VERIFY_JWT per function. This PR might help: https://github.com/supabase/cli/pull/786
      VERIFY_JWT: "${FUNCTIONS_VERIFY_JWT}"
    command:
      [
        "start",
        "--inspect=0.0.0.0:9229",
        "--inspect-main",
        "--main-service",
        "/home/deno/functions/main"
      ]
      
     # docker compose restart functions
     # docker compose logs functions --tail 20
      
      
      


docker compose restart edge-runtime				# pigsty çš„ docker
	docker compose restart supabase-edge-functions  # å®˜æ–¹ä»£ç çš„ docker
		docker compose restart
	# è¿™ä¸ªå¦‚æœä¸è¡Œå°±ç”¨åé¢çš„
	
docker compose down \
  && docker compose up -d
  

docker compose ps

docker compose logs -f

curl http://localhost:8000/functions/v1/main


http://xxx:8000/functions/v1/login_with_aliyun
{
  "email": "123456@qq.com",
  "password": "123456",
  "captchaVerifyParam": "eyJjZXJ0aWZ5SWQiOiJYcDBFWUt3VmU1Iiwic2NlbmVJZCI6IjFrODEyeWN4IiwiaXNTaWduIjp0cnVlLCJzZWN1cml0eVRva2VuIjoiNm9PbzdlNzJuQTYxdVZMaVpWS2lMUlVZOXlNNExnV3VNZFZRYUFaZ3laajBKT0NIMWFjS0R0NUxvRzR4UGJXWGNlMHZCZ1J0c00xWDlWK0Vqbk50UWRsa1U2L3pJbGwwUHk3UmZEN1N1blJzZFUzaEp3L2FNR0NyTEpGSkpFRmQifQ=="
}
	# raw data POST
	# edge function å®é™…è°ƒç”¨åœ°å€

  const performLogin = async () => {
    if (!captchaToken) {
      message = 'Please complete the CAPTCHA verification.';
      return;
    }
    try {
      loading = true;
      const { data, error } = await supabase.functions.invoke('login_with_aliyun', {
        body: {
          email,
          password,
          captchaVerifyParam: captchaToken
        }
      });

      if (error) throw error;

      if (data?.session) {
        const { error: sessionError } = await supabase.auth.setSession(data.session);
        if (sessionError) throw sessionError;
        push('/');
      } else {
        if (!data.session) throw new Error('No session returned from server');
      }
    } catch (error) {
      console.error('Login error:', error);
      message = error.error_description || error.message || 'Login failed';
      captchaToken = '';
    } finally {
      loading = false;
    }
  };

```





#### å®ƒç”¨çš„æ˜¯é­”æ”¹ç‰ˆçš„ Deno

https://github.com/supabase/edge-runtime

1. æ€æ ·ä»æºç ç¼–è¯‘
2. åœ¨é­”æ”¹ Deno ä¸Šç§»å€¼æˆ‘ä»¬çš„åç«¯ä»£ç  

```

æŠŠæˆ‘ä»¬ä¼ ç»Ÿçš„ nodejs åç«¯æ•´ä¸ªä½œä¸ºè¾¹ç¼˜å‡½æ•°æ¥è¿è¡Œ


irm https://deno.land/install.ps1 | iex
	--> to C:\Users\Administrator\.deno\bin\deno.exe
	deno --help
	

deno run -A .\server.js
	èƒ½æ— ç¼è¿è¡Œ


```



#### æ¥å…¥ AI å¼€å‘

https://github.com/supabase-community/supabase-mcp

1. å®ƒåªæ”¯æŒå®˜æ–¹ Supabase ï¼Œæ€æ ·è®©è‡ªå»º Supabase ä¹Ÿèƒ½ç”¨ä¸Š mcp

```

ä»£ç ä¸»è¦ç”± AI æ¥å†™ï¼Œæˆ‘ä»¬åªè¦æä¾›éœ€æ±‚å’Œè®¾è®¡æ–‡æ¡£

```



#### ubuntu 24.04 æ€ä¹ˆå®‰è£… rust:1.79.0

```
      
åœ¨ Ubuntu 24.04 ä¸Šå®‰è£…ç‰¹å®šç‰ˆæœ¬ Rust (1.79.0) æœ€æ¨èçš„æ–¹æ³•æ˜¯ä½¿ç”¨å®˜æ–¹çš„ç‰ˆæœ¬ç®¡ç†å·¥å…· `rustup`ã€‚

ä»¥ä¸‹æ˜¯å…·ä½“æ­¥éª¤ï¼š

1. å®‰è£…åŸºç¡€ä¾èµ–
åœ¨å®‰è£… Rust ä¹‹å‰ï¼Œé€šå¸¸éœ€è¦å®‰è£… `build-essential`ï¼ˆåŒ…å« gcc ç­‰ç¼–è¯‘å™¨ï¼‰å’Œ `curl`ï¼š

â€‹```bash
sudo apt update
sudo apt install -y build-essential curl
â€‹```

2. å®‰è£… rustup
è¿è¡Œå®˜æ–¹å®‰è£…è„šæœ¬ï¼š

â€‹```bash
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh
â€‹```
*   å®‰è£…è¿‡ç¨‹ä¸­ä¼šæç¤ºé€‰æ‹©å®‰è£…é€‰é¡¹ï¼Œç›´æ¥æŒ‰ **Enter** é€‰æ‹©é»˜è®¤å®‰è£…å³å¯ã€‚
*   å®‰è£…å®Œæˆåï¼Œä½ éœ€è¦é…ç½®ç¯å¢ƒå˜é‡ï¼ˆè„šæœ¬æœ€åä¼šæç¤ºï¼‰ï¼Œæˆ–è€…ç›´æ¥**é‡å¯ç»ˆç«¯**ï¼Œæˆ–è€…è¿è¡Œï¼š
    ```bash
    source "$HOME/.cargo/env"
```

3. å®‰è£… Rust 1.79.0
ä½¿ç”¨ `rustup` å®‰è£…æŒ‡å®šç‰ˆæœ¬ï¼š

```bash
rustup install 1.79.0
â€‹```

4. è®¾ç½®ä¸ºé»˜è®¤ç‰ˆæœ¬ï¼ˆå¯é€‰ï¼‰
å¦‚æœä½ å¸Œæœ› `cargo` å’Œ `rustc` å‘½ä»¤é»˜è®¤ä½¿ç”¨ 1.79.0 ç‰ˆæœ¬ï¼š

â€‹```bash
rustup default 1.79.0
â€‹```

5. éªŒè¯å®‰è£…
æ£€æŸ¥ç‰ˆæœ¬æ˜¯å¦æ­£ç¡®ï¼š

â€‹```bash
rustc --version
 è¾“å‡ºåº”åŒ…å«: rustc 1.79.0 (...)
â€‹```

---

ğŸ’¡ ä¸ºä»€ä¹ˆä¸ç”¨ `apt install rustc`ï¼Ÿ
Ubuntu çš„ apt æºé‡Œçš„ Rust ç‰ˆæœ¬é€šå¸¸æ¯”è¾ƒæ—§ï¼Œä¸”æ— æ³•çµæ´»åˆ‡æ¢ç‰ˆæœ¬ã€‚ä½¿ç”¨ `rustup` å¯ä»¥è®©ä½ è½»æ¾åœ°åœ¨ä¸åŒç‰ˆæœ¬ï¼ˆå¦‚ stable, nightly, 1.79.0ï¼‰ä¹‹é—´åˆ‡æ¢ï¼Œè¿™å¯¹äºå¼€å‘ä¾èµ–ç‰¹å®š Rust ç‰ˆæœ¬çš„é¡¹ç›®éå¸¸é‡è¦ã€‚

```



#### ç¼–è¯‘ edge-runtime

```

see huggingface_echodict/Supabase/source/supabase/edge-runtime/Dockerfile

apt update \
&& apt-get install -y llvm-dev libclang-dev clang cmake binutils libblas-dev \
  liblapack-dev libopenblas-dev pkg-config libssl-dev


GIT_V_TAG=2.43.0 cargo build --profile release 
	cli v0.1.0 (/root/Supabase/source/supabase/edge-runtime/cli)
	ext_ai v0.1.0 (/root/Supabase/source/supabase/edge-runtime/ext/ai)

```





### å®‰è£…å‰æ

```

å®‰è£…å‰æï¼š
  å…·æœ‰å…å¯† ssh å’Œ sudo æƒé™çš„ ç®¡ç†ç”¨æˆ·

è¦æ±‚ï¼šssh root@127.0.0.1  è¿™ä¸ªå‘½ä»¤èƒ½ç™»å½•æœ¬æœº


apt update && sudo apt install openssh-server -y

vi /etc/ssh/sshd_config
PermitRootLogin yes
PasswordAuthentication yes

systemctl restart ssh \
  && systemctl status ssh


ssh root@127.0.0.1
	# ç°åœ¨åº”è¯¥èƒ½ä¸è¦å¯†ç ç™»å½•äº†

```



### ubuntu24.04 æ¢æº

```

cp /etc/apt/sources.list.d/ubuntu.sources /etc/apt/sources.list.d/ubuntu.sources.bak  \
  && vi  /etc/apt/sources.list.d/ubuntu.sources

é˜¿é‡Œäº‘é•œåƒæºé…ç½®ç¤ºä¾‹
Types: deb
URIs: https://mirrors.aliyun.com/ubuntu/
Suites: noble noble-updates noble-backports
Components: main restricted universe multiverse
Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg

Types: deb
URIs: https://mirrors.aliyun.com/ubuntu/
Suites: noble-security
Components: main restricted universe multiverse
Signed-By: /usr/share/keyrings/ubuntu-archive-keyring.gpg

curl -fsSL https://repo.pigsty.cc/get | bash; cd ~/pigsty  # å›½å†…
./configure -c supabase    # ä½¿ç”¨ supabase é…ç½®ï¼ˆè¯·åœ¨ pigsty.yml ä¸­æ›´æ”¹å‡­æ®ï¼‰
vi pigsty.yml              # ç¼–è¾‘åŸŸåã€å¯†ç ã€å¯†é’¥...
./install.yml              # å®‰è£… pigsty
./docker.yml               # å®‰è£… docker compose ç»„ä»¶
./app.yml                   # ä½¿ç”¨ docker å¯åŠ¨ supabase æ— çŠ¶æ€éƒ¨åˆ†ï¼ˆå¯èƒ½è¾ƒæ…¢ï¼‰
vi pigsty.yml
	# è‡ªå·²å…ˆæ‰‹åŠ¨è®¾ç½®å¯†ç ï¼é™¤éå†…ç½‘ç¯å¢ƒ

IMPORTANT: CHANGE JWT_SECRET AND REGENERATE CREDENTIAL ACCORDING!!!!!!!!!!!
              # https://supabase.com/docs/guides/self-hosting/docker#securing-your-services

Generate and configure API keys#

JWT_SECRET: Used by PostgREST and GoTrue to sign and verify JWTs.
9wvi0AlFWkvZKsdBsUxcMHbAlRk04SsIWbUcDClx

ANON_KEY: Client-side API key with limited permissions (anon role). Use this in your frontend applications.
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoiYW5vbiIsImlzcyI6InN1cGFiYXNlIiwiaWF0IjoxNzY3NzE1MjAwLCJleHAiOjE5MjU0ODE2MDB9.nJblK0q4I3djqRSk0qwkr3XKwVplqO-lqk6MIeww7DM

SERVICE_ROLE_KEY: Server-side API key with full database access (service_role role). Never expose this in client code.
eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoic2VydmljZV9yb2xlIiwiaXNzIjoic3VwYWJhc2UiLCJpYXQiOjE3Njc3MTUyMDAsImV4cCI6MTkyNTQ4MTYwMH0.dzJyYBEJhWIm2h6SgK7gfYhE8PkJDGqxi3kiUC5AAPU


postgres connection string (use the correct ip and port)
              POSTGRES_HOST: 192.168.1.7      # point to the local postgres node
              POSTGRES_PORT: 5436             # access via the 'default' service, which always route to the primary postgres
              POSTGRES_DB: postgres           # the supabase underlying database
              POSTGRES_PASSWORD: DBUser.SupaxX  # password for supabase_admin and multiple supabase users
è¿™ä¸ªæ˜¯ supabaser ä¸“ç”¨çš„ db è¿æ¥æ–¹æ³•


å®‰è£…å‰æï¼š
  å…·æœ‰å…å¯† ssh å’Œ sudo æƒé™çš„ ç®¡ç†ç”¨æˆ·

è¦æ±‚ï¼šssh root@127.0.0.1  è¿™ä¸ªå‘½ä»¤èƒ½ç™»å½•æœ¬æœº


apt update && sudo apt install openssh-server -y

vi /etc/ssh/sshd_config
PermitRootLogin yes
PasswordAuthentication yes

systemctl restart ssh \
  && systemctl status ssh



```



é…ç½®ä¿®æ”¹

```

vi /root/pigsty/roles/minio/tasks/config.yml
	line 72
	      loop:
        - { src: "{{ playbook_dir }}/files/pki/ca/ca.crt"                       ,dest: "/home/{{ minio_user }}/.minio/certs/CAs/ca.crt"  ,owner: "{{ minio_user }}", group: "minio" ,mode: "0644" }
        - { src: "{{ playbook_dir }}/files/pki/minio/{{ minio_instance }}.crt"  ,dest: "/home/{{ minio_user }}/.minio/certs/public.crt"  ,owner: "{{ minio_user }}", group: "minio" ,mode: "0644" }
        - { src: "{{ playbook_dir }}/files/pki/minio/{{ minio_instance }}.key"  ,dest: "/home/{{ minio_user }}/.minio/certs/private.key" ,owner: "{{ minio_user }}", group: "minio" ,mode: "0600" }
	# è¿™ä¸‰è¡Œæ”¹æˆè¿™æ ·



$ hostname -I
10.7.0.9 172.17.0.1 172.18.0.1 192.168.122.1 192.168.121.1 10.10.10.1 

(TraeAI-4) /opt/supabase [0] $ ss -tuln | grep 5436
tcp   LISTEN 0      4096          0.0.0.0:5436       0.0.0.0:* 


vi /root/pigsty/pigsty.yml

        app: supabase                                     # specify app name (supa) to be installed (in the apps)
        apps:                                             # define all applications
          supabase:                                       # the definition of supabase app
            conf:                                         # override /opt/supabase/.env
    
              postgres connection string (use the correct ip and port)
              POSTGRES_HOST: 172.17.0.1      # point to the local postgres node
              	# ip ä» 127.0.0.1 æ”¹æˆè¿™ä¸ªäº†
              POSTGRES_PORT: 5436             # access via the 'default' service, which 
    
    ./app.yml è¿è¡Œå‡ºé”™æ‰è¿™æ ·æ”¹çš„



```



### AUTH_JWT_SECRET  SUPABASE_ANON_KEY åˆ†åˆ«ä»€ä¹ˆç”¨

```

`\root\Supabase_official\docker\docker-compose.yml#L45-49`  AUTH_JWT_SECRET  SUPABASE_ANON_KEY åˆ†åˆ«ä½œä»€ä¹ˆç”¨


è¿™ä¸¤è€…æ˜¯ Supabase å®‰å…¨æœºåˆ¶ä¸­çš„æ ¸å¿ƒé…ç½®ï¼Œå®ƒä»¬åœ¨ docker-compose.yml ä¸­è¢«ä¼ é€’ç»™å„ä¸ªæœåŠ¡ï¼ˆå¦‚ Studioã€Kongã€GoTrue ç­‰ï¼‰ï¼Œå…¶å…·ä½“ä½œç”¨å¦‚ä¸‹ï¼š

1. AUTH_JWT_SECRET (JWT å¯†é’¥)
- å¯¹åº”å˜é‡ : é€šå¸¸å¯¹åº” .env æ–‡ä»¶ä¸­çš„ JWT_SECRET ã€‚
- ä½œç”¨ : è¿™æ˜¯ æœ€æ ¸å¿ƒçš„å®‰å…¨å¯†é’¥ ï¼Œç”¨äºç”Ÿæˆå’ŒéªŒè¯ JSON Web Tokens (JWT)ã€‚
  - ç­¾å (Signing) : å½“ç”¨æˆ·ç™»å½•æ—¶ï¼ŒAuth æœåŠ¡ (GoTrue) ä¼šä½¿ç”¨è¿™ä¸ªå¯†é’¥å¯¹ç”¨æˆ·çš„ Access Token è¿›è¡ŒåŠ å¯†ç­¾åã€‚
  - éªŒè¯ (Verification) : PostgRESTï¼ˆæ•°æ®åº“æ¥å£ï¼‰ã€Realtimeã€Storage ç­‰æœåŠ¡ä½¿ç”¨åŒä¸€ä¸ªå¯†é’¥æ¥è§£å¯†å’ŒéªŒè¯ç”¨æˆ·è¯·æ±‚ä¸­æºå¸¦çš„ Token æ˜¯å¦åˆæ³•ï¼Œä»¥åŠè§£æå…¶ä¸­çš„ç”¨æˆ·ä¿¡æ¯ï¼ˆå¦‚ user_id , role ï¼‰ã€‚
- å®‰å…¨æ€§ : ç»å¯¹ä¿å¯† ã€‚å¦‚æœæ­¤å¯†é’¥æ³„éœ²ï¼Œæ”»å‡»è€…å¯ä»¥ä¼ªé€ ä»»æ„ç”¨æˆ·çš„èº«ä»½ä»¤ç‰Œï¼ˆåŒ…æ‹¬ç®¡ç†å‘˜ï¼‰ï¼Œä»è€Œå®Œå…¨æ§åˆ¶ä½ çš„ç³»ç»Ÿã€‚
2. SUPABASE_ANON_KEY (åŒ¿å/å…¬é’¥)
- å¯¹åº”å˜é‡ : é€šå¸¸å¯¹åº” .env æ–‡ä»¶ä¸­çš„ ANON_KEY ã€‚
- ä½œç”¨ : è¿™æ˜¯ å…¬å¼€çš„ API å¯†é’¥ ï¼Œä¸»è¦ç”¨äºå‰ç«¯å®¢æˆ·ç«¯ã€‚
  - å®¢æˆ·ç«¯åˆå§‹åŒ– : å‰ç«¯åº”ç”¨ï¼ˆWebã€Appï¼‰åˆå§‹åŒ– Supabase Client æ—¶å¿…é¡»æä¾›æ­¤ Keyã€‚
  - ç½‘å…³é€šè¿‡ : å®ƒå…è®¸æœªç™»å½•çš„ç”¨æˆ·ï¼ˆæˆ–åˆšåˆå§‹åŒ–çš„å®¢æˆ·ç«¯ï¼‰é€šè¿‡ API ç½‘å…³ï¼ˆKongï¼‰ã€‚
  - æƒé™æ§åˆ¶ : è¿™ä¸ª Key æœ¬è´¨ä¸Šä¹Ÿæ˜¯ä¸€ä¸ªç”± AUTH_JWT_SECRET ç­¾åçš„ JWTï¼Œä½†å®ƒçš„è§’è‰² (Role) è¢«ç¡¬ç¼–ç ä¸º anon ã€‚ä½¿ç”¨æ­¤ Key å‘èµ·çš„è¯·æ±‚ å—é™äºæ•°æ®åº“çš„è¡Œçº§å®‰å…¨ç­–ç•¥ (RLS) ã€‚è¿™æ„å‘³ç€ï¼Œé™¤éä½ åœ¨æ•°æ®åº“ä¸­é…ç½®äº†å…è®¸ anon è§’è‰²è®¿é—®çš„ RLS ç­–ç•¥ï¼Œå¦åˆ™å®ƒæ— æ³•è¯»å–æˆ–ä¿®æ”¹æ•æ„Ÿæ•°æ®ã€‚
- å®‰å…¨æ€§ : å¯ä»¥å…¬å¼€ ã€‚å®ƒè®¾è®¡ç”¨äºåœ¨æµè§ˆå™¨æˆ–ç§»åŠ¨ç«¯ä»£ç ä¸­æš´éœ²ã€‚åªè¦ä½ æ­£ç¡®é…ç½®äº†æ•°æ®åº“çš„ RLSï¼Œæš´éœ²è¿™ä¸ª Key æ˜¯å®‰å…¨çš„ã€‚
æ€»ç»“å¯¹æ¯”
å˜é‡å ä½œç”¨åŸŸ å®‰å…¨çº§åˆ« ç”¨é€” AUTH_JWT_SECRET åç«¯å†…éƒ¨ æåº¦æ•æ„Ÿ (Secret) ç­¾å‘å’ŒéªŒè¯æ‰€æœ‰ Tokenï¼Œç³»ç»Ÿçš„ä¿¡ä»»åŸºçŸ³ã€‚ SUPABASE_ANON_KEY å‰ç«¯/å®¢æˆ·ç«¯ å…¬å¼€ (Public) å…è®¸å®¢æˆ·ç«¯è¿æ¥ APIï¼Œå— RLS ç­–ç•¥é™åˆ¶ã€‚


```





### èƒ½ç™»å½• supabase ä¸‹ä¸€æ­¥æ€ä¹ˆåš

```

Based on the configuration files in /opt/supabase , the Supabase Studio dashboard is protected by Basic Authentication via the Kong gateway. The "Unauthorized" error you are seeing is because you need to log in.

Here is the information you need to proceed:

### 1. Access the Dashboard
When you visit http://xx.xx.xx.xx:8000/project/default , your browser should prompt you for a username and password. Use the following credentials found in your .env file:

- Username : supabase
- Password : pigsty
### 2. API Keys for Development
Once you have access to the dashboard, you will need API keys to connect your applications to Supabase. These are also defined in your .env file:

- anon key (public, for frontend use):
  
```
  eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.
  eyJyb2xlIjoiYW5vbiIsImlzcyI6InN1cGFiYXNlIiwiaWF0IjoxNzY3ODAxNjAwLCJleHAiOjE5MjU1
  NjgwMDB9.GtkruGMgbxm3kS_1eIHKyz0uaVjhvlWLvqUuS5b-DRc

```
- service_role key (private, for backend admin use - keep secret ):
  
```
  eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.
  eyJyb2xlIjoic2VydmljZV9yb2xlIiwiaXNzIjoic3VwYWJhc2UiLCJpYXQiOjE3Njc4MDE2MDAsImV4
  cCI6MTkyNTU2ODAwMH0.JHimTs0hXELAEp1FtwPp2SXq-l8Dzfv8oHoGJ9oWvF8

  ```
### 3. Next Steps
1. Log in to the dashboard using the credentials above.
2. Verify that you can see the "Default Project".
3. If you need to change the password , you can edit the /opt/supabase/.env file, update DASHBOARD_PASSWORD , and run docker-compose up -d to apply changes.
<todo_status>
{"todos":[{"id":"check_config","status":"completed","content":"Check Supabase installation and configuration in /opt/supabase","priority":"high","created_at":1767836783},{"id":"check_docker","status":"completed","content":"Check running Docker containers for Supabase services","priority":"high","created_at":1767836783},{"id":"resolve_access","status":"completed","content":"Resolve "Unauthorized" error or provide access instructions","priority":"high","created_at":1767836783}]}
</todo_status>

  ```



### Dashboard æ˜¯ä»€ä¹ˆè¿˜å¯ä»¥æ–°å»º project å—ï¼Ÿ

  ```

Dashboard æ˜¯ä»€ä¹ˆ Supabase Dashboard (Supabase Studio) æ˜¯ Supabase çš„å¯è§†åŒ–ç®¡ç†ç•Œé¢ã€‚ä½ å¯ä»¥é€šè¿‡å®ƒæ¥ï¼š

- ç®¡ç†æ•°æ®åº“è¡¨ç»“æ„ (Table Editor)
- ç¼–å†™å’Œæ‰§è¡Œ SQL (SQL Editor)
- ç®¡ç†ç”¨æˆ·è®¤è¯å’Œæƒé™ (Authentication)
- ç®¡ç†å¯¹è±¡å­˜å‚¨ (Storage)
- æŸ¥çœ‹ API æ–‡æ¡£
é™¤äº†é»˜è®¤ project è¿˜å¯ä»¥æ–°å»º project å— ä¸å¯ä»¥ ã€‚
åœ¨è‡ªæ‰˜ç®¡ (Self-Hosted) çš„ Docker ç¯å¢ƒä¸‹ï¼ŒSupabase Studio ä¸åº•å±‚çš„ Docker æœåŠ¡å®¹å™¨ï¼ˆKong, GoTrue, PostgREST ç­‰ï¼‰ä»¥åŠ Postgres æ•°æ®åº“æ˜¯ 1 å¯¹ 1 ç»‘å®š çš„ã€‚

- "Default Project" ç›´æ¥å¯¹åº”ä½ å½“å‰çš„è¿™å¥— Docker æœåŠ¡å’Œ Postgres æ•°æ®åº“ã€‚
- Studio ç•Œé¢ä¸Šæ˜¾ç¤ºçš„ "Default Project" åªæ˜¯ä¸€ä¸ªé€šè¿‡ç¯å¢ƒå˜é‡é…ç½®çš„åç§° ( STUDIO_DEFAULT_PROJECT=Pigsty )ã€‚
- å¦‚æœä½ éœ€è¦å¦ä¸€ä¸ª "Project"ï¼ˆå³å¦ä¸€å¥—å®Œå…¨éš”ç¦»çš„ Supabase ç¯å¢ƒï¼‰ï¼Œä½ éœ€è¦éƒ¨ç½²å¦ä¸€å¥— Supabase Docker å®¹å™¨æ ˆï¼Œå¹¶ç›‘å¬ä¸åŒçš„ç«¯å£ã€‚

  ```





### ä¿®æ”¹é»˜è®¤ Project åç§°çš„æ–¹æ³•

```

sed -i 's/STUDIO_DEFAULT_PROJECT=Pigsty/STUDIO_DEFAULT_PROJECT=MyNewProject/' /opt/supabase/.env

cd /opt/supabase && docker compose up -d


ä¿®æ”¹ Supabase é»˜è®¤ Project åç§°éœ€è¦ä¿®æ”¹ç¯å¢ƒå˜é‡é…ç½®æ–‡ä»¶ï¼Œå¹¶é‡å¯ç›¸å…³å®¹å™¨ã€‚

1. ä¿®æ”¹é…ç½®æ–‡ä»¶ ä¿®æ”¹ /opt/supabase/.env æ–‡ä»¶ä¸­çš„ STUDIO_DEFAULT_PROJECT å˜é‡ã€‚
   
   /opt/supabase/.env
   STUDIO_DEFAULT_PROJECT=MyNewProjectÂ Â #Â å°†åŸæ¥çš„Â PigstyÂ ä¿®æ”¹ä¸ºä½ æƒ³è¦çš„åç§°

   (æˆ‘å·²ç»å¸®ä½ æ‰§è¡Œäº†è¿™ä¸€æ­¥ï¼Œå°†åç§°ä¿®æ”¹ä¸ºäº† MyNewProject )
2. é‡å¯ Supabase ä¿®æ”¹é…ç½®åï¼Œå¿…é¡»é‡å¯ Supabase æœåŠ¡ï¼ˆä¸»è¦æ˜¯ Studio å®¹å™¨ï¼‰æ‰èƒ½ç”Ÿæ•ˆã€‚
   
   cdÂ /opt/supabase
   dockerÂ composeÂ upÂ -d
   (æˆ‘å·²ç»å¸®ä½ æ‰§è¡Œäº†è¿™ä¸€æ­¥ï¼Œ supabase-studio å®¹å™¨å·²é‡å»º)
ç°åœ¨ä½ å¯ä»¥åˆ·æ–°æµè§ˆå™¨è®¿é—® Dashboardï¼Œåº”è¯¥èƒ½çœ‹åˆ° Project åç§°å·²ç»å˜æˆäº† MyNewProject ã€‚


```





### æ–°å»ºçš„ç”¨æˆ·å¯ä»¥æœ‰è‡ªå·²çš„å„ç§ key å—

   ```

`http://xx.xx.xx.xx:8000/project/default/auth/users`  æˆ‘åœ¨è¿™é‡Œæ–°å»ºäº†ä¸€ä¸ª user ï¼Œè¿™ä¸ªç”¨æˆ·å¯ä»¥æœ‰è‡ªå·²çš„å„ç§ key å—

åœ¨ Supabase ä¸­ï¼Œç”¨æˆ·ï¼ˆUserï¼‰å’Œ é¡¹ç›®ï¼ˆProjectï¼‰çš„ Key æ˜¯å®Œå…¨ä¸åŒçš„æ¦‚å¿µã€‚

ç®€å•æ¥è¯´ï¼š ä½ åœ¨ Auth é¡µé¢æ–°å»ºçš„ç”¨æˆ·ï¼Œä¸ä¼šæ‹¥æœ‰ç±»ä¼¼ anon æˆ– service_role é‚£æ ·çš„æ°¸ä¹… API Keyã€‚

1. é¡¹ç›®çº§ Key (Project Keys)
è¿™æ˜¯ä½ ä¹‹å‰åœ¨ .env æ–‡ä»¶é‡Œçœ‹åˆ°çš„ï¼Œå±äºæ•´ä¸ªé¡¹ç›®çš„â€œå¤§é—¨é’¥åŒ™â€ã€‚

- anon key : å…¬é’¥ã€‚ç»™å‰ç«¯ç”¨çš„ï¼Œæƒé™å¾ˆä½ï¼Œå¿…é¡»é…åˆ Row Level Security (RLS) ä½¿ç”¨ã€‚
- service_role key : ç§é’¥ã€‚æ‹¥æœ‰ä¸Šå¸æƒé™ï¼Œå¯ä»¥ç»•è¿‡æ‰€æœ‰ RLS è§„åˆ™ã€‚ ç»å¯¹ä¸èƒ½ç»™æ™®é€šç”¨æˆ· ã€‚
2. ç”¨æˆ·çº§ Token (User Access Token / JWT)
å½“ä½ åœ¨ http://xx.xx.xx.xx:8000/project/default/auth/users åˆ›å»ºä¸€ä¸ªç”¨æˆ·åï¼Œè¿™ä¸ªç”¨æˆ·æ˜¯ç”¨æ¥ ç™»å½•ä½ çš„åº”ç”¨ çš„ã€‚

- ç”¨æˆ·æ²¡æœ‰æ°¸ä¹… Key ï¼šç”¨æˆ·ç™»å½•ï¼ˆé€šè¿‡ Email/å¯†ç , OAuth ç­‰ï¼‰æˆåŠŸåï¼ŒSupabase ä¼šå‘ç»™å‰ç«¯ä¸€ä¸ªä¸´æ—¶çš„ Access Token (JWT) ã€‚
- Token ä»£è¡¨èº«ä»½ ï¼šå‰ç«¯åœ¨è¯·æ±‚ Supabase æ•°æ®åº“æˆ– API æ—¶ï¼Œä¼šåœ¨ Header é‡Œå¸¦ä¸Šè¿™ä¸ª Tokenã€‚
- RLS å†³å®šæƒé™ ï¼šPostgres æ•°æ®åº“ä¼šè§£æè¿™ä¸ª Tokenï¼ŒçŸ¥é“â€œè¿™æ˜¯ User Aâ€ï¼Œç„¶åæ ¹æ®ä½ è®¾ç½®çš„ RLS (Row Level Security) è§„åˆ™ï¼Œå†³å®š User A èƒ½æŸ¥å“ªäº›æ•°æ®ï¼Œèƒ½æ”¹å“ªäº›æ•°æ®ã€‚
æ€»ç»“
- Project Keys ( anon / service_role ) ï¼šæ˜¯ç»™ å¼€å‘è€… ç”¨æ¥è¿æ¥ Supabase æœåŠ¡çš„ã€‚
- User Users ï¼šæ˜¯ä½ çš„ App çš„æœ€ç»ˆç”¨æˆ· ã€‚ä»–ä»¬é€šè¿‡ç™»å½•è·å– ä¸´æ—¶ Token æ¥è¯æ˜èº«ä»½ï¼Œè€Œä¸æ˜¯æ‹¥æœ‰æ°¸ä¹… Keyã€‚
å¦‚æœä½ éœ€è¦ç»™æŸä¸ªç¨‹åºï¼ˆè€Œä¸æ˜¯äººï¼‰åˆ†é…ä¸€ä¸ªé•¿æœŸæœ‰æ•ˆçš„å‡­è¯ï¼Œé€šå¸¸çš„åšæ³•æ˜¯ï¼š

1. åˆ›å»ºä¸€ä¸ªç‰¹å®šçš„ Userã€‚
2. åœ¨æ•°æ®åº“ä¸­æ‰‹åŠ¨ç”Ÿæˆä¸€ä¸ªé•¿æœŸæœ‰æ•ˆçš„ JWTï¼ˆä¸æ¨èï¼Œæœ‰å®‰å…¨é£é™©ï¼‰ã€‚
3. æˆ–è€…ï¼Œåªä½¿ç”¨ service_role key å¹¶åœ¨åç«¯ä»£ç ä¸­æ§åˆ¶æƒé™ï¼ˆè¿™æ˜¯ä½œä¸ºç®¡ç†å‘˜çš„æ“ä½œæ–¹å¼ï¼‰ã€‚



   ```





### SQL Editor æŸ¥ç”¨æˆ·ä¿¡æ¯

```

SELECT * 
FROM auth.users 
WHERE email = 'your_email@example.com';

```



### å‰ç«¯ç”¨æˆ·å¦‚ä½•å®Œæˆæ³¨å†Œ

```

`\root\pigsty\pigsty.yml` åˆ†æ Supabase æ–°ç”¨æˆ·æ³¨å†Œæ–¹é¢çš„é…ç½®ï¼Œé…å¥½ååœ¨å‰ç«¯ç”¨æˆ·å¦‚ä½•å®Œæˆæ³¨å†Œ

é…ç½®åˆ†æ
æŸ¥çœ‹ /opt/supabase/.env æ–‡ä»¶ï¼Œå½“å‰çš„æ³¨å†Œé…ç½®å¦‚ä¸‹ï¼š

1. å…è®¸é‚®ç®±æ³¨å†Œ ( ENABLE_EMAIL_SIGNUP=true )ï¼šå¼€å¯ã€‚
2. è‡ªåŠ¨ç¡®è®¤é‚®ç®± ( ENABLE_EMAIL_AUTOCONFIRM=true )ï¼š å¼€å¯ ã€‚
   - è¿™æ˜¯ä¸€ä¸ªéå¸¸å…³é”®çš„é…ç½®ã€‚å› ä¸ºä½ çš„ SMTP é‚®ä»¶æœåŠ¡é…ç½®çš„æ˜¯å‡çš„ ( fake_mail_user )ï¼Œå¦‚æœå…³é—­è‡ªåŠ¨ç¡®è®¤ï¼ŒSupabase ä¼šå°è¯•å‘é€éªŒè¯é‚®ä»¶ä½†å¤±è´¥ï¼Œå¯¼è‡´ç”¨æˆ·æ— æ³•æ¿€æ´»ã€‚
   - ç°çŠ¶ ï¼šç”¨æˆ·æ³¨å†Œå ç«‹å³æ¿€æ´» ï¼Œæ— éœ€ç‚¹å‡»é‚®ä»¶éªŒè¯é“¾æ¥ã€‚
3. SMTP é…ç½® ï¼šç›®å‰æ˜¯é»˜è®¤çš„å‡é…ç½® ( fake_sender ç­‰)ã€‚ç”±äºå¼€å¯äº†è‡ªåŠ¨ç¡®è®¤ï¼Œè¿™æš‚æ—¶ä¸ä¼šå½±å“æ³¨å†Œæµç¨‹ã€‚
å‰ç«¯æ³¨å†Œå®ç°
ç”±äºé…ç½®äº†è‡ªåŠ¨ç¡®è®¤ï¼Œå‰ç«¯æ³¨å†Œæµç¨‹éå¸¸ç®€å•ã€‚ä½ åªéœ€è¦ä½¿ç”¨ supabase-js å®¢æˆ·ç«¯åº“ã€‚
 1. å®‰è£…ä¾èµ–

npmÂ installÂ @supabase/supabase-js
2. æ³¨å†Œä»£ç ç¤ºä¾‹
ä½ éœ€è¦ç”¨åˆ°ä¹‹å‰è·å–çš„ SUPABASE_URL (ä½ çš„å…¬ç½‘ IP + ç«¯å£) å’Œ ANON_KEY ã€‚

importÂ {Â createClientÂ }Â fromÂ '@supabase/supabase-js'

//Â 1.Â åˆå§‹åŒ–å®¢æˆ·ç«¯
constÂ supabaseUrlÂ =Â 'http://xx.xx.xx.xx:8000'
constÂ supabaseKeyÂ =Â 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.
eyJyb2xlIjoiYW5vbiIsImlzcyI6InN1cGFiYXNlIiwiaWF0IjoxNzY3ODAxNjAwLCJleHAiOjE5MjU1Njg
wMDB9.GtkruGMgbxm3kS_1eIHKyz0uaVjhvlWLvqUuS5b-DRc'Â //Â å¡«å…¥ä½ çš„Â anonÂ key
constÂ supabaseÂ =Â createClient(supabaseUrl,Â supabaseKey)

//Â 2.Â æ³¨å†Œå‡½æ•°
asyncÂ functionÂ signUpNewUser()Â {
Â Â constÂ {Â data,Â errorÂ }Â =Â awaitÂ supabase.auth.signUp({
Â Â Â Â email:Â 'example@email.com',
Â Â Â Â password:Â 'example-password',
Â Â })

Â Â ifÂ (error)Â {
Â Â Â Â console.error('æ³¨å†Œå¤±è´¥:',Â error.message)
Â Â Â Â return
Â Â }

Â Â //Â å› ä¸ºå¼€å¯äº†Â ENABLE_EMAIL_AUTOCONFIRM=true
Â Â //Â data.userÂ ä¼šç«‹å³è¿”å›ï¼Œä¸”Â data.sessionÂ ä¹Ÿä¼šæœ‰å€¼ï¼ˆè¡¨ç¤ºå·²è‡ªåŠ¨ç™»å½•ï¼‰
Â Â console.log('æ³¨å†ŒæˆåŠŸ:',Â data)
Â Â console.log('ç”¨æˆ·Â ID:',Â data.user.id)
Â Â console.log('AccessÂ Token:',Â data.session.access_token)
}

signUpNewUser()

æ€»ç»“
ç›®å‰çš„é…ç½®éå¸¸é€‚åˆå¼€å‘ç¯å¢ƒï¼š æ³¨å†Œå³ç™»å½•ï¼Œæ— éœ€é‚®ä»¶éªŒè¯ ã€‚å¦‚æœä½ å°†æ¥è¦ä¸Šçº¿ç”Ÿäº§ç¯å¢ƒå¹¶è¦æ±‚çœŸå®çš„é‚®ä»¶éªŒè¯ï¼Œä½ éœ€è¦ï¼š

1. åœ¨ .env ä¸­é…ç½®çœŸå®çš„ SMTP æœåŠ¡ï¼ˆå¦‚ SendGrid, AWS SES ç­‰ï¼‰ã€‚
2. å°† ENABLE_EMAIL_AUTOCONFIRM æ”¹ä¸º false ã€‚
3. é‡å¯ Supabase æœåŠ¡ã€‚


```



### å‰ç«¯ç”¨æˆ·å¦‚ä½•å®Œæˆç™»å½•

```
å‰ç«¯ç”¨æˆ·ç™»å½•åŒæ ·éå¸¸ç®€å•ï¼Œä½¿ç”¨ supabase.auth.signInWithPassword æ–¹æ³•å³å¯ã€‚

å‰ç«¯ç™»å½•ä»£ç ç¤ºä¾‹

importÂ {Â createClientÂ }Â fromÂ '@supabase/supabase-js'

//Â 1.Â åˆå§‹åŒ–å®¢æˆ·ç«¯Â (ä¸æ³¨å†Œæ—¶ç›¸åŒ)
constÂ supabaseUrlÂ =Â 'http://xx.xx.xx.xx:8000'
constÂ supabaseKeyÂ =Â 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.
eyJyb2xlIjoiYW5vbiIsImlzcyI6InN1cGFiYXNlIiwiaWF0IjoxNzY3ODAxNjAwLCJleHAiOjE5MjU1Njg
wMDB9.GtkruGMgbxm3kS_1eIHKyz0uaVjhvlWLvqUuS5b-DRc'
constÂ supabaseÂ =Â createClient(supabaseUrl,Â supabaseKey)

//Â 2.Â ç™»å½•å‡½æ•°
asyncÂ functionÂ signInUser()Â {
Â Â constÂ {Â data,Â errorÂ }Â =Â awaitÂ supabase.auth.signInWithPassword({
Â Â Â Â email:Â 'example@email.com',
Â Â Â Â password:Â 'example-password',
Â Â })

Â Â ifÂ (error)Â {
Â Â Â Â console.error('ç™»å½•å¤±è´¥:',Â error.message)
Â Â Â Â return
Â Â }

Â Â //Â ç™»å½•æˆåŠŸ
Â Â console.log('ç™»å½•æˆåŠŸï¼ŒSessionÂ ä¿¡æ¯:',Â data.session)
Â Â console.log('AccessÂ TokenÂ (JWT):',Â data.session.access_token)

Â Â //Â ä½ å¯ä»¥å°†Â access_tokenÂ å­˜å‚¨èµ·æ¥ï¼Œæˆ–è€…ç”±Â supabase-jsÂ è‡ªåŠ¨ç®¡ç†ï¼ˆé»˜è®¤å­˜å‚¨åœ¨Â 
Â Â localStorageï¼‰
}

signInUser()

å…³é”®ç‚¹è¯´æ˜

1. Session ç®¡ç† ï¼š supabase-js é»˜è®¤ä¼šè‡ªåŠ¨å°† Session ä¿¡æ¯ï¼ˆåŒ…æ‹¬ Tokenï¼‰ä¿å­˜åœ¨æµè§ˆå™¨çš„ localStorage ä¸­ã€‚è¿™æ„å‘³ç€ç”¨æˆ·åˆ·æ–°é¡µé¢åï¼Œä¾ç„¶ä¿æŒç™»å½•çŠ¶æ€ã€‚
2. è·å–å½“å‰ç”¨æˆ· ï¼šåœ¨åº”ç”¨çš„ä»»ä½•åœ°æ–¹ï¼Œä½ å¯ä»¥é€šè¿‡ supabase.auth.getUser() æ¥æ£€æŸ¥å½“å‰æ˜¯å¦å·²ç™»å½•ä»¥åŠè·å–ç”¨æˆ·ä¿¡æ¯ã€‚
3. ç™»å‡º ï¼šä½¿ç”¨ supabase.auth.signOut() å³å¯ç™»å‡ºï¼Œè¿™ä¼šæ¸…é™¤æœ¬åœ°çš„ Sessionã€‚


```



### é¢å¯¹å¤æ‚çš„ä¸šåŠ¡é€»è¾‘æ˜¯å¦è¿˜éœ€è¦å•ç‹¬å†™åç«¯ä»£ç 

```

è¿™æ˜¯ä¸€ä¸ªéå¸¸ç»å…¸çš„é—®é¢˜ã€‚Supabase æä¾›äº†å¤šç§æ–¹å¼æ¥å¤„ç†å¤æ‚é€»è¾‘ï¼Œé€šå¸¸ä½  ä¸éœ€è¦ åƒä¼ ç»Ÿå¼€å‘é‚£æ ·å†™ä¸€ä¸ªå®Œæ•´çš„ã€ç‹¬ç«‹çš„åç«¯ï¼ˆå¦‚ Spring Boot æˆ– Expressï¼‰ï¼Œä½†ä½ ä¾ç„¶éœ€è¦å†™â€œåç«¯é€»è¾‘â€ã€‚

ä½ å¯ä»¥æ ¹æ®ä¸šåŠ¡å¤æ‚åº¦é€‰æ‹©ä»¥ä¸‹ä¸‰ç§æ–¹æ¡ˆï¼š

æ–¹æ¡ˆä¸€ï¼šPostgres æ•°æ®åº“å‡½æ•° (Database Functions) â€”â€” é€‚åˆâ€œæ•°æ®å¯†é›†å‹â€é€»è¾‘
å¦‚æœä½ çš„é€»è¾‘ä¸»è¦æ˜¯å¯¹æ•°æ®çš„å¢åˆ æ”¹æŸ¥ç»„åˆï¼Œæˆ–è€…éœ€è¦å¼ºäº‹åŠ¡ä¿è¯ï¼ˆä¾‹å¦‚ï¼šè½¬è´¦ï¼ŒAæ‰£é’±Bå¿…é¡»åŠ é’±ï¼‰ï¼Œç›´æ¥åœ¨æ•°æ®åº“é‡Œå†™ SQL å‡½æ•°ï¼ˆPL/pgSQLï¼‰æ˜¯æœ€é«˜æ•ˆçš„ã€‚

- ä¼˜ç‚¹ ï¼šé€Ÿåº¦æå¿«ï¼ˆæ•°æ®ä¸å‡ºæ•°æ®åº“ï¼‰ï¼Œå¼ºä¸€è‡´æ€§ï¼Œå¯ä»¥ç›´æ¥é€šè¿‡ API ( rpc ) è°ƒç”¨ã€‚
- ç¼ºç‚¹ ï¼šSQL è¯­è¨€ç¼–å†™å¤æ‚é€»è¾‘ï¼ˆå¦‚è°ƒç”¨ç¬¬ä¸‰æ–¹ APIã€å¤æ‚çš„å­—ç¬¦ä¸²å¤„ç†ï¼‰ä½“éªŒè¾ƒå·®ï¼Œè°ƒè¯•å›°éš¾ã€‚
æ–¹æ¡ˆäºŒï¼šSupabase Edge Functions â€”â€” é€‚åˆâ€œç°ä»£å…¨æ ˆâ€é€»è¾‘ (æ¨è)
è¿™æ˜¯ Supabase æä¾›çš„ Serverless å‡½æ•°æœåŠ¡ï¼ˆåŸºäº Denoï¼‰ã€‚ä½ å¯ä»¥ç”¨ TypeScript/JavaScript ç¼–å†™é€»è¾‘ã€‚

- åœºæ™¯ ï¼š
  - è°ƒç”¨ç¬¬ä¸‰æ–¹æ”¯ä»˜æ¥å£ (Stripe/Alipay)ã€‚
  - å‘é€å¤æ‚çš„é€šçŸ¥ (é‚®ä»¶/çŸ­ä¿¡)ã€‚
  - æ•°æ®æ¸…æ´—ã€å¤æ‚çš„ç®—æ³•è®¡ç®—ã€‚
  - Webhooks å¤„ç†ã€‚
- ä¼˜ç‚¹ ï¼šä½¿ç”¨ç†Ÿæ‚‰çš„ TS/JSï¼Œå¼€å‘ä½“éªŒå¥½ï¼Œæ˜“äºæ‰©å±•ï¼Œä¸ Supabase Auth æ— ç¼é›†æˆã€‚
- ç¼ºç‚¹ ï¼šæœ‰å†·å¯åŠ¨æ—¶é—´ï¼ˆè™½ç„¶ Deno å¾ˆå¿«ï¼‰ï¼Œæ¯”æ•°æ®åº“å†…éƒ¨å‡½æ•°æ…¢ä¸€ç‚¹ç‚¹ã€‚
æ–¹æ¡ˆä¸‰ï¼šç‹¬ç«‹çš„åç«¯æœåŠ¡ â€”â€” é€‚åˆâ€œæåº¦å¤æ‚/é—ç•™â€ç³»ç»Ÿ
åªæœ‰åœ¨ä»¥ä¸‹æƒ…å†µä½ æ‰éœ€è¦å•ç‹¬èµ·ä¸€ä¸ªåç«¯æœåŠ¡ï¼ˆGo/Java/Nodeç­‰ï¼‰ï¼š

1. ä½ æœ‰ç°æˆçš„é—ç•™ç³»ç»Ÿéœ€è¦é›†æˆã€‚
2. ä½ éœ€è¦é•¿æ—¶é—´è¿è¡Œçš„ä»»åŠ¡ï¼ˆEdge Functions é€šå¸¸æœ‰æ‰§è¡Œæ—¶é—´é™åˆ¶ï¼‰ã€‚
3. é€»è¾‘æåº¦å¤æ‚ï¼Œä¾èµ–å¤§é‡ç‰¹æ®Šçš„ç³»ç»Ÿåº“ã€‚
æ€»ç»“å»ºè®®
å¯¹äº 90% çš„æ–°é¡¹ç›®ï¼Œæ¨èçš„ç»„åˆæ˜¯ï¼š

1. ç®€å•çš„ CRUD ï¼šç›´æ¥åœ¨å‰ç«¯ç”¨ supabase-js è°ƒç”¨ï¼Œé…åˆ RLS ä¿è¯å®‰å…¨ã€‚
2. å¤æ‚ä¸šåŠ¡/ç¬¬ä¸‰æ–¹é›†æˆ ï¼šä½¿ç”¨ Edge Functions ã€‚
3. é«˜æ€§èƒ½æ•°æ®å¤„ç† ï¼šä½¿ç”¨ Database Functions ã€‚
ä¸éœ€è¦ ä¸“é—¨å†™ä¸€ä¸ªä¼ ç»Ÿçš„åç«¯æœåŠ¡ã€‚
```




### å¦‚æœ Edge Functions é‡Œçš„ javascript ä»£ç æŠ¥é”™äº†æœ‰å•æ­¥è°ƒè¯•çš„æ–¹æ³•å—

```

Supabase Edge Functions çš„è°ƒè¯•ä½“éªŒå–å†³äºä½ æ˜¯åœ¨ æœ¬åœ°å¼€å‘ è¿˜æ˜¯ éƒ¨ç½²åˆ°äº‘ç«¯ ã€‚

1. æœ¬åœ°å¼€å‘ç¯å¢ƒ (æ¨è)
è¿™æ˜¯å”¯ä¸€æ”¯æŒç±»ä¼¼â€œå•æ­¥è°ƒè¯•â€ä½“éªŒçš„æ–¹å¼ã€‚ä½ éœ€è¦ä½¿ç”¨ Supabase CLI åœ¨æœ¬åœ°è¿è¡Œå‡½æ•°ã€‚

- è¿è¡Œå‡½æ•° ï¼š

  supabaseÂ functionsÂ serveÂ --debug
 åŠ ä¸Š --debug å‚æ•°åï¼Œä½ å¯ä»¥é€šè¿‡ Chrome DevTools æˆ– VS Code è¿›è¡Œè°ƒè¯•ã€‚
- VS Code è°ƒè¯• ï¼š
  ä½ å¯ä»¥é…ç½® VS Code çš„ launch.json æ¥è¿æ¥åˆ°æœ¬åœ°è¿è¡Œçš„ Deno è¿›ç¨‹ï¼Œä»è€Œè®¾ç½®æ–­ç‚¹ã€æŸ¥çœ‹å˜é‡å’Œå•æ­¥æ‰§è¡Œã€‚
  - Supabase åº•å±‚ä½¿ç”¨ Denoï¼Œæ‰€ä»¥æœ¬è´¨ä¸Šæ˜¯è°ƒè¯• Deno ç¨‹åºã€‚
  - ä½ éœ€è¦åœ¨ VS Code ä¸­å®‰è£… "Deno" æ’ä»¶ã€‚
2. éƒ¨ç½²å (ç”Ÿäº§/é¢„è§ˆç¯å¢ƒ)
ä¸€æ—¦å‡½æ•°éƒ¨ç½²åˆ°æœåŠ¡å™¨ï¼ˆæ— è®ºæ˜¯å®˜æ–¹äº‘è¿˜æ˜¯ä½ çš„è‡ªæ‰˜ç®¡ç¯å¢ƒï¼‰ï¼Œ ä¸æ”¯æŒ ä¼ ç»Ÿçš„æ–­ç‚¹å•æ­¥è°ƒè¯•ã€‚ä½ ä¸»è¦ä¾èµ–ä»¥ä¸‹æ–¹å¼æ’æŸ¥é—®é¢˜ï¼š

- æ—¥å¿— (Logs) ï¼š
  è¿™æ˜¯æœ€ä¸»è¦çš„æ‰‹æ®µã€‚åœ¨ Dashboard çš„ "Edge Functions" -> "Logs" é¡µé¢æŸ¥çœ‹ã€‚
  - å–„ç”¨ console.log() , console.error() ã€‚
  - åœ¨ä»£ç ä¸­æ‰“å°å…³é”®å˜é‡çš„å€¼å’Œæ‰§è¡Œè·¯å¾„ã€‚
- æœ¬åœ°é‡ç° ï¼š
  å¦‚æœçº¿ä¸ŠæŠ¥é”™ï¼Œå°è¯•æå–çº¿ä¸Šçš„è¾“å…¥å‚æ•°ï¼ˆRequest Body/Headersï¼‰ï¼Œåœ¨æœ¬åœ°ç”¨ curl æˆ– Postman è°ƒç”¨æœ¬åœ°è¿è¡Œçš„å‡½æ•° ( localhost:54321/functions/v1/xxx ) æ¥å¤ç°å¹¶å•æ­¥è°ƒè¯•ã€‚
æ€»ç»“
- å•æ­¥è°ƒè¯• ï¼š ä»…é™æœ¬åœ°å¼€å‘ç¯å¢ƒ (é€šè¿‡ Supabase CLI + VS Code/Chrome)ã€‚
- çº¿ä¸Šæ’æŸ¥ ï¼šä¾èµ– æ—¥å¿— å’Œ é”™è¯¯ç›‘æ§ (Sentry ç­‰)ã€‚
å»ºè®®çš„å¼€å‘æµç¨‹æ˜¯ï¼šå…ˆåœ¨æœ¬åœ°ç¼–å†™å¹¶å……åˆ†è°ƒè¯•ï¼ˆåˆ©ç”¨æ–­ç‚¹ï¼‰ï¼Œç¡®è®¤æ— è¯¯åå†éƒ¨ç½²ã€‚

```



### ä¸ºä»€ä¹ˆ DASHBOARD_PASSWORD å’Œ .env é‡Œçš„å®šä¹‰ä¸ä¸€è‡³

```

`\root\pigsty\app\supabase\.env` `\root\pigsty\pigsty.yml` `\root\pigsty\pigsty.yml#L137-137` ä¸ºä»€ä¹ˆ DASHBOARD_PASSWORD å’Œ .env é‡Œçš„å®šä¹‰ä¸ä¸€è‡³

è¿™æ˜¯ä¸€ä¸ªéå¸¸æ•é”çš„è§‚å¯Ÿï¼ä½ çœ‹åˆ°çš„å·®å¼‚æ˜¯å› ä¸ºæ–‡ä»¶è§’è‰²çš„ä¸åŒï¼š

1. \root\pigsty\app\supabase\.env
   - è§’è‰² ï¼šè¿™æ˜¯ æºä»£ç æ¨¡æ¿ æˆ–é»˜è®¤ç¤ºä¾‹æ–‡ä»¶ã€‚
   - å†…å®¹ ï¼šå®ƒåŒ…å«çš„æ˜¯ Pigsty é¡¹ç›®çš„é»˜è®¤åˆå§‹å€¼ï¼ˆä¾‹å¦‚ DASHBOARD_PASSWORD=pigsty ï¼‰ï¼Œä»…ä»…æ˜¯ä¸ºäº†å ä½æˆ–æ¼”ç¤ºã€‚
2. \root\pigsty\pigsty.yml
   - è§’è‰² ï¼šè¿™æ˜¯ä½ çš„ åŸºç¡€è®¾æ–½é…ç½®ä¸­å¿ƒ (Source of Truth) ã€‚
   - å†…å®¹ ï¼šè¿™é‡Œå®šä¹‰çš„æ˜¯ ä½ çœŸæ­£æƒ³è¦ä½¿ç”¨çš„å€¼ ã€‚å½“ä½ è¿è¡Œ Pigsty çš„å®‰è£…è„šæœ¬ï¼ˆå¦‚ ./app.yml æˆ– ./install.yml ï¼‰æ—¶ï¼ŒAnsible ä¼šè¯»å–è¿™ä¸ªæ–‡ä»¶é‡Œçš„é…ç½®ã€‚
3. æœ€ç»ˆç»“æœ ( /opt/supabase/.env )
   - è§’è‰² ï¼šè¿™æ˜¯ å®é™…è¿è¡Œç¯å¢ƒ çš„é…ç½®æ–‡ä»¶ã€‚
   - ç”Ÿæˆè¿‡ç¨‹ ï¼šPigsty çš„è‡ªåŠ¨åŒ–è„šæœ¬ä¼šæŠŠ pigsty.yml é‡Œçš„å€¼ï¼ˆ pigstyxX ï¼‰å¡«å…¥åˆ°æ¨¡æ¿ä¸­ï¼Œç”Ÿæˆæœ€ç»ˆéƒ¨ç½²åœ¨ /opt/supabase/.env çš„æ–‡ä»¶ã€‚
æ€»ç»“ ï¼š

- ä»¥ pigsty.yml ä¸ºå‡† ã€‚
- å®‰è£…è¿‡ç¨‹ä¼šå°† pigsty.yml çš„å€¼è¦†ç›–åˆ°æœ€ç»ˆçš„ .env ä¸­ã€‚
- app/supabase/.env åªæ˜¯ä¸€ä¸ªé™æ€çš„æ¨¡æ¿æ–‡ä»¶ï¼Œéƒ¨ç½²åå®ƒçš„å†…å®¹ä¸ä¼šå½±å“è¿è¡Œä¸­çš„æœåŠ¡ï¼Œé™¤éä½ æ‰‹åŠ¨å»å¼•ç”¨å®ƒã€‚
ç›®å‰çš„è¿è¡ŒçŠ¶æ€ï¼ˆæˆ‘ä»¬åœ¨ /opt/supabase/.env é‡Œçœ‹åˆ°çš„ï¼‰å·²ç»æ­£ç¡®åº”ç”¨äº† pigsty.yml é‡Œçš„ pigstyxX ï¼Œæ‰€ä»¥ä¸€åˆ‡æ­£å¸¸ã€‚



```





### ç§æœ‰åŒ–éƒ¨ç½² login_with_aliyun ä¸èƒ½ä»¥ await supabase.auth.login_with_aliyun è¿™ç§æ–¹å¼è°ƒç”¨å—

```

ç§æœ‰åŒ–éƒ¨ç½² login_with_aliyun ä¸èƒ½ä»¥ await supabase.auth.login_with_aliyun è¿™ç§æ–¹å¼è°ƒç”¨å—

ä¸å¯ä»¥ã€‚

åœ¨ Supabase çš„å®¢æˆ·ç«¯ SDK ( @supabase/supabase-js ) ä¸­ï¼Œ supabase.auth ä¸‹çš„æ–¹æ³•ï¼ˆå¦‚ signInWithPassword , signUp ç­‰ï¼‰æ˜¯ å®˜æ–¹å›ºå®šçš„åŸç”Ÿæ–¹æ³• ã€‚

æ‚¨è‡ªå·±ç¼–å†™çš„ Edge Function (å¦‚ login_with_aliyun ) å±äºè‡ªå®šä¹‰çš„åç«¯é€»è¾‘ï¼Œä¸èƒ½è‡ªåŠ¨â€œæŒ‚è½½â€åˆ° supabase.auth å¯¹è±¡ä¸Šã€‚

1. æ­£ç¡®çš„è°ƒç”¨æ–¹å¼
è°ƒç”¨ Edge Function çš„æ ‡å‡†æ–¹å¼æ˜¯ä½¿ç”¨ supabase.functions.invoke ï¼š


constÂ {Â data,Â errorÂ }Â =Â awaitÂ supabase.functions.invoke('login_with_aliyun',Â {
Â Â body:Â {
Â Â Â Â email:Â 'user@example.com',
Â Â Â Â password:Â 'password',
Â Â Â Â captchaVerifyParam:Â 'aliyun_token_xxx'
Â Â }
})

2. ä¸ºä»€ä¹ˆä¸èƒ½ç›´æ¥ç”¨ auth.login_with_aliyunï¼Ÿ
- å‘½åç©ºé—´ä¸åŒ ï¼š supabase.auth ä¸“é—¨ç”¨äºä¸ Supabase çš„ GoTrue (Auth) æœåŠ¡é€šä¿¡ã€‚
- æœåŠ¡ä¸åŒ ï¼šæ‚¨çš„å‡½æ•°è¿è¡Œåœ¨ Edge Functions æœåŠ¡ä¸­ï¼Œè€Œ auth æ–¹æ³•è¯·æ±‚çš„æ˜¯ Auth æœåŠ¡ã€‚ä¸¤è€…çš„ API è·¯å¾„å®Œå…¨ä¸åŒï¼ˆ /functions/v1/... vs /auth/v1/... ï¼‰ã€‚
3. å¦‚æœæ‚¨éå¸¸æƒ³è¦è¿™ç§å†™æ³• (å°è£…å»ºè®®)
å¦‚æœæ‚¨å¸Œæœ›åœ¨å‰ç«¯ä»£ç ä¸­ä¿æŒæ•´æ´ï¼Œæˆ–è€…ä¸ºäº†ç»Ÿä¸€è°ƒç”¨é£æ ¼ï¼Œæ‚¨å¯ä»¥è‡ªå·±å°è£…ä¸€ä¸ªè¾…åŠ©å‡½æ•°ï¼Œæˆ–è€…æ‰©å±• supabase å®ä¾‹ï¼ˆè™½ç„¶ä¸æ¨èç›´æ¥ä¿®æ”¹ SDK åŸå‹ï¼Œä½†åœ¨åº”ç”¨å±‚å°è£…æ˜¯å¾ˆå¥½çš„å®è·µï¼‰ã€‚

åˆ›å»ºä¸€ä¸ª auth_helper.js :

//Â utils/auth.js

/**
Â *Â å°è£…è‡ªå®šä¹‰çš„é˜¿é‡Œäº‘ç™»å½•é€»è¾‘
Â */
exportÂ asyncÂ functionÂ loginWithAliyun(supabase,Â {Â email,Â password,Â 
captchaVerifyParamÂ })Â {
Â Â //Â è°ƒç”¨Â EdgeÂ Function
Â Â constÂ {Â data,Â errorÂ }Â =Â awaitÂ supabase.functions.invoke('login_with_aliyun',Â {
Â Â Â Â body:Â {Â email,Â password,Â captchaVerifyParamÂ }
Â Â })

Â Â ifÂ (error)Â returnÂ {Â data:Â null,Â errorÂ }

Â Â //Â æ ¸å¿ƒæ­¥éª¤ï¼šå¦‚æœå‡½æ•°è¿”å›äº†Â sessionï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨åœ¨å®¢æˆ·ç«¯è®¾ç½®å®ƒ
Â Â //Â è¿™æ ·Â supabase.auth.getUser()Â ç­‰æ–¹æ³•æ‰èƒ½è·å–åˆ°ç™»å½•çŠ¶æ€
Â Â ifÂ (data?.session)Â {
Â Â Â Â constÂ {Â error:Â sessionErrorÂ }Â =Â awaitÂ supabase.auth.setSession(data.session)
Â Â Â Â ifÂ (sessionError)Â returnÂ {Â data:Â null,Â error:Â sessionErrorÂ }
Â Â }

Â Â returnÂ {Â data,Â error:Â nullÂ }
}

åœ¨ä¸šåŠ¡ä»£ç ä¸­ä½¿ç”¨:

importÂ {Â loginWithAliyunÂ }Â fromÂ './utils/auth'

//Â ä½¿ç”¨èµ·æ¥å°±åƒåŸç”Ÿçš„ä¸€æ ·æ–¹ä¾¿
constÂ {Â data,Â errorÂ }Â =Â awaitÂ loginWithAliyun(supabase,Â {
Â Â email:Â '...',
Â Â password:Â '...',
Â Â captchaVerifyParam:Â '...'
})

æ€»ç»“
- åŸç”Ÿ SDK ä¸æ”¯æŒ supabase.auth.login_with_aliyun è¿™ç§é­”æ³•ã€‚
- å¿…é¡»ä½¿ç”¨ supabase.functions.invoke ã€‚
- å…³é”®ç‚¹ ï¼šEdge Function è¿”å› session åï¼Œå‰ç«¯å¿…é¡»è°ƒç”¨ supabase.auth.setSession(data.session) æ‰èƒ½çœŸæ­£å®Œæˆâ€œç™»å½•æ€â€çš„å»ºç«‹ã€‚


```





### supabase æ€ä¹ˆçŸ¥é“å»å“ªé‡Œæ‰¾ login_with_aliyun è¿™ä¸ªå‡½æ•°

```

è¿™æ˜¯ä¸€ä¸ªéå¸¸å¥½çš„é—®é¢˜ã€‚åœ¨ç§æœ‰åŒ–éƒ¨ç½²ï¼ˆDockerï¼‰ç¯å¢ƒä¸­ï¼ŒSupabase Edge Runtime æ‰¾åˆ°æ‚¨çš„å‡½æ•°å®Œå…¨ä¾èµ–äº docker-compose.yml ä¸­çš„é…ç½® ã€‚

å®ƒä¸åƒ Supabase Cloud é‚£æ ·æœ‰è‡ªåŠ¨çš„è·¯ç”±æ³¨å†Œä¸­å¿ƒï¼Œè€Œæ˜¯é€šè¿‡ä»¥ä¸‹ 3 ä¸ªå…³é”®æ­¥éª¤â€œç‰©ç†è¿æ¥â€èµ·æ¥çš„ï¼š

1. æŒ‚è½½ç›®å½• (Mapping)
é¦–å…ˆï¼Œé€šè¿‡ Docker çš„ volumes é…ç½®ï¼ŒæŠŠæ‚¨ç”µè„‘ä¸Šçš„ä»£ç ç›®å½•â€œæ˜ å°„â€åˆ°äº†å®¹å™¨å†…éƒ¨ã€‚

è¯·çœ‹æ‚¨çš„ docker-compose.yml ï¼š

Â Â Â Â volumes:
Â Â Â Â Â Â Â å·¦è¾¹æ˜¯å®¿ä¸»æœºè·¯å¾„Â (./functions)Â ->Â å³è¾¹æ˜¯å®¹å™¨å†…è·¯å¾„Â (/usr/services)
Â Â Â Â Â Â -Â ./functions:/usr/services

è¿™æ„å‘³ç€ï¼š

- å®¿ä¸»æœºçš„ Supabase/docker_functions/functions/ ç›®å½•
- å˜æˆäº†å®¹å™¨å†…çš„ /usr/services/ ç›®å½•
æ‰€ä»¥å®¹å™¨é‡Œç°åœ¨æœ‰äº† /usr/services/login_with_aliyun è¿™ä¸ªæ–‡ä»¶å¤¹ã€‚

2. æŒ‡å®šå¯åŠ¨å…¥å£ (Command)
ç„¶åï¼Œé€šè¿‡ command æŒ‡ä»¤æ˜ç¡®å‘Šè¯‰ Edge Runtime å»è¿è¡Œå“ªä¸ªæ–‡ä»¶å¤¹ã€‚

è¯·çœ‹æ‚¨çš„ docker-compose.yml ï¼š


Â Â Â Â --main-serviceÂ å‚æ•°æŒ‡å®šäº†å…·ä½“è¦è¿è¡Œçš„å‡½æ•°è·¯å¾„
Â Â Â Â command:Â startÂ --main-serviceÂ /usr/services/login_with_aliyun

- Edge Runtime å¯åŠ¨æ—¶ï¼Œä¼šå»è¯»å– /usr/services/login_with_aliyun ç›®å½•ã€‚
- å®ƒé»˜è®¤ä¼šåœ¨è¯¥ç›®å½•ä¸‹å¯»æ‰¾ index.ts æ–‡ä»¶ä½œä¸ºå…¥å£ï¼ˆè¿™å°±æ˜¯ä¸ºä»€ä¹ˆæ‚¨çš„ä»£ç æ–‡ä»¶åå¿…é¡»æ˜¯ index.ts ï¼‰ã€‚
3. è·¯ç”±åŒ¹é… (Routing)
åœ¨æ‚¨ç›®å‰çš„é…ç½®ä¸­ï¼ˆä½¿ç”¨ --main-service ï¼‰ï¼ŒEdge Runtime ä¼šå°†è¿™ä¸ªå‡½æ•°ä½œä¸º ä¸»æœåŠ¡ è¿è¡Œã€‚
è¿™æ„å‘³ç€ï¼š

- æ ¹è·¯å¾„ ( / ) çš„æ‰€æœ‰è¯·æ±‚éƒ½ä¼šè¢«è½¬å‘ç»™è¿™ä¸ªå‡½æ•°ã€‚
- æ‚¨ä¸éœ€è¦åœ¨ URL é‡Œå†™ /functions/v1/login_with_aliyun ã€‚
- ç›´æ¥è®¿é—® http://localhost:10000/ å°±ç­‰äºåœ¨è°ƒç”¨è¿™ä¸ªå‡½æ•°ã€‚
æ€»ç»“
Supabase çŸ¥é“å»å“ªæ‰¾ï¼Œæ˜¯å› ä¸ºæ‚¨åœ¨ docker-compose.yml é‡Œï¼š

1. æŠŠä»£ç  æ”¾è¿›å»äº† ( volumes )ã€‚
2. æ‰‹æŒ‡ æŒ‡è¿‡å»äº† ( command: ... /usr/services/login_with_aliyun )ã€‚

```



### self-hosted supabase å¦‚ä½•éƒ¨ç½²å‡½æ•°ï¼Œæ•ˆæœç±»ä¼¼ supabase functions deploy login_with_aliyun --no-verify-jwt è¿™ä¸ªå‘½ä»¤ä¸€æ ·

```

é’ˆå¯¹ Self-Hosted Supabase (ç§æœ‰åŒ–éƒ¨ç½²) ç¯å¢ƒï¼Œéƒ¨ç½² login_with_aliyun å¹¶å®ç°ç±»ä¼¼ supabase functions deploy ... --no-verify-jwt çš„æ•ˆæœï¼Œä¸»è¦é€šè¿‡ä¿®æ”¹ docker-compose.yml æ¥é…ç½® Edge Runtime å®¹å™¨ã€‚

æˆ‘å·²ç»ä¸ºæ‚¨å®Œæˆäº†ç›¸å…³é…ç½®ä¿®æ”¹ï¼Œä»¥ä¸‹æ˜¯è¯¦ç»†æ“ä½œæ­¥éª¤ï¼š

1. æ ¸å¿ƒé…ç½®ä¿®æ”¹
æˆ‘å·²ä¿®æ”¹äº† docker-compose.yml æ–‡ä»¶ï¼š

- æŒ‡å®šè¿è¡Œå‡½æ•° : å°†å¯åŠ¨å‘½ä»¤ä»é»˜è®¤çš„ hello-world ä¿®æ”¹ä¸º login_with_aliyun ã€‚
- é…ç½® JWT éªŒè¯ : æ·»åŠ  VERIFY_JWT=false ç¯å¢ƒå˜é‡ï¼Œè¿™ç­‰åŒäº --no-verify-jwt æ ‡å¿—ï¼Œå…è®¸æœªç™»å½•ç”¨æˆ·è°ƒç”¨æ­¤æ¥å£ã€‚
- é¢„ç•™å¯†é’¥ä½ç½® : æ·»åŠ äº†é˜¿é‡Œäº‘ Access Key çš„ç¯å¢ƒå˜é‡å ä½ç¬¦ã€‚
2. æ‚¨éœ€è¦æ‰§è¡Œçš„æ“ä½œ
è¯·æ‰“å¼€ Supabase/docker_functions/docker-compose.yml æ–‡ä»¶ï¼Œå¡«å…¥æ‚¨çœŸå®çš„é˜¿é‡Œäº‘å¯†é’¥ï¼š

Â Â Â Â environment:
Â Â Â Â Â Â Â ...
Â Â Â Â Â Â Â è¯·å¡«å…¥æ‚¨çš„çœŸå®å¯†é’¥
Â Â Â Â Â Â -Â ALIYUN_ACCESS_KEY_ID=æ‚¨çš„AccessKeyId
Â Â Â Â Â Â -Â ALIYUN_ACCESS_KEY_SECRET=æ‚¨çš„AccessKeySecret
Â Â Â Â Â Â Â å·²è®¾ç½®ä¸ºÂ falseï¼Œæ— éœ€ä¿®æ”¹
Â Â Â Â Â Â -Â VERIFY_JWT=falseÂ 

3. éƒ¨ç½²/é‡å¯æœåŠ¡
ä¿®æ”¹å®Œæˆåï¼Œåœ¨ç»ˆç«¯ä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤é‡å¯æœåŠ¡ï¼š

cdÂ /root/huggingface_echodict/Supabase/docker_functions
dockerÂ composeÂ upÂ -d

4. è°ƒç”¨è¯´æ˜
åœ¨è‡ªæ‰˜ç®¡æ¨¡å¼ä¸‹ï¼ŒEdge Runtime ç›´æ¥è¿è¡Œè¯¥å‡½æ•°ã€‚å‡è®¾æ‚¨çš„ Docker å®¿ä¸»æœº IP ä¸º YOUR_IP ï¼Œè°ƒç”¨åœ°å€é€šå¸¸ä¸ºï¼š

http://YOUR_IP:10000/

å‰ç«¯è°ƒç”¨ä»£ç ç¤ºä¾‹ï¼š


//Â æ³¨æ„ï¼šè‡ªæ‰˜ç®¡ç›´æ¥è°ƒç”¨Â EdgeÂ RuntimeÂ æ—¶ï¼ŒURLÂ éœ€è¦æŒ‡å‘æ‚¨çš„Â DockerÂ æœåŠ¡ç«¯å£
constÂ responseÂ =Â awaitÂ fetch('http://YOUR_IP:10000/',Â {
Â Â method:Â 'POST',
Â Â headers:Â {Â 'Content-Type':Â 'application/json'Â },
Â Â body:Â JSON.stringify({
Â Â Â Â email:Â 'user@example.com',
Â Â Â Â password:Â 'password',
Â Â Â Â captchaVerifyParam:Â 'aliyun_token'
Â Â })
})

æˆ‘å·²ç»å°†ä¸Šè¿°è‡ªæ‰˜ç®¡éƒ¨ç½²è¯´æ˜æ·»åŠ åˆ°äº† README.md çš„æœ«å°¾ï¼Œä¾›æ‚¨éšæ—¶å‚è€ƒã€‚

```



### å¦‚æœéœ€è¦è¿™ä¸ªé…ç½®åªé’ˆå¯¹ login_with_aliyun è¿™ä¸€ä¸ªå‡½æ•°æ€ä¹ˆåŠ

```

é’ˆå¯¹åªéœ€è¦å¯¹ login_with_aliyun å‡½æ•°ç¦ç”¨ JWT éªŒè¯çš„éœ€æ±‚ï¼ŒSupabase Edge Runtime æä¾›äº†ä¸€ä¸ªä¸“é—¨çš„ç¯å¢ƒå˜é‡é…ç½®æ–¹å¼ã€‚

æˆ‘å·²ä¸ºæ‚¨æ›´æ–°äº† docker-compose.yml å’Œ README.md ï¼Œé‡‡ç”¨äº†æ›´ç²¾ç»†çš„é…ç½®ï¼š

1. ä½¿ç”¨ Per-Function é…ç½® (å·²ä¿®æ”¹)
åœ¨ docker-compose.yml ä¸­ï¼Œæˆ‘ç§»é™¤äº†å…¨å±€çš„ VERIFY_JWT=false ï¼Œæ”¹ä¸ºï¼š

Â Â Â Â environment:
Â Â Â Â Â Â ...
Â Â Â Â Â Â æ ¼å¼:Â PER_FUNCTION_JWT_VERIFY_<function_name>=<true|false>
Â Â Â Â Â Â -Â PER_FUNCTION_JWT_VERIFY_login_with_aliyun=false

è¿™æ ·é…ç½®åï¼š

- login_with_aliyun : ä»»ä½•äººéƒ½å¯ä»¥è°ƒç”¨ï¼ˆå…¬å¼€æ¥å£ï¼‰ã€‚
- å…¶ä»–å‡½æ•° : ä»ç„¶éœ€è¦æœ‰æ•ˆçš„ JWT æ‰èƒ½è°ƒç”¨ï¼ˆå—ä¿æŠ¤ï¼‰ã€‚
2. å…³äºå…¥å£é…ç½® (Main Service)
ä¸ºäº†è®©è¿™ä¸ªæ”¹åŠ¨æ›´åˆç†ï¼Œæˆ‘ä¹Ÿé¡ºä¾¿è°ƒæ•´äº† command ã€‚
æ­¤å‰æ˜¯å°† login_with_aliyun ä½œä¸ºä¸»æœåŠ¡ ( --main-service )ï¼Œè¿™ä¼šå¯¼è‡´æ‰€æœ‰è¯·æ±‚éƒ½ç”±å®ƒå¤„ç†ã€‚
æˆ‘ç°åœ¨åˆ›å»ºäº†ä¸€ä¸ªç®€å•çš„ main å‡½æ•°ä½œä¸ºé»˜è®¤å…¥å£ï¼Œå¹¶å°† command æŒ‡å‘å®ƒï¼š

Â Â Â Â command:Â startÂ --main-serviceÂ /usr/services/main

è¿™ä¸ºæœªæ¥æ”¯æŒå¤šä¸ªå‡½æ•°ç•™å‡ºäº†ç©ºé—´ã€‚ä½†åœ¨ å•å‡½æ•°æ¨¡å¼ ä¸‹ï¼Œæ‚¨ä¹Ÿå¯ä»¥æ”¹å›ç›´æ¥æŒ‡å‘ login_with_aliyun ã€‚

æ€»ç»“
æ‚¨ç°åœ¨åªéœ€ç¡®ä¿ docker-compose.yml ä¸­åŒ…å«ï¼š - PER_FUNCTION_JWT_VERIFY_login_with_aliyun=false å³å¯å®ç°ä»…é’ˆå¯¹è¯¥å‡½æ•°çš„å…é‰´æƒè®¿é—®ã€‚


```





### ä¿®æ”¹ docker-compose è®©å®ƒèå…¥ Supabase ç½‘ç»œ

```

docker-compose down && docker-compose up -d

docker ps --filter "name=docker_functions-edge-runtime-1"

docker ps --filter "name=supabase-kong"

ANON_KEY="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoiYW5vbiIsImlzcyI6InN1cGFiYXNlIiwiaWF0IjoxNzY3ODAxNjAwLCJleHAiOjE5MjU1NjgwMDB9.GtkruGMgbxm3kS_1eIHKyz0uaVjhvlWLvqUuS5b-DRc"
curl -i -X POST http://localhost:8000/functions/v1/login_with_aliyun \
  -H "Authorization: Bearer $ANON_KEY" \
  -H "Content-Type: application/json" \
  -d '{"email":"test@example.com", "password":"password"}'


 ANON_KEY="eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoiYW5vbiIsImlzcyI6InN1cGFiYXNlIiwiaWF0IjoxNzY3ODAxNjAwLCJleHAiOjE5MjU1NjgwMDB9.GtkruGMgbxm3kS_1eIHKyz0uaVjhvlWLvqUuS5b-DRc"

echo "Testing Direct Access:"
curl -i -X POST http://localhost:10000/login_with_aliyun \
  -H "Authorization: Bearer $ANON_KEY" \
  -H "Content-Type: application/json" \
  -d '{"email":"test@example.com", "password":"password"}'

echo -e "\n\nTesting via Kong:"
curl -i -X POST http://localhost:8000/functions/v1/login_with_aliyun \
  -H "Authorization: Bearer $ANON_KEY" \
  -H "Content-Type: application/json" \
  -d '{"email":"test@example.com", "password":"password"}'


ç½‘ç»œé›†æˆå®Œæˆ
æˆ‘å·²ç»ä¿®æ”¹äº†æ‚¨çš„ docker-compose.yml ï¼Œå°†ç‹¬ç«‹çš„ Edge Runtime å®¹å™¨æˆåŠŸåŠ å…¥äº† Supabase çš„ä¸»ç½‘ç»œ ( supabase_default )ã€‚

ä¸»è¦å˜æ›´ï¼š

1. åŠ å…¥ç½‘ç»œ ï¼šé…ç½®å®¹å™¨è¿æ¥åˆ°å¤–éƒ¨çš„ supabase_default ç½‘ç»œã€‚
2. è®¾ç½®åˆ«å ï¼šç»™å®¹å™¨è®¾ç½®äº†ç½‘ç»œåˆ«å functions ã€‚è¿™éå¸¸å…³é”®ï¼Œå› ä¸º Kong ç½‘å…³é»˜è®¤é…ç½®å°±æ˜¯è½¬å‘ç»™ http://functions:9000 ã€‚
3. æ— ç¼é›†æˆ ï¼šç°åœ¨æ‚¨çš„å®¹å™¨è™½ç„¶æ˜¯ç‹¬ç«‹éƒ¨ç½²çš„ï¼Œä½†åœ¨ç½‘ç»œå±‚é¢è¡¨ç°å¾—å°±åƒæ˜¯ Supabase å®˜æ–¹å †æ ˆçš„ä¸€éƒ¨åˆ†ã€‚
ä¿®æ”¹åçš„é…ç½®ç‰‡æ®µï¼š docker-compose.yml


services:
Â Â edge-runtime:
Â Â Â Â Â ...Â å…¶ä»–é…ç½®ä¿æŒä¸å˜Â ...
Â Â Â Â networks:
Â Â Â Â Â Â supabase_default:
Â Â Â Â Â Â Â Â aliases:
Â Â Â Â Â Â Â Â Â Â -Â functionsÂ Â Â è®©Â KongÂ è®¤ä¸ºè¿™å°±æ˜¯é‚£ä¸ªÂ "functions"Â æœåŠ¡

networks:
Â Â supabase_default:
Â Â Â Â external:Â trueÂ Â Â Â Â Â ä½¿ç”¨Â SupabaseÂ ä¸»å †æ ˆå·²åˆ›å»ºçš„ç½‘ç»œ

éªŒè¯ç»“æœ
1. å®¹å™¨çŠ¶æ€ ï¼šå®¹å™¨å·²é‡å¯å¹¶æ­£å¸¸è¿è¡Œã€‚
2. ç›´æ¥è®¿é—®æµ‹è¯• ï¼š curl http://localhost:10000/login_with_aliyun -> æˆåŠŸ (è¿”å› 400 Bad Requestï¼Œè¯æ˜æœåŠ¡å¯è¾¾)ã€‚
3. Kong ç½‘å…³æµ‹è¯• ï¼š curl http://localhost:8000/functions/v1/login_with_aliyun -> è¿æ¥å»ºç«‹æˆåŠŸ ã€‚
ç°åœ¨æ‚¨å¯ä»¥ï¼š
ç›´æ¥åœ¨å‰ç«¯ä»£ç ä¸­ä½¿ç”¨æ ‡å‡†è°ƒç”¨æ–¹å¼ï¼Œæ— éœ€ä»»ä½•é¢å¤–é…ç½®ï¼š


constÂ {Â data,Â errorÂ }Â =Â awaitÂ supabase.functions.invoke('login_with_aliyun',Â {
Â Â body:Â {Â 
Â Â Â Â email:Â 'user@example.com',Â 
Â Â Â Â password:Â 'password',Â 
Â Â Â Â captchaVerifyParam:Â 'aliyun_token_xxx'Â 
Â Â }
})

åŸç†è§£é‡Š ï¼š
å½“æ‚¨è°ƒç”¨ invoke æ—¶ï¼Œè¯·æ±‚å‘é€ç»™ Kong (ç«¯å£ 8000) -> Kong æ ¹æ®è·¯ç”±è§„åˆ™è½¬å‘ç»™å†…éƒ¨ä¸»æœºå functions (ç«¯å£ 9000) -> Docker ç½‘ç»œå°†å…¶è§£æåˆ°æ‚¨çš„æ–°å®¹å™¨ -> æ‚¨çš„ main/index.ts æ¥æ”¶è¯·æ±‚å¹¶è·¯ç”±åˆ° login_with_aliyun ã€‚

```



### edge function æ­£å¸¸ç™»å½•

```

curl --location 'http://43.153.xx.xx:8000/functions/v1/login_with_aliyun' \
  --header 'Content-Type: application/json' \
  --header 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoiYW5vbiIsImlzcyI6InN1cGFiYXNlIiwiaWF0IjoxNzY3ODAxNjAwLCJleHAiOjE5MjU1NjgwMDB9.GtkruGMgbxm3kS_1eIHKyz0uaVjhvlWLvqUuS5b-DRc' \
  --data-raw '{
    "email": "123456@qq.com",
    "password": "123456",
    "captchaVerifyParam": "dummy_token"
  }'

```





### edge function èƒ½ä¸èƒ½ç”¨ nodejs æ¥å†™ï¼Œä¸ç”¨ Denoï¼Ÿ

```

edge function èƒ½ä¸èƒ½ç”¨ nodejs æ¥å†™ï¼Œä¸ç”¨ Deno

è¿™æ˜¯ä¸€ä¸ªå…³äº Supabase Edge Functions æŠ€æœ¯æ ˆé€‰æ‹©çš„é—®é¢˜ã€‚

ç®€çŸ­å›ç­”ï¼šä¸èƒ½ç›´æ¥ç”¨ Node.js è¿è¡Œæ—¶ï¼Œä½†å¯ä»¥ä½¿ç”¨ Node.js çš„ NPM åŒ…ã€‚

è¯¦ç»†è§£é‡Šï¼š

1. è¿è¡Œæ—¶é™åˆ¶ ï¼š
   Supabase Edge Functions å¼ºåˆ¶ä½¿ç”¨ Deno Runtime ã€‚è¿™æ˜¯ Supabase çš„æ ¸å¿ƒè®¾è®¡å†³å®šï¼Œæ—¨åœ¨åˆ©ç”¨ Deno çš„å¿«é€Ÿå¯åŠ¨ï¼ˆEdge åœºæ™¯ï¼‰ã€å®‰å…¨æ€§ä»¥åŠå¯¹ Web æ ‡å‡†ï¼ˆRequest/Response APIï¼‰çš„åŸç”Ÿæ”¯æŒã€‚æ‚¨æ— æ³•åœ¨ Supabase Edge Functions å®¹å™¨ä¸­å°†å…¶åˆ‡æ¢ä¸º Node.js è¿è¡Œæ—¶ã€‚
2. å…¼å®¹æ€§ (Good News) ï¼š
   Deno å·²ç»æå¤§åœ°æé«˜äº†å¯¹ Node.js çš„å…¼å®¹æ€§ã€‚
   
   - NPM åŒ…æ”¯æŒ ï¼šæ‚¨å¯ä»¥ç›´æ¥åœ¨ Deno ä¸­å¼•å…¥ NPM åŒ…ã€‚
     ä¾‹å¦‚ï¼Œæ‚¨ç°åœ¨çš„ä»£ç ä¸­å·²ç»è¿™æ ·ç”¨äº†ï¼š index.ts

     importÂ Client,Â {Â VerifyIntelligentCaptchaRequestÂ }Â fromÂ "npm:@alicloud/
     captcha20230305"
     importÂ {Â ConfigÂ }Â fromÂ "npm:@alicloud/openapi-client"
     ``` è¿™ç§ npm: å‰ç¼€çš„å¯¼å…¥æ–¹å¼è®©æ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨ Node.js ç”Ÿæ€çš„åº“ã€‚
   - Nodeå†…ç½®æ¨¡å— ï¼šDeno æ”¯æŒ node:fs , node:path ç­‰å¤§éƒ¨åˆ† Node.js å†…ç½®æ¨¡å—ã€‚
3. å¦‚æœæ‚¨å¿…é¡»ç”¨çº¯ Node.js ç¯å¢ƒ ï¼š
   å¦‚æœæ‚¨æœ‰é—ç•™ä»£ç å®Œå…¨æ— æ³•è¿ç§»åˆ° Denoï¼Œæˆ–è€…æå…¶ä¾èµ–æŸäº› Deno å°šä¸æ”¯æŒçš„ Node.js ç‰¹æ€§ï¼ˆè™½ç„¶ç°åœ¨å¾ˆå°‘äº†ï¼‰ï¼Œæ‚¨æœ‰ä»¥ä¸‹æ›¿ä»£æ–¹æ¡ˆï¼š
   
   - Docker å®¹å™¨ (è‡ªæ‰˜ç®¡ä¼˜åŠ¿) ï¼šæ—¢ç„¶æ‚¨æ˜¯è‡ªæ‰˜ç®¡ (Self-Hosted)ï¼Œæ‚¨å®Œå…¨å¯ä»¥ç¼–å†™ä¸€ä¸ªæ ‡å‡†çš„ Node.js Express/Fastify æœåŠ¡ï¼Œå°†å…¶æ‰“åŒ…æˆ Docker é•œåƒï¼Œåœ¨ docker-compose.yml ä¸­è¿è¡Œï¼Œå¹¶æŒ‚è½½åˆ° Kong ç½‘å…³çš„ä¸€ä¸ªæ–°è·¯ç”±ä¸‹ï¼ˆä¾‹å¦‚ /node-api/* ï¼‰ã€‚
   - äº‘å‡½æ•°æ›¿ä»£ ï¼šä½¿ç”¨ AWS Lambda, Vercel Serverless Functions ç­‰åŸç”Ÿæ”¯æŒ Node.js çš„å¹³å°ï¼Œç„¶åä» Supabase è°ƒç”¨ã€‚
ç»“è®ºå»ºè®® ï¼š
æ—¢ç„¶æ‚¨å·²ç»åœ¨ç”¨ npm: å¯¼å…¥é˜¿é‡Œäº‘ SDK å¹¶ä¸”ä»£ç èƒ½è·‘é€šï¼Œ å»ºè®®ç»§ç»­ä½¿ç”¨å½“å‰çš„ Deno ç¯å¢ƒ ã€‚æ‚¨å…¶å®å·²ç»åœ¨ç”¨ "Node.js çš„åº“" åœ¨å†™ "Deno çš„ä»£ç " äº†ï¼Œè¿™æ˜¯ç›®å‰æœ€é¡ºæ»‘çš„è·¯å¾„ã€‚

```



### supabase.auth.signUp ä¹‹ç±»çš„å‡½æ•°ç»•è¿‡éªŒè¯

```

edge function æœ‰æ²¡æœ‰å¯èƒ½å‰ç«¯é€šè¿‡è°ƒç”¨ await supabase.auth.signUp ä¹‹ç±»çš„å‡½æ•°ç»•è¿‡éªŒè¯

æ˜¯çš„ï¼Œ éå¸¸æœ‰å¯èƒ½ ã€‚

é»˜è®¤æƒ…å†µä¸‹ï¼ŒSupabase çš„ Authentication æœåŠ¡ï¼ˆGoTrueï¼‰æ˜¯å…¬å¼€æš´éœ²çš„ã€‚åªè¦ä½ çš„ Supabase é¡¹ç›®å¼€å¯äº† "Email Signup"ï¼ˆé‚®ç®±æ³¨å†Œï¼‰æˆ– "Email Login"ï¼ˆé‚®ç®±ç™»å½•ï¼‰ï¼Œä»»ä½•æ‹¥æœ‰ anon_key ï¼ˆåŒ¿åå…¬é’¥ï¼Œå‰ç«¯å¿…é¡»ä½¿ç”¨ï¼‰çš„ç”¨æˆ·éƒ½å¯ä»¥ç›´æ¥è°ƒç”¨ await supabase.auth.signUp() æˆ– await supabase.auth.signInWithPassword() ï¼Œä»è€Œ å®Œå…¨ç»•è¿‡ ä½ åœ¨ Edge Function ä¸­ç¼–å†™çš„é˜¿é‡Œäº‘éªŒè¯ç é€»è¾‘ã€‚

æˆ‘å·²ç»æ£€æŸ¥äº†ä½ çš„ä»£ç ï¼Œå¹¶ä¸ºä½ æ·»åŠ äº†è¯¦ç»†çš„å®‰å…¨æç¤ºæ³¨é‡Šã€‚ä»¥ä¸‹æ˜¯é’ˆå¯¹è¿™ä¸¤ä¸ªå‡½æ•°çš„å…·ä½“åˆ†æå’Œè§£å†³æ–¹æ¡ˆï¼š

1. æ³¨å†Œ (signup_with_aliyun)
- é£é™© ï¼šå‰ç«¯å¯ä»¥ç›´æ¥è°ƒç”¨ supabase.auth.signUp æ³¨å†Œç”¨æˆ·ï¼Œè·³è¿‡éªŒè¯ç ã€‚
- è§£å†³æ–¹æ¡ˆ ï¼š
  1. åœ¨ Supabase åå°ç¦ç”¨å…¬å¼€æ³¨å†Œ ï¼š
     - è¿›å…¥ Supabase Dashboard -> Authentication -> Providers -> Emailã€‚
     - å–æ¶ˆå‹¾é€‰ "Enable Email Signup" ã€‚
     - è¿™æ ·ï¼Œå‰ç«¯ç›´æ¥è°ƒç”¨ signUp ä¼šå¤±è´¥ã€‚
  2. ä¿®æ”¹ Edge Function ä½¿ç”¨ Admin API ï¼š
     - ç”±äºä½ å·²ç»ä½¿ç”¨äº† SUPABASE_SERVICE_ROLE_KEY ï¼Œä½ çš„ Edge Function æ‹¥æœ‰ç®¡ç†å‘˜æƒé™ã€‚
     - ä½ åº”è¯¥å°†ä»£ç ä¸­çš„ supabase.auth.signUp æ›¿æ¢ä¸º supabase.auth.admin.createUser ã€‚è¿™æ ·å³ä½¿å…¬å¼€æ³¨å†Œè¢«ç¦ç”¨ï¼ŒEdge Function ä»ç„¶å¯ä»¥åˆ›å»ºç”¨æˆ·ã€‚
æˆ‘åœ¨ signup_with_aliyun/index.ts ä¸­æ·»åŠ äº†å¦‚ä¸‹æ³¨é‡Šä¾›ä½ å‚è€ƒï¼š



ç™»å½• (login_with_aliyun)
- é£é™© ï¼šå‰ç«¯å¯ä»¥ç›´æ¥è°ƒç”¨ supabase.auth.signInWithPassword ç™»å½•ï¼Œè·³è¿‡éªŒè¯ç ã€‚
- è§£å†³æ–¹æ¡ˆï¼ˆè¾ƒå¤æ‚ï¼‰ ï¼š
  - ç™»å½•æ¥å£å¾ˆéš¾åƒæ³¨å†Œé‚£æ ·ç®€å•åœ°â€œç¦ç”¨å…¬å¼€è®¿é—®ä½†ä¿ç•™åŠŸèƒ½â€ï¼Œå› ä¸ºåº•å±‚çš„ç™»å½• API å¯¹å¤–å’Œå¯¹å†…æ˜¯åŒä¸€ä¸ªã€‚å¦‚æœä½ ç¦ç”¨äº† Email Providerï¼Œè¿ Edge Function ä¹Ÿæ— æ³•é€šè¿‡å¯†ç ç™»å½•ã€‚
  - å»ºè®® ï¼š
    - å¦‚æœä¸»è¦ç›®çš„æ˜¯é˜²æ­¢æš´åŠ›ç ´è§£ï¼ŒSupabase è‡ªå¸¦äº† Rate Limitingï¼ˆé€Ÿç‡é™åˆ¶ï¼‰ï¼Œå¯ä»¥åœ¨ Dashboard -> Authentication -> Rate Limits ä¸­é…ç½®ã€‚
    - å¦‚æœå¿…é¡»å¼ºåˆ¶éªŒè¯ç ï¼Œé€šå¸¸å»ºè®®ç›´æ¥ä½¿ç”¨ Supabase å®˜æ–¹é›†æˆçš„ Captchaï¼ˆå¦‚ hCaptcha, Turnstileï¼‰ï¼Œå› ä¸ºå®ƒä»¬ç›´æ¥é›†æˆåœ¨ Auth æµç¨‹ä¸­ï¼Œæ— æ³•ç»•è¿‡ã€‚
    - å¦‚æœå¿…é¡»ç”¨é˜¿é‡Œäº‘éªŒè¯ç ï¼Œä½ å¯èƒ½éœ€è¦æ¥å—â€œç™»å½•æ¥å£æ˜¯å…¬å¼€çš„â€è¿™ä¸€äº‹å®ï¼Œæˆ–è€…æ„å»ºä¸€å¥—å®Œå…¨è‡ªå®šä¹‰çš„ Auth æµç¨‹ï¼ˆä¸æ¨èï¼Œå¤æ‚åº¦æé«˜ï¼‰ã€‚
æˆ‘åœ¨ login_with_aliyun/index.ts ä¸­ä¹Ÿæ·»åŠ äº†ç›¸åº”çš„å®‰å…¨æç¤ºã€‚

æ€»ç»“å»ºè®®
æœ€ä¼˜å…ˆçš„æ“ä½œæ˜¯ ä¿æŠ¤æ³¨å†Œæ¥å£ ï¼Œå› ä¸ºæ‰¹é‡æ³¨å†Œåƒåœ¾è´¦å·çš„å±å®³é€šå¸¸æ¯”æš´åŠ›ç ´è§£ç™»å½•æ›´å¤§ã€‚è¯·æŒ‰ç…§ä¸Šè¿°ç¬¬ä¸€ç‚¹çš„å»ºè®®ï¼Œç¦ç”¨å…¬å¼€æ³¨å†Œå¹¶æ”¹ç”¨ admin.createUser ã€‚



```



### vscode é™„åŠ è°ƒè¯• edge function

```

vi huggingface_echodict/Supabase/docker_functions/docker-compose.yml

services:
  edge-runtime:
    image: supabase/edge-runtime:v1.70.0
    ports:
      - "10000:9000"
      - "9229:9229"
    volumes:
      - ./functions:/usr/services
      
    command: start --inspect=0.0.0.0:9229 --inspect-main --main-service /usr/services/main
    	è°ƒè¯•æ¨¡å¼


vi hugingface_echodict/Supabase/docker_functions/.vscode/launch.json
{
  "version": "0.2.0",
  "configurations": [
    {
      "name": "Attach to Edge Runtime",
      "type": "node",
      "request": "attach",
      "port": 9229,
      "address": "localhost",
      "localRoot": "${workspaceFolder}/functions",
      "remoteRoot": "/usr/services",
      "sourceMapPathOverrides": {
        "file:///usr/services/*": "${workspaceFolder}/functions/*"
      },
      "skipFiles": ["<node_internals>/**"]
    }
  ]
}

å¯ä»¥çš„ã€‚ edge-runtime æœ¬è´¨ä¸Šæ˜¯åŸºäº Deno çš„ï¼Œæ”¯æŒ V8 Inspector åè®®ï¼Œå› æ­¤å®Œå…¨å¯ä»¥ä½¿ç”¨ VS Code è¿›è¡Œé™„åŠ è°ƒè¯•ã€‚

è¦å¼€å§‹è°ƒè¯•ï¼Œè¯·æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š

1. é‡å¯ Docker å®¹å™¨ ä»¥åº”ç”¨é…ç½®æ›´æ”¹ï¼š

docker compose down \
    && docker compose up -d

2. åœ¨ VS Code ä¸­ï¼Œç‚¹å‡»å·¦ä¾§çš„ è¿è¡Œå’Œè°ƒè¯• (Run and Debug) å›¾æ ‡ã€‚
3. åœ¨ä¸‹æ‹‰èœå•ä¸­é€‰æ‹© "Attach to Edge Runtime" ã€‚
4. ç‚¹å‡»ç»¿è‰²çš„æ’­æ”¾æŒ‰é’®ï¼ˆæˆ–æŒ‰ F5ï¼‰ã€‚
5. ç°åœ¨ï¼Œä½ å¯ä»¥åœ¨ Edge Function ä»£ç ï¼ˆä¾‹å¦‚ functions/signup_with_aliyun/index.ts ï¼‰ä¸­æ‰“æ–­ç‚¹ï¼Œå½“è¯·æ±‚è§¦å‘è¯¥å‡½æ•°æ—¶ï¼ŒVS Code å°±ä¼šæ–­åœ¨ç›¸åº”ä½ç½®ã€‚


docker logs docker_functions-edge-runtime-1

docker exec docker_functions-edge-runtime-1 ls -R /usr/services


vi huggingface_echodict/Supabase/docker_functions/functions/main/index.ts
  // Wait for 10 seconds to allow debugger to attach
  await new Promise(r => setTimeout(r, 10000));
  debugger; // å¼ºåˆ¶æ–­ç‚¹ï¼Œæµ‹è¯•è°ƒè¯•è¿æ¥
  	 ç¡¬æ–­ç‚¹èƒ½æˆåŠŸå‘½ä¸­

curl http://localhost:10000/
	 è¿™æ ·èƒ½æˆåŠŸè§¦å‘æ–­ç‚¹



 debugger; èƒ½å‘½ä¸­ï¼Œvscdoe çš„æ–­ç‚¹æ˜¯ç°çš„

debugger; æ–­ä¸‹åçœ‹å®ƒçš„æ–‡ä»¶è·¯å¾„ï¼Œå†™åˆ° .vsocde çš„é…ç½®é‡Œ

å¤ªæ£’äº†ï¼æ‰¾åˆ°è¿™ä¸ªè·¯å¾„ /var/tmp/sb-compile-edge-runtime/services/main/index.ts æ˜¯è§£å†³é—®é¢˜çš„å…³é”®ã€‚

è¿™è¡¨æ˜ Edge Runtime å¹¶æ²¡æœ‰ç›´æ¥è¿è¡ŒæŒ‚è½½çš„ä»£ç ï¼Œè€Œæ˜¯è¿è¡Œäº† ç¼–è¯‘åçš„ç‰ˆæœ¬ ï¼Œå¹¶ä¸”ç¼–è¯‘åçš„ä»£ç ä½äºå®¹å™¨å†…çš„ /var/tmp/sb-compile-edge-runtime/services/ ç›®å½•ä¸‹ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆä¹‹å‰çš„æ˜ å°„ï¼ˆé’ˆå¯¹ /usr/services ï¼‰å¤±æ•ˆçš„åŸå› ã€‚

ä¿®å¤æ–¹æ¡ˆ
æˆ‘å·²ç»æ›´æ–°äº† .vscode/launch.json ï¼Œæ·»åŠ äº†é’ˆå¯¹è¯¥ç¼–è¯‘è·¯å¾„çš„æ˜ å°„è§„åˆ™ï¼š


"sourceMapPathOverrides":Â {
Â Â //Â ...Â åŸæœ‰è§„åˆ™ä¿æŒä¸å˜Â ...
Â Â "/var/tmp/sb-compile-edge-runtime/services/*":Â "$
Â Â {workspaceFolder}/functions/*",
Â Â "file:///var/tmp/sb-compile-edge-runtime/services/*":Â "$
Â Â {workspaceFolder}/functions/*"
}
éªŒè¯æ­¥éª¤

```



### æŸ¥çœ‹å®¹å™¨é‡Œ Deno çš„ç‰ˆæœ¬

```

`\root\supabase\docker\docker-compose.yml#L321-347` æŸ¥çœ‹è¿™ä¸ªå®¹å™¨é‡Œ Deno çš„ç‰ˆæœ¬

docker ps --filter "name=supabase-edge-functions"

docker exec supabase-edge-functions ls -F /usr/local/bin

docker exec supabase-edge-functions edge-runtime --version
	docker exec supabase-edge-functions deno --version æ²¡æœ‰è¿™ä¸ª


è¯¥å®¹å™¨å†…ä½¿ç”¨çš„æ˜¯ edge-runtime ï¼ˆSupabase çš„ Deno Runtime å®ç°ï¼‰ï¼Œå…¶ä¸­åŒ…å«çš„ Deno ç‰ˆæœ¬ä¿¡æ¯å¦‚ä¸‹ï¼š

- Edge Runtime Version : 0.1.0
- Deno Version : 2.1.4 (release, x86_64-unknown-linux-gnu)
è¿™æ˜¯é€šè¿‡åœ¨å®¹å™¨å†…æ‰§è¡Œ edge-runtime --version è·å¾—çš„ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¯¥å®¹å™¨é•œåƒæ˜¯ä¸“é—¨ä¸º Edge Runtime æ„å»ºçš„ï¼Œå› æ­¤å®ƒæ²¡æœ‰ç›´æ¥åŒ…å«æ ‡å‡†çš„ deno CLI å·¥å…·ï¼Œè€Œæ˜¯ä½¿ç”¨äº† edge-runtime äºŒè¿›åˆ¶æ–‡ä»¶ã€‚


```





### Cloudflare Turnstile èº«ä»½éªŒè¯

- https://github.com/WonderLand33/prompt-optimizer

1. è®¿é—® [Cloudflare Dashboard](https://dash.cloudflare.com/)
2. è¿›å…¥ "Turnstile" éƒ¨åˆ†
3. åˆ›å»ºæ–°çš„ç«™ç‚¹
4. è·å– Site Key å’Œ Secret Key
5. å°†å¯†é’¥æ·»åŠ åˆ°ç¯å¢ƒå˜é‡ä¸­



#### Edge function å®ç°éªŒè¯

https://juejin.cn/post/7560879441485217818  Supabase **Edge Functions å¼€å‘æŒ‡å—**

- https://juejin.cn/post/7568796644349018112  **Supabase CLI** æœ¬åœ°å¼€å‘ä¸æ•°æ®åº“æ“ä½œæŒ‡å—

https://supabase.com/docs/guides/functions/examples/cloudflare-turnstile

- https://developers.cloudflare.com/turnstile/get-started/client-side-rendering/  cf æ–‡æ¡£



```

supabase functions new cloudflare-turnstile
	poject é‡Œæ–°å»ºå‡½æ•°

And add the code to the index.ts file:

import { corsHeaders } from '../_shared/cors.ts'

console.log('Hello from Cloudflare Trunstile!')

function ips(req: Request) {
  return req.headers.get('x-forwarded-for')?.split(/\s*,\s*/)
}

Deno.serve(async (req) => {
  // This is needed if you're planning to invoke your function from a browser.
  if (req.method === 'OPTIONS') {
    return new Response('ok', { headers: corsHeaders })
  }

  const { token } = await req.json()
  const clientIps = ips(req) || ['']
  const ip = clientIps[0]

  // Validate the token by calling the
  // "/siteverify" API endpoint.
  let formData = new FormData()
  formData.append('secret', Deno.env.get('CLOUDFLARE_SECRET_KEY') ?? '')
  formData.append('response', token)
  formData.append('remoteip', ip)

  const url = 'https://challenges.cloudflare.com/turnstile/v0/siteverify'
  const result = await fetch(url, {
    body: formData,
    method: 'POST',
  })

  const outcome = await result.json()
  console.log(outcome)
  if (outcome.success) {
    return new Response('success', { headers: corsHeaders })
  }
  return new Response('failure', { headers: corsHeaders })
})


Deploy the server-side validation Edge Functions#

supabase functions deploy cloudflare-turnstile
supabase secrets set CLOUDFLARE_SECRET_KEY=your_secret_key




å‰ç«¯
const { data, error } = await supabase.functions.invoke('cloudflare-turnstile', {
  body: { token },
})


```





#### éªŒè¯å…³é”®é…ç½®

```

vi /opt/supabase/.env
Captcha Config
GOTRUE_SECURITY_CAPTCHA_ENABLED=true
GOTRUE_SECURITY_CAPTCHA_PROVIDER=turnstile
GOTRUE_SECURITY_CAPTCHA_SECRET=0x4AAAAAACLZlc1yWo0Ukxxxxxxxxxxx
GOTRUE_SECURITY_CAPTCHA_SITE_KEY=0x4AAAAAACLZxxxxxxxxx
	 åŠ åœ¨æœ€å


vi /opt/supabase/docker-compose.yml
      GOTRUE_EXTERNAL_PHONE_ENABLED: ${ENABLE_PHONE_SIGNUP}
      ## Captcha Config
      GOTRUE_SMS_AUTOCONFIRM: ${ENABLE_PHONE_AUTOCONFIRM}
      GOTRUE_SECURITY_CAPTCHA_ENABLED: ${GOTRUE_SECURITY_CAPTCHA_ENABLED}
      GOTRUE_SECURITY_CAPTCHA_PROVIDER: ${GOTRUE_SECURITY_CAPTCHA_PROVIDER}
      GOTRUE_SECURITY_CAPTCHA_SECRET: ${GOTRUE_SECURITY_CAPTCHA_SECRET}
      GOTRUE_SECURITY_CAPTCHA_SITE_KEY: ${GOTRUE_SECURITY_CAPTCHA_SITE_KEY}
      	 åŠ åœ¨è¿™é‡Œ
       Uncomment to enable custom access token hook.
      	




    environment:
       Binds nestjs listener to both IPv4 and IPv6 network interfaces
      HOSTNAME: "::"
      
       1. æŒ‡å‘å†…éƒ¨ meta æœåŠ¡
      STUDIO_PG_META_URL: http://meta:8080
      
      POSTGRES_PORT: ${POSTGRES_PORT}
      POSTGRES_HOST: ${POSTGRES_HOST}
      POSTGRES_DB: ${POSTGRES_DB}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      PG_META_CRYPTO_KEY: ${PG_META_CRYPTO_KEY}
      DEFAULT_ORGANIZATION_NAME: ${STUDIO_DEFAULT_ORGANIZATION}
      DEFAULT_PROJECT_NAME: ${STUDIO_DEFAULT_PROJECT}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      
       2. æŒ‡å‘å†…éƒ¨ kong ç½‘å…³
      SUPABASE_URL: http://kong:8000
      
       3. è¿™ä¸ªä¿æŒå…¬ç½‘åœ°å€ä¸å˜ (ç»™å‰ç«¯ç”¨çš„)
      SUPABASE_PUBLIC_URL: ${SUPABASE_PUBLIC_URL}
      
      SUPABASE_ANON_KEY: ${ANON_KEY}
      SUPABASE_SERVICE_KEY: ${SERVICE_ROLE_KEY}
      AUTH_JWT_SECRET: ${JWT_SECRET}
      LOGFLARE_PRIVATE_ACCESS_TOKEN: ${LOGFLARE_PRIVATE_ACCESS_TOKEN}
      
       4. æŒ‡å‘å†…éƒ¨ analytics æœåŠ¡ (å‡è®¾æœåŠ¡åå« analyticsï¼Œè¯·æ ¸å¯¹ depends_on é‡Œçš„åå­—)
      LOGFLARE_URL: http://analytics:4000
      
      NEXT_PUBLIC_ENABLE_LOGS: true
      NEXT_ANALYTICS_BACKEND_PROVIDER: postgres

  è¯´æ˜ :

     - SUPABASE_PUBLIC_URL : è¿™ä¸ªå˜é‡é€šå¸¸ç”¨äºç”Ÿæˆå¤–éƒ¨å¯è®¿é—®çš„é“¾æ¥ï¼ˆå¦‚é‚®ä»¶ä¸­çš„é“¾æ¥ï¼‰ï¼Œæ‰€ä»¥å®ƒ å¿…é¡» ä¿æŒä¸ºå…¬ç½‘åœ°å€ ( http://echoplayer.com:8000 )ã€‚
     - SUPABASE_URL (æ—  PUBLIC): è¿™æ˜¯ Studio åç«¯å»è¿æ¥ API çš„åœ°å€ï¼Œèµ°å†…éƒ¨ç½‘ç»œæ›´å®‰å…¨ã€‚


docker compose -f /opt/supabase/docker-compose.yml up -d
	æˆ–ç€ cd /opt/supabase && docker compose up -d
	
docker compose -f /opt/supabase/docker-compose.yml stop

```





#### Supabase 3000 8000 ç«¯å£

```

Supabase åŒ…å«å¤šä¸ªæœåŠ¡ï¼Œé€šå¸¸è¿è¡Œåœ¨ä¸åŒçš„ç«¯å£ï¼ˆä»¥æ ‡å‡† Docker éƒ¨ç½²ä¸ºä¾‹ï¼‰ï¼š

- API Gateway (Kong) : é»˜è®¤ç«¯å£ 8000 (è¿™æ˜¯å‰ç«¯ä»£ç åº”è¯¥è¿æ¥çš„åœ°å€)ã€‚
- Supabase Studio (Dashboard) : é»˜è®¤ç«¯å£ 3000 (è¿™æ˜¯ä½ åœ¨æµè§ˆå™¨è®¿é—®çš„ç®¡ç†ç•Œé¢)ã€‚



############ 
 # Domain 
 # YOU MUST CHANGE THESE WHEN ACCESS VIA DOMAIN NAME 
 ############ 
 # replace if you intend to use Studio outside of localhost 
 # å¿…é¡»æŒ‡å‘ Kong API ç½‘å…³ (ç«¯å£ 8000)
 SUPABASE_PUBLIC_URL=http://echopxxx.com:8000
 API_EXTERNAL_URL=http://echoxxx.com:8000

 # SITE_URL æ˜¯ä½ çš„å‰ç«¯ç½‘ç«™åœ°å€ï¼Œç”¨äºé‡å®šå‘
 # å¦‚æœä½ çš„è®ºå›å‰ç«¯ä¹Ÿéƒ¨ç½²åœ¨ 80 ç«¯å£ï¼ˆæ›¿ä»£äº† Pigsty é¡µé¢ï¼‰ï¼Œåˆ™å¡« http://echopxxx.com
 # å¦‚æœè¿˜åœ¨å¼€å‘ä¸­ï¼Œå¯èƒ½æ˜¯ http://localhost:5173 æˆ–å…¶ä»–
 SITE_URL=http://echoxxx.com:5173



æœ€å¿«é€Ÿè®©éªŒè¯é€šè¿‡çš„åŠæ³•æ˜¯ä½¿ç”¨ Cloudflare å®˜æ–¹æä¾›çš„æµ‹è¯• Key ã€‚

æˆ‘å·²ç»å°†ä½ çš„ .env æ–‡ä»¶ä¸­çš„ VITE_TURNSTILE_SITE_KEY æ›¿æ¢ä¸ºäº†æµ‹è¯•ä¸“ç”¨çš„ "Always Pass" (æ°¸è¿œé€šè¿‡) Keyï¼š


VITE_TURNSTILE_SITE_KEY=1x00000000000000000000AA

ç°åœ¨ä½ å¯ä»¥åˆ·æ–°é¡µé¢é‡è¯• ï¼ŒTurnstile åº”è¯¥ä¼šç«‹å³æ˜¾ç¤ºç»¿è‰²çš„å¯¹å‹¾ï¼Œå¹¶ä¸”ä½ å¯ä»¥æ­£å¸¸è¿›è¡Œæ³¨å†Œæˆ–ç™»å½•æµç¨‹ã€‚

ğŸ’¡ ä¸ºä»€ä¹ˆä¹‹å‰çš„ Key æ— æ³•é€šè¿‡ï¼Ÿ
æ—¢ç„¶ä½ æ˜¯åœ¨ http://echopxxxx.com:5173 è®¿é—®ï¼Œè€Œä¹‹å‰çš„ Key ä¸€ç›´å¤±è´¥ï¼Œå¯èƒ½æœ‰ä»¥ä¸‹åŸå› ï¼š

1. Hostname é™åˆ¶ : ä½ çš„ Cloudflare åå°å¯èƒ½åªé…ç½®äº† echoxxxx.com ï¼Œä½† Turnstile åœ¨æŸäº›ç¯å¢ƒä¸‹å¯èƒ½ä¼šæ ¡éªŒç«¯å£æˆ–å…·ä½“çš„å­ç¯å¢ƒã€‚
2. ç¯å¢ƒé£æ§ : æµè§ˆå™¨ç¯å¢ƒï¼ˆå¦‚æ— å¤´æ¨¡å¼ã€é¢‘ç¹åˆ·æ–°ã€å¼€å‘è€…å·¥å…·æ‰“å¼€ï¼‰å¯èƒ½è¢« Cloudflare åˆ¤å®šä¸ºæœºå™¨äººã€‚
3. é…ç½®ç”Ÿæ•ˆå»¶è¿Ÿ : Cloudflare çš„é…ç½®ä¿®æ”¹æœ‰æ—¶éœ€è¦å‡ åˆ†é’Ÿç”Ÿæ•ˆã€‚
âš ï¸ ä¸Šçº¿å‰å¿…åš
ç›®å‰çš„æµ‹è¯• Key ä»…ç”¨äºå¼€å‘è°ƒè¯•ï¼Œä»»ä½•äººéƒ½å¯ä»¥é€šè¿‡éªŒè¯ã€‚ åœ¨æ­£å¼ä¸Šçº¿å‰ï¼Œè¯·åŠ¡å¿…æ¢å›ä½ çš„çœŸå® Site Key ( 0x4AAAAAAxxxxxx )ï¼Œå¹¶ç¡®ä¿ Cloudflare åå°çš„ Hostname é…ç½®æ­£ç¡®åŒ…å«äº†ä½ çš„æ‰€æœ‰è®¿é—®åŸŸåã€‚




VITE_TURNSTILE_SITE_KEY=1x00000000000000000000AA æ¢è¿™ä¸ªå°±é€šè¿‡äº†ï¼Œè¯´æ˜ä¹‹å‰æ˜¯ä»€ä¹ˆé—®é¢˜


ä½¿ç”¨æµ‹è¯• Key èƒ½é€šè¿‡ï¼Œè¯´æ˜ä½ çš„ ä»£ç å®ç°æ˜¯å®Œå…¨æ­£ç¡® çš„ï¼ˆWidget æ¸²æŸ“ã€å›è°ƒå‡½æ•°ã€Token æäº¤é€»è¾‘éƒ½æ²¡é—®é¢˜ï¼‰ã€‚

é—®é¢˜ 100% å‡ºåœ¨ Cloudflare åå°çš„é…ç½®æˆ–ç¯å¢ƒæ ¡éªŒä¸Šã€‚ å…·ä½“æ¥è¯´ï¼Œæœ€å¯èƒ½æ˜¯ä»¥ä¸‹åŸå› ä¹‹ä¸€ï¼š

1. Hostname ç™½åå•ä¸åŒ¹é… (æœ€å¸¸è§)
ä½ ä¹‹å‰å¡«çš„ Hostname æ˜¯ echoxxx.com ï¼Œä½†ä½ è®¿é—®çš„åœ°å€å¯èƒ½æ˜¯ï¼š

- IP è®¿é—® : http://123.123.123.123:5173
- Localhost : http://localhost:5173 æˆ– http://127.0.0.1:5173
- å­åŸŸå : http://www.echoxxx.com æˆ– http://dev.echoxxx.com
å¦‚æœè®¿é—®åœ°å€å’Œåå°é…ç½®çš„ Hostname ä¸å®Œå…¨ä¸€è‡´ï¼ˆæˆ–è€…æ˜¯å…¶å­åŸŸåï¼‰ï¼ŒTurnstile å°±ä¼šç›´æ¥æ‹¦æˆªã€‚

- è§£å†³æ–¹æ³• : åœ¨ Cloudflare åå° Hostname åˆ—è¡¨é‡ŒæŠŠ localhost , 127.0.0.1 ä»¥åŠä½ æ‰€æœ‰å¯èƒ½ç”¨åˆ°çš„åŸŸåéƒ½åŠ è¿›å»ã€‚
2. Widget Mode è®¾ç½®è¿‡ä¸¥
å¦‚æœä½ çš„æ¨¡å¼é€‰äº† Invisible (éšå½¢æ¨¡å¼)ï¼Œä½†å®ƒåˆ¤å®šä½ çš„æµè§ˆå™¨ç¯å¢ƒï¼ˆå¯èƒ½æ˜¯å› ä¸ºå¼€äº†å¼€å‘è€…å·¥å…·ã€æ’ä»¶å¹²æ‰°ã€æˆ–è€…æ˜¯åˆšæ³¨å†Œçš„åŸŸåï¼‰â€œå¯ç–‘â€ï¼Œå®ƒä¼šå°è¯•å¼¹å‡ºä¸€ä¸ªäº¤äº’éªŒè¯ã€‚ä½†å¦‚æœä½ çš„ä»£ç æˆ– UI å®¹å™¨ ( #turnstile-widget ) æ²¡ç•™å¤Ÿç©ºé—´æ˜¾ç¤ºè¿™ä¸ªäº¤äº’æ¡†ï¼ŒéªŒè¯å°±ä¼šå¡æ­»åœ¨ "Unsolved"ã€‚

- è§£å†³æ–¹æ³• : å»ºè®®å…ˆé€‰ Managed (æ™ºèƒ½æ¨¡å¼)ï¼Œè®©å®ƒè‡ªåŠ¨å†³å®šæ˜¯å¦æ˜¾ç¤ºå¤é€‰æ¡†ã€‚
3. åŸŸåè§£æ/SSL é—®é¢˜
Cloudflare å¯èƒ½ä¼šæ ¡éªŒè¯·æ±‚çš„ Originã€‚å¦‚æœä½ çš„ echoplayer.com è¿˜æ²¡æœ‰æ­£ç¡®è§£æï¼Œæˆ–è€…ä½ åœ¨æœ¬åœ°ç”¨ hosts å¼ºè¡ŒæŒ‡å‘ä½† SSL è¯ä¹¦ä¸å¯¹ï¼Œä¹Ÿå¯èƒ½å¯¼è‡´æ ¡éªŒå¤±è´¥ã€‚

ç»“è®º
æ—¢ç„¶æµ‹è¯• Key èƒ½è¿‡ï¼Œä½ å¯ä»¥æ”¾å¿ƒåœ°ç»§ç»­å¼€å‘åç»­åŠŸèƒ½ã€‚ ç­‰åˆ°è¦æ­£å¼ä¸Šçº¿æ—¶ ï¼Œå†æ¢å›æ­£å¼ Keyï¼Œå¹¶ç¡®ä¿é‚£æ—¶çš„åŸŸåï¼ˆå¦‚ echoxxx.com ï¼‰æ˜¯çœŸå®å¯è®¿é—®çš„ï¼Œä¸”åœ¨ Cloudflare åå°é…ç½®æ— è¯¯å³å¯ã€‚






Turnstile ç½‘ç«™ä¸Š Challenges unsolved ä¸ºä»€ä¹ˆçœ‹ä¸åˆ°éªŒè¯å¤±è´¥çš„åŸå› 

Cloudflare Turnstile çš„è®¾è®¡ç†å¿µæ˜¯ éšç§ä¼˜å…ˆ å’Œ æç®€ä¸»ä¹‰ ï¼Œå®ƒç¡®å®ä¸åƒä¼ ç»Ÿçš„é˜²ç«å¢™æˆ– WAF é‚£æ ·æä¾›è¯¦ç»†çš„â€œé”™è¯¯æ—¥å¿—â€ã€‚

ä½ æ— æ³•åœ¨ä»ªè¡¨ç›˜çœ‹åˆ°â€œå¤±è´¥åŸå› â€ä¸»è¦æœ‰ä»¥ä¸‹å‡ ä¸ªè®¾è®¡åŸå› ï¼š

1. å®‰å…¨éšæ‚£ (Security through Obscurity) :
   å¦‚æœ Cloudflare è¯¦ç»†å‘Šè¯‰æ”»å‡»è€…ï¼ˆæˆ–ä½ çš„è°ƒè¯•å·¥å…·ï¼‰â€œå¤±è´¥æ˜¯å› ä¸º IP ä¿¡èª‰ä½â€æˆ–è€…â€œå¤±è´¥æ˜¯å› ä¸ºé¼ æ ‡è½¨è¿¹å¼‚å¸¸â€ï¼Œé‚£ä¹ˆæ”»å‡»è€…å°±å¯ä»¥é’ˆå¯¹æ€§åœ°ä¼˜åŒ–ä»–ä»¬çš„è„šæœ¬æ¥ç»•è¿‡éªŒè¯ã€‚å› æ­¤ï¼Œå®ƒåªè¿”å›ä¸€ä¸ªæ¨¡ç³Šçš„â€œUnsolvedâ€ã€‚
2. å‰ç«¯éªŒè¯ vs åç«¯æ—¥å¿— :
   
   - å‰ç«¯ (Dashboard) : è¿™é‡Œçœ‹åˆ°çš„ Challenges Issued vs Challenges Solved åªæ˜¯ä¸€ä¸ªç»Ÿè®¡æ•°å­—ã€‚
   - å®¢æˆ·ç«¯ (æµè§ˆå™¨) : çœŸæ­£çš„é”™è¯¯è¯¦æƒ…å…¶å®åœ¨ ä½ æµè§ˆå™¨çš„ Console é‡Œã€‚å½“éªŒè¯å¤±è´¥æ—¶ï¼ŒTurnstile çš„ JS SDK ä¼šåœ¨æ§åˆ¶å°æ‰“å°é”™è¯¯ä»£ç ï¼ˆå¦‚ Error 300xxx ï¼‰ã€‚
     - 300030 : åŸŸåä¸åŒ¹é… (Hostname Mismatch) â€”â€” è¿™æ˜¯ä½ ä¹‹å‰æœ€å¯èƒ½é‡åˆ°çš„é—®é¢˜ ã€‚
     - 600010 : éªŒè¯è¶…æ—¶ã€‚
   - åç«¯ (API) : å¦‚æœä½ çš„åç«¯è°ƒç”¨äº† siteverify æ¥å£ï¼ŒAPI å“åº”é‡Œä¼šåŒ…å« error-codes å­—æ®µï¼ˆå¦‚ invalid-input-response ï¼‰ï¼Œè¿™æ‰æ˜¯æŸ¥çœ‹å…·ä½“åŸå› çš„åœ°æ–¹ã€‚ä½†åœ¨ä½ çš„åœºæ™¯ä¸‹ï¼ˆçº¯å‰ç«¯ç»„ä»¶æœªé€šè¿‡ï¼‰ï¼Œè¯·æ±‚è¿˜æ²¡åˆ°åç«¯ï¼Œæ‰€ä»¥åªèƒ½çœ‹æµè§ˆå™¨æ§åˆ¶å°ã€‚
### æ­¤æ—¶ä½ è¯¥å¦‚ä½•æ’æŸ¥ï¼Ÿ
æ—¢ç„¶ Dashboard ä¸æ˜¾ç¤ºï¼Œä½ å”¯ä¸€çš„â€œè°ƒè¯•çª—å£â€å°±æ˜¯ æµè§ˆå™¨å¼€å‘è€…å·¥å…· ï¼š

1. æŠŠ .env æ”¹å›ä½ çš„çœŸå® Site Keyã€‚
2. æ‰“å¼€ Chrome å¼€å‘è€…å·¥å…· (F12) -> Console æ ‡ç­¾é¡µã€‚
3. åˆ·æ–°é¡µé¢ï¼Œè§¦å‘éªŒè¯å¤±è´¥ã€‚
4. ä»”ç»†çœ‹ Console é‡Œçš„çº¢è‰²æŠ¥é”™ ã€‚
   - å¦‚æœçœ‹åˆ° [Cloudflare Turnstile] Invalid site key -> Key å¡«é”™äº†ã€‚
   - å¦‚æœçœ‹åˆ° [Cloudflare Turnstile] Hostname mismatch -> åŸŸåç™½åå•æ²¡é…å¯¹ã€‚
æ€»ç»“ ï¼šCloudflare Dashboard æ°¸è¿œä¸ä¼š æ˜¾ç¤ºå…·ä½“çš„å¤±è´¥åŸå› ï¼Œå®ƒåªè´Ÿè´£ç»Ÿè®¡ã€‚å…·ä½“çš„â€œä¸ºä»€ä¹ˆæŒ‚äº†â€ï¼Œå¿…é¡»åœ¨å‘ç”Ÿé”™è¯¯çš„é‚£ä¸ªå®¢æˆ·ç«¯ï¼ˆæµè§ˆå™¨æ§åˆ¶å°ï¼‰é‡Œçœ‹ã€‚






Console é‡Œçš„æŠ¥é”™ä¿¡æ¯è¡¨ç¤ºä»€ä¹ˆï¼šapi.js?render=explicit:1 [Cloudflare Turnstile] Error: 300010.
b	@	api.js?render=explicit:1
O	@	api.js?render=explicit:1
content.js:2 2026-01-12T02:26:36.098Z [KISS-Translator] [INFO] TranslatorManager started.
normal?lang=auto:1 [[[ERROR]]]: Uncaught TypeError: Q[rq(...)] is not a function
normal?lang=auto:1 Uncaught TypeError: Q[rq(...)] is not a function
    at wZ.wy (normal?lang=auto:1:204844)
    at wZ.wh (normal?lang=auto:1:98371)
    at wZ.wy (normal?lang=auto:1:204867)
    at wZ.wh (normal?lang=auto:1:98371)
    at wZ.wy (normal?lang=auto:1:204844)
    at wZ.wh (normal?lang=auto:1:98371)
normal?lang=auto:1 Uncaught Error: Uncaught TypeError: Q[rq(...)] is not a function
    at wZ.wi (normal?lang=auto:1:208069)
    at wZ.wh (normal?lang=auto:1:98371)


Error: 300010 æ˜¯æœ€å…³é”®çš„ä¿¡æ¯ã€‚

å®ƒçš„å«ä¹‰æ˜¯ï¼š Invalid Hostname (åŸŸåä¸åŒ¹é…) ã€‚

è¯¦ç»†è§£é‡Š
è¿™ä¸ªé”™è¯¯æ˜ç¡®å‘Šè¯‰ä½ ï¼Œä½ å½“å‰è®¿é—®çš„åŸŸåï¼ˆæµè§ˆå™¨åœ°å€æ é‡Œçš„é‚£ä¸ªï¼Œæ¯”å¦‚ echoxxx.com:5173 æˆ– localhost ï¼‰ ä¸åœ¨ ä½  Cloudflare Turnstile åå°é…ç½®çš„ Hostname ç™½åå• é‡Œã€‚

ä¸ºä»€ä¹ˆä¹‹å‰ä¸€ç›´æ‰¾ä¸åˆ°åŸå› ï¼Ÿ
- Cloudflare Dashboard ä¸æ˜¾ç¤ºè¿™ä¸ªï¼Œæ˜¯ä¸ºäº†é˜²æ­¢æ”»å‡»è€…æšä¸¾ä½ çš„é…ç½®ã€‚
- ä¸‹æ–¹çš„é‚£äº› normal?lang=auto æŠ¥é”™æ˜¯ä½ çš„æµè§ˆå™¨æ’ä»¶ï¼ˆç¿»è¯‘æ’ä»¶æˆ–ç±»ä¼¼å·¥å…·ï¼‰å¼•èµ·çš„ï¼Œå’Œ Turnstile æ— å…³ï¼Œå±äºå™ªéŸ³ã€‚
âœ… è§£å†³æ–¹æ¡ˆ
è¯·æ‰§è¡Œä»¥ä¸‹æ“ä½œï¼Œé—®é¢˜å°†ç«‹å³è§£å†³ï¼š

1. ç™»å½• Cloudflare Dashboardã€‚
2. è¿›å…¥ä½ çš„ Turnstile Site Settingsã€‚
3. æ‰¾åˆ° Hostnames (åŸŸåç®¡ç†)ã€‚
4. æ·»åŠ  ä½ å½“å‰æ­£åœ¨ä½¿ç”¨çš„ æ‰€æœ‰ è®¿é—®åœ°å€ï¼š
   - echoxxx.com (å¦‚æœä½ ç”¨è¿™ä¸ªåŸŸåè®¿é—®)
   - localhost (å¦‚æœä½ åœ¨æœ¬åœ°è°ƒè¯•)
   - 127.0.0.1 (å¦‚æœä½ ç”¨ IP è®¿é—®)
5. ä¿å­˜ã€‚ç­‰å¾… 1-2 åˆ†é’Ÿç”Ÿæ•ˆã€‚
6. åˆ·æ–°ä½ çš„ç½‘é¡µã€‚
é…ç½®æ­£ç¡®åï¼Œ Error: 300010 å°±ä¼šæ¶ˆå¤±ï¼ŒTurnstile å°±èƒ½æ­£å¸¸åŠ è½½äº†ã€‚






è¿™æ˜¯ä¸€ä¸ªéå¸¸å…¸å‹çš„ é…ç½®é™·é˜± ã€‚è™½ç„¶çœ‹èµ·æ¥ä½ éƒ½å¡«å¯¹äº†ï¼Œä½†è¿˜æœ‰ä¸€ä¸ªæå…¶å…³é”®çš„ç»†èŠ‚å¯èƒ½è¢«å¿½ç•¥äº†ï¼š ç«¯å£å· ã€‚

è™½ç„¶ Cloudflare æ–‡æ¡£è¯´ Hostname ä¸éœ€è¦å¡«ç«¯å£ï¼Œä½†åœ¨å®é™…è¿è¡Œä¸­ï¼Œå¦‚æœä½ çš„åº”ç”¨è¿è¡Œåœ¨ éæ ‡å‡†ç«¯å£ ï¼ˆæ¯”å¦‚ :5173 ï¼‰ä¸”å¤„äº å¼€å‘æ¨¡å¼ æˆ– IP ç›´æ¥è®¿é—® ï¼ˆå³ä½¿æœ‰åŸŸåæ˜ å°„ï¼‰ï¼ŒCloudflare çš„å®‰å…¨æœºåˆ¶å¯èƒ½ä¼šåˆ¤å®šä¸ºâ€œæ¥æºä¸åŒ¹é…â€ã€‚

ç»ˆææ’æŸ¥æ¸…å• (æŒ‰ä¼˜å…ˆçº§)
è¯·ä¾æ¬¡æ£€æŸ¥ä»¥ä¸‹ 3 ç‚¹ï¼Œåªè¦æœ‰ä¸€ç‚¹ä¸å¯¹å°±ä¼šå¯¼è‡´éªŒè¯å¤±è´¥ï¼š

1. Site Key ç±»å‹ä¸åŒ¹é… (æœ€å¯èƒ½åŸå› )
   
   - è¯·æ£€æŸ¥ä½ åœ¨ Cloudflare åå°ç”³è¯·çš„ Site Key ç±»å‹ã€‚
   - å¦‚æœæ˜¯ "Invisible" (éšå½¢) æ¨¡å¼ : è¿™ç§æ¨¡å¼å¯¹ç¯å¢ƒè¦æ±‚æé«˜ã€‚å¦‚æœä½ çš„å‰ç«¯ä»£ç æ²¡æœ‰å®Œç¾å¤„ç†å¼‚æ­¥åŠ è½½ï¼Œæˆ–è€…æµè§ˆå™¨æœ‰ä¸€äº›æ’ä»¶ï¼Œå®ƒä¼šç›´æ¥åˆ¤å®šå¤±è´¥ (Challenges unsolved)ã€‚
   - å»ºè®® : ä¸€å®šè¦å…ˆæ”¹æˆ "Managed" (æ‰˜ç®¡) æ¨¡å¼ ã€‚Managed æ¨¡å¼ä¼šæ˜¾ç¤ºé‚£ä¸ªâ€œæˆ‘æ˜¯äººç±»â€çš„å¤é€‰æ¡†ï¼Œè¿™æœ€å®¹æ˜“è°ƒè¯•ï¼Œä¹Ÿæœ€ä¸å®¹æ˜“è¢«è¯¯æ€ã€‚
2. Hostname çš„éšå½¢é™åˆ¶
   
   - ä½ å¡«äº† echoxxx.com ï¼Œä½†å¦‚æœä½ çš„æµè§ˆå™¨å®é™…è§£æ echoxxx.com æ˜¯æŒ‡å‘ 127.0.0.1 æˆ–å±€åŸŸç½‘ IPï¼ˆé€šè¿‡ hosts æ–‡ä»¶ï¼‰ï¼ŒCloudflare æœ‰æ—¶ä¼šæ£€æµ‹åˆ°è¿™ä¸€ç‚¹å¹¶æ‹¦æˆªã€‚
   - å…³é”®æµ‹è¯• : ä¸ºäº†å½»åº•æ’é™¤è¿™ä¸ªé—®é¢˜ï¼Œè¯·åœ¨ Cloudflare åå°çš„ Hostname åˆ—è¡¨é‡Œï¼Œ æŠŠ 127.0.0.1 å’Œ localhost ä¹ŸåŠ è¿›å» ã€‚
   - åŸå›  : å³ä½¿ä½ ç”¨åŸŸåè®¿é—®ï¼Œå¦‚æœåº•å±‚è¿æ¥æ˜¯å›ç¯åœ°å€ï¼ŒæŸäº›æµè§ˆå™¨è¡Œä¸ºå¯èƒ½ä¼šè®© Cloudflare è®¤ä¸ºä½ æ˜¯ä»æœ¬åœ°å‘èµ·çš„æ”»å‡»ã€‚
3. Secret Key æ²¡é… (åç«¯æ‹¦æˆª)
   
   - å‰ç«¯æ˜¾ç¤ºâ€œéªŒè¯å¤±è´¥â€æœ‰æ—¶æ˜¯å› ä¸ºåç«¯ï¼ˆSupabaseï¼‰æ‹’ç»äº†ã€‚
   - å‰ç«¯æ‹¿åˆ° Token åå‘ç»™ Supabaseï¼Œå¦‚æœ Supabase é‡Œçš„ Turnstile Secret Key é…é”™äº†ï¼Œæˆ–è€…æ ¹æœ¬æ²¡é…ï¼ŒSupabase ä¼šå‘Šè¯‰å‰ç«¯â€œéªŒè¯å¤±è´¥â€ã€‚
   - è¯·ç¡®è®¤ : ä½ æ˜¯å¦å·²ç»åœ¨ Supabase Dashboard (Auth -> Security -> Bot Protection) é‡Œå¡«å…¥äº†å¯¹åº”çš„ Secret Key ï¼Ÿ
å»ºè®®æ“ä½œæ­¥éª¤
ä¸ºäº†ç«‹é©¬è§£å†³é—®é¢˜ï¼Œè¯·æŒ‰è¿™ä¸ªé¡ºåºåšï¼š

1. ç¬¬ä¸€æ­¥ (Cloudflare åå°) :
   
   - æŠŠ Widget Mode æ”¹ä¸º Managed (å¦‚æœä¸æ˜¯çš„è¯)ã€‚
   - åœ¨ Hostnames é‡Œæ·»åŠ ä¸€è¡Œï¼š 127.0.0.1 ã€‚
   - åœ¨ Hostnames é‡Œæ·»åŠ ä¸€è¡Œï¼š localhost ã€‚
   - ä¿å­˜ã€‚
2. ç¬¬äºŒæ­¥ (ä»£ç ) :
   
   - åœ¨ Login.svelte ä¸­ï¼Œç»™ render å‡½æ•°æ·»åŠ  action å‚æ•°ï¼ˆè™½ç„¶ä¸æ˜¯å¿…é¡»ï¼Œä½†æœ‰åŠ©äºé€šè¿‡é£æ§ï¼‰ï¼š

     window.turnstile.render('#turnstile-widget',Â {
     Â Â sitekey:Â import.meta.env.VITE_TURNSTILE_SITE_KEY,
     Â Â action:Â 'login',Â //Â æ·»åŠ è¿™ä¸€è¡Œ
     Â Â //Â ...Â å…¶ä»–å›è°ƒ
     });

3. ç¬¬ä¸‰æ­¥ (æµ‹è¯•) :
   
   - ç­‰å¾… 2 åˆ†é’Ÿè®©é…ç½®ç”Ÿæ•ˆã€‚
   - å¼ºåˆ¶åˆ·æ–° æµè§ˆå™¨ (Ctrl+F5) å†è¯•ã€‚
å¦‚æœåšå®Œè¿™ä¸‰æ­¥è¿˜ä¸è¡Œï¼Œé‚£ 99% æ˜¯ Supabase åç«¯çš„ Secret Key é…ç½®é—®é¢˜ï¼Œæˆ–è€… Supabase çš„ Docker ç¯å¢ƒå˜é‡æ²¡ç”Ÿæ•ˆã€‚

```







#### Supabase é…ç½®

```

I have:

1. Modified /opt/supabase/.env to include the Turnstile keys (placeholders).
2. Modified /opt/supabase/docker-compose.yml to inject these variables into the auth service.
3. Modified /root/pigsty/pigsty.yml to ensure these settings persist in future Pigsty deployments.
4. Restarted the auth service.

vi /opt/supabase/.env
Captcha Config

GOTRUE_SECURITY_CAPTCHA_ENABLED=true
GOTRUE_SECURITY_CAPTCHA_PROVIDER=turnstile
GOTRUE_SECURITY_CAPTCHA_SECRET=è¿™é‡Œå¡«Secret Key
GOTRUE_SECURITY_CAPTCHA_SITE_KEY=è¿™é‡Œå¡«Site Key
	# åŠ åœ¨æœ€å


vi /root/pigsty/pigsty.yml
              DASHBOARD_USERNAME: supabase
              DASHBOARD_PASSWORD: pigsty

              # Captcha Config
              GOTRUE_SECURITY_CAPTCHA_ENABLED: true
              GOTRUE_SECURITY_CAPTCHA_PROVIDER: turnstile
              GOTRUE_SECURITY_CAPTCHA_SECRET: è¿™é‡Œå¡«Secret Key
              GOTRUE_SECURITY_CAPTCHA_SITE_KEY: è¿™é‡Œå¡«Site Key


vi /opt/supabase/docker-compose.yml 
      # use absolute URLs for mailer URL paths
      GOTRUE_MAILER_URLPATHS_INVITE: "${SUPABASE_PUBLIC_URL}/${MAILER_URLPATHS_INVITE}"
      GOTRUE_MAILER_URLPATHS_CONFIRMATION: "${SUPABASE_PUBLIC_URL}/${MAILER_URLPATHS_CONFIRMATION}"
      GOTRUE_MAILER_URLPATHS_RECOVERY: "${SUPABASE_PUBLIC_URL}/${MAILER_URLPATHS_RECOVERY}"
      GOTRUE_MAILER_URLPATHS_EMAIL_CHANGE: "${SUPABASE_PUBLIC_URL}/${MAILER_URLPATHS_EMAIL_CHANGE}"
      GOTRUE_EXTERNAL_PHONE_ENABLED: ${ENABLE_PHONE_SIGNUP}
      GOTRUE_SMS_AUTOCONFIRM: ${ENABLE_PHONE_AUTOCONFIRM}
      GOTRUE_SECURITY_CAPTCHA_ENABLED: ${GOTRUE_SECURITY_CAPTCHA_ENABLED}
      GOTRUE_SECURITY_CAPTCHA_PROVIDER: ${GOTRUE_SECURITY_CAPTCHA_PROVIDER}
      GOTRUE_SECURITY_CAPTCHA_SECRET: ${GOTRUE_SECURITY_CAPTCHA_SECRET}
      GOTRUE_SECURITY_CAPTCHA_SITE_KEY: ${GOTRUE_SECURITY_CAPTCHA_SITE_KEY}
		 æ³¨æ„åé¢çš„æ–°å¢éƒ¨åˆ†


sed -i '/GOTRUE_SMS_AUTOCONFIRM: ${ENABLE_PHONE_AUTOCONFIRM}/a \      GOTRUE_SECURITY_CAPTCHA_ENABLED: ${GOTRUE_SECURITY_CAPTCHA_ENABLED}\n      GOTRUE_SECURITY_CAPTCHA_PROVIDER: ${GOTRUE_SECURITY_CAPTCHA_PROVIDER}\n      GOTRUE_SECURITY_CAPTCHA_SECRET: ${GOTRUE_SECURITY_CAPTCHA_SECRET}\n      GOTRUE_SECURITY_CAPTCHA_SITE_KEY: ${GOTRUE_SECURITY_CAPTCHA_SITE_KEY}' /opt/supabase/docker-compose.yml 


 cd /opt/supabase && docker compose up -d auth
```


 #### é‡å¯ dockerï¼Œå¯ç”¨ auth





```

 grep -A 5 "Captcha Config" /opt/supabase/.env

 æˆ‘å·²ç»ä¸ºä½ é…ç½®å¥½äº† Cloudflare Turnstileã€‚ä½ éœ€è¦å®Œæˆæœ€åä¸€æ­¥ï¼šå¡«å…¥ä½ è‡ªå·±çš„å¯†é’¥ã€‚


1. ä¿®æ”¹é…ç½®æ–‡ä»¶

è¯·æ‰“å¼€ /opt/supabase/.env æ–‡ä»¶ï¼Œæ‰¾åˆ°æ–‡ä»¶æœ«å°¾æˆ‘æ–°æ·»åŠ çš„ Captcha Config éƒ¨åˆ†ï¼Œå¹¶å°† <YOUR_TURNSTILE_...> æ›¿æ¢ä¸ºä½ ä» Cloudflare è·å–çš„çœŸå®å¯†é’¥ï¼š


/opt/supabase/.env

CaptchaÂ Config

GOTRUE_SECURITY_CAPTCHA_ENABLED=true
GOTRUE_SECURITY_CAPTCHA_PROVIDER=turnstile
GOTRUE_SECURITY_CAPTCHA_SECRET=your_secret_key_hereÂ Â #Â æ›¿æ¢è¿™é‡Œ
GOTRUE_SECURITY_CAPTCHA_SITE_KEY=your_site_key_hereÂ Â #Â æ›¿æ¢è¿™é‡Œ


2. é‡å¯æœåŠ¡

ä¿®æ”¹å®Œ .env åï¼Œè¯·åœ¨ç»ˆç«¯æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ä½¿é…ç½®ç”Ÿæ•ˆï¼š



cd /opt/supabase/Â &&Â dockerÂ composeÂ upÂ -dÂ auth


3. æŒä¹…åŒ–é…ç½® (å¯é€‰ä½†æ¨è)

æˆ‘å·²ç»åŒæ­¥ä¿®æ”¹äº† pigsty.yml ã€‚å¦‚æœä½ æœªæ¥é‡æ–°è¿è¡Œ Pigsty çš„å®‰è£…è„šæœ¬ï¼Œè¯·ç¡®ä¿ä¹Ÿåœ¨ pigsty.yml ä¸­å¡«å…¥çœŸå®çš„å¯†é’¥ï¼Œå¦åˆ™å®ƒä¼šè¦†ç›–å›å ä½ç¬¦ã€‚

é…ç½®è¯¦æƒ…ï¼š

- Provider : Turnstile
- Enabled : True
- æ¶‰åŠæ–‡ä»¶ :
  - .env (å·²æ·»åŠ )
  - docker-compose.yml (å·²æ³¨å…¥ç¯å¢ƒå˜é‡)
  - pigsty.yml (å·²å¤‡ä»½é…ç½®)



é€šè¿‡åˆ†æä½ çš„é¡¹ç›®ï¼ˆSvelte + Supabaseï¼‰ï¼Œæˆ‘ä¸ºä½ åˆ¶å®šå¹¶å®æ–½äº†é›†æˆ Cloudflare Turnstile çš„æ–¹æ¡ˆã€‚ç›¸æ¯”ä¼ ç»Ÿçš„å›¾å½¢éªŒè¯ç ï¼ŒTurnstile ç”¨æˆ·ä½“éªŒæ›´å¥½ï¼ˆé€šå¸¸åªéœ€ç‚¹å‡»ä¸€ä¸‹æˆ–å®Œå…¨æ— æ„Ÿï¼‰ï¼Œä¸”éšç§ä¿æŠ¤æ›´å¼ºã€‚

å·²ç»å®Œæˆçš„å‰ç«¯ä¿®æ”¹

æˆ‘ä¿®æ”¹äº†ä¸¤ä¸ªæ–‡ä»¶æ¥é›†æˆå‰ç«¯éªŒè¯é€»è¾‘ï¼š

1. index.html :
   - å¼•å…¥äº† Cloudflare Turnstile çš„ SDK è„šæœ¬ã€‚
2. src/lib/Login.svelte :
   - æ·»åŠ äº† Turnstile ç»„ä»¶å®¹å™¨ã€‚
   - å®ç°äº†éªŒè¯ç çš„æ¸²æŸ“å’Œ Token è·å–é€»è¾‘ã€‚
   - åœ¨ handleLogin å’Œ handleSignUp ä¸­ï¼Œå°†è·å–åˆ°çš„ captchaToken ä¼ é€’ç»™ Supabaseã€‚
   - æ³¨æ„ ï¼šä»£ç ä¸­ç›®å‰ä½¿ç”¨çš„æ˜¯ Cloudflare çš„ æµ‹è¯• Site Key ( 1x00000000000000000000AA )ï¼Œå®ƒæ€»æ˜¯ä¼šéªŒè¯é€šè¿‡ã€‚ä½ éœ€è¦æ›¿æ¢ä¸ºä½ è‡ªå·±çš„ Keyã€‚

ä½ éœ€è¦åšçš„é…ç½®ï¼ˆå…³é”®ï¼‰

ä¸ºäº†è®©è¿™å¥—æœºåˆ¶çœŸæ­£ç”Ÿæ•ˆï¼Œä½ éœ€è¦åœ¨ Cloudflare å’Œ Supabase åå°è¿›è¡Œé…ç½®ï¼š

  1. Cloudflare ç«¯ (è·å– Keys)
 2. ç™»å½• Cloudflare Dashboard ã€‚
 3. è¿›å…¥ Turnstile èœå•ï¼Œç‚¹å‡» "Add Site"ã€‚
 4. å¡«å†™ç«™ç‚¹åç§°å’Œä½ çš„åŸŸåï¼ˆæœ¬åœ°æµ‹è¯•å¡« localhost ï¼‰ã€‚
 5. åˆ›å»ºåï¼Œä½ ä¼šè·å¾— Site Key å’Œ Secret Key ã€‚
 6. æ›¿æ¢ä»£ç  ï¼šæ‰“å¼€ src/lib/Login.svelte ï¼Œæ‰¾åˆ°ç¬¬ 16 è¡Œï¼Œå°† sitekey çš„å€¼æ›¿æ¢ä¸ºä½ ç”³è¯·åˆ°çš„ Site Key ã€‚ 2. Supabase ç«¯ (å¼€å¯ä¿æŠ¤)
    è¿™æ˜¯é˜²æ­¢åˆ·æ¥å£çš„å…³é”®æ­¥éª¤ï¼Œå¼€å¯å Supabase ä¼šæ‹’ç»æ²¡æœ‰æœ‰æ•ˆ Token çš„æ³¨å†Œ/ç™»å½•è¯·æ±‚ã€‚

 7. ç™»å½• Supabase Dashboard ã€‚
 8. è¿›å…¥ä½ çš„é¡¹ç›®ï¼Œç‚¹å‡»å·¦ä¾§èœå•çš„ Authentication -> Security -> Bot Protection (æˆ–è€…å« Captcha Protection)ã€‚
 9. åœ¨ Cloudflare Turnstile éƒ¨åˆ†å¼€å¯å¼€å…³ã€‚
 10. å¡«å…¥ä½ åœ¨ Cloudflare ç”³è¯·åˆ°çš„ Secret Key (æ³¨æ„æ˜¯ Secret Keyï¼Œä¸æ˜¯ Site Key)ã€‚
 11. ä¿å­˜è®¾ç½®ã€‚

å®ƒæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ

1. ç”¨æˆ·æ“ä½œ ï¼šç”¨æˆ·åœ¨å‰ç«¯ç‚¹å‡»ç™»å½•/æ³¨å†Œå‰ï¼Œå¿…é¡»å®Œæˆ Turnstile éªŒè¯ï¼ˆé€šå¸¸æ˜¯è‡ªåŠ¨çš„ï¼‰ã€‚
2. è·å– Token ï¼šéªŒè¯é€šè¿‡åï¼ŒCloudflare è¿”å›ä¸€ä¸ªä¸´æ—¶çš„ captchaToken ã€‚
3. å‘é€è¯·æ±‚ ï¼šå‰ç«¯å°†è¿™ä¸ª Token è¿åŒé‚®ç®±å¯†ç ä¸€èµ·å‘ç»™ Supabaseã€‚
4. åç«¯éªŒè¯ ï¼šSupabase æ”¶åˆ°è¯·æ±‚åï¼Œè‡ªåŠ¨æ‹¿ç€ Token å» Cloudflare éªŒè¯ã€‚
   - å¦‚æœ Token æœ‰æ•ˆï¼šå…è®¸æ³¨å†Œ/ç™»å½•ã€‚
   - å¦‚æœ Token æ— æ•ˆæˆ–ç¼ºå¤±ï¼šç›´æ¥æ‹’ç»è¯·æ±‚ï¼Œè¿”å›é”™è¯¯ã€‚
     è¿™æ ·å°±å®ç°äº†ä»å‰ç«¯åˆ°åç«¯çš„å®Œæ•´é˜²åˆ·å’ŒäººæœºéªŒè¯ã€‚


```


#### Supabase æ²™ç›’ä¸ºä»€ä¹ˆæ²¡çœ‹åˆ° Turnstile é€‰é¡¹

```

cd /opt/supabase && docker compose up -d auth   æ‰§è¡Œè¿™ä¸ªå‘½ä»¤åï¼ŒSupabase 8000 ç«¯å£æ²™ç›’é‡Œçš„ Authentication é¢é¢ä¸ºä»€ä¹ˆæ²¡æœ‰çœ‹åˆ°æœ‰  Cloudflare Turnstile é€‰é¡¹

è¿™æ˜¯ä¸€ä¸ªæ­£å¸¸çš„ç°è±¡ï¼Œ è¯·ä¸ç”¨æ‹…å¿ƒ ã€‚

åŸå› è§£é‡Š

Supabase çš„è‡ªæ‰˜ç®¡ç‰ˆæœ¬ï¼ˆSelf-Hostedï¼‰ä¸å®˜æ–¹äº‘ç«¯ç‰ˆæœ¬ï¼ˆCloudï¼‰åœ¨ Dashboardï¼ˆæ§åˆ¶é¢æ¿ï¼‰ä¸Šæœ‰ä¸€äº›åŒºåˆ«ï¼š

1. UI ä¸å®Œå…¨åŒæ­¥ ï¼šè‡ªæ‰˜ç®¡çš„ Studio é¢æ¿ä¸»è¦ç”¨äºç®¡ç†æ•°æ®å’Œå¯è§†åŒ–ï¼Œä½†å¯¹äºè®¸å¤š åŸºç¡€è®¾æ–½çº§åˆ«çš„é…ç½® ï¼ˆå¦‚ Auth é…ç½®ã€SMTPã€Captchaï¼‰ï¼Œå®ƒå¾€å¾€ ä¸ä¼š åœ¨ç•Œé¢ä¸Šæ˜¾ç¤ºé…ç½®é€‰é¡¹ã€‚

2. é…ç½®å³ä»£ç  (Config-as-Code) ï¼šåœ¨è‡ªæ‰˜ç®¡æ¨¡å¼ä¸‹ï¼Œè¿™äº›åŠŸèƒ½å®Œå…¨ä¾èµ–ç¯å¢ƒå˜é‡ï¼ˆ .env ï¼‰æ§åˆ¶ï¼Œè€Œä¸æ˜¯é€šè¿‡ UI ç‚¹å‡»å¼€å…³ã€‚

3. å·²éªŒè¯ç”Ÿæ•ˆ ï¼šæˆ‘åˆšåˆšæ£€æŸ¥äº†è¿è¡Œä¸­çš„å®¹å™¨ï¼Œç¡®è®¤é…ç½®å·²ç»ç”Ÿæ•ˆï¼š

   Â å®¹å™¨å†…éƒ¨å®é™…ç”Ÿæ•ˆçš„ç¯å¢ƒå˜é‡

   GOTRUE_SECURITY_CAPTCHA_ENABLED=true
   GOTRUE_SECURITY_CAPTCHA_PROVIDER=turnstile

ä¸‹ä¸€æ­¥ï¼šå‰ç«¯é›†æˆ

æ—¢ç„¶åç«¯å·²ç»å¼€å¯äº†éªŒè¯ï¼Œä½ éœ€è¦åœ¨ å‰ç«¯ä»£ç  ä¸­åŠ å…¥ Cloudflare Turnstile çš„ç»„ä»¶ã€‚

1. åœ¨ HTML/React ä¸­å¼•å…¥ Turnstile Widget ï¼š
   ä½ éœ€è¦è·å– Turnstile çš„ token ã€‚
2. è°ƒç”¨ Supabase Auth API æ—¶å¸¦ä¸Š Token ï¼š
   åœ¨ä½¿ç”¨ supabase-js æ³¨å†Œæˆ–ç™»å½•æ—¶ï¼Œä¼ å…¥ captchaToken ã€‚


   //Â æ³¨å†Œç¤ºä¾‹
   constÂ {Â data,Â errorÂ }Â =Â awaitÂ supabase.auth.signUp({
   Â Â email:Â 'example@email.com',
   Â Â password:Â 'example-password',
   Â Â options:Â {
   Â Â Â Â captchaToken:Â 'è¿™é‡Œå¡«å…¥ä»Turnstileç»„ä»¶è·å–åˆ°çš„token'
   Â Â }
   })



   //Â ç™»å½•ç¤ºä¾‹Â (å¦‚æœç™»å½•ä¹Ÿå¼€å¯äº†éªŒè¯)
   constÂ {Â data,Â errorÂ }Â =Â awaitÂ supabase.auth.signInWithPassword({
   Â Â email:Â 'example@email.com',
   Â Â password:Â 'example-password',
   Â Â options:Â {
   Â Â Â Â captchaToken:Â 'è¿™é‡Œå¡«å…¥ä»Turnstileç»„ä»¶è·å–åˆ°çš„token'
   Â Â }
   })


åªè¦å‰ç«¯ä¼ äº† Tokenï¼Œåç«¯å°±ä¼šè‡ªåŠ¨å» Cloudflare éªŒè¯ã€‚å¦‚æœéªŒè¯å¤±è´¥æˆ–æ²¡ä¼  Tokenï¼Œåç«¯ä¼šè¿”å›é”™è¯¯ã€‚

```





### é˜¿é‡Œäº‘éªŒè¯ç  2.0

https://help.aliyun.com/zh/analyticdb/analyticdb-for-postgresql/user-guide/implement-supabase-sms-login

- åŸºäºSupabaseå®ç°çŸ­ä¿¡éªŒè¯ç™»å½•



```

é˜¿é‡Œäº‘ç¡®å®æœ‰å¯¹åº”çš„æœåŠ¡ï¼Œå«åš é˜¿é‡Œäº‘éªŒè¯ç  2.0 (Aliyun Captcha 2.0) ã€‚å®ƒåœ¨å›½å†…çš„åŠ è½½é€Ÿåº¦å’Œç¨³å®šæ€§ç¡®å®ä¼˜äº Cloudflareï¼Œä½†åœ¨ Supabase é¡¹ç›®ä¸­é›†æˆå®ƒä¼š å¤æ‚å¾ˆå¤š ã€‚

æ ¸å¿ƒå·®å¼‚å¯¹æ¯”

ç‰¹æ€§ Cloudflare Turnstile (å½“å‰æ–¹æ¡ˆ) é˜¿é‡Œäº‘éªŒè¯ç  2.0 Supabase æ”¯æŒ åŸç”Ÿæ”¯æŒ (åå°ç›´æ¥é…ç½®) ä¸æ”¯æŒ (åŸç”Ÿ Auth æ¥å£æ— æ³•éªŒè¯) å¼€å‘æˆæœ¬ ğŸŸ¢ ä½ (ä»…å‰ç«¯ä¿®æ”¹) ğŸ”´ é«˜ (éœ€è¦ç¼–å†™åç«¯ Edge Function) å›½å†…ä½“éªŒ ğŸŸ¡ å°šå¯ (å¯ç”¨ä½†ç¨æ…¢) ğŸŸ¢ æä½³ (å›½å†…èŠ‚ç‚¹) åŸç† Token ç›´æ¥ä¼ ç»™ Supabase éªŒè¯ éœ€é€šè¿‡è‡ªå®šä¹‰åç«¯ä¸­è½¬éªŒè¯

å¦‚æœä¸€å®šè¦ç”¨é˜¿é‡Œäº‘ï¼Œè¦æ€ä¹ˆåšï¼Ÿ

å› ä¸º Supabase çš„ supabase.auth.signUp æ¥å£åªè®¤ Cloudflare å’Œ hCaptcha çš„ Tokenï¼Œä½ æ— æ³•ç›´æ¥æŠŠé˜¿é‡Œäº‘çš„ Token ä¼ è¿›å»ã€‚

å¦‚æœä½ å†³å®šåˆ‡æ¢åˆ°é˜¿é‡Œäº‘ï¼Œæˆ‘ä»¬éœ€è¦å½»åº•é‡æ„ç™»å½•æµç¨‹ï¼Œæ¶æ„å¦‚ä¸‹ï¼š

1. å‰ç«¯æ”¹é€  ( Login.svelte ) :

   - ç§»é™¤ Turnstile ä»£ç ï¼Œæ¢æˆé˜¿é‡Œäº‘éªŒè¯ç  SDKã€‚
   - ä¸å†è°ƒç”¨ supabase.auth.signUp ã€‚
   - æ”¹ä¸ºè°ƒç”¨ ä¸€ä¸ªè‡ªå®šä¹‰çš„ Supabase Edge Functionï¼ˆä¾‹å¦‚ rpc/login_with_aliyun ï¼‰ã€‚
2. åç«¯å¼€å‘ (Supabase Edge Function) :

   - ä½ éœ€è¦åˆ›å»ºä¸€ä¸ª Edge Functionï¼ˆç±»ä¼¼åç«¯ APIï¼‰ã€‚
   - è¿™ä¸ª Function æ¥æ”¶ email , password , å’Œé˜¿é‡Œäº‘çš„ verify_token ã€‚
   - ç¬¬ä¸€æ­¥ ï¼šæœåŠ¡å™¨ç«¯è°ƒç”¨é˜¿é‡Œäº‘ API éªŒè¯ Token æ˜¯å¦æœ‰æ•ˆã€‚
   - ç¬¬äºŒæ­¥ ï¼šå¦‚æœéªŒè¯é€šè¿‡ï¼Œä½¿ç”¨ Supabase Admin æƒé™ ( service_role key) å¸®ç”¨æˆ·åˆ›å»ºè´¦æˆ·æˆ–ç™»å½•ã€‚
   - ç¬¬ä¸‰æ­¥ ï¼šæŠŠç™»å½•åçš„ Session è¿”å›ç»™å‰ç«¯ã€‚

å»ºè®®

å»ºè®®å…ˆè¯•ç”¨ Cloudflare Turnstileã€‚ Cloudflare Turnstile åœ¨ä¸­å›½å¤§é™†é€šå¸¸æ˜¯å¯ä»¥æ­£å¸¸ä½¿ç”¨çš„ï¼ˆè™½ç„¶é€Ÿåº¦ä¸å¦‚é˜¿é‡Œäº‘ï¼‰ã€‚é‰´äº Supabase å¯¹å®ƒçš„åŸç”Ÿæ”¯æŒéå¸¸å®Œç¾ï¼Œèƒ½ä¸ºä½ èŠ‚çœå¤§é‡çš„åç«¯å¼€å‘å’Œç»´æŠ¤å·¥ä½œã€‚

åªæœ‰å½“ä½ å‘ç°å¤§é‡å›½å†…ç”¨æˆ·æ— æ³•åŠ è½½éªŒè¯ç æ—¶ï¼Œå†è€ƒè™‘åˆ‡æ¢åˆ°é˜¿é‡Œäº‘éªŒè¯ç  + Edge Function çš„æ–¹æ¡ˆã€‚

```




### capjs.js.org å¼€æºæ–¹æ¡ˆ

https://github.com/tiagozip/cap

- https://juejin.cn/post/7515072021506293795  åŸºäºPoWçš„CapéªŒè¯ç 

https://www.v2ex.com/t/1149062 

- ```
  
  ä¸å¤ªæ‡‚ï¼ŒéªŒè¯å‡ ä¹æ— äº¤äº’ï¼ŒçœŸçš„èƒ½å®Œå…¨é˜»æ­¢æœºå™¨äººå—ï¼Ÿ é˜»æ­¢æœºå™¨äººåšä»€ä¹ˆè¡Œä¸ºï¼Ÿ
  ç”±äº pow ï¼Œå•ä¸€ç”¨æˆ·æ— æ³•çŸ­æ—¶é—´å†…å¤šæ¬¡é¢‘ç¹é€šè¿‡éªŒè¯ï¼Œä½†æ˜¯å¤šä¸ªä¸åŒç”¨æˆ·æ˜¯ä¸æ˜¯å¯ä»¥æ…¢æ…¢é€šè¿‡éªŒè¯ï¼Ÿ
  
  æ— è®ºæ˜¯ä»€ä¹ˆæ ·çš„éªŒè¯ç éƒ½æ— æ³• 100%é˜»æ­¢æ‰€æœ‰æœºå™¨äººï¼Œè€Œæ˜¯å¢åŠ å…¶æ“ä½œæˆæœ¬ã€‚è™½ç„¶éªŒè¯æœ¬èº«æ— äº¤äº’ï¼Œä½†é€šè¿‡ PoW ï¼ˆå·¥ä½œé‡è¯æ˜ï¼‰æœºåˆ¶ï¼Œå¯ä»¥é™åˆ¶å•ä¸ªç”¨æˆ·é«˜é¢‘è¯·æ±‚ï¼›å¤šä¸ªä¸åŒç”¨æˆ·ç¡®å®å¯ä»¥æ…¢æ…¢é€šè¿‡ï¼Œä½†åªè¦ä½ è®¾ç½®è¶³å¤Ÿçš„éš¾åº¦ï¼Œå°±èƒ½æœ‰æ•ˆé˜²æ­¢æ‰¹é‡æ»¥ç”¨ï¼Œæ¯”å¦‚åˆ·æ¥å£ã€è–…ç¾Šæ¯›ã€æ’åº“ç­‰ã€‚æœ¬è´¨ä¸Šå°±æ˜¯ä¸€ç§æ‰‹æ®µé€šè¿‡æé«˜æ“ä½œæˆæœ¬ï¼ˆ PoW è®¡ç®—éœ€è¦æ—¶é—´ï¼‰æ¥æ”¾æ…¢è®¿é—®çš„é€Ÿåº¦ï¼Œå®ç°ç±»ä¼¼äºé€Ÿç‡é™åˆ¶ï¼Œé˜²æ­¢ DDOS çš„æ•ˆæœ
  
  ```
```

```

```

```

```

```





### é‚®ç®±éªŒè¯

```

http://43.153.153.16:8000/project/default/auth/

Configuration ä¸‹é¢åªæœ‰ Policies 

åœ¨Dashboardä¾§è¾¹æ å•å‡»Authentication -> Emails
	# ç›®æ ‡æ˜¯è®© AI ç»™åŠ ä¸Šè¿™é‡Œçš„ EMails


```



### æ ‘å½¢ç›®å½•çš„è®¾è®¡

```

Supabase é‡Œå¦‚æœè¦å­˜æ ‘å½¢ç›®å½•ç»“æ„çš„æ•°æ®ï¼Œè¦æ€æ ·è®¾è®¡æ›´åˆç†ï¼Ÿå‰ç«¯æ‹¿åˆ°æ•°æ®è‡ªå·²ç»„è£…æˆæ ‘å½¢ç»“æ„ï¼Œè¿˜æ˜¯ Supabase ç›´æ¥è¿”å›ç»“æ„åŒ–çš„ JSON

åœ¨ Supabase (PostgreSQL) ä¸­è®¾è®¡æ ‘å½¢ç»“æ„ï¼Œæœ€æ¨èä¸”æœ€çµæ´»çš„æ–¹æ¡ˆæ˜¯ Adjacency List (é‚»æ¥è¡¨) æ¨¡å¼ï¼Œå³åœ¨è¡¨ä¸­æ·»åŠ  parent_id å­—æ®µã€‚

å…³äºâ€œå‰ç«¯ç»„è£… vs åç«¯ç›´æ¥è¿”å›â€ï¼Œé€šå¸¸å»ºè®® å‰ç«¯ç»„è£…ï¼Œé™¤éæ•°æ®é‡å·¨å¤§ã€‚

ä»¥ä¸‹æ˜¯è¯¦ç»†çš„è®¾è®¡å»ºè®®å’Œå¯¹æ¯”ï¼š

1. æ•°æ®åº“è®¾è®¡æ–¹æ¡ˆ (æ¨è Adjacency List)
è¿™æ˜¯æœ€æ ‡å‡†çš„è®¾è®¡ï¼Œåˆ©ç”¨ Postgres å¼ºå¤§çš„é€’å½’æŸ¥è¯¢èƒ½åŠ›ã€‚

SQL



create table categories (  id bigint generated by default as identity primary key,  parent_id bigint references categories(id), -- æŒ‡å‘çˆ¶èŠ‚ç‚¹  name text not null,  created_at timestamp with time zone default timezone('utc'::text, now()) not null);-- å¯é€‰ï¼šæ·»åŠ ç´¢å¼•ä»¥åŠ é€ŸæŸ¥è¯¢create index idx_categories_parent_id on categories(parent_id);
å¤‡é€‰æ–¹æ¡ˆï¼šltree æ‰©å±• å¦‚æœä½ éœ€è¦é¢‘ç¹æŸ¥è¯¢â€œæŸä¸ªèŠ‚ç‚¹ä¸‹çš„æ‰€æœ‰å­å­™èŠ‚ç‚¹â€ï¼ˆä¸ä»…ä»…æ˜¯ç›´æ¥å­èŠ‚ç‚¹ï¼‰ï¼ŒPostgres çš„ ltree æ‰©å±•éå¸¸å¼ºå¤§ï¼Œä½†å­¦ä¹ æ›²çº¿ç¨é«˜ã€‚å¯¹äºå¤§å¤šæ•°åº”ç”¨ï¼Œparent_id è¶³å¤Ÿäº†ã€‚

2. æ•°æ®è·å–ç­–ç•¥å¯¹æ¯”
æ–¹æ¡ˆ Aï¼šåç«¯è¿”å›æ‰å¹³æ•°æ®ï¼Œå‰ç«¯ç»„è£… (æœ€æ¨è)
Supabase ç›´æ¥è¿”å›æ‰€æœ‰èŠ‚ç‚¹ï¼ˆæˆ–æŒ‰éœ€ç­›é€‰ï¼‰ï¼Œå‰ç«¯å°†å…¶è½¬æ¢ä¸ºæ ‘ã€‚

ä¼˜ç‚¹ï¼š
æ•°æ®åº“è´Ÿè½½ä½ï¼šSQL æŸ¥è¯¢éå¸¸ç®€å• (select * from categories).
ç±»å‹å®‰å…¨ï¼šSupabase ç”Ÿæˆçš„ TypeScript ç±»å‹ç›´æ¥å¯¹åº”æ‰å¹³ç»“æ„ï¼Œæ˜“äºå¤„ç†ã€‚
çµæ´»æ€§ï¼šå‰ç«¯å¯ä»¥æ ¹æ® UI éœ€æ±‚ï¼ˆå¦‚ Antd Tree, dnd-kitï¼‰è‡ªç”±è½¬æ¢ç»“æ„ã€‚
ç¼“å­˜å‹å¥½ï¼šæ‰å¹³åˆ—è¡¨æ›´å®¹æ˜“ç¼“å­˜å’Œæ›´æ–°ï¼ˆå¢åˆ æ”¹åªéœ€æ“ä½œå•ä¸ªæ¡ç›®ï¼‰ã€‚
ç¼ºç‚¹ï¼š
å¦‚æœæ•°æ®é‡è¾¾åˆ°æ•°ä¸‡æ¡ï¼Œå‰ç«¯å¤„ç†å¯èƒ½ä¼šæœ‰å¾®å°çš„æ€§èƒ½æŸè€—ï¼ˆä½†åœ¨ç°ä»£æµè§ˆå™¨ä¸­é€šå¸¸å¿½ç•¥ä¸è®¡ï¼‰ã€‚
å‰ç«¯ç»„è£…ä»£ç ç¤ºä¾‹ (TypeScript):

TypeScript



// 1. ä» Supabase è·å–æ‰å¹³æ•°æ®const { data: categories } = await supabase.from('categories').select('*');// 2. è½¬æ¢å·¥å…·å‡½æ•°function buildTree(items: any[]) {  const map = new Map();  const roots: any[] = [];  // åˆå§‹åŒ– Mapï¼Œå¹¶åœ¨æ¯ä¸ª item ä¸ŠåŠ ä¸ª children æ•°ç»„  items.forEach(item => {    map.set(item.id, { ...item, children: [] });  });  items.forEach(item => {    if (item.parent_id) {      // å¦‚æœæœ‰çˆ¶èŠ‚ç‚¹ï¼Œåœ¨è¿™ä¸ªçˆ¶èŠ‚ç‚¹çš„ children é‡ŒåŠ å…¥å½“å‰èŠ‚ç‚¹      const parent = map.get(item.parent_id);      if (parent) {        parent.children.push(map.get(item.id));      }    } else {      // æ²¡æœ‰ parent_idï¼Œåˆ™æ˜¯æ ¹èŠ‚ç‚¹      roots.push(map.get(item.id));    }  });  return roots;}const treeData = buildTree(categories || []);
æ–¹æ¡ˆ Bï¼šSupabase ç›´æ¥è¿”å›åµŒå¥— JSON (Postgres ä¾§ç»„è£…)
åˆ©ç”¨ Postgres çš„ json_agg æˆ–é€’å½’ CTEï¼Œåœ¨æ•°æ®åº“å±‚å®Œæˆç»„è£…ã€‚

ä¼˜ç‚¹ï¼š
å‰ç«¯æ‹¿åˆ°å³ç”¨ï¼Œé€»è¾‘ç®€å•ã€‚
èŠ‚çœå¸¦å®½ï¼ˆå¦‚æœåªéœ€è¦æ ‘çš„ä¸€éƒ¨åˆ†ï¼‰ã€‚
ç¼ºç‚¹ï¼š
SQL å¤æ‚ï¼šéœ€è¦ç¼–å†™å¤æ‚çš„ Postgres Function æˆ– Viewã€‚
æ€§èƒ½éšæ‚£ï¼šéšç€æ·±åº¦å¢åŠ ï¼Œæ•°æ®åº“è®¡ç®—å‹åŠ›å˜å¤§ã€‚
ç±»å‹å®šä¹‰éº»çƒ¦ï¼šSupabase è‡ªåŠ¨ç”Ÿæˆçš„ç±»å‹é€šå¸¸æ˜¯æ‰å¹³çš„ï¼Œä½ éœ€è¦æ‰‹åŠ¨å®šä¹‰é€’å½’ç±»å‹ã€‚
åç«¯ç»„è£…ä»£ç ç¤ºä¾‹ (RPC Function):

å¦‚æœä½ åšæŒè¦åç«¯è¿”å›ï¼Œå¯ä»¥åˆ›å»ºä¸€ä¸ª Postgres Functionï¼š

SQL

create or replace function get_category_tree()returns jsonlanguage sqlas $$with recursive tree_path as (    -- 1. åŸºç¡€æƒ…å†µï¼šè·å–æ ¹èŠ‚ç‚¹    select         id,         parent_id,         name,         jsonb_build_object('id', id, 'name', name, 'children', '[]'::jsonb) as         node_json    from categories    where parent_id is null        union all        -- 2. é€’å½’éƒ¨åˆ†ï¼šè·å–å­èŠ‚ç‚¹    select         c.id,         c.parent_id,         c.name,         jsonb_build_object('id', c.id, 'name', c.name, 'children', '[]'::jsonb)    from categories c    join tree_path tp on c.parent_id = tp.id)-- æ³¨æ„ï¼šçº¯ SQL é€’å½’ç»„è£…æˆåµŒå¥— JSON éå¸¸ç¹çï¼Œé€šå¸¸å»ºè®®åªç”¨é€’å½’æŸ¥å‡ºè·¯å¾„ï¼Œæˆ–è€…å¦‚ä¸‹ç®€å•èšåˆï¼š-- å®é™…ä¸Šåœ¨ SQL é‡Œåš "æ— é™å±‚çº§åµŒå¥— JSON" æå…¶ç—›è‹¦ä¸”æ€§èƒ½å·®ã€‚-- é€šå¸¸æˆ‘ä»¬åªç”¨ Postgres åš "æœ‰é™å±‚çº§" (æ¯”å¦‚å…³è”æŸ¥è¯¢) çš„åµŒå¥—ã€‚$$;
(æ³¨ï¼šPostgres å¹¶ä¸æ“…é•¿ç›´æ¥è¾“å‡ºæ— é™é€’å½’çš„ JSON ç»“æ„ï¼Œå†™èµ·æ¥éå¸¸æ™¦æ¶©ã€‚é€šå¸¸æ‰€è°“çš„â€œåç«¯è¿”å›ç»“æ„åŒ–â€æ˜¯æŒ‡å›ºå®šå±‚çº§çš„ select *, children:categories(...)ï¼Œè¿™åœ¨ Supabase ä¸­é€šè¿‡å¤–é”®å®¹æ˜“å®ç°ï¼Œä½†ä»…é™å›ºå®šå±‚æ•°ã€‚)

æ€»ç»“å»ºè®®
é¦–é€‰æ–¹æ¡ˆï¼šæ•°æ®åº“å­˜ parent_idï¼ŒAPI è¿”å› æ‰å¹³æ•°ç»„ï¼Œå‰ç«¯ç»„è£…ã€‚è¿™æ˜¯ç°ä»£ SPA åº”ç”¨çš„æ ‡å‡†åšæ³•ã€‚
ç‰¹æ®Šæƒ…å†µï¼šå¦‚æœæ ‘éå¸¸æ·±ä¸”åºå¤§ï¼ˆå¦‚æ–‡ä»¶ç³»ç»Ÿï¼Œæ•°ç™¾ä¸‡èŠ‚ç‚¹ï¼‰ï¼Œä¸è¦ä¸€æ¬¡æ€§åŠ è½½ã€‚æ”¹ä¸º æ‡’åŠ è½½ (Lazy Load)ï¼š
ç‚¹å‡»çˆ¶èŠ‚ç‚¹æ—¶ï¼Œè¯·æ±‚ supabase.from('categories').select('*').eq('parent_id', nodeId)ã€‚






ç”¨ Supabase Edge Functions å®Œæˆç›®å½•ç»„è£…å¯è¡Œå—ï¼Ÿ

ä½¿ç”¨ Supabase Edge Functions å®Œæˆç›®å½•ç»„è£…æ˜¯ å®Œå…¨å¯è¡Œä¸”éå¸¸åˆç† çš„æ–¹æ¡ˆã€‚

è¿™å®é™…ä¸Šæ˜¯ä¸€ä¸ªâ€œé»„é‡‘ä¸­é—´åœ°å¸¦â€ï¼šå®ƒç»“åˆäº† SQL æŸ¥è¯¢çš„é«˜æ•ˆï¼ˆç›´æ¥ select * ï¼‰å’Œ JavaScript/TypeScript å¤„ç†å¤æ‚é€»è¾‘çš„çµæ´»æ€§ï¼ˆç»„è£…æ ‘ï¼‰ï¼ŒåŒæ—¶é¿å…äº†åœ¨æ•°æ®åº“ä¸­å†™å¤æ‚é€’å½’ SQL çš„ç—›è‹¦ã€‚

### æ ¸å¿ƒä¼˜åŠ¿
1. å¤šç«¯é€»è¾‘å¤ç”¨ ï¼šå¦‚æœä½ æœ‰ Webã€iOSã€Android å¤šä¸ªç«¯ï¼Œä¸éœ€è¦åœ¨æ¯ä¸ªç«¯éƒ½å†™ä¸€éâ€œç»„è£…æ ‘â€çš„ç®—æ³•ï¼Œé€»è¾‘ç»Ÿä¸€ç»´æŠ¤åœ¨ Edge Function é‡Œã€‚
2. æ¯” SQL æ›´å®¹æ˜“ç»´æŠ¤ ï¼šç”¨ TS å†™é€’å½’æˆ–å¾ªç¯ç»„è£… JSON æ¯”å†™ Postgres çš„é€’å½’ CTE è¦ç›´è§‚å¾—å¤šï¼Œè°ƒè¯•ä¹Ÿæ–¹ä¾¿ã€‚
3. å‡è½»å®¢æˆ·ç«¯è´Ÿæ‹… ï¼šè™½ç„¶ç»„è£…æ ‘çš„è®¡ç®—é‡é€šå¸¸ä¸å¤§ï¼Œä½†å¦‚æœæ•°æ®ç»“æ„å¤æ‚ï¼ˆæ¯”å¦‚è¿˜éœ€è¦åšæƒé™è¿‡æ»¤ã€å­—æ®µè£å‰ªï¼‰ï¼Œæ”¾åœ¨æœåŠ¡ç«¯å¤„ç†æ›´å¹²å‡€ã€‚
### å®ç°ä»£ç ç¤ºä¾‹
å‡è®¾ä½ å·²ç»åˆå§‹åŒ–äº† Supabase Edge Function (ä¾‹å¦‚åä¸º get-categories-tree )ã€‚

æ–‡ä»¶: supabase/functions/get-categories-tree/index.ts

```
importÂ {Â serveÂ }Â fromÂ "https://deno.land/std@0.168.0/http/server.ts"
importÂ {Â createClientÂ }Â fromÂ "https://esm.sh/@supabase/supabase-js@2"

//Â å®šä¹‰æ•°æ®ç±»å‹
interfaceÂ CategoryÂ {
Â Â id:Â number
Â Â parent_id:Â numberÂ |Â null
Â Â name:Â string
Â Â children?:Â Category[]
}

//Â æ ¸å¿ƒç»„è£…å‡½æ•°Â (æ—¶é—´å¤æ‚åº¦Â O(n))
functionÂ buildTree(items:Â Category[])Â {
Â Â constÂ mapÂ =Â newÂ Map<number,Â Category>()
Â Â constÂ roots:Â Category[]Â =Â []

Â Â //Â 1.Â åˆå§‹åŒ–æ‰€æœ‰èŠ‚ç‚¹ï¼Œå»ºç«‹Â idÂ ->Â nodeÂ çš„æ˜ å°„
Â Â items.forEach(itemÂ =>Â {
Â Â Â Â //Â æµ…æ‹·è´å¯¹è±¡ï¼Œå¹¶åˆå§‹åŒ–Â children
Â Â Â Â map.set(item.id,Â {Â ...item,Â children:Â []Â })
Â Â })

Â Â //Â 2.Â ç»„è£…æ ‘
Â Â items.forEach(itemÂ =>Â {
Â Â Â Â constÂ nodeÂ =Â map.get(item.id)!
Â Â Â Â 
Â Â Â Â ifÂ (item.parent_id)Â {
Â Â Â Â Â Â constÂ parentÂ =Â map.get(item.parent_id)
Â Â Â Â Â Â ifÂ (parent)Â {
Â Â Â Â Â Â Â Â //Â å¦‚æœæœ‰çˆ¶èŠ‚ç‚¹ï¼ŒåŠ å…¥çˆ¶èŠ‚ç‚¹çš„Â children
Â Â Â Â Â Â Â Â parent.children!.push(node)
Â Â Â Â Â Â }Â elseÂ {
Â Â Â Â Â Â Â Â //Â è¾¹ç¼˜æƒ…å†µï¼šå¦‚æœçˆ¶èŠ‚ç‚¹Â IDÂ å­˜åœ¨ä½†æ‰¾ä¸åˆ°çˆ¶èŠ‚ç‚¹æ•°æ®ï¼ˆæ¯”å¦‚çˆ¶èŠ‚ç‚¹è¢«åˆ äº†ï¼‰ï¼Œ
Â Â Â Â Â Â Â Â //Â è§†å…·ä½“ä¸šåŠ¡å†³å®šæ˜¯ä¸¢å¼ƒè¿˜æ˜¯ä½œä¸ºæ ¹èŠ‚ç‚¹ã€‚è¿™é‡Œæš‚ä½œæ ¹èŠ‚ç‚¹å¤„ç†æˆ–å¿½ç•¥ã€‚
Â Â Â Â Â Â Â Â console.warn(`OrphanÂ nodeÂ found:Â ${item.id}`)
Â Â Â Â Â Â }
Â Â Â Â }Â elseÂ {
Â Â Â Â Â Â //Â æ²¡æœ‰Â parent_idï¼Œåˆ™æ˜¯æ ¹èŠ‚ç‚¹
Â Â Â Â Â Â roots.push(node)
Â Â Â Â }
Â Â })

Â Â returnÂ roots
}

serve(asyncÂ (req)Â =>Â {
Â Â tryÂ {
Â Â Â Â //Â 1.Â åˆ›å»ºÂ SupabaseÂ ClientÂ (ä½¿ç”¨Â ServiceÂ RoleÂ KeyÂ ç»•è¿‡Â RLSï¼Œæˆ–è€…ä½¿ç”¨Â AnonÂ KeyÂ é…åˆÂ 
Â Â Â Â RLS)
Â Â Â Â //Â é€šå¸¸è¯»å–å…¬å¼€ç›®å½•ç”¨Â AnonÂ KeyÂ å³å¯ï¼›å¦‚æœæ˜¯ç§æœ‰ç›®å½•ï¼Œéœ€ä¼ é€’ç”¨æˆ·Â AuthÂ Header
Â Â Â Â constÂ authHeaderÂ =Â req.headers.get('Authorization')!
Â Â Â Â constÂ supabaseÂ =Â createClient(
Â Â Â Â Â Â Deno.env.get('SUPABASE_URL')Â ??Â '',
Â Â Â Â Â Â Deno.env.get('SUPABASE_ANON_KEY')Â ??Â '',
Â Â Â Â Â Â {Â global:Â {Â headers:Â {Â Authorization:Â authHeaderÂ }Â }Â }
Â Â Â Â )

Â Â Â Â //Â 2.Â ä»æ•°æ®åº“è·å–æ‰å¹³æ•°æ®
Â Â Â Â //Â è¿™é‡Œåªå–éœ€è¦çš„å­—æ®µï¼Œå‡å°‘ä¼ è¾“ä½“ç§¯
Â Â Â Â constÂ {Â data:Â categories,Â errorÂ }Â =Â awaitÂ supabase
Â Â Â Â Â Â .from('categories')
Â Â Â Â Â Â .select('id,Â parent_id,Â name')
Â Â Â Â Â Â .order('id')Â //Â æ’åºé€šå¸¸å¯¹æ ‘çš„é¡ºåºä¹Ÿå¾ˆé‡è¦

Â Â Â Â ifÂ (error)Â throwÂ error

Â Â Â Â //Â 3.Â åœ¨Â EdgeÂ FunctionÂ å†…å­˜ä¸­ç»„è£…æ ‘
Â Â Â Â constÂ treeDataÂ =Â buildTree(categoriesÂ asÂ Category[])

Â Â Â Â //Â 4.Â è¿”å›ç»„è£…å¥½çš„Â JSON
Â Â Â Â returnÂ newÂ Response(JSON.stringify(treeData),Â {
Â Â Â Â Â Â headers:Â {Â 
Â Â Â Â Â Â Â Â "Content-Type":Â "application/json",
Â Â Â Â Â Â Â Â //Â å¯é€‰ï¼šæ·»åŠ ç¼“å­˜æ§åˆ¶ï¼Œæ¯”å¦‚ç¼“å­˜Â 60Â ç§’
Â Â Â Â Â Â Â Â "Cache-Control":Â "public,Â max-age=60,Â s-maxage=60"Â 
Â Â Â Â Â Â },
Â Â Â Â Â Â status:Â 200,
Â Â Â Â })

Â Â }Â catchÂ (error)Â {
Â Â Â Â returnÂ newÂ Response(JSON.stringify({Â error:Â error.messageÂ }),Â {
Â Â Â Â Â Â headers:Â {Â "Content-Type":Â "application/json"Â },
Â Â Â Â Â Â status:Â 500,
Â Â Â Â })
Â Â }
})
â€‹```
### æœ€ä½³å®è·µå»ºè®®
1. åˆ©ç”¨ç¼“å­˜ (Cache-Control) ï¼š
   ç›®å½•ç»“æ„é€šå¸¸ä¸ä¼šé¢‘ç¹å˜åŒ–ã€‚Edge Functions éƒ¨ç½²åœ¨å…¨çƒè¾¹ç¼˜èŠ‚ç‚¹ï¼Œä½ å¯ä»¥é€šè¿‡è®¾ç½®å“åº”å¤´ "Cache-Control": "public, max-age=300" è®© CDN ç¼“å­˜ç»“æœ 5 åˆ†é’Ÿã€‚è¿™æ ·åç»­çš„è¯·æ±‚ç›´æ¥ä»æœ€è¿‘çš„ CDN èŠ‚ç‚¹è¿”å›ï¼Œé€Ÿåº¦æå¿«ï¼Œä¸”ä¸æ¶ˆè€—æ•°æ®åº“èµ„æºã€‚
2. å¤„ç†å¤§é‡æ•°æ® ï¼š
   Edge Functions æœ‰å†…å­˜é™åˆ¶ï¼ˆé€šå¸¸ 128MB - 1GB è§†å¥—é¤è€Œå®šï¼‰ã€‚å¦‚æœä½ çš„ç›®å½•èŠ‚ç‚¹æœ‰å‡ åä¸‡æ¡ï¼Œä¸€æ¬¡æ€§åŠ è½½è¿›å†…å­˜ç»„è£…å¯èƒ½ä¼š OOM (Out Of Memory)ã€‚
   
   - å‡ åƒæ¡ä»¥å†… ï¼šæ¯«æ— å‹åŠ›ï¼Œä¸Šè¿°ä»£ç å³å¯ã€‚
   - å‡ ä¸‡æ¡ä»¥ä¸Š ï¼šå»ºè®®æ”¹å›â€œå‰ç«¯ç»„è£…â€æˆ–â€œæ‡’åŠ è½½â€ï¼ˆåªè¯·æ±‚æŸä¸€å±‚çº§çš„æ•°æ®ï¼‰ã€‚
3. å®‰å…¨æ€§ (RLS) ï¼š
   åœ¨ä»£ç ä¸­ï¼Œæˆ‘ä½¿ç”¨äº† req.headers.get('Authorization') æ¥é€ä¼ ç”¨æˆ·çš„ Tokenã€‚è¿™å¾ˆé‡è¦ï¼Œè¿™æ · Supabase Client åœ¨æŸ¥è¯¢æ•°æ®åº“æ—¶ï¼Œä¾ç„¶ä¼šéµå®ˆä½ åœ¨æ•°æ®åº“å±‚è®¾ç½®çš„ RLS (Row Level Security) è§„åˆ™ã€‚å¦‚æœæ¯ä¸ªç”¨æˆ·çœ‹åˆ°çš„ç›®å½•æ ‘ä¸åŒï¼Œè¿™ä¸€ç‚¹è‡³å…³é‡è¦ã€‚




```





### PG

https://pigsty.cc/docs/setup/pgsql/

```

p
	# æŒ‡å‘äº† psql


é»˜è®¤ å•æœºå®‰è£… æ¨¡æ¿ä¸‹ï¼Œæ‚¨å°†åœ¨å½“å‰èŠ‚ç‚¹ä¸Šåˆ›å»ºä¸€ä¸ªåä¸º pg-meta çš„ PostgreSQL æ•°æ®åº“é›†ç¾¤ï¼Œåªæœ‰ä¸€ä¸ªä¸»åº“å®ä¾‹ã€‚

PostgreSQL ç›‘å¬åœ¨ 5432 ç«¯å£ï¼Œé›†ç¾¤ä¸­å¸¦æœ‰ä¸€ä¸ªé¢„ç½®çš„æ•°æ®åº“ meta å¯ä¾›ä½¿ç”¨ã€‚

æ‚¨å¯ä»¥åœ¨å®‰è£…å®Œæ¯•åé€€å‡ºå½“å‰ç®¡ç†ç”¨æˆ· ssh ä¼šè¯ï¼Œå¹¶é‡æ–°ç™»é™†åˆ·æ–°ç¯å¢ƒå˜é‡åï¼Œ é€šè¿‡ç®€å•åœ°æ•²ä¸€ä¸ª p å›è½¦ï¼Œé€šè¿‡å‘½ä»¤è¡Œå·¥å…· psql è®¿é—®è¯¥æ•°æ®åº“é›†ç¾¤ï¼š

vagrant@pg-meta-1:~$ p
psql (18.1 (Ubuntu 18.1-1.pgdg24.04+2))
Type "help" for help.

postgres=#
æ‚¨ä¹Ÿå¯ä»¥åˆ‡æ¢ä¸ºæ“ä½œç³»ç»Ÿçš„ postgres ç”¨æˆ·ï¼Œç›´æ¥æ‰§è¡Œ psql å‘½ä»¤ï¼Œå³å¯è¿æ¥åˆ°é»˜è®¤çš„ postgres ç®¡ç†æ•°æ®åº“ä¸Šã€‚

è¿æ¥æ•°æ®åº“
æƒ³è¦è®¿é—® PostgreSQL æ•°æ®åº“ï¼Œæ‚¨éœ€è¦ä½¿ç”¨ å‘½ä»¤è¡Œå·¥å…· æˆ–è€… å›¾å½¢åŒ–å®¢æˆ·ç«¯ å·¥å…·ï¼Œå¡«å…¥ PostgreSQL çš„ è¿æ¥å­—ç¬¦ä¸²ï¼š

psql postgres://dbuser_dba:DBUser.DBA@10.10.10.10/meta



åœ¨éƒ¨ç½²äº† Pigsty çš„æœåŠ¡å™¨ä¸Šï¼Œä½ å¯ä»¥ç›´æ¥ä½¿ç”¨ psql è¿æ¥æœ¬åœ°æ•°æ®åº“ï¼š

# æœ€ç®€å•çš„æ–¹å¼ï¼šä½¿ç”¨ postgres ç³»ç»Ÿç”¨æˆ·æœ¬åœ°è¿æ¥ï¼ˆæ— éœ€å¯†ç ï¼‰
sudo -u postgres psql

# ä½¿ç”¨è¿æ¥å­—ç¬¦ä¸²ï¼ˆæ¨èï¼Œé€šç”¨æ€§æœ€å¥½ï¼‰
psql 'postgres://dbuser_dba:DBUser.DBA@10.10.10.10:5432/meta'

# ä½¿ç”¨å‚æ•°å½¢å¼
psql -h 10.10.10.10 -p 5432 -U dbuser_dba -d meta

# ä½¿ç”¨ç¯å¢ƒå˜é‡é¿å…å¯†ç å‡ºç°åœ¨å‘½ä»¤è¡Œ
export PGPASSWORD='DBUser.DBA'
psql -h 10.10.10.10 -p 5432 -U dbuser_dba -d meta
æˆåŠŸè¿æ¥åï¼Œä½ ä¼šçœ‹åˆ°ç±»ä¼¼è¿™æ ·çš„æç¤ºç¬¦ï¼š

psql (18.1)
Type "help" for help.

meta=#

```







### è‡ªå»ºè®ºå›

```

ä½¿ç”¨ sveltejs å’Œ Supabase å¼€å‘ä¸€ä¸ªè®ºå›ç½‘ç«™ã€‚ `
                  http://xx.xx.xx.xx:8000/
                  ` è¿™æ˜¯è‡ªå»º Supabase çš„åœ°å€ï¼Œ ANON_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoiYW5vbiIsImlzcyI6InN1cGFiYXNlIiwiaWF0IjoxNzY3ODAxNjAwLCJleHAiOjE5MjU1NjgwMDB9.GtkruGMgbxm3kS_1eIHKyz0uaVjhvlWLvqUuS5b-DRc

npm install pg dotenv




node -v && npm -v
v24.12.0
11.6.2

npm create svelte@latest . -- --template skeleton --types ts --no-prettier --no-eslint --no-playwright --no-vitest

npx sv create . --template skeleton --types ts --no-prettier --no-eslint --no-playwright --no-vitest

npx sv create . --template minimal --types ts --no-add-ons --no-install

npm install && npm install @supabase/supabase-js




```







#### é›†ç¾¤ä¸­å»ºæ•°æ®åº“

https://pigsty.cc/docs/pgsql/config/db/

```

ä¸‹é¢æ˜¯ Pigsty æ¼”ç¤ºç¯å¢ƒä¸­é»˜è®¤é›†ç¾¤ pg-meta ä¸­çš„æ•°æ®åº“å®šä¹‰ï¼š

pg-meta:
  hosts: { 10.10.10.10: { pg_seq: 1, pg_role: primary } }
  vars:
    pg_cluster: pg-meta
    pg_databases:
      - { name: meta ,baseline: cmdb.sql ,comment: pigsty meta database ,schemas: [pigsty] ,extensions: [{name: postgis, schema: public}, {name: timescaledb}]}
      - { name: grafana  ,owner: dbuser_grafana  ,revokeconn: true ,comment: grafana primary database }
      - { name: bytebase ,owner: dbuser_bytebase ,revokeconn: true ,comment: bytebase primary database }
      - { name: kong     ,owner: dbuser_kong     ,revokeconn: true ,comment: kong the api gateway database }
      - { name: gitea    ,owner: dbuser_gitea    ,revokeconn: true ,comment: gitea meta database }
      - { name: wiki     ,owner: dbuser_wiki     ,revokeconn: true ,comment: wiki meta database }
      - { name: noco     ,owner: dbuser_noco     ,revokeconn: true ,comment: nocodb database }
      
      
      
æ¯ä¸ªæ•°æ®åº“å®šä¹‰éƒ½æ˜¯ä¸€ä¸ª objectï¼Œå¯èƒ½åŒ…æ‹¬ä»¥ä¸‹å­—æ®µï¼Œä»¥ meta æ•°æ®åº“ä¸ºä¾‹ï¼š

- name: meta                      # å¿…é€‰ï¼Œ`name` æ˜¯æ•°æ®åº“å®šä¹‰çš„å”¯ä¸€å¿…é€‰å­—æ®µ
  state: create                   # å¯é€‰ï¼Œæ•°æ®åº“çŠ¶æ€ï¼šcreateï¼ˆåˆ›å»ºï¼Œé»˜è®¤ï¼‰ã€absentï¼ˆåˆ é™¤ï¼‰ã€recreateï¼ˆé‡å»ºï¼‰
  baseline: cmdb.sql              # å¯é€‰ï¼Œæ•°æ®åº“ sql çš„åŸºçº¿å®šä¹‰æ–‡ä»¶è·¯å¾„ï¼ˆansible æœç´¢è·¯å¾„ä¸­çš„ç›¸å¯¹è·¯å¾„ï¼Œå¦‚ files/ï¼‰
  pgbouncer: true                 # å¯é€‰ï¼Œæ˜¯å¦å°†æ­¤æ•°æ®åº“æ·»åŠ åˆ° pgbouncer æ•°æ®åº“åˆ—è¡¨ï¼Ÿé»˜è®¤ä¸º true
  schemas: [pigsty]               # å¯é€‰ï¼Œè¦åˆ›å»ºçš„é™„åŠ æ¨¡å¼ï¼Œç”±æ¨¡å¼åç§°å­—ç¬¦ä¸²ç»„æˆçš„æ•°ç»„
  extensions:                     # å¯é€‰ï¼Œè¦å®‰è£…çš„é™„åŠ æ‰©å±•ï¼š æ‰©å±•å¯¹è±¡çš„æ•°ç»„
    - { name: postgis , schema: public }  # å¯ä»¥æŒ‡å®šå°†æ‰©å±•å®‰è£…åˆ°æŸä¸ªæ¨¡å¼ä¸­ï¼Œä¹Ÿå¯ä»¥ä¸æŒ‡å®šï¼ˆä¸æŒ‡å®šåˆ™å®‰è£…åˆ° search_path é¦–ä½æ¨¡å¼ä¸­ï¼‰
    - { name: timescaledb }               # ä¾‹å¦‚æœ‰çš„æ‰©å±•ä¼šåˆ›å»ºå¹¶ä½¿ç”¨å›ºå®šçš„æ¨¡å¼ï¼Œå°±ä¸éœ€è¦æŒ‡å®šæ¨¡å¼ã€‚
  comment: pigsty meta database   # å¯é€‰ï¼Œæ•°æ®åº“çš„è¯´æ˜ä¸å¤‡æ³¨ä¿¡æ¯
  owner: postgres                 # å¯é€‰ï¼Œæ•°æ®åº“æ‰€æœ‰è€…ï¼Œä¸æŒ‡å®šåˆ™ä¸ºå½“å‰ç”¨æˆ·
  template: template1             # å¯é€‰ï¼Œè¦ä½¿ç”¨çš„æ¨¡æ¿ï¼Œé»˜è®¤ä¸º template1ï¼Œç›®æ ‡å¿…é¡»æ˜¯ä¸€ä¸ªæ¨¡æ¿æ•°æ®åº“
  strategy: FILE_COPY             # å¯é€‰ï¼Œå…‹éš†ç­–ç•¥ï¼šFILE_COPY æˆ– WAL_LOGï¼ˆPG15+ï¼‰ï¼Œä¸æŒ‡å®šä½¿ç”¨ PG é»˜è®¤
  encoding: UTF8                  # å¯é€‰ï¼Œä¸æŒ‡å®šåˆ™ç»§æ‰¿æ¨¡æ¿/é›†ç¾¤é…ç½®ï¼ˆUTF8ï¼‰
  locale: C                       # å¯é€‰ï¼Œä¸æŒ‡å®šåˆ™ç»§æ‰¿æ¨¡æ¿/é›†ç¾¤é…ç½®ï¼ˆCï¼‰
  lc_collate: C                   # å¯é€‰ï¼Œä¸æŒ‡å®šåˆ™ç»§æ‰¿æ¨¡æ¿/é›†ç¾¤é…ç½®ï¼ˆCï¼‰
  lc_ctype: C                     # å¯é€‰ï¼Œä¸æŒ‡å®šåˆ™ç»§æ‰¿æ¨¡æ¿/é›†ç¾¤é…ç½®ï¼ˆCï¼‰
  locale_provider: libc           # å¯é€‰ï¼Œæœ¬åœ°åŒ–æä¾›è€…ï¼šlibcã€icuã€builtinï¼ˆPG15+ï¼‰
  icu_locale: en-US               # å¯é€‰ï¼ŒICU æœ¬åœ°åŒ–è§„åˆ™ï¼ˆPG15+ï¼‰
  icu_rules: ''                   # å¯é€‰ï¼ŒICU æ’åºè§„åˆ™ï¼ˆPG16+ï¼‰
  builtin_locale: C.UTF-8         # å¯é€‰ï¼Œå†…ç½®æœ¬åœ°åŒ–æä¾›è€…è§„åˆ™ï¼ˆPG17+ï¼‰
  tablespace: pg_default          # å¯é€‰ï¼Œé»˜è®¤è¡¨ç©ºé—´ï¼Œé»˜è®¤ä¸º 'pg_default'
  is_template: false              # å¯é€‰ï¼Œæ˜¯å¦æ ‡è®°ä¸ºæ¨¡æ¿æ•°æ®åº“ï¼Œå…è®¸ä»»ä½•æœ‰ CREATEDB æƒé™çš„ç”¨æˆ·å…‹éš†
  allowconn: true                 # å¯é€‰ï¼Œæ˜¯å¦å…è®¸è¿æ¥ï¼Œé»˜è®¤ä¸º trueã€‚æ˜¾å¼è®¾ç½® false å°†å®Œå…¨ç¦æ­¢è¿æ¥åˆ°æ­¤æ•°æ®åº“
  revokeconn: false               # å¯é€‰ï¼Œæ’¤é”€å…¬å…±è¿æ¥æƒé™ã€‚é»˜è®¤ä¸º falseï¼Œè®¾ç½®ä¸º true æ—¶ï¼Œå±ä¸»å’Œç®¡ç†å‘˜ä¹‹å¤–ç”¨æˆ·çš„ CONNECT æƒé™ä¼šè¢«å›æ”¶
  register_datasource: true       # å¯é€‰ï¼Œæ˜¯å¦å°†æ­¤æ•°æ®åº“æ³¨å†Œåˆ° grafana æ•°æ®æºï¼Ÿé»˜è®¤ä¸º trueï¼Œæ˜¾å¼è®¾ç½®ä¸º false ä¼šè·³è¿‡æ³¨å†Œ
  connlimit: -1                   # å¯é€‰ï¼Œæ•°æ®åº“è¿æ¥é™åˆ¶ï¼Œé»˜è®¤ä¸º -1 ï¼Œä¸é™åˆ¶ï¼Œè®¾ç½®ä¸ºæ­£æ•´æ•°åˆ™ä¼šé™åˆ¶è¿æ¥æ•°ã€‚
  parameters:                     # å¯é€‰ï¼Œæ•°æ®åº“çº§å‚æ•°ï¼Œé€šè¿‡ ALTER DATABASE SET è®¾ç½®
      work_mem: '64MB'
      statement_timeout: '30s'
  pool_auth_user: dbuser_meta     # å¯é€‰ï¼Œè¿æ¥åˆ°æ­¤ pgbouncer æ•°æ®åº“çš„æ‰€æœ‰è¿æ¥éƒ½å°†ä½¿ç”¨æ­¤ç”¨æˆ·è¿›è¡ŒéªŒè¯ï¼ˆå¯ç”¨ pgbouncer_auth_query æ‰æœ‰ç”¨ï¼‰
  pool_mode: transaction          # å¯é€‰ï¼Œæ•°æ®åº“çº§åˆ«çš„ pgbouncer æ± åŒ–æ¨¡å¼ï¼Œé»˜è®¤ä¸º transaction
  pool_size: 64                   # å¯é€‰ï¼Œæ•°æ®åº“çº§åˆ«çš„ pgbouncer é»˜è®¤æ± å­å¤§å°ï¼Œé»˜è®¤ä¸º 64
  pool_reserve: 32                # å¯é€‰ï¼Œæ•°æ®åº“çº§åˆ«çš„ pgbouncer æ± å­ä¿ç•™ç©ºé—´ï¼Œé»˜è®¤ä¸º 32ï¼Œå½“é»˜è®¤æ± å­ä¸å¤Ÿç”¨æ—¶ï¼Œæœ€å¤šå†ç”³è¯·è¿™ä¹ˆå¤šæ¡çªå‘è¿æ¥ã€‚
  pool_size_min: 0                # å¯é€‰ï¼Œæ•°æ®åº“çº§åˆ«çš„ pgbouncer æ± çš„æœ€å°å¤§å°ï¼Œé»˜è®¤ä¸º 0
  pool_connlimit: 100             # å¯é€‰ï¼Œæ•°æ®åº“çº§åˆ«çš„æœ€å¤§æ•°æ®åº“è¿æ¥æ•°ï¼Œé»˜è®¤ä¸º 100
å”¯ä¸€å¿…é€‰çš„å­—æ®µæ˜¯ nameï¼Œå®ƒåº”è¯¥æ˜¯å½“å‰ PostgreSQL é›†ç¾¤ä¸­æœ‰æ•ˆä¸”å”¯ä¸€çš„æ•°æ®åº“åç§°ï¼Œå…¶ä»–å‚æ•°éƒ½æœ‰åˆç†çš„é»˜è®¤å€¼ã€‚      
      
  

```



#### admin ç”¨æˆ·ç»„

```

sudo usermod -aG admin <username>

```



#### ç£ç›˜å†™æ»¡äº†å¦‚ä½•æŠ¢æ•‘



```

å¦‚æœç£ç›˜å†™æ»¡äº†ï¼Œè¿ Shell å‘½ä»¤éƒ½æ— æ³•æ‰§è¡Œï¼Œrm -rf /pg/dummy å¯ä»¥é‡Šæ”¾ä¸€äº›æ•‘å‘½ç©ºé—´ã€‚

é»˜è®¤æƒ…å†µä¸‹ï¼Œpg_dummy_filesize è®¾ç½®ä¸º 64MBã€‚åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œå»ºè®®å°†å…¶å¢åŠ åˆ° 8GB æˆ–æ›´å¤§ã€‚

å®ƒå°†è¢«æ”¾ç½®åœ¨ PGSQL ä¸»æ•°æ®ç£ç›˜ä¸Šçš„ /pg/dummy è·¯å¾„ä¸‹ã€‚ä½ å¯ä»¥åˆ é™¤è¯¥æ–‡ä»¶ä»¥é‡Šæ”¾ä¸€äº›ç´§æ€¥ç©ºé—´ï¼šè‡³å°‘å¯ä»¥è®©ä½ åœ¨è¯¥èŠ‚ç‚¹ä¸Šè¿è¡Œä¸€äº› shell è„šæœ¬æ¥è¿›ä¸€æ­¥å›æ”¶å…¶ä»–ç©ºé—´ã€‚

```





### Supabase æ‰§è¡Œ SQL

http://xx.xx.xx.xx:8000/project/default/sql/1

```

select * from
  (select version()) as version,
  (select current_setting('server_version_num')) as version_number;
  	# SQL Editor é‡ŒæˆåŠŸæ‰§è¡Œ

```



```
postgres://dbuser_dba:DBUser.DBA@10.7.0.9:5432/meta
postgres://dbuser_meta:DBUser.Meta@10.7.0.9:5432/meta
postgres://dbuser_view:DBUser.View@10.7.0.9:5432/meta
	# ä½¿ç”¨ä¸‰ä¸ªä¸åŒçš„ç”¨æˆ·è¿æ¥åˆ° pg-meta é›†ç¾¤çš„ meta æ•°æ®åº“
	# https://pigsty.cc/docs/setup/pgsql/
		psql -h 10.7.0.9 -p 5432 -U dbuser_dba -d meta
			export PGPASSWORD='DBUser.DBA'
			psql -h 10.7.0.9 -p 5432 -U dbuser_dba -d meta

psql postgres://dbuser_dba:DBUser.DBA@10.7.0.9:5432/meta
  -> error: connection to server at "10.7.0.9", port 5432 failed: FATAL:  database "meta" does not exist
	# å‡ºé”™ï¼šæ²¡æœ‰ meta è¿™ä¸ªæ•°æ®åº“ï¼Œæ•°æ®æº pg-meta æ˜¯æœ‰çš„
	
psql postgres://dbuser_dba:DBUser.DBA@10.7.0.9:5432/postgres
	# æˆåŠŸ
	
psql postgres://dbuser_dba:DBUser.DBA@10.7.0.9:5433/meta
	
@pg-meta:5433/meta

psql postgres://dbuser_meta:DBUser.Meta@10.7.0.9:5433/meta
			
```





psql postgres://dbuser_dba:DBUser.DBA@10.10.10.10/meta



### å•èŠ‚ç‚¹å¼€å‘ç®±ï¼ˆmetaï¼‰

https://pigsty.cc/docs/deploy/sandbox/

**Grafana**

Pigsty [**`INFRA`**](https://pigsty.cc/docs/infra) æ¨¡å—ä¸­è‡ªå¸¦äº† [**Grafana**](https://pigsty.cc/docs/infra)ï¼Œå¹¶é¢„å…ˆé…ç½®å¥½äº† PostgreSQL æ•°æ®æºï¼ˆMetaï¼‰ã€‚ æ‚¨å¯ä»¥ç›´æ¥é€šè¿‡ [**æµè§ˆå™¨å›¾å½¢ç•Œé¢**](https://pigsty.cc/docs/setup/webui)ï¼Œä» Grafana Explore é¢æ¿ä¸­ä½¿ç”¨ SQL æŸ¥è¯¢æ•°æ®åº“ï¼Œæ— éœ€é¢å¤–å®‰è£…å®¢æˆ·ç«¯å·¥å…·ã€‚

Grafana é»˜è®¤çš„ç”¨æˆ·åæ˜¯ **`admin`**ï¼Œå¯†ç å¯ä»¥åœ¨ [**é…ç½®æ¸…å•**](https://pigsty.cc/docs/concept/iac/inventory) ä¸­çš„ [**`grafana_admin_password`**](https://pigsty.cc/docs/infra/param#grafana_admin_password) å­—æ®µæ‰¾åˆ°ï¼ˆé»˜è®¤ `pigsty`ï¼‰ã€‚



Grafana Web GUI 

xx.xx.xx.xx:3000/login admin pigsty

ç‚¹å¼€ Dashboards -> PGSQL -> Database **å¯ä»¥çœ‹åˆ°æ•°æ®æº pg-meta**



```

`f:\t\pigsty\Makefile` ubuntu22.04 æ‰§è¡Œå‘½ä»¤å‡ºé”™ï¼Œä¿®å¤å®ƒï¼š# make meta
./configure -s -c meta
configure pigsty v3.7.0 begin
[ OK ] region = default
[ OK ] kernel  = Linux
[ OK ] machine = x86_64
[ OK ] package = deb,apt
[ OK ] vendor  = ubuntu (Ubuntu)
[ OK ] version = 24 (24.04)
[ OK ] sudo = root ok
[ OK ] ssh = root@127.0.0.1 ok
[ OK ] primary_ip = skip
[ OK ] admin ssh = skip checking (due to --skip)
[ OK ] mode = meta (manually set)
[ OK ] skip ip replacement (due to --skip)
[WARN] replace oltp template with tiny due to cpu < 4
[ OK ] locale  = C.UTF-8
[ OK ] ansible = ready
[ OK ] pigsty configured
[WARN] don't forget to check it and change passwords!
proceed with ./install.yml 
cd vagrant && vagrant destroy -f
A Vagrant environment or target machine is required to run this
command. Run `vagrant init` to create a new Vagrant environment. Or,
get an ID of a target machine from `vagrant global-status` to run
this command on. A final option is to change to a directory with a
Vagrantfile and to try again.
make: *** [Makefile:259: del] Error


vi Makefile
del:
	# 209 è¡Œ cd vagrant && vagrant destroy -f
	cd vagrant && if [ -f Vagrantfile ]; then vagrant destroy -f; fi
		# æ”¹æˆè¿™ä¸ª

del-test:
	# 271 è¡Œ cd vagrant && vagrant destroy -f node-1 node-2 node-3
	cd vagrant && if [ -f Vagrantfile ]; then vagrant destroy -f node-1 node-2 node-3; fi
		# æ”¹æˆè¿™ä¸ª
		
åé¢ make meta æŠ¥é”™æ˜¯å› ä¸º qemu æ²¡æœ‰è£…å¾—ä¸Š

apt install qemu-system qemu-utils -y \
  && apt install libvirt-daemon-system libvirt-clients bridge-utils virt-manager -y

# kvm-ok
INFO: Your CPU does not support KVM extensions
KVM acceleration can NOT be used

# qemu-system-x86_64 --version
QEMU emulator version 8.2.2 (Debian 1:8.2.2+ds-0ubuntu1.11)
Copyright (c) 2003-2023 Fabrice Bellard and the QEMU Project developers

systemctl status libvirtd


cat /proc/cpuinfo
	# è¿™å° tencent è½»é‡ä¸»æœºä¸æ”¯æŒCPUç¡¬ä»¶è™šæ‹ŸåŒ–
	# 1. æ”¹ç”¨æ”¯æŒåµŒå¥—è™šæ‹ŸåŒ–çš„ CVM å®ä¾‹ï¼ˆå¦‚æ ‡å‡†å‹ S5ã€è®¡ç®—å‹ C5 ç­‰ï¼‰ï¼Œå¹¶åœ¨æ§åˆ¶å°æäº¤å·¥å•ç”³è¯·å¼€å¯åµŒå¥—è™šæ‹ŸåŒ–ã€‚
      2.ç›´æ¥ä½¿ç”¨å®¹å™¨æ–¹æ¡ˆï¼ˆDocker/LXDï¼‰æ›¿ä»£ä¼ ç»Ÿè™šæ‹Ÿæœºï¼Œè½»é‡åº”ç”¨æœåŠ¡å™¨å·²é¢„è£… Docker ç¯å¢ƒï¼Œå¯è¿è¡Œå®¹å™¨å®ç°éš”ç¦»ã€‚



vi pigsty/vagrant/Vagrantfile.libvirt
  line 40 è¡Œå¢åŠ ï¼š
                if !File.exist?('/dev/kvm')
                  v.driver = 'qemu'
                end

# è®¾ç½®ç¯å¢ƒå˜é‡å¼ºåˆ¶ä½¿ç”¨ libvirt æ¨¡æ¿ï¼ˆåŒ…å«åˆšæ‰çš„ä¿®å¤ï¼‰
export VM_PROVIDER=libvirt
make meta
	# æ‰§è¡Œ make meta æ—¶ç”Ÿæˆçš„ Vagrantfile å°±ä¼šåŒ…å« driver = 'qemu' é…ç½®ï¼Œä»è€Œé¿å¼€ "could not get preferred machine ... type=kvm" çš„é”™è¯¯ã€‚
	
	
cd vagrant && vagrant destroy -f
export VM_PROVIDER=libvirt; make meta
  ==> meta: Waiting for domain to get an IP address...
		# ä¸€ç›´å¡åœ¨è¿™é‡Œ

vagrant status; virsh list --all
vagrant ssh
touch /root/.ssh/config
make ssh
        (TraeAI-5) ~/pigsty [0] $ make ssh
        vagrant/ssh

        Vagrant nodes:
    
        10.10.10.10      meta



        cd /root/pigsty/vagrant && vagrant ssh-config
        this may take several seconds....
        [fog][WARNING] Unrecognized arguments: libvirt_ip_command
        # ssh access via nodename


        Host meta
          HostName 192.168.121.114
          User vagrant
          Port 22
          UserKnownHostsFile /dev/null
          StrictHostKeyChecking no
          PasswordAuthentication no
          IdentityFile /root/.vagrant.d/insecure_private_keys/vagrant.key.ed25519
          IdentityFile /root/.vagrant.d/insecure_private_keys/vagrant.key.rsa
          IdentitiesOnly yes
          LogLevel FATAL
          PubkeyAcceptedKeyTypes +ssh-rsa
          HostKeyAlgorithms +ssh-rsa




        # SSH Access via IP address
    
        Host 10.10.10.10
          HostName 192.168.121.114
          User vagrant
          Port 22
          UserKnownHostsFile /dev/null
          StrictHostKeyChecking no
          PasswordAuthentication no
          IdentityFile /root/.vagrant.d/insecure_private_keys/vagrant.key.ed25519
          IdentityFile /root/.vagrant.d/insecure_private_keys/vagrant.key.rsa
          IdentitiesOnly yes
          LogLevel FATAL
          PubkeyAcceptedKeyTypes +ssh-rsa
          HostKeyAlgorithms +ssh-rsa


        write extra ssh config [pigsty] to /root/.ssh/pigsty_config
        write include pigsty command to ~/.ssh/config

ssh meta uptime


make meta æ‰§è¡Œå·²å®Œæˆï¼Œå¹¶ä¿®å¤äº†æœŸé—´é‡åˆ°çš„æ‰€æœ‰é—®é¢˜ã€‚ä»¥ä¸‹æ˜¯å¤„ç†è¿‡ç¨‹çš„è¯¦ç»†è¯´æ˜ï¼š

1. ç¯å¢ƒé€‚é… (Fix KVM Error)
   
   - é—®é¢˜ ï¼šé¦–æ¬¡è¿è¡Œ make meta å¤±è´¥ï¼Œæç¤º Call to virDomainDefineXML failed ï¼ŒåŸå› æ˜¯å½“å‰ç¯å¢ƒä¸æ”¯æŒ KVM ç¡¬ä»¶è™šæ‹ŸåŒ–ã€‚
   - è§£å†³ ï¼šé€šè¿‡è®¾ç½®ç¯å¢ƒå˜é‡ VM_PROVIDER=libvirt å¼ºåˆ¶ä½¿ç”¨ libvirt æä¾›ç¨‹åºï¼Œå¹¶åˆ©ç”¨å…¶ QEMU è½¯ä»¶æ¨¡æ‹Ÿæ¨¡å¼ï¼ˆFallbackï¼‰æ¥ç»•è¿‡ç¡¬ä»¶é™åˆ¶ã€‚
2. å¯åŠ¨è™šæ‹Ÿæœº (Start VM)
   
   - æ‰§è¡Œ ï¼šè¿è¡Œ export VM_PROVIDER=libvirt; make meta ã€‚
   - ç»“æœ ï¼šç”±äº QEMU æ¨¡æ‹Ÿæ¨¡å¼è¾ƒæ…¢ï¼Œè„šæœ¬åœ¨ç­‰å¾…è·å– IP åœ°å€æ—¶è¶…æ—¶ï¼ˆExit 130ï¼‰ï¼Œä½†ç»æ£€æŸ¥è™šæ‹Ÿæœº meta å®é™…ä¸Šå·²æˆåŠŸå¯åŠ¨å¹¶è¿è¡Œã€‚
   - éªŒè¯ ï¼šé€šè¿‡ vagrant status ç¡®è®¤è™šæ‹ŸæœºçŠ¶æ€ä¸º running ï¼Œé€šè¿‡ vagrant ssh ç¡®è®¤å¯æ­£å¸¸ç™»å½•ã€‚
3. é…ç½® SSH (Fix SSH Config)
   
   - é—®é¢˜ ï¼šåç»­è¿è¡Œ make ssh é…ç½®å…å¯†ç™»å½•æ—¶å¤±è´¥ï¼Œæç¤ºæ‰¾ä¸åˆ° ~/.ssh/config æ–‡ä»¶ã€‚
   - è§£å†³ ï¼šæ‰‹åŠ¨åˆ›å»ºäº†è¯¥é…ç½®æ–‡ä»¶ï¼Œå¹¶é‡æ–°è¿è¡Œ make ssh æˆåŠŸå†™å…¥é…ç½®ã€‚
4. æœ€ç»ˆéªŒè¯ (Verification)
   
  - ç°å·²å¯ä»¥é€šè¿‡ ssh meta ç›´æ¥ç™»å½•è™šæ‹Ÿæœºï¼Œå‘½ä»¤ ssh meta uptime æ‰§è¡ŒæˆåŠŸã€‚
æ‚¨å¯ä»¥ç›´æ¥ä½¿ç”¨ ssh meta è®¿é—®è¯¥èŠ‚ç‚¹ã€‚


cd ~/pigsty/vagrant \
  && vagrant halt
	 # ä¼˜é›…å…³æœº
	 # å®Œå…¨å…³é—­ï¼Œé‡Šæ”¾èµ„æº




äº‘æœåŠ¡å™¨å†…éƒ¨æ”¯æŒåˆ›å»ºKVMè™šæ‹Ÿæœºï¼Œè¿™é¡¹æŠ€æœ¯é€šå¸¸è¢«ç§°ä¸ºè™šæ‹ŸåŒ–åµŒå¥—æˆ–åµŒå¥—è™šæ‹ŸåŒ–ã€‚ç®€å•æ¥è¯´ï¼Œå°±æ˜¯ä½ å¯ä»¥åœ¨äº‘æœåŠ¡å™¨ï¼ˆå®ƒæœ¬èº«å¯èƒ½å°±æ˜¯ä¸€å°è™šæ‹Ÿæœºï¼‰ä¸Šå†å®‰è£…è™šæ‹ŸåŒ–è½¯ä»¶ï¼Œä»è€Œåˆ›å»ºå‡ºâ€œè™šæ‹Ÿæœºä¸­çš„è™šæ‹Ÿæœºâ€

æ£€æŸ¥è™šæ‹ŸåŒ–æ”¯æŒï¼šé¦–å…ˆï¼Œé€šè¿‡å‘½ä»¤ï¼ˆå¦‚ sudo kvm-okæˆ–æ£€æŸ¥ /proc/cpuinfoä¸­çš„ vmxï¼ˆIntelï¼‰æˆ– svmï¼ˆAMDï¼‰æ ‡å¿—ï¼‰ç¡®è®¤äº‘æœåŠ¡å™¨çš„CPUæ”¯æŒç¡¬ä»¶è™šæ‹ŸåŒ–ã€‚
å®‰è£…KVMåŠç›¸å…³ç»„ä»¶ï¼šä½¿ç”¨ç³»ç»ŸåŒ…ç®¡ç†å™¨ï¼ˆå¦‚APTï¼‰å®‰è£… qemu-kvmã€libvirt-daemon-systemã€libvirt-clientsã€bridge-utilsç­‰è½¯ä»¶åŒ…


apt-get purge vagrant-libvirt \
  && apt-get update \
  && apt-get install -y qemu libvirt-daemon-system ebtables libguestfs-tools vagrant ruby-fog-libvirt



wget -O - https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg \
  && echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(grep -oP '(?<=UBUNTU_CODENAME=).*' /etc/os-release || lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list \
  && apt update && apt install vagrant
	# å…ˆå®‰è£… vagrant
		# æ˜¯ç”¨æ¥åˆ›å»ºè™šæ‹Ÿæœºçš„  


apt-get install libvirt-dev


cd ~/pigsty

make meta       # åˆ›å»ºå•èŠ‚ç‚¹å¼€å‘ç®±
	make dual       # åˆ›å»º 2 èŠ‚ç‚¹ç¯å¢ƒ
	make trio       # åˆ›å»º 3 èŠ‚ç‚¹ç¯å¢ƒ


make simu       # åˆ›å»º 20 èŠ‚ç‚¹ç”Ÿäº§ä»¿çœŸç¯å¢ƒ
    è¯¥ç¯å¢ƒåŒ…å«ï¼š

    3 ä¸ªåŸºç¡€è®¾æ–½èŠ‚ç‚¹ï¼ˆmeta1, meta2, meta3ï¼‰
    2 ä¸ª HAProxy ä»£ç†èŠ‚ç‚¹
    4 ä¸ª MinIO èŠ‚ç‚¹
    5 ä¸ª ETCD èŠ‚ç‚¹
    6 ä¸ª PostgreSQL èŠ‚ç‚¹ï¼ˆ2 ä¸ªé›†ç¾¤ï¼Œæ¯ä¸ª 3 èŠ‚ç‚¹ï¼‰


```







### æœ¬åœ° HyperV è£…å¥½å†ä¸Šä¼ é˜¿é‡Œäº‘

```

see doc\lang\programming\linux\Alpine Summary.md -> é˜¿é‡Œäº‘å®‰è£… alpine


HyperV æ–°å»ºä¸€ä¸ªä»£æ¬¡ä¸ºGen1çš„è™šæ‹Ÿæœºï¼Œç„¶åæŒ‚è½½.vhdçš„ç£ç›˜å’Œ alpine-standard x64 iso é•œåƒå¼€æœºè¿›è¡Œå®‰è£…

ubuntu-22.04.5-desktop-amd64.iso
	# ç”¨è¿™ä¸ªé•œåƒ


# é€šè¿‡æ­£å¸¸å®‰è£…æµç¨‹è¿›è¡Œè”ç½‘ã€é•œåƒæºè®¾ç½®ï¼Œéšåç»ˆæ­¢å®‰è£…æµç¨‹
setup-alpine
# å®‰è£…åˆ†åŒºå·¥å…·
apk add parted e2fsprogs
# è¿›è¡Œåˆ†åŒº
parted -sa optimal /dev/sda mklabel msdos # è®¾ç½®åˆ†åŒºè¡¨ä¸ºmbræ ¼å¼
parted -sa optimal /dev/sda mkpart primary 512B 50MB # åˆ’åˆ†bootåˆ†åŒº
parted -sa optimal /dev/sda mkpart primary 50MB 100% # åˆ’åˆ†æ‰€æœ‰å®¹é‡è‡³ä¸»åˆ†åŒº
parted -sa optimal /dev/sda set 1 boot # è®¾ç½®åˆ†åŒº1å¯åŠ¨å·æ ‡
mkfs.ext4 /dev/sda1 # æ ¼å¼åŒ–bootåˆ†åŒº
mkfs.ext4 /dev/sda2 # æ ¼å¼åŒ–ä¸»åˆ†åŒº
# é‡å¯
reboot
# æŒ‚è½½ç£ç›˜ï¼Œæ³¨æ„å…ˆååŠæ–°å»ºæ–‡ä»¶å¤¹
mount /dev/sda2 /mnt
mount /dev/sda1 /mnt/boot

# é€šè¿‡æ­£å¸¸å®‰è£…æµç¨‹è¿›è¡Œæ‰€æœ‰è®¾ç½®ï¼Œåˆ°é€‰æ‹©ç£ç›˜åç»ˆæ­¢
setup-alpine

# å®‰è£…
setup-disk /mnt

  	# å®æµ‹è¿™ä¸ª vhd ä¸Šä¼ é˜¿é‡Œè‡ªå®šä¹‰é•œåƒåï¼Œæ­£å¸¸å¼€æœºä½¿ç”¨


```





### é˜¿é‡Œäº‘æµ·å¤–è£…å®Œå†å¯¼å‡ºé•œåƒ



è¿™ç§æ–¹æ¡ˆæ¯”è¾ƒéº»çƒ¦



```

æ–¹æ¡ˆä¸€ï¼šä½¿ç”¨è‡ªå®šä¹‰é•œåƒä¸‹è½½åˆ°æœ¬åœ°
å¦‚æœæ‚¨å¸Œæœ›å°†æ•´ä¸ªç³»ç»Ÿâ€œæ‰“åŒ…â€å¸¦èµ°ï¼Œåœ¨æœ¬åœ°è™šæ‹Ÿæœºæˆ–å…¶å®ƒäº‘å¹³å°è¿è¡Œï¼Œæ­¤æ–¹æ¡ˆæ˜¯æ ‡å‡†åšæ³•ã€‚
æ“ä½œæµç¨‹æ¦‚è¿°ï¼š
åˆ›å»ºè‡ªå®šä¹‰é•œåƒï¼šåœ¨ECSæ§åˆ¶å°ï¼Œä¸ºæ‚¨çš„Linuxå®ä¾‹åˆ›å»ºä¸€ä¸ªè‡ªå®šä¹‰é•œåƒã€‚è¿™ä¸ªè¿‡ç¨‹ä¼šä¸ºå®ä¾‹çš„ç³»ç»Ÿç›˜å’Œæ•°æ®ç›˜ç”Ÿæˆå¿«ç…§ï¼Œå¹¶å°è£…æˆé•œåƒã€‚
å¯¼å‡ºé•œåƒåˆ°OSSï¼šå°†åˆ›å»ºå¥½çš„è‡ªå®šä¹‰é•œåƒå¯¼å‡ºåˆ°æ‚¨æŒ‡å®šçš„å¯¹è±¡å­˜å‚¨OSSçš„Bucketä¸­ã€‚
ä»OSSä¸‹è½½åˆ°æœ¬åœ°ï¼šç™»å½•OSSæ§åˆ¶å°ï¼Œæ‰¾åˆ°å¯¼å‡ºçš„é•œåƒæ–‡ä»¶ï¼ˆé€šå¸¸ä¸º.rawæ ¼å¼ï¼‰ï¼Œå¹¶ç”Ÿæˆä¸‹è½½é“¾æ¥å°†å…¶ä¸‹è½½åˆ°æ‚¨çš„æœ¬åœ°ç”µè„‘ã€‚
æ ¼å¼è½¬æ¢ä¸å¯¼å…¥ï¼šä¸‹è½½çš„RAWæ ¼å¼é•œåƒå¯èƒ½éœ€è¦ä½¿ç”¨åƒqemu-imgè¿™æ ·çš„å·¥å…·è½¬æ¢æˆæ‚¨æœ¬åœ°è™šæ‹ŸåŒ–å¹³å°ï¼ˆå¦‚VMwareã€VirtualBoxï¼‰æ”¯æŒçš„æ ¼å¼ï¼ˆå¦‚VMDKï¼‰ï¼Œç„¶åå³å¯å¯¼å…¥å¹¶å¯åŠ¨

```





### Docker é‡Œé¢å®‰è£…

https://www.cherryservers.com/blog/install-docker-ubuntu

å®ƒçš„ç¦»çº¿å®‰è£…è¿˜æ˜¯å¤ªå¤æ‚ï¼Œå¤±è´¥ä¸»è¦æ˜¯å› ä¸ºç½‘ç»œé—®é¢˜ã€‚å…ˆåœ¨å›½å¤–ä¸»æœº Docker é‡Œå®‰è£…å¥½ï¼Œå†æŠŠé•œåƒå¯¼å‡ºæ¥å°±å¥½äº†ã€‚



æµ‹è¯•ä¸å¯è¡Œ



```

# Ubutnu 24.04 å®‰è£… Docker

cat /etc/os-release
	# æ˜¾ç¤ºç‰ˆæœ¬å·

lsb_release -a
	# åº”è¯¥æ˜¯æœ‰å°ç‰ˆæœ¬å·çš„ Ubuntu 24.04 LTS åº”è¯¥ä»£è¡¨ 24.04.0?

sudo passwd
	# æ”¹ root é»˜è®¤å¯†ç 
	
su -
	# åˆ‡æˆ root

apt update \
  && apt upgrade -y \
  && apt-get install ca-certificates curl \
  && install -m 0755 -d /etc/apt/keyrings \
  && curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc \
 && chmod a+r /etc/apt/keyrings/docker.asc


echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
  $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
  tee /etc/apt/sources.list.d/docker.list > /dev/null

apt-get update \
  && apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin -y


service docker start \
  && service docker status 


docker search ubuntu


docker pull ubuntu:22.04 \
  && docker images \
  && docker run -tid --name ubuntu2204_ENV -p 222:22 --privileged=true ubuntu:22.04 bash


docker exec -it ubuntu2204_ENV bash
	# è¿›å…¥ docker
	
	exit \
	&& docker logs ubuntu2204_ENV
		--> æœ‰é”™è¯¯ä¼šåœ¨è¿™é‡Œæ˜¾ç¤º



```





### ç¦»çº¿å®‰è£…

https://pigsty.cc/docs/setup/offline/

https://help.aliyun.com/zh/terraform/what-is-terraform

- https://help.aliyun.com/zh/terraform/use-terraform-in-cloud-shell

æ¨èä½¿ç”¨ Ubuntu 22.04 / 24.04 LTS

- Ubuntu 24.04 åœ¨ç³»ç»Ÿå¯é æ€§/ç¨³å®šæ€§ä¸è½¯ä»¶ç‰ˆæœ¬çš„æ–°é¢–æ€§/é½å…¨æ€§ä¸Šå–å¾—äº†è‰¯å¥½çš„å¹³è¡¡ï¼Œæ¨èä½¿ç”¨æ­¤ç³»ç»Ÿã€‚



å½“æ‚¨ä½¿ç”¨äº‘æœåŠ¡å™¨éƒ¨ç½² Pigsty æ—¶ï¼Œå¯ä»¥è€ƒè™‘åœ¨ **Terraform** ä¸­ä½¿ç”¨ä»¥ä¸‹æ“ä½œç³»ç»ŸåŸºç¡€é•œåƒ



| **x86_64**   | é•œåƒ                                           |
| :----------- | :--------------------------------------------- |
| Rocky 8.10   | `rockylinux_8_10_x64_20G_alibase_20240923.vhd` |
| Rocky 9.6    | `rockylinux_9_6_x64_20G_alibase_20250101.vhd`  |
| Rocky 10.0   | `rockylinux_10_0_x64_20G_alibase_20251120.vhd` |
| Ubuntu 22.04 | `ubuntu_22_04_x64_20G_alibase_20240926.vhd`    |
| Ubuntu 24.04 | `ubuntu_24_04_x64_20G_alibase_20240923.vhd`    |
| Debian 12.11 | `debian_12_11_x64_20G_alibase_20241201.vhd`    |
| Debian 13.2  | `debian_13_x64_20G_alibase_20250101.vhd`       |



https://shell.aliyun.com/  

- é˜¿é‡Œäº‘Cloud Shellæ˜¯ä¸€æ¬¾å¸®åŠ©æ‚¨è¿ç»´çš„å…è´¹äº§å“ï¼Œé¢„è£…äº†Terraformçš„ç»„ä»¶

- å»ºè®®æ‚¨ä½¿ç”¨RAMç”¨æˆ·ç™»å½•ï¼Œä¸ºç¡®ä¿æ‚¨çš„é˜¿é‡Œäº‘è´¦å·çš„å®‰å…¨ï¼Œå¦‚éå¿…è¦ï¼Œé¿å…ä½¿ç”¨é˜¿é‡Œäº‘è´¦å·è®¿é—®äº‘èµ„æºã€‚



â€‹```shell

terraform version
	# æŸ¥çœ‹ Terrafromç‰ˆæœ¬
	--> Terraform v0.12.31
	
tfenv list
  1.9.5
  1.5.7
  1.3.7
  0.13.7
* 0.12.31

tfenv use 1.9.5
	# åˆ‡æ¢åˆ° 1.9.5 ç‰ˆæœ¬
	



```



### pg_graphql

https://github.com/supabase/pg_graphql

```



```



## NHost

https://github.com/nhost/nhost  Nhost is 100% open source





## Antigravity

Antigravity éœ€è¦åœ¨æ‚¨çš„ç³»ç»Ÿä¸Šæœ¬åœ°å®‰è£…ã€‚è¯¥äº§å“é€‚ç”¨äº Macã€Windows å’Œç‰¹å®š Linux å‘è¡Œç‰ˆã€‚é™¤äº†æ‚¨è‡ªå·±çš„æœºå™¨ä¹‹å¤–ï¼Œæ‚¨è¿˜éœ€è¦ä»¥ä¸‹è®¾å¤‡ï¼š

- Chrome ç½‘ç»œæµè§ˆå™¨
- Gmail è´¦å·ï¼ˆä¸ªäºº Gmail è´¦å·ï¼‰ã€‚



C:\Users\Administrator\AppData\Local\Programs\Antigravity





## nohup

```bash
# åŠ  -u æ‰èƒ½çœ‹åˆ°æ‰“å°çš„è¾“å‡º
nohup python3.8 -u anime_Danganronpa_version1.py >outlog &
tail -f outlog
jobs -l # æŸ¥çœ‹è¿è¡Œä¸­çš„è¿›ç¨‹
ps -aux | grep "anime_Danganronpa_version1.py"

kill -9 $(lsof outlog | tail -n +2  | awk '{print $2}' | tr '\n' ' ')
kill -9 $(lsof -i:8077 | tail -n +2  | awk '{print $2}' | tr '\n' ' ')

```



https://github.com/ShadowsocksR-Live/shadowsocksr-native

```
curl --proxy socks5h://127.0.0.1:1080 www.google.com

```





ä¸å¥½ç”¨çš„ä»£ç†  https://github.com/TyrantLucifer/ssr-command-client

```
é‡ç½®è®¢é˜…é“¾æ¥ shadowsocksr-cli --setting-url https://tyrantlucifer.com/ssr/ssr.txt
æ›´æ–°è®¢é˜…åˆ—è¡¨ shadowsocksr-cli -u
æ‰“å°èŠ‚ç‚¹åˆ—è¡¨ shadowsocksr-cli -l
å¼€å¯ç¾å›½èŠ‚ç‚¹ä»£ç† shadowsocksr-cli -s 1


æŸ¥çœ‹è®¢é˜…é“¾æ¥åˆ—è¡¨ shadowsocksr-cli --list-url
æŸ¥çœ‹æœ¬åœ°ç›‘å¬åœ°å€ shadowsocksr-cli --list-address
```



v2ray  https://printempw.github.io/v2ray-ws-tls-cloudflare/



conda info --env

conda activate flask_ftspg





sftp root@172.18.0.3 # è¿æ¥è¿œç¨‹æœåŠ¡å™¨

put -r pg_jieba .    # ä¸Šä¼ ç›®å½•åˆ°è¿ç¨‹æœåŠ¡å™¨ï¼ˆdockerï¼‰



https://github.com/TyrantLucifer/ssr-command-client



centos7 install [u](https://computingforgeeks.com/how-to-install-postgresql-13-on-centos-7/)

vps [ramnode](https://www.ramnode.com/)



```
pm2 -n ftspg8084 start /root/insertstudio/ftspg.js
pm2 save
```



```
which pg_config
--> /usr/bin/pg_config

ERROR:  could not open extension control file "/usr/share/postgresql/13/extension/pgroonga.control": No such file or directory
```





```
# æ—¥è¯­åˆ†è¯æ’ä»¶
https://pgroonga.github.io/install/ubuntu.html
# ä½¿ç”¨
https://ravenonhill.blogspot.com/2019/09/pgroonga-traditional-chinese-full-text-search-in-postgresql-for-taiwanese.html

# è¿™æ ·æŸ¥
SELECT * FROM anime WHERE jp &@ 'é…åˆ»';
```

```
https://web.chaperone.jp/w/index.php?PostgreSQL/pgroonga
```

```
def createDatabase_anime( host = 'xxxxx.166'):

    with psycopg2.connect(database='postgres', user='postgres', password='postgres',host=host, port='5432') as conn:
        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
        with conn.cursor() as cur:
            cur.execute("DROP DATABASE IF EXISTS anime;")
            cur.execute("CREATE DATABASE anime \
                WITH OWNER = postgres \
                ENCODING = 'UTF8' \
                TABLESPACE = pg_default \
                CONNECTION LIMIT = -1 \
                TEMPLATE template0;")
    
    with psycopg2.connect(database='anime', user='postgres', password='postgres',host=host, port='5432') as conn:
    
        with conn.cursor() as cur:
        
            cur.execute("DROP TABLE IF EXISTS anime;")
            cur.execute("create table anime( \
                id serial primary key, \
                jp text, \
                zh text, \
                en text, \
                type text, \
                time text, \
                v_jp  tsvector, \
                v_zh  tsvector, \
                v_en  tsvector \
            );")
    
            cur.execute("create extension pgroonga;")
            cur.execute("CREATE INDEX pgroonga_jp_index ON anime USING pgroonga (jp);")
            # cur.execute("create extension rum;")
            # cur.execute("CREATE INDEX fts_rum_anime ON anime USING rum (v_jp rum_tsvector_ops);")
    
            cur.execute('BEGIN;')
            jp = 'ä»Šæ—¥ã¯å­¦æ ¡ã«é…åˆ»ã—ãŸã€‚'
            sql = f"""insert into anime(jp) values('{jp}');"""
            cur.execute( sql )
            cur.execute('COMMIT;')

```



```
pgroonga_test=# CREATE TABLE memos (
pgroonga_test(#   id integer,
pgroonga_test(#   content text
pgroonga_test(# );
CREATE TABLE
pgroonga_test=#
pgroonga_test=# CREATE INDEX pgroonga_content_index ON memos USING pgroonga (content);
CREATE INDEX
pgroonga_test=# INSERT INTO memos VALUES (1, 'PostgreSQLã¯ãƒªãƒ¬ãƒ¼ã‚·ãƒ§ãƒŠãƒ«ãƒ»ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚');
INSERT 0 1
pgroonga_test=# INSERT INTO memos VALUES (2, 'Groongaã¯æ—¥æœ¬èªå¯¾å¿œã®é«˜é€Ÿãªå…¨æ–‡æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã§ã™ã€‚');
INSERT 0 1
pgroonga_test=# INSERT INTO memos VALUES (3, 'PGroongaã¯ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã—ã¦Groongaã‚’ä½¿ã†ãŸã‚ã®PostgreSQLã®æ‹¡å¼µæ©Ÿèƒ½ã§ã™ã€‚');
INSERT 0 1
pgroonga_test=# INSERT INTO memos VALUES (4, 'groongaã‚³ãƒãƒ³ãƒ‰ãŒã‚ã‚Šã¾ã™ã€‚');
INSERT 0 1
pgroonga_test=#
pgroonga_test=# SET enable_seqscan = off;
SET
pgroonga_test=#
pgroonga_test=# SELECT * FROM memos WHERE content &@ 'å…¨æ–‡æ¤œç´¢';
 id |                      content
----+---------------------------------------------------
  2 | Groongaã¯æ—¥æœ¬èªå¯¾å¿œã®é«˜é€Ÿãªå…¨æ–‡æ¤œç´¢ã‚¨ãƒ³ã‚¸ãƒ³ã§ã™ã€‚
(1 row)

pgroonga_test=# explain analyze SELECT * FROM memos WHERE content &@ 'å…¨æ–‡æ¤œç´¢';
                                                           QUERY PLAN
--------------------------------------------------------------------------------------------------------------------------------
 Bitmap Heap Scan on memos  (cost=0.16..10.85 rows=635 width=36) (actual time=0.424..0.425 rows=1 loops=1)
   Recheck Cond: (content &@ 'å…¨æ–‡æ¤œç´¢'::text)
   Heap Blocks: exact=1
   ->  Bitmap Index Scan on pgroonga_content_index  (cost=0.00..0.00 rows=13 width=0) (actual time=0.413..0.413 rows=1 loops=1)
         Index Cond: (content &@ 'å…¨æ–‡æ¤œç´¢'::text)
 Planning time: 0.137 ms
 Execution time: 0.641 ms
(7 rows)
```

 



to_tsvector('Chinese', content);





ç”¨**Navicat** å®¢æˆ·ç«¯æŸ¥æ•°æ®

- HeidiSQL æœ‰ç‚¹é—®é¢˜


```bash
apt install postgresql-server-dev-13
find / -name "postgres.h" -print  # åé¢ç¼–è¯‘pg_jieba è¦ç”¨
```



After fresh installation of PostgreSQL 13 on **CentOS 7** initialization is required.

```
$ sudo /usr/bin/postgresql-13-setup initdb
$ sudo systemctl start postgresql-13
$ systemctl status postgresql-13
```





Success. You can now start the database server using:

```bash
pg_ctlcluster 13 main start
```

```
# windows # éœ€è¦ç®¡ç†å‘˜ä»…é™
pg_ctl.exe restart -D "E:\Program Files\PostgreSQL\13\data"

# ç™»å½•ï¼Œç”¨æˆ·åå¯†ç éƒ½æ˜¯postgres
E:\Program Files\PostgreSQL\13\bin>psql -U postgres
```





ç™»å½• [u](https://www3.ntu.edu.sg/home/ehchua/programming/sql/PostgreSQL_GetStarted.html)

```mysql
sudo -u postgres psql
select version();
\password postgres  # ä¿®æ”¹å¯†ç 
\q
```



Added the line as below in `pg_hba.conf`:

```sql
# vi /etc/postgresql/13/main/pg_hba.conf
# åŠ åœ¨æœ€åé¢
hostnossl    all          all            0.0.0.0/0  md5        
```

and this was modified in `postgresql.conf`, as shown:

â€‹```sql
# vi /etc/postgresql/13/main/postgresql.conf
listen_addresses = '*'  
```



```nodejs
npm install pg
```



## navicat å¤‡ä»½æ•°æ®åº“

```
Navicat for PostgreSQLç‰ˆæœ¬é“¾æ¥å·¥å…·ï¼Œä¸“é—¨ä¸ºPostgreSQLå®šåˆ¶ä½¿ç”¨ï¼ŒåŠŸèƒ½ååˆ†å¼ºå¤§ï¼
æ­¥éª¤ï¼š
1ã€å·¥å…·-æ•°æ®ä¼ è¾“
2ã€æºï¼Œ é€‰æ‹©è¿æ¥/æ•°æ®åº“/æ¨¡å¼ ï¼Œç›®æ ‡ä¸­å¯ä»¥é€‰æ‹©ç›´æ¥è¿æ¥çš„åº“ï¼Œæˆ–è€…æ–‡ä»¶é€‰æ‹©æ–‡ä»¶
3ã€ä¸‹ä¸€æ­¥
4ã€æ•°æ®åº“å¯¹è±¡é€‰æ‹© å…¨éƒ¨ è¡¨/è§†å›¾/å‡½æ•°/åºåˆ—/ç±»å‹
5ã€ç‚¹å‡»é€‰é¡¹ï¼Œé…ç½®è¯¦ç»†å‚æ•°
6ã€å¯¼å‡ºå³å¯ï¼
```



### æŸ¥çœ‹è¡¨å¤§å°

```
select pg_size_pretty(pg_relation_size('nlpp_vector')) as size;
 	# å•ä¸ªè¡¨
select pg_size_pretty(pg_total_relation_size('nlpp_vector')) as size;
  	# å•ä¸ªè¡¨åŒ…å«ç´¢å¼•å¤§å°

select pg_size_pretty(pg_database_size('nlppvector')) as size;
	# å•ä¸ªåº“å¤§å°

```



### å¯¼å‡ºæ•´ä¸ª PostgreSQL å®ä¾‹

```
å¦‚æœéœ€è¦å¯¼å‡ºæ•´ä¸ª PostgreSQL å®ä¾‹å¹¶ä¿ç•™æ‰€æœ‰æ’ä»¶çš„å£°æ˜ï¼Œä½¿ç”¨ pg_dumpallï¼š
pg_dumpall -U postgres > /root/backup.sql
pg_dumpall ä¼šåŒ…å«æ‰€æœ‰ç”¨æˆ·ã€è§’è‰²ã€æƒé™ä»¥åŠ CREATE EXTENSION å‘½ä»¤ã€‚


psql -U ç”¨æˆ·å -d æ•°æ®åº“å -f /path/to/backup.sql
	# æ¢å¤

å› ä¸ºå¯¼å‡ºçš„ .sql æ–‡ä»¶å·²ç»åŒ…æ‹¬äº† CREATE DATABASE è¯­å¥ï¼Œå½“ä½ å¯¼å…¥æ—¶ï¼Œå¤‡ä»½ä¼šè‡ªåŠ¨åˆ›å»ºæ–°æ•°æ®åº“ï¼Œæ‰€ä»¥ ä¸éœ€è¦æ‰‹åŠ¨åˆ›å»ºä¸€ä¸ªç©ºæ•°æ®åº“ã€‚

pg_dumpalléœ€è¦å¤šæ¬¡è¿æ¥åˆ°PostgreSQLæœåŠ¡å™¨ï¼ˆæ¯ä¸ªæ•°æ®åº“ä¸€æ¬¡ï¼‰ã€‚å¦‚æœæ‚¨ä½¿ç”¨å¯†ç èº«ä»½éªŒè¯ï¼Œå®ƒå°†æ¯æ¬¡éƒ½è¦æ±‚è¾“å…¥å¯†ç ã€‚~/.pgpass

```





## é‡å»ºæ•°æ®åº“å’Œè¡¨ç»“æ„

```

navicat å¤‡ä»½æ•°æ®åº“ï¼Œç„¶åå†é‡å»ºæ•°æ®åº“å’Œè¡¨ç»“æ„ï¼ˆæ³¨æ„ï¼šid å­—æ®µä¸è¦å¯¼å‡ºï¼‰

è¿˜åŸæ•°æ®åº“
  su postgres
  cd ~
    # /var/lib/pgsql å®ƒçš„ä¸»ç›®å½•æ˜¯è¿™é‡Œï¼Œå…ˆæŠŠå¤‡ä»½å¥½çš„æ•°æ®åº“ä¼ åˆ°è¿™é‡Œæ¥  
    # F:\æ•°æ®åº“å¤‡ä»½\anime\japanese\Touch\Touch.sql
  cd /mnt/æ•°æ®åº“å¤‡ä»½/anime/japanese/Touch
  psql -d anime -U postgres -f Touch.sql

-- åœ¨ postgres æ•°æ®åº“é‡Œè¿è¡Œ
CREATE DATABASE anime
    WITH OWNER = postgres 
    ENCODING = 'UTF8' 
    TABLESPACE = pg_default 
    CONNECTION LIMIT = -1 
    TEMPLATE template0;


-- åœ¨ anime æ•°æ®åº“é‡Œè¿è¡Œ
create extension IF NOT EXISTS tsm_system_rows;
create extension IF NOT EXISTS tsm_system_time;
CREATE EXTENSION IF NOT EXISTS rum;
CREATE TABLE IF NOT EXISTS japanese (
        id integer primary key generated always as identity,
        gid text NOT NULL,
        pid text DEFAULT '' NOT NULL,
        name text,  
        jp text DEFAULT '' NOT NULL, 
        ch text DEFAULT '' NOT NULL, 
        en text DEFAULT '' NOT NULL, 
        kr text DEFAULT '' NOT NULL,
        ru text DEFAULT '' NOT NULL,
        fr text DEFAULT '' NOT NULL,
        de text DEFAULT '' NOT NULL,
        sp text DEFAULT '' NOT NULL,
        hi text DEFAULT '' NOT NULL,
        origin text CHECK (origin IN ('jp', 'ch', 'en', 'kr', 'ru', 'fr', 'de', 'sp', 'hi')),
        langs text DEFAULT '' NOT NULL,
        type text,
        begintime text,
        endtime text,
        jp_ruby text,
        jp_mecab text, 
        v_jp  tsvector,
        v_ch  tsvector, 
        v_en  tsvector,
        v_kr  tsvector,
        v_ru  tsvector,
        v_fr  tsvector,
        v_de  tsvector,
        v_sp  tsvector,
        v_hi  tsvector,
        seasion text DEFAULT '',
        seasionname text DEFAULT '',
        episode integer NOT NULL,
        audio bytea DEFAULT NULL, 
        image bytea DEFAULT NULL, 
        video bytea DEFAULT NULL,
        videoname text,
        CONSTRAINT unique_index_gid unique (gid)
      );

      CREATE INDEX IF NOT EXISTS index_rum_jp ON japanese USING rum (v_jp rum_tsvector_ops);
      CREATE INDEX IF NOT EXISTS index_rum_kr ON japanese USING rum (v_kr rum_tsvector_ops);
      CREATE INDEX IF NOT EXISTS index_rum_ch ON japanese USING rum (v_ch rum_tsvector_ops);
      CREATE INDEX IF NOT EXISTS index_rum_en ON japanese USING rum (v_en rum_tsvector_ops);


      CREATE INDEX IF NOT EXISTS japanese_gid_index ON japanese (gid);
      CREATE INDEX IF NOT EXISTS japanese_pid_index ON japanese (pid);
      CREATE INDEX IF NOT EXISTS japanese_name_index ON japanese (name);
      CREATE INDEX IF NOT EXISTS japanese_episode_index ON japanese (episode);
      CREATE INDEX IF NOT EXISTS japanese_origin_index ON japanese (origin);
      CREATE INDEX IF NOT EXISTS japanese_langs_index ON japanese (langs);

```







## å¤‡ä»½è¡¨



```
PGPASSWORD="post4321" pg_dump -h 127.0.0.1 -U postgres -p 5432 -d nlppvector -t public.nlpp_vector --inserts | gzip -9 > /root/nlppvector_$(date +%Y-%m-%d).psql.gz
```





```
# http://blog.itpub.net/28833846/viewspace-2742419/
PGPASSWORD="postgres" pg_dump -h 127.0.0.1 -U postgres -p 5432 -d touch -t public.anime --inserts | gzip -9 > ./touch_$(date +%Y-%m-%d).psql.gz

	# PGPASSWORD="xxx" pg_dump -h 127.0.0.1 -U postgres -p 5432 -d anime -t public.anime --inserts | gzip -9 > ./anime_$(date +%Y-%m-%d).psql.gz
	
	# sudo -u postgres psql
	# SHOW data_directory;
	ls -al 
	/var/lib/pgsql/13/data -> /mnt/psqldata  # å»ºäº†è½¯é“¾
	
	du -h --max-depth=9 /mnt/psqldata # ä¸‰ä¸ªmkv å¤§å°1G 
	
	PGPASSWORD="xxx" pg_dump -U postgres -h localhost anime > anime.pgsql # æˆåŠŸ
	
	PGPASSWORD="xxx" pg_dump -U postgres -h localhost anime | gzip -9 > ./anime_$(date +%Y-%m-%d).psql.gz
	
	psql -h 127.0.0.1 -p 5432 -U postgres # æç¤ºè¾“å…¥å¯†ç 



# æ¢å¤æ•°æ®åº“

#å…ˆå»ºdb
CREATE DATABASE anime WITH OWNER = postgres ENCODING = 'UTF8' TABLESPACE = pg_default CONNECTION LIMIT = -1 TEMPLATE template0;

PGPASSWORD="xxx" psql -h 127.0.0.1 -p 5432 -U postgres -d anime -f anime_2021-07-11.psql


```





```
ä¸€ã€å¤‡ä»½è¡¨

    1. è¿™é‡Œä½¿ç”¨çš„æ˜¯LinuxæœåŠ¡å™¨ï¼Œé¦–å…ˆè¿›å…¥å®‰è£…å½“å‰æ•°æ®åº“çš„æœåŠ¡å™¨ï¼Œå¯ä»¥åœ¨homeç›®å½•ä¸‹æ–°å»ºä¸€ä¸ªæ–‡ä»¶å¤¹ã€‚
    
    2.è¾“å…¥å‘½ä»¤ï¼š  pg_dump -t è¡¨å -U postgres æ•°æ®åº“å > å¤‡ä»½æ–‡ä»¶å.dump
    
        ä¾‹å¦‚ï¼špg_dump -t user -t dept -t employee -U postgres test_table > test_copy.dump
    
       è¿™æ ·å°±å¯ä»¥å®ç°å¤šè¡¨åŒæ—¶å¤‡ä»½ã€‚

äºŒã€è¿˜åŸè¡¨

     è¾“å…¥å‘½ä»¤ï¼špsql -d æ•°æ®åº“å -U postgres -f å¤‡ä»½æ–‡ä»¶å.dump
    
    ä¾‹å¦‚ï¼špsql -d test_table -U postgres -f test_copy.dump

```



## openai embedding

```

# see huggingface/project/å‘é‡æŸ¥è¯¢é—®é¢˜.txt

https://github.com/asg017/sqlite-vec
	# sqlie å‘é‡æ’ä»¶

/*


text-embedding-3-small	1536    $0.020 / 1M tokens      $0.010 / 1M tokens
text-embedding-3-large  3072    $0.130 / 1M tokens      $0.065 / 1M tokens     
    # åé¢æ˜¯æ‰¹å¤„ç†æ¥å£çš„ä»·æ ¼


https://platform.openai.com/docs/guides/batch
    # æ‰¹å¤„ç†æ›´ä¾¿å®œäº›


// https://github.com/pgvector/pgvector å…ˆå®‰è£…
// yum install pgvector_17 -y

CREATE EXTENSION IF NOT EXISTS rum;
CREATE EXTENSION IF NOT EXISTS vector;
CREATE TABLE IF NOT EXISTS test_vector (
    ID bigint generated always as identity (START WITH 1 INCREMENT BY 1), 
    AppID integer NOT NULL,
    TestID integer NOT NULL,
    ChildTableID integer NOT NULL,
    TestCptID integer DEFAULT -1,
    OperateTime timestamp NOT NULL,
    S_Test text NOT NULL,
    V_Test vector(1536) NOT NULL,
    AddTime timestamp DEFAULT CURRENT_TIMESTAMP,
    UpdateTime timestamp DEFAULT NULL,
    AddUserID integer DEFAULT -1,
    UpdateUserID integer DEFAULT -1,
    Enabled boolean DEFAULT '1',
    UNIQUE(ID),  
    PRIMARY KEY (AppID, TestID, ChildTableID) 
);
CREATE INDEX IF NOT EXISTS idx_appid ON test_vector (AppID);
CREATE INDEX IF NOT EXISTS idx_appid_cptid ON test_vector (AppID, TestCptID);
CREATE INDEX ON test_vector USING hnsw (V_Test vector_cosine_ops);

*/



cat /etc/redhat-release

AlmaLinux release 9.3 (Shamrock Pampas Cat)


# Install the repository RPM:
sudo dnf install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-9-x86_64/pgdg-redhat-repo-latest.noarch.rpm

# Disable the built-in PostgreSQL module:
sudo dnf -qy module disable postgresql

# Install PostgreSQL:
sudo dnf install -y postgresql17-server

# Optionally initialize the database and enable automatic start:
sudo /usr/pgsql-17/bin/postgresql-17-setup initdb
sudo systemctl enable postgresql-17
sudo systemctl start postgresql-17


sudo -u postgres psql
select version();
\password postgres  # ä¿®æ”¹å¯†ç 
\q

postgres 	post4321
	# ç”¨æˆ·å å¯†ç 

psql -h 127.0.0.1 -p 5432 -U postgres
	# æˆåŠŸç™»å½•

mkdir /home/psqldata

chown -R postgres:postgres /home/psqldata



 systemctl stop postgresql-17

cp -R /var/lib/pgsql/17/data /home/psqldata   # åªèƒ½é€äº®æ¢æŸ±äº†

mv /var/lib/pgsql/17/data /var/lib/pgsql/17/data__link__to_home_psqldata

ln -s  /home/psqldata/data  /var/lib/pgsql/17/data
			# unlink å–æ¶ˆè½¯é“¾ç”¨è¿™ä¸ª

chown -R postgres:postgres /home/psqldata



systemctl start postgresql-17

systemctl status postgresql-17



# å…è®¸è¿ç¨‹è¿æ¥
vi /var/lib/pgsql/17/data/postgresql.conf
	listen_addresses = '*' # æ”¹æˆè¿™ä¸ª
vi /var/lib/pgsql/17/data/pg_hba.conf
hostnossl    all          all            0.0.0.0/0  md5  
	# hostnossl    all          all            0.0.0.0/0  trust  # ä»»ä½•å¯†ç éƒ½èƒ½è¿
	# åŠ åœ¨æœ€åé¢ï¼Œæ¥å—æ‰€æœ‰è¿œç¨‹IP


systemctl restart postgresql-17
systemctl status postgresql-17



yum groupinstall "Development Tools" && \
yum install llvm-toolset-7-clang && \
yum install postgresql17-devel && \
yum install postgresql17-contrib && \
yum install systemtap-sdt-devel


git clone https://github.com/postgrespro/rum && \
cd rum && \
export PATH=$PATH:/usr/pgsql-17/bin/ && \
make USE_PGXS=1 && \
make USE_PGXS=1 install

make USE_PGXS=1 installcheck && \
psql DB -c "CREATE EXTENSION rum;"



yum install pgvector_17 -y
	# https://github.com/pgvector/pgvector å…ˆå®‰è£…

CREATE EXTENSION IF NOT EXISTS rum;
CREATE EXTENSION IF NOT EXISTS vector;
CREATE TABLE IF NOT EXISTS test_vector (
    ID integer generated always as identity,
    AppID integer NOT NULL,
    TestID integer NOT NULL,
    ChildTableID integer NOT NULL,
    TestCptID integer DEFAULT -1,
    S_Test text NOT NULL,
    V_Test vector(1536) NOT NULL,
    AddedTime timestamp DEFAULT CURRENT_TIMESTAMP,
    UpdateTime timestamp DEFAULT NULL,
    AddUserID integer DEFAULT -1,
    UpdateUserID integer DEFAULT -1,
    Enabled boolean DEFAULT '1',
    UNIQUE(ID),  
    PRIMARY KEY (AppID, TestID, ChildTableID) 
);
CREATE INDEX IF NOT EXISTS idx_appid ON test_vector (AppID);
CREATE INDEX IF NOT EXISTS idx_appid_cptid ON test_vector (AppID, TestCptID);
CREATE INDEX ON test_vector USING hnsw (V_Test vector_cosine_ops);


(async () => {
  let bent = require('bent')
  let post = bent("http://xxxx:xxx", 'POST', 'json', 200)

  let response = await post('/embeddings', JSON.stringify({"sentence":"ä»€ä¹ˆä»€ä¹ˆå‘é‡"}), { 'Content-Type': "application/json;chart-set:utf-8" })

  if (response.status == 0) {
      return [response.data, '']
  } else {
      return [null, response.msg]
  }
})()

```





## å‘é‡æŸ¥è¯¢

    # see huggingface/NLPP_vector_server/readme.txt
    https://github.com/lanterndata/lantern  
        # pg æ”¯æŒ but up to 16
https://liaoxuefeng.com/blogs/all/2023-08-10-ai-search-engine-by-postgres/

```
å…¶ä¸­ï¼Œembedding <=> %sæ˜¯pgvectoræŒ‰ä½™å¼¦è·ç¦»æŸ¥è¯¢çš„è¯­æ³•ï¼Œå€¼è¶Šå°è¡¨ç¤ºç›¸ä¼¼åº¦è¶Šé«˜ï¼Œå–ç›¸ä¼¼åº¦æœ€é«˜çš„3ä¸ªæ–‡æ¡£ã€‚

ç”¨Pythoné…åˆpsycopg2æŸ¥è¯¢ä»£ç å¦‚ä¸‹ï¼š

def db_select_by_embedding(embedding: np.array):
    sql = 'SELECT id, name, content, embedding <=> %s AS distance FROM docs ORDER BY embedding <=> %s LIMIT 3'
    with db_conn() as conn:
        cursor = conn.cursor(cursor_factory=RealDictCursor)
        values = (embedding, embedding)
        cursor.execute(sql, values)
        results = cursor.fetchall()
        cursor.close()
        return results
```





## è·¨åº“æŸ¥è¯¢

- https://cloud.tencent.com/document/product/409/67298

```
  yum install postgresql13-contrib

  create extension postgres_fdw;

  create server server_danganronpa2 foreign data wrapper postgres_fdw options (dbname 'danganronpa2'); 
  	# ä¸è·¨ä¸»æœºï¼Œä»…è·¨æ•°æ®åº“ï¼ŒæŒ‡å®š dbname æ—¢å¯


  create foreign table remote_danganronpa2
  (
    "id" int4 NOT NULL GENERATED ALWAYS AS IDENTITY (
  INCREMENT 1
  MINVALUE  1
  MAXVALUE 2147483647
  START 1
  ),
    "name" text COLLATE "pg_catalog"."default",
    "jp" text COLLATE "pg_catalog"."default",
    "zh" text COLLATE "pg_catalog"."default" DEFAULT ''::text,
    "en" text COLLATE "pg_catalog"."default" DEFAULT ''::text,
    "type" text COLLATE "pg_catalog"."default",
    "begintime" text COLLATE "pg_catalog"."default",
    "endtime" text COLLATE "pg_catalog"."default",
    "jp_ruby" text COLLATE "pg_catalog"."default",
    "jp_mecab" text COLLATE "pg_catalog"."default",
    "v_jp" tsvector,
    "v_zh" tsvector,
    "v_en" tsvector,
    "seasion" text COLLATE "pg_catalog"."default" DEFAULT ''::text,
    "seasionname" text COLLATE "pg_catalog"."default" DEFAULT ''::text,
    "episode" text COLLATE "pg_catalog"."default" DEFAULT ''::text,
    "audio" bytea,
    "video" bytea,
    "videoname" text COLLATE "pg_catalog"."default"
  ) server server_danganronpa2 options(table_name 'danganronpa');
  	# åˆ›å»ºå¤–éƒ¨è¡¨

  create user mapping for postgres server server_danganronpa2 options (user 'postgres',password 'password2');
  	# 
  	
  SELECT * FROM remote_danganronpa2 LIMIT 1;

  

  INSERT INTO anime ("name",
  jp,
  zh,
  en,
  "type",
  begintime,
  endtime,
  jp_ruby,
  jp_mecab,
  v_jp,
  v_zh,
  v_en,
  seasion,
  seasionname,
  episode,
  audio,
  video,
  videoname)

  SELECT 
  "name",
  jp,
  zh,
  en,
  "type",
  begintime,
  endtime,
  jp_ruby,
  jp_mecab,
  v_jp,
  v_zh,
  v_en,
  seasion,
  seasionname,
  episode,
  audio,
  video,
  videoname
  FROM remote_danganronpa2;

```

  

  ## ç®€ä»‹

  FDWï¼ˆFOREIGN DATA WRAPPERï¼Œå¤–éƒ¨æ•°æ®åŒ…è£…å™¨ï¼‰æ˜¯ PostgreSQL æä¾›ç”¨äºè®¿é—®å¤–éƒ¨æ•°æ®æºçš„ä¸€ç±»æ’ä»¶ï¼Œå¤–éƒ¨æ•°æ®æºåŒ…æ‹¬æœ¬å®ä¾‹å…¶ä»–åº“ä¸­æ•°æ®æˆ–è€…å…¶ä»–å®ä¾‹çš„æ•°æ®ã€‚ä½¿ç”¨è¿‡ç¨‹åŒ…å«ä»¥ä¸‹æ­¥éª¤ï¼š

  1. ä½¿ç”¨ â€œCREATE EXTENSIONâ€ è¯­å¥å®‰è£… FDW æ’ä»¶ã€‚
  2. ä½¿ç”¨ â€œCREATE SERVERâ€ è¯­å¥ï¼Œä¸ºæ¯ä¸ªéœ€è¦è¿æ¥çš„è¿œç¨‹æ•°æ®åº“åˆ›å»ºä¸€ä¸ªå¤–éƒ¨æœåŠ¡å™¨å¯¹è±¡ã€‚æŒ‡å®šé™¤äº† user å’Œ password ä»¥å¤–çš„è¿æ¥ä¿¡æ¯ä½œä¸ºæœåŠ¡å™¨å¯¹è±¡çš„é€‰é¡¹ã€‚
  3. ä½¿ç”¨ â€œCREATE USER MAPPINGâ€ è¯­å¥ï¼Œä¸ºæ¯ä¸ªéœ€è¦é€šè¿‡å¤–éƒ¨æœåŠ¡å™¨è®¿é—®çš„æ•°æ®åº“åˆ›å»ºç”¨æˆ·æ˜ å°„ã€‚æŒ‡å®šè¿œç¨‹çš„å¸å·å’Œå¯†ç ä½œä¸ºæ˜ å°„ç”¨æˆ·çš„ user å’Œ passwordã€‚
  4. ä½¿ç”¨ â€œCREATE FOREIGN TABLEâ€ è¯­å¥ï¼Œä¸ºæ¯ä¸ªéœ€è¦è®¿é—®çš„è¿œç¨‹è¡¨åˆ›å»ºå¤–éƒ¨è¡¨ã€‚åˆ›å»ºçš„å¤–éƒ¨è¡¨çš„å¯¹åº”åˆ—å¿…é¡»ä¸è¿œç¨‹è¡¨åŒ¹é…ã€‚ä¹Ÿå¯ä»¥åœ¨å¤–éƒ¨è¡¨ä¸­ä½¿ç”¨ä¸è¿œç¨‹è¡¨ä¸åŒçš„è¡¨åå’Œåˆ—åï¼Œ ä½†å‰ææ˜¯æ‚¨å¿…é¡»å°†æ­£ç¡®çš„è¿œç¨‹å¯¹è±¡åä½œä¸ºåˆ›å»ºå¤–éƒ¨è¡¨å¯¹è±¡çš„é€‰é¡¹ã€‚

  ç”±äº FDW æ’ä»¶å¯ä»¥ç›´æ¥è·¨å®ä¾‹è®¿é—®æˆ–åœ¨åŒå®ä¾‹ä¸­è¿›è¡Œè·¨ database è®¿é—®ã€‚äº‘æ•°æ®åº“ PostgreSQL å¯¹åˆ›å»ºå¤–éƒ¨æœåŠ¡å™¨å¯¹è±¡æ—¶è¿›è¡Œäº†æƒé™æ§åˆ¶ä¼˜åŒ–ï¼Œæ ¹æ®ç›®æ ‡å®ä¾‹æ‰€åœ¨ç¯å¢ƒè¿›è¡Œåˆ†ç±»ç®¡ç†ã€‚åœ¨å¼€æºç‰ˆæœ¬åŸºç¡€ä¸Šå¢åŠ äº†é¢å¤–è¾…åŠ©å‚æ•°ï¼Œæ¥éªŒè¯ç”¨æˆ·èº«ä»½å’Œè°ƒæ•´ç½‘ç»œç­–ç•¥ã€‚

  ## postgres_fdw æ’ä»¶è¾…åŠ©å‚æ•°

  - **host**
    è·¨å®ä¾‹è®¿é—®æ—¶å€™ä¸ºå¿…é¡»é¡¹ã€‚ç›®æ ‡å®ä¾‹çš„ IP åœ°å€ï¼Œpostgres_fdw ä½¿ç”¨ã€‚
  - **port**
    è·¨å®ä¾‹è®¿é—®æ—¶å€™ä¸ºå¿…é¡»é¡¹ã€‚ç›®æ ‡å®ä¾‹çš„ portã€‚
  - **instanceid**
    å®ä¾‹ ID
    a. åœ¨äº‘æ•°æ®åº“ PostgreSQL é—´è·¨å®ä¾‹è®¿é—®æ—¶ä½¿ç”¨ï¼Œå½“è·¨å®ä¾‹è®¿é—®æ—¶ä¸ºå¿…é€‰é¡¹ã€‚æ ¼å¼ç±»ä¼¼ postgres-xxxxxxã€pgro-xxxxxxï¼Œå¯åœ¨ [æ§åˆ¶å°](https://console.cloud.tencent.com/postgres) æŸ¥çœ‹ã€‚
    b. å¦‚æœç›®æ ‡å®ä¾‹åœ¨è…¾è®¯äº‘ CVM ä¸Šï¼Œåˆ™ä¸º CVM æœºå™¨çš„å®ä¾‹ IDï¼Œæ ¼å¼ç±»ä¼¼ ins-xxxxxã€‚
  - **dbname**
    database åï¼Œå¡«å†™éœ€è¦è®¿é—®çš„è¿œç«¯ PostgreSQL æœåŠ¡çš„ database åå­—ã€‚è‹¥ä¸è·¨å®ä¾‹è®¿é—®ï¼Œä»…åœ¨åŒå®ä¾‹ä¸­è¿›è¡Œè·¨åº“è®¿é—®ï¼Œåˆ™åªéœ€è¦é…ç½®æ­¤å‚æ•°å³å¯ï¼Œå…¶ä»–å‚æ•°éƒ½å¯ä¸ºç©ºã€‚
  - **access_type**
    éå¿…é¡»é¡¹ã€‚ç›®æ ‡å®ä¾‹æ‰€å±ç±»å‹ï¼š
    1ï¼šç›®æ ‡å®ä¾‹ä¸º TencentDB å®ä¾‹ï¼ŒåŒ…æ‹¬äº‘æ•°æ®åº“ PostgreSQLã€äº‘æ•°æ®åº“ MySQL ç­‰ï¼Œå¦‚æœä¸æ˜¾ç¤ºæŒ‡å®šï¼Œåˆ™é»˜è®¤è¯¥é¡¹ã€‚
    2ï¼šç›®æ ‡å®ä¾‹åœ¨è…¾è®¯äº‘ CVM æœºå™¨ä¸Šã€‚
    3ï¼šç›®æ ‡å®ä¾‹ä¸ºè…¾è®¯äº‘å¤–ç½‘è‡ªå»ºã€‚
    4ï¼šç›®æ ‡å®ä¾‹ä¸ºäº‘ VPN æ¥å…¥çš„å®ä¾‹ã€‚
    5ï¼šç›®æ ‡å®ä¾‹ä¸ºè‡ªå»º VPN æ¥å…¥çš„å®ä¾‹ã€‚
    6ï¼šç›®æ ‡å®ä¾‹ä¸ºä¸“çº¿æ¥å…¥çš„å®ä¾‹ã€‚
  - **uin**
    éå¿…é¡»é¡¹ã€‚å®ä¾‹æ‰€å±çš„è´¦å· IDï¼Œé€šè¿‡è¯¥ä¿¡æ¯é‰´å®šç”¨æˆ·æƒé™ï¼Œå¯å‚è§ [æŸ¥è¯¢ uin](https://console.cloud.tencent.com/developer)ã€‚
  - **own_uin**
    éå¿…é¡»é¡¹ã€‚å®ä¾‹æ‰€å±çš„ä¸»è´¦å· IDï¼ŒåŒæ ·éœ€è¦è¯¥ä¿¡æ¯é‰´å®šç”¨æˆ·æƒé™ã€‚
  - **vpcid**
    éå¿…é¡»é¡¹ã€‚ç§æœ‰ç½‘ç»œ IDï¼Œç›®æ ‡å®ä¾‹å¦‚æœåœ¨è…¾è®¯äº‘ CVM çš„ VPC ç½‘ç»œä¸­ï¼Œåˆ™éœ€è¦æä¾›è¯¥å‚æ•°ï¼Œå¯åœ¨ [VPC æ§åˆ¶å°](https://console.cloud.tencent.com/vpc/vpc) ä¸­æŸ¥çœ‹ã€‚
  - **subnetid**
    éå¿…é¡»é¡¹ã€‚ç§æœ‰ç½‘ç»œå­ç½‘IDï¼Œç›®æ ‡å®ä¾‹å¦‚æœåœ¨è…¾è®¯äº‘CVMçš„VPCç½‘ç»œä¸­ï¼Œåˆ™éœ€è¦æä¾›è¯¥å‚æ•°ï¼Œå¯åœ¨ [VPC æ§åˆ¶å°](https://console.cloud.tencent.com/vpc/subnet) çš„å­ç½‘ä¸­æŸ¥çœ‹ã€‚
  - **dcgid**
    éå¿…é¡»é¡¹ã€‚ä¸“çº¿ IDï¼Œç›®æ ‡å®ä¾‹å¦‚æœéœ€è¦é€šè¿‡ä¸“çº¿ç½‘ç»œè¿æ¥ï¼Œåˆ™éœ€è¦æä¾›è¯¥å‚æ•°å€¼ã€‚
  - **vpngwid**
    éå¿…é¡»é¡¹ã€‚VPN ç½‘å…³ IDï¼Œç›®æ ‡å®ä¾‹å¦‚æœéœ€è¦é€šè¿‡ VPN ç½‘ç»œè¿æ¥ï¼Œåˆ™éœ€è¦æä¾›è¯¥å‚æ•°å€¼ã€‚
  - **region**
    éå¿…é¡»é¡¹ã€‚ç›®æ ‡å®ä¾‹æ‰€åœ¨åœ°åŸŸï¼Œå¦‚ â€œap-guangzhouâ€ è¡¨ç¤ºå¹¿å·ã€‚å¦‚æœéœ€è¦è·¨åœ°åŸŸè®¿é—®æ•°æ®ï¼Œåˆ™éœ€è¦æä¾›è¯¥å‚æ•°å€¼ã€‚

  ## ä½¿ç”¨ postgres_fdw ç¤ºä¾‹

  ä½¿ç”¨ postgres_fdw æ’ä»¶å¯ä»¥è®¿é—®æœ¬å®ä¾‹å…¶ä»–åº“æˆ–è€…å…¶ä»– postgres å®ä¾‹çš„æ•°æ®ã€‚

  ### æ­¥éª¤1ï¼šå‰ç½®æ¡ä»¶

  1. åœ¨æœ¬å®ä¾‹ä¸­åˆ›å»ºæµ‹è¯•æ•°æ®ã€‚

  ```
     postgres=>create role user1 with LOGIN  CREATEDB PASSWORD 'password1';
     postgres=>create database testdb1;
     CREATE DATABASE
  ```

     > æ³¨æ„ï¼š
     >
     > è‹¥åˆ›å»ºæ’ä»¶æŠ¥é”™ï¼Œè¯· [æäº¤å·¥å•](https://console.cloud.tencent.com/workorder/category) è”ç³»è…¾è®¯äº‘å”®åååŠ©å¤„ç†ã€‚

  2. åœ¨ç›®æ ‡å®ä¾‹ä¸­åˆ›å»ºæµ‹è¯•æ•°æ®ã€‚

     ```
     postgres=>create role user2 with LOGIN  CREATEDB PASSWORD 'password2';
     postgres=> create database testdb2;
     CREATE DATABASE
     postgres=> \c testdb2 user2
     You are now connected to database "testdb2" as user "user2".
     testdb2=> create table test_table2(id integer);
     CREATE TABLE
     testdb2=> insert into test_table2 values (1);
     INSERT 0 1
     ```

  ### æ­¥éª¤2ï¼šåˆ›å»º postgres_fdw æ’ä»¶

  > è¯´æ˜ï¼š
  >
  > è‹¥åˆ›å»ºæ’ä»¶æ—¶ï¼Œæç¤ºæ’ä»¶ä¸å­˜åœ¨æˆ–æƒé™ä¸è¶³ï¼Œè¯· [æäº¤å·¥å•](https://console.cloud.tencent.com/workorder/category) å¤„ç†ã€‚

  

  ```
  #åˆ›å»º
  postgres=> \c testdb1
  You are now connected to database "testdb1" as user "user1".
  testdb1=> create extension postgres_fdw;
  CREATE EXTENSION
  #æŸ¥çœ‹
  testdb1=> \dx
                              List of installed extensions
        Name     | Version |   Schema   |                    Description
  --------------+---------+------------+----------------------------------------------------
    plpgsql      | 1.0     | pg_catalog | PL/pgSQL procedural language
    postgres_fdw | 1.0     | public     | foreign-data wrapper for remote PostgreSQL servers
  (2 rows)
  ```

  

  ### æ­¥éª¤3ï¼šåˆ›å»º SERVER

  > æ³¨æ„ï¼š
  >
  > ä»… v10.17_r1.2ã€v11.12_r1.2ã€v12.7_r1.2ã€v13.3_r1.2ã€v14.2_r1.0 åŠä¹‹åçš„å†…æ ¸ç‰ˆæœ¬æ”¯æŒè·¨å®ä¾‹è®¿é—®ã€‚

  - è·¨å®ä¾‹è®¿é—®ã€‚

    ```
    #ä»æœ¬å®ä¾‹çš„ testdb1 è®¿é—®ç›®æ ‡å®ä¾‹ testdb2 çš„æ•°æ®
    testdb1=>create server srv_test1 foreign data wrapper postgres_fdw options (host 'xxx.xxx.xxx.xxx',dbname 'testdb2', port '5432', instanceid 'postgres-xxxxx');
    CREATE SERVER
    ```

    

  - ä¸è·¨å®ä¾‹ï¼Œä»…è·¨ database è®¿é—®,ä»…éœ€è¦å¡«å†™ dbname å‚æ•°å³å¯ã€‚

    ```
    #ä»æœ¬å®ä¾‹çš„ testdb1 è®¿é—®æœ¬å®ä¾‹ testdb2 çš„æ•°æ®
    create server srv_test1 foreign data wrapper postgres_fdw options (dbname 'testdb2');
    ```

    

  - ç›®æ ‡å®ä¾‹åœ¨è…¾è®¯äº‘ CVM ä¸Šï¼Œä¸”ç½‘ç»œç±»å‹ä¸ºåŸºç¡€ç½‘ç»œã€‚

    ```
        testdb1=>create server srv_test foreign data wrapper postgres_fdw options (host 'xxx.xxx.xxx.xxx', dbname 'testdb2', port '5432', instanceid 'ins-xxxxx', access_type '2', region 'ap-guangzhou'ï¼Œuin 'xxxxxx'ï¼Œown_uin 'xxxxxx');
        CREATE SERVER
    ```

    

  - ç›®æ ‡å®ä¾‹åœ¨è…¾è®¯äº‘ CVM ä¸Šï¼Œä¸”ç½‘ç»œç±»å‹ä¸ºç§æœ‰ç½‘ç»œã€‚

    ```
        testdb1=>create server srv_test1 foreign data wrapper postgres_fdw options (host 'xxx.xxx.xxx.xxx',dbname 'testdb2', port '5432', instanceid 'ins-xxxxx', access_type '2', region 'ap-guangzhou', uin 'xxxxxx', own_uin 'xxxxxx', vpcid 'vpc-xxxxxx', subnetid 'subnet-xxxxx');
        CREATE SERVER
    ```

    

  - ç›®æ ‡å®ä¾‹åœ¨è…¾è®¯äº‘å¤–ç½‘è‡ªå»ºã€‚

    ```
        testdb1=>create server srv_test1 foreign data wrapper postgres_fdw options (host 'xxx.xxx.xxx.xxx',dbname 'testdb2', port '5432', access_type '3', region 'ap-guangzhou', uin 'xxxxxx', own_uin 'xxxxxx');
        CREATE SERVER 
    ```

    

  - ç›®æ ‡å®ä¾‹åœ¨è…¾è®¯äº‘ VPN æ¥å…¥çš„å®ä¾‹ã€‚

    ```
        testdb1=>create server srv_test1 foreign data wrapper postgres_fdw options (host 'xxx.xxx.xxx.xxx',dbname 'testdb2', port '5432', access_type '4', region 'ap-guangzhou', uin 'xxxxxx', own_uin 'xxxxxx', vpngwid 'xxxxxx');
    ```

    

  - ç›®æ ‡å®ä¾‹åœ¨è‡ªå»º VPN æ¥å…¥çš„å®ä¾‹ã€‚

    ```
        testdb1=>create server srv_test1 foreign data wrapper postgres_fdw options (host 'xxx.xxx.xxx.xxx',dbname 'testdb2', port '5432', access_type '5', region 'ap-guangzhou', uin 'xxxxxx', own_uin 'xxxxxx', vpngwid 'xxxxxx');   
    ```

    

  - ç›®æ ‡å®ä¾‹åœ¨è…¾è®¯äº‘ä¸“çº¿æ¥å…¥çš„å®ä¾‹ã€‚

    ```
        testdb1=>create server srv_test1 foreign data wrapper postgres_fdw options (host 'xxx.xxx.xxx.xxx',dbname 'testdb2', port '5432', access_type '6', region 'ap-guangzhou', uin 'xxxxxx', own_uin 'xxxxxx', dcgid 'xxxxxx');    
        CREATE SERVER       
    ```

    

  ### æ­¥éª¤4ï¼šåˆ›å»ºç”¨æˆ·æ˜ å°„

  > è¯´æ˜ï¼š
  >
  > åŒå®ä¾‹çš„è·¨ database è®¿é—®åˆ™å¯è·³è¿‡æ­¤æ­¥éª¤ã€‚

  

  ```
  testdb1=> create user mapping for user1 server srv_test1 options (user 'user2',password 'password2');
  CREATE USER MAPPING
  ```

  

  ### æ­¥éª¤5ï¼šåˆ›å»ºå¤–éƒ¨è¡¨

  

  ```
  testdb1=> create foreign table foreign_table1(id integer) server srv_test1 options(table_name 'test_table2');
  CREATE FOREIGN TABLE
  ```

  

  ### æ­¥éª¤6ï¼šè®¿é—®å¤–éƒ¨æ•°æ®

  

  ```
  testdb1=> select * from foreign_table1;
    id
  ----
     1
  (1 row)
  ```

  

  ## postgres_fdw ä½¿ç”¨æ³¨æ„

  ç›®æ ‡å®ä¾‹ï¼Œéœ€è¦æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š

  1. éœ€è¦æ”¾å¼€ PostgreSQL çš„ hba é™åˆ¶ï¼Œå…è®¸åˆ›å»ºçš„æ˜ å°„ç”¨æˆ·ï¼ˆå¦‚ï¼šuser2ï¼‰ä»¥ MD5 æ–¹å¼è®¿é—®ã€‚hba çš„ä¿®æ”¹å¯å‚è€ƒ [PostgreSQL å®˜æ–¹è¯´æ˜](https://www.postgresql.org/docs/10/static/auth-pg-hba-conf.html)ã€‚
  2. å¦‚æœç›®æ ‡å®ä¾‹é TencentDB å®ä¾‹ï¼Œä¸”æ­å»ºæœ‰çƒ­å¤‡æ¨¡å¼ï¼Œå½“ä¸»å¤‡åˆ‡æ¢åï¼Œéœ€è¦è‡ªè¡Œæ›´æ–° server è¿æ¥åœ°å€æˆ–è€…é‡æ–°åˆ›å»º serverã€‚

- https://segmentfault.com/a/1190000041034644

```
create extension postgres_fdw;

CREATE SERVER myserver FOREIGN DATA WRAPPER postgres_fdw OPTIONS (host 'foo', dbname 'foodb', port '5432');

è‡ªå»ºPostgreSQLå®ä¾‹å¯ä»¥é€šè¿‡oracle_fdwæˆ–mysql_fdwè¿æ¥VPCå¤–éƒ¨çš„Oracleå®ä¾‹æˆ–MySQLå®ä¾‹ã€‚
è¿æ¥è‡ªèº«è·¨åº“æ“ä½œæ—¶ï¼Œhostè¯·å¡«å†™127.0.0.1ï¼Œportè¯·å¡«å†™show portå‘½ä»¤è¿”å›çš„æœ¬åœ°ç«¯å£ã€‚
éœ€è¦å°†RDS PostgreSQLçš„ä¸“æœ‰ç½‘ç»œç½‘æ®µï¼ˆä¾‹å¦‚172.xx.xx.xx/16ï¼‰æ·»åŠ åˆ°ç›®æ ‡æ•°æ®åº“çš„ç™½åå•ä¸­ï¼Œå…è®¸RDS PostgreSQLè®¿é—®ã€‚

```





```
# dblink() -- executes a query in a remote database
SELECT * 
FROM   table1 tb1 
LEFT   JOIN (
   SELECT *
   FROM   dblink('dbname=db2','SELECT id, code FROM table2')
   AS     tb2(id int, code text);
) AS tb2 ON tb2.column = tb1.column;

Don't forget to create extension CREATE EXTENSION IF NOT EXISTS dblink; 
```



## æŸ¥æ‰€æœ‰æ•°æ®åº“å

```
SELECT datname FROM pg_database;
postgres
template1
template0
	# æ’é™¤è¿™ä¸‰ä¸ªç³»ç»Ÿåº“ï¼Œå‰©ä¸‹çš„å°±æ˜¯è¦æ‰¾çš„
```



## create datebase if not exist

```
CREATE EXTENSION IF NOT EXISTS dblink;
DO $$
BEGIN
PERFORM dblink_exec('', 'CREATE DATABASE tt WITH OWNER = postgres ENCODING = ''UTF8'' TABLESPACE = pg_default CONNECTION LIMIT = -1 TEMPLATE template0');
EXCEPTION WHEN duplicate_database THEN RAISE NOTICE '%, skipping', SQLERRM USING ERRCODE = SQLSTATE;
END
$$;
```







## BIGSERIAL PRIMARY KEY

```
id BIGSERIAL PRIMARY KEY, 

    CREATE TABLE $$(tablename) (
        id integer primary key generated always as identity, 
        name text, 
        jp text, 
        zh text DEFAULT '', 
        en text DEFAULT '', 
        type text, 
        begintime text,
        endtime text,
        jp_ruby text,
        jp_mecab text, 
        v_jp  tsvector, 
        v_zh  tsvector, 
        v_en  tsvector, 
        seasion text DEFAULT '',
        seasionname text DEFAULT '',
        episode text DEFAULT '',
        audio bytea, 
        video bytea,
        videoname text 
      );

```



## vector

```
# see huggingface/NLPP_Audio/vector.py
# see nodejs summary.md -> proxynt
# see huggingface\powershell\readme.txt -> proxynt 

# http://xxx.57:7851/wsproxy/admin
#  ali57:2222 -> homepc_wsl2_ssh:22
#  ali57:54322 -> homepc_wsl2_ssh:5432
```



```
const { Pool } = require('pg');
config = require('../../../config.js')

const pool = new Pool(config.db_vector)

async function getVectorIDs(appID, testIDs, childTableIDs) {

    const client = await pool.connect()
    try {
        let sq = `
            SELECT appid, testid, childtableid, testcptid, TO_CHAR(operatetime, 'YYYY-MM-DD HH24:MI:SS') AS operatetime FROM test_vector 
            WHERE appid = ${appID} and enabled = 't';
        `
        if (testIDs.length > 0) {
            sq = `
                SELECT appid, testid, childtableid, testcptid, TO_CHAR(operatetime, 'YYYY-MM-DD HH24:MI:SS') AS operatetime FROM test_vector 
                WHERE appid = ${appID} and testid in (${ testIDs.join(',') }) and enabled = 't';
            `
        }

        if (testIDs.length > 0 && childTableIDs.length > 0) {
            sq = `
                SELECT appid, testid, childtableid, testcptid, TO_CHAR(operatetime, 'YYYY-MM-DD HH24:MI:SS') AS operatetime FROM test_vector 
                WHERE appid = ${appID} and testid in (${ testIDs.join(',') }) and childtableid in ( ${ childTableIDs.join(',') } ) and enabled = 't';
            `
        }

        const re = await client.query(sq, [])
        return [re.rows, ""]
    } catch (err) {
        let errmsg = `### æŸ¥è¯¢å‘é‡å¤±è´¥. appid: ${appID} ${err}`
        console.error(errmsg)
        return [null, errmsg]
    } finally {
        client.release()
    }
}

async function insertVectors(list) {
    
    const client = await pool.connect()

    let t = []
    for (let {appid, testid, childtableid, testcptid, operatetime, s_test, v_test, userid} of list) {
        t.push(`(${appid}, ${testid}, ${childtableid}, ${testcptid}, '${operatetime}', '${s_test}', '${v_test}', ${userid})`)
    }
    t = t.join(',\n')

    
    try {
      const queryText = `
      INSERT INTO test_vector (appid, testid, childtableid, testcptid, operatetime, s_test, v_test, adduserid) 
      VALUES 
        ${t}
      ON CONFLICT (appid, testid, childtableid)
      DO UPDATE SET s_test = EXCLUDED.s_test, v_test = EXCLUDED.v_test, updatetime=now(), updateuserid=EXCLUDED.adduserid, enabled='t';
      `;
      const re = await client.query(queryText, [])
      console.log(`Inserted vectors. appid: ${list[0].appid} rowCount: ${re.rowCount}`)
      return [re, ""]
    } catch (err) {
      let errmsg = `### æ’å…¥å‘é‡å¤±è´¥: ${err}`
      console.error(errmsg)
      return [null, errmsg]
    } finally {
      client.release()
    }
}

async function disableVectors(appID, testIDs) {
    const client = await pool.connect()
    try {
        const queryText = `
            UPDATE test_vector SET enabled = 'f' 
            WHERE appid = ${appID} and testid in (${ testIDs.join(',') });
        `;
        const re = await client.query(queryText, [])
        return [re, ""]
      } catch (err) {
        let errmsg = `### ç¦ç”¨å‘é‡å¤±è´¥: ${err}`
        console.error(errmsg)
        return [null, errmsg]
      } finally {
        client.release()
      }
}
```



```

// https://github.com/pgvector/pgvector å…ˆå®‰è£…
// yum install pgvector_17 -y

CREATE EXTENSION IF NOT EXISTS rum;
CREATE EXTENSION IF NOT EXISTS vector;
CREATE TABLE IF NOT EXISTS test_vector (
    ID bigint generated always as identity (START WITH 1 INCREMENT BY 1), 
    AppID integer NOT NULL,
    TestID integer NOT NULL,
    ChildTableID integer NOT NULL,
    TestCptID integer DEFAULT -1,
    OperateTime timestamp NOT NULL,
    S_Test text NOT NULL,
    V_Test vector(1536) NOT NULL,
    AddTime timestamp DEFAULT CURRENT_TIMESTAMP,
    UpdateTime timestamp DEFAULT NULL,
    AddUserID integer DEFAULT -1,
    UpdateUserID integer DEFAULT -1,
    Enabled boolean DEFAULT '1',
    UNIQUE(ID),  
    PRIMARY KEY (AppID, TestID, ChildTableID) 
);
CREATE INDEX IF NOT EXISTS idx_appid ON test_vector (AppID);
CREATE INDEX IF NOT EXISTS idx_appid_cptid ON test_vector (AppID, TestCptID);
CREATE INDEX ON test_vector USING hnsw (V_Test vector_cosine_ops);
```



### cosine_similarity

```
from openai.embeddings_utils import get_embedding, cosine_similarity

def search_reviews(df, product_description, n=3, pprint=True):
   embedding = get_embedding(product_description, model='text-embedding-3-small')
   df['similarities'] = df.ada_embedding.apply(lambda x: cosine_similarity(x, embedding))
   res = df.sort_values('similarities', ascending=False).head(n)
   return res

res = search_reviews(df, 'delicious beans', n=3)
```



## jsonb

### è”åˆç´¢å¼•

```
CREATE TABLE my_table (
    id serial PRIMARY KEY,
    category text,
    data jsonb
);

CREATE INDEX my_btree_index ON my_table (category, (data->>'key'));

CREATE INDEX ON my_table USING GIN ((data->'key')), category;

SELECT * FROM my_table WHERE category = 'some_category' AND data->>'key' = 'some_value';



```



```
-- åˆ›å»ºä¸€ä¸ªåŒ…å« jsonb å±æ€§çš„èŠ‚ç‚¹
SELECT * 
FROM cypher('your_graph', $$
    CREATE (n:Person {name: 'Alice', attributes: '{"age": 30, "hobbies": ["reading", "hiking"]}'::jsonb})
$$) AS (a agtype);

```





## UUID

```
ä»PostgreSQL v13å¼€å§‹ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨æ ¸å¿ƒå‡½æ•°uuid_generate_v4()
ç”Ÿæˆç‰ˆæœ¬4ï¼ˆéšæœºï¼‰uuidã€‚
```



### æ’å…¥åè¿”å› ID

```
INSERT INTO users (firstname, lastname) VALUES ('Joe', 'Cool') RETURNING id;

CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE TABLE key_values (
    key uuid DEFAULT uuid_generate_v4(),
    value jsonb,
    EXCLUDE using hash (key with =)
);
CREATE INDEX idx_key_values ON key_values USING hash (key);
postgres=# do $$
begin
for r in 1..1000 loop
INSERT INTO key_values (value)
VALUES ('{"somelarge_json": "bla"}');
end loop;
end;
$$;
```



## æŸ¥è¯¢è½¬æ•°æ®å¸§

```
# see huggingface/NLPP_Audio/vector.py
async def fetch_data(sql_query) -> pd.DataFrame:
    global async_pool
    await async_pool.open()

    async with async_pool.connection() as conn:
        async with conn.cursor() as cur:
            await cur.execute(sql_query)
            rows = await cur.fetchall()
            df = pd.DataFrame(rows, columns=[desc[0] for desc in cur.description])
    return df
```





## é‡è®¾è‡ªå¢ID



```
ALTER TABLE <table name> 
    ALTER COLUMN <column name> 
        RESTART WITH <new value to restart with>;
```



## æ˜¾ç¤ºæ•°æ®ç›®å½•

show data_directory;



## åˆ—å‡ºæ‰€æœ‰å¯ç”¨æ•°æ®åº“

\l

\c studio  # åˆ‡æ¢æ•°æ®åº“

```mysql
insert into studio(en, zh, type, time, v_en, v_zh ) values('When something does not go as you expected and you feel anxious or upset, it helps to understand that these feelings are part of the package.', 'ç•¶äº‹æƒ…é€²è¡Œä¸å¦‚é æœŸï¼Œè®“ä½ æ„Ÿåˆ°ç„¦æ…®å¿ƒç…©æ™‚ï¼Œè‹¥èƒ½ç­è§£é€™äº›æƒ…ç·’æ˜¯ä¸å¯é¿å…çš„ï¼Œå°‡æœƒå¤§æœ‰å¹«åŠ©ã€‚','AD050851', '01:20.3', 'no', to_tsvector('jiebacfg', 'ç•¶äº‹æƒ…é€²è¡Œä¸å¦‚é æœŸï¼Œè®“ä½ æ„Ÿåˆ°ç„¦æ…®å¿ƒç…©æ™‚ï¼Œè‹¥èƒ½ç­è§£é€™äº›æƒ…ç·’æ˜¯ä¸å¯é¿å…çš„ï¼Œå°‡æœƒå¤§æœ‰å¹«åŠ©ã€‚'));
```





```sql
sudo -u postgres psql -c '\set AUTOCOMMIT on'
```



è¦æƒ³ä½¿å¾—é…ç½®æ°¸ä¹…ç”Ÿæ•ˆï¼Œéœ€è¦åœ¨/data/postgresql.confæ€»æ·»åŠ lc_messages='zh_CN.UTF-8'ï¼Œä¿å­˜åï¼Œé‡å¯æœåŠ¡æˆ–è€…é‡è½½ã€‚



## insert into å†²çªæ—¶ä»€ä¹ˆä¹Ÿä¸åš

```

insert into public.profiles (id, email)
select id, email from auth.users
on conflict (id) do nothing;
	# å†²çªæ—¶ä»€ä¹ˆä¹Ÿä¸åš

```





## çº§è”åˆ é™¤







## insert studio



```python
"""
pip install xmltodict
GFW
https://www.ishells.cn/archives/linux-ssr-server-client-install
"""

import psycopg2
from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT
import sqlite3 as sqlite # Python è‡ªå¸¦çš„

from pymysql import escape_string
import glob

import json
import decimal
import datetime

import xmltodict

class DecimalEncoder(json.JSONEncoder):
    def default(self, o):
        if isinstance(o, decimal.Decimal):
            return float(o)
        elif isinstance(o, datetime.datetime):
            return str(o)
        super(DecimalEncoder, self).default(o)

def save_json(filename, dics):
    with open(filename, 'w', encoding='utf-8') as fp:
        json.dump(dics, fp, indent=4, cls=DecimalEncoder, ensure_ascii=False)
        fp.close()

def load_json(filename):
    with open(filename, encoding='utf-8') as fp:
        js = json.load(fp)
        fp.close()
        return js

#escape_string = pymysql.escape_string

#host = 'xxxxx.195'
host = '127.0.0.1'
#host = 'xxxxx.166'






def createDatabase_studio( host = '127.0.0.1', studiodb = './db/studioclassroom.db' ):

    with psycopg2.connect(database='postgres', user='postgres', password='postgres',host=host, port='5432') as conn:
        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
        with conn.cursor() as cur:
            cur.execute("DROP DATABASE IF EXISTS studio;")
            cur.execute("CREATE DATABASE studio \
                WITH OWNER = postgres \
                ENCODING = 'UTF8' \
                TABLESPACE = pg_default \
                CONNECTION LIMIT = -1 \
                TEMPLATE template0;")

    with psycopg2.connect(database='studio', user='postgres', password='postgres',host=host, port='5432') as conn:

        with conn.cursor() as cur:
        
            cur.execute("DROP TABLE IF EXISTS studio;")
            cur.execute("create table studio( \
                id serial primary key, \
                en text, \
                zh text, \
                type text, \
                time text, \
                v_en  tsvector, \
                v_zh  tsvector \
            );")
            """
            éœ€è¦å®‰è£…ä¸¤ä¸ªæ‰©å±•ï¼Œä¸€ä¸ªåˆ†è¯ï¼Œä¸€ä¸ªFTS
                https://github.com/postgrespro/rum
            """
            cur.execute("create extension pg_jieba;")
            cur.execute("create extension rum;")
            cur.execute("CREATE INDEX fts_rum_studio ON studio USING rum (v_zh rum_tsvector_ops);")
        
            with sqlite.connect(studiodb) as cx: # './db/studioclassroom.db'

                cu = cx.cursor()
                cu.execute("SELECT * FROM studioclassroom_content;", [])
                rows = cu.fetchall()

                cur.execute('BEGIN;')

                for row in rows:
                    # sql è¯­å¥é‡Œæœ¬èº«æœ‰å•å¼•å·æ—¶ç”¨ä¸¤ä¸ªå•å¼•å·æ¥ä»£æ›¿
                    en = row[1].replace("'", "''").replace("\n",'')
                    zh = row[2].replace("'", "''").replace("\n",'')
                    ty = row[3].replace("'", "''").replace("\n",'')
                    ti = row[4].replace("'", "''").replace("\n",'')

                    sql = f"""insert into studio(en, zh, type, time, v_en, v_zh ) values('{en}', '{zh}', '{ty}', '{ti}', 'no', to_tsvector('jiebacfg', '{zh}'));"""

                    cur.execute( sql )
        
            cur.execute('COMMIT;')


def createDatabase_economistglobl( host = '127.0.0.1',  economistglobl= './db/economist/data/data/com.economist.hummingbird/databases/t_economics_database.db' ):
        
    with psycopg2.connect(database='postgres', user='postgres', password='postgres',host=host, port='5432') as conn:
        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
        with conn.cursor() as cur:
            cur.execute("DROP DATABASE IF EXISTS economistglobl;")
            cur.execute("CREATE DATABASE economistglobl \
                WITH OWNER = postgres \
                ENCODING = 'UTF8' \
                TABLESPACE = pg_default \
                CONNECTION LIMIT = -1 \
                TEMPLATE template0;")
        

    with psycopg2.connect(database='economistglobl', user='postgres', password='postgres',host=host, port='5432') as conn:

        with conn.cursor() as cur:
            cur.execute("DROP TABLE IF EXISTS article;")
            cur.execute("create table article( \
                id serial primary key, \
                issue_time text, \
                pubdate text, \
                en text, \
                zh text, \
                zh_tw text, \
                v_en tsvector, \
                v_zh  tsvector, \
                v_zh_tw  tsvector \
            );")

            """
            éœ€è¦å®‰è£…ä¸¤ä¸ªæ‰©å±•ï¼Œä¸€ä¸ªåˆ†è¯ï¼Œä¸€ä¸ªFTS
                https://github.com/postgrespro/rum
            """
            cur.execute("create extension pg_jieba;")
            cur.execute("create extension rum;")
            cur.execute("CREATE INDEX fts_rum_article ON article USING rum (zh_tw rum_tsvector_ops);")


        with sqlite.connect(economistglobl) as cx:
            
            cu = cx.cursor()
            cu.execute("select issue_id, title as issue_time from issue_table;", [])
            rows = cu.fetchall()

            issue_time = {}

            for row in rows:
                issueid = row[0]
                issuetime = row[1]
                issue_time[ issueid ] = issuetime

            cu.execute("select article_folder as folder_id, issue_id from article_table;", [])
            rows = cu.fetchall()
            
            
            folder_id = {}
            
            for row in rows:
                folderid = row[0]
                issueid  = row[1]
                folder_id[ folderid ] = issueid

            articles = []
            idioms = []

            xmls = glob.glob('./db/economist/**/article.xml', recursive=True)
            for xml in xmls:
                with open(xml, "r", encoding="utf-8") as fp:
                    data = fp.read()
                    js = xmltodict.parse(data)
                    article = {}
                    idiom = {}
                    _id = js['article']['@id']
                    pubdate = js['article']['pubdate']
                    
                    article['issue_time'] = issue_time[ folder_id[_id] ]
                    article['pubdate'] = pubdate

                    #print(type( js['article']['body']['idioms'] ))
                    
                    if js['article']['body']['idioms'] != None:
                        idiom['issue_time'] = issue_time[ folder_id[_id] ]
                        idiom['pubdate'] = pubdate
                        idiom['idiom'] = js['article']['body']['idioms']['idiom']
                        idioms.append(idiom)

                    article['content'] = []



                    for ph in js['article']['body']['content']['paragraph']:
                        
                        if ph == 'copy':
                            copy = js['article']['body']['content']['paragraph']['copy']
                            en = copy[0]['#text']
                            zh = copy[1]['#text']
                            zw = copy[2]['#text']
                        else:
                            copy = ph['copy']
                            en = copy[0]['#text']                
                            zh = copy[1]['#text']
                            zw = copy[2]['#text']


                        article['content'].append( { 'en':en, 'zh':zh, 'zh_tw':zw } )

                    articles.append( article )
                
            return articles, idioms



# createDatabase_studio()
articles, idioms = createDatabase_economistglobl()

print('hi')
```






## nodejs

https://github.com/sehrope/node-pg-db



```

curl -sL https://rpm.nodesource.com/setup_14.x | sudo bash - && \
sudo yum install nodejs && \
npm install -g pm2



```





```javascript
const { Pool, Client } = require('pg')
const connectionString = 'postgresql://postgres:postgres@111.229.53.195:5432/studio'
const pool = new Pool({
  connectionString,
})

sql = "select id, en, zh, type from studio where v_zh @@  to_tsquery('jiebacfg', $1) ORDER BY RANDOM() limit 3;"
keywd = 'æƒ…ç·’'
pool.query(sql, [keywd], (err, res) => {
  if(err) {
    return console.error('error fetching client from pool', err);
  }
  console.log(res['rows'])
  pool.end()
})
```



### Server



```javascript
'use strict';
var express = require('express'),
  app = express(),
  cookieParser = require('cookie-parser'),
  expressSession = require('express-session'),
  bodyParser = require('body-parser');

const { Pool, Client } = require('pg')
const connectionString = 'postgresql://postgres:postgres@111.229.53.195:5432/studio'
const pool = new Pool({
  connectionString,
})

// var db = require('pg-db')("postgres://postgres:psql@192.157.212.220/studio");

app.use(cookieParser());
app.use(expressSession({
  secret: 'somesecrettokenhere'
}));
app.use(bodyParser());

app.get('/', function(req, res) {

  var html = '<form action="/" method="post">' +
    'keyword: <input type="text" name="keyword"><br>' +
    '<button type="submit">Search</button>' +
    '</form>';
  if (req.session.keyword) {
    var keywd = req.session.keyword;
    if (typeof keywd != 'undefined' &&
      typeof keywd != null && keywd.trim().length > 0) {
      keywd = keywd.trim();
      var zhQ = false;
      for (var i in keywd) {
        if (keywd.charCodeAt(i) > 127) {
          zhQ = true;
          break;
        }
      }

      /*

      select id, en, zh, type, time from studio where v_en @@  to_tsquery('en', 'achieving') limit 3;

SELECT id, ts_headline(en, q), rank
FROM (SELECT id, en, q, ts_rank_cd(en, q) AS rank
FROM studio, to_tsquery('en', 'achieving') q
WHERE en @@ q
ORDER BY rank DESC
LIMIT 3) AS foo;
      */

      var sql = "";
      if (zhQ) {
        sql = "select id, en, zh, type from studio where v_zh @@  to_tsquery('jiebacfg', $1) ORDER BY RANDOM() limit 3;"
      } else {
        sql = "SELECT id, ts_headline(en, q) as en, zh, type \
                FROM studio, plainto_tsquery('en', $1) q \
                WHERE v_en @@ q \
                ORDER BY RANDOM() LIMIT 3 ;";
      }

      pool.query(sql, [keywd], (err, rt) => {
        if (err) throw err;
        // JSON.stringify
        for (var i in rt['rows']) {
          html += ('<br>' + rt['rows'][i].en + '<br>' + rt['rows'][i].zh + '<br>' + rt['rows'][i].type);
          html += ('<br>' + '<br>');
        }

        res.cookie('keywd', req.session.keyword);
        html += '<br>Your keyword is: ' + req.session.keyword;
        console.log('session is: ' + req.session.keyword);
        html += '<form action="/next" method="post">' +
          '<button type="submit">Next</button>' +
          '</form>';

        res.send(html);
      });

    } else {
      html += 'ooops: keyword plz.'
      res.send(html);
    }
  } else {
    res.send(html);
  }
});

app.post('/', function(req, res) {
  //if (req.cookies.bar) {
  //req.session.keyword = req.body.keyword;
  req.session.keyword = req.body.keyword;
  res.redirect('/');
    //}
    //res.send(req.cookies.bar);
    //res.redirect('/');
});

app.post('/next', function(req, res) {
  console.log('cookies is: ', req.cookies.keywd);
  req.session.keyword = req.cookies.keywd;
  res.redirect('/');
});


app.listen(80, function() {
  console.log("ready captain.");
});
```







```javascript

// pg.js

/*
// drop database studio
pg_ctlcluster 9.5 main stop --force
pg_ctlcluster 9.5 main start
dropdb -U postgres  studio -h 127.0.0.1 -p 5432
*/

var dbpostgres = require('pg-db')("postgres://postgres:psql@192.157.212.220/postgres");
var db = require('pg-db')("postgres://postgres:psql@192.157.212.220/studio");
var sqlite3 = require('sqlite3').verbose();
var dbsq = new sqlite3.Database('./db/studioclassroom.db', sqlite3.OPEN_READONLY);
var util = require('util');

// CREATE TABLE 'studioclassroom_content'(docid INTEGER PRIMARY KEY, 'c0en', 'c1zh', 'c2name', 'c3time');
// SELECT * FROM "studioclassroom_content;

function queryStudio(callback) {
	dbsq.all("SELECT * FROM studioclassroom_content;", function(err, rows) {
		callback(rows);
	}); /**/
}

function createDatabase(cb) {
	dbpostgres.execute("CREATE DATABASE studio \
WITH OWNER = postgres \
   ENCODING = 'UTF8' \
   TABLESPACE = pg_default \
   LC_COLLATE = 'zh_CN.UTF-8' \
   CONNECTION LIMIT = -1 \
   TEMPLATE template0;", function(err, result) {
		cb(err, 'createDatabase ok.');
	});
}

function dropTable(cb) {
	db.execute("DROP TABLE IF EXISTS studio;", function(err, result) {
		cb(err, 'dropTable ok.');
	});
}

function createTable(cb) {
	db.execute("create table studio( \
   id serial primary key, \
   en text, \
   zh text, \
   type text, \
   time text, \
   v_en  tsvector, \
   v_zh  tsvector \
);", function(err, result) {
		cb(err, 'createTable ok.');
	});
}

function insertStudio(cb) {
	db.execute("insert into studio(en, zh, type, time, v_en, v_zh ) values('When something does not go as you expected and you feel anxious or upset, it helps to understand that these feelings are part of the package.', 'ç•¶äº‹æƒ…é€²è¡Œä¸å¦‚é æœŸï¼Œè®“ä½ æ„Ÿåˆ°ç„¦æ…®å¿ƒç…©æ™‚ï¼Œè‹¥èƒ½ç­è§£é€™äº›æƒ…ç·’æ˜¯ä¸å¯é¿å…çš„ï¼Œå°‡æœƒå¤§æœ‰å¹«åŠ©ã€‚','AD050851', '01:20.3', 'no', to_tsvector('jiebacfg', 'ç•¶äº‹æƒ…é€²è¡Œä¸å¦‚é æœŸï¼Œè®“ä½ æ„Ÿåˆ°ç„¦æ…®å¿ƒç…©æ™‚ï¼Œè‹¥èƒ½ç­è§£é€™äº›æƒ…ç·’æ˜¯ä¸å¯é¿å…çš„ï¼Œå°‡æœƒå¤§æœ‰å¹«åŠ©ã€‚'));", function(err, result) {
		cb(err, 'insertStudio ok.');
	});
}

queryStudio(function(rows) {
	createDatabase(function(err, msg) {
		if (err) throw err;
		console.log(msg);
		db.tx.series([
			dropTable,
			createTable,
			function(cb) {
				db.execute('create extension pg_jieba;', function(err) {
					cb(err, 'create extension pg_jieba ok.');
				});
			},
			function(cb) {

				var curr = 0;
				var last = 10000 - 1; // rows.length - 1;

				for (var i = 0; i < rows.length; i++) {
					var sql = "insert into studio(en, zh, type, time, v_en, v_zh ) values('%s', '%s', '%s', '%s', 'no', to_tsvector('jiebacfg', '%s'));";
					sql = util.format(sql, rows[curr].c0en.replace(/\n/g, '').replace(/[",']/g, ''), rows[curr].c1zh.replace(/\n/g, '').replace(/[",']/g, ''), rows[curr].c2name.replace(/\n/g, ''), rows[curr].c3time.replace(/\n/g, ''), rows[curr].c1zh.replace(/\n/g, '').replace(/[",']/g, ''));
					//console.log(sql);
					db.execute(sql, function(err, result) {
						if (err) {
							console.log(sql);
							throw err;
						}
						curr = curr + 1;
						console.log('insrt one task done. curr/last is: ', curr, '/', last); //console.log(rows.length, rows[curr].c0en, rows[curr].c1zh, rows[curr].c2name, rows[curr].c3time);
						if (curr > last) {
							console.log('insrt all task done. curr is: ' + curr);
							cb(null, 'insertStudio ok.');
						}
					});
				}

				function insrt(curr, last) {
					if (curr > last) {
						console.log('insrt all task done. curr is: ' + curr);
						cb(null, 'insertStudio ok.');
						return;
					}
					var sql = "insert into studio(en, zh, type, time, v_en, v_zh ) values('%s', '%s', '%s', '%s', 'no', to_tsvector('jiebacfg', '%s'));";
					sql = util.format(sql, rows[curr].c0en.replace(/\n/g, '').replace(/[",']/g, ''), rows[curr].c1zh.replace(/\n/g, '').replace(/[",']/g, ''), rows[curr].c2name.replace(/\n/g, ''), rows[curr].c3time.replace(/\n/g, ''), rows[curr].c1zh.replace(/\n/g, '').replace(/[",']/g, ''));
					//console.log(sql);
					//db.execute("insert into studio(en, zh, type, time, v_en, v_zh ) values('When something does not go as you expected and you feel anxious or upset, it helps to understand that these feelings are part of the package.', 'ç•¶äº‹æƒ…é€²è¡Œä¸å¦‚é æœŸï¼Œè®“ä½ æ„Ÿåˆ°ç„¦æ…®å¿ƒç…©æ™‚ï¼Œè‹¥èƒ½ç­è§£é€™äº›æƒ…ç·’æ˜¯ä¸å¯é¿å…çš„ï¼Œå°‡æœƒå¤§æœ‰å¹«åŠ©ã€‚','AD050851', '01:20.3', 'no', to_tsvector('jiebacfg', 'ç•¶äº‹æƒ…é€²è¡Œä¸å¦‚é æœŸï¼Œè®“ä½ æ„Ÿåˆ°ç„¦æ…®å¿ƒç…©æ™‚ï¼Œè‹¥èƒ½ç­è§£é€™äº›æƒ…ç·’æ˜¯ä¸å¯é¿å…çš„ï¼Œå°‡æœƒå¤§æœ‰å¹«åŠ©ã€‚'));", function(err, result) {
					db.execute(sql, function(err, result) {
						if (err) {
							console.log(sql);
							throw err;
						}
						console.log('insrt one task done. curr/last is: ', curr, '/', last);
						insrt(curr + 1, last);
						//console.log(rows.length, rows[curr].c0en, rows[curr].c1zh, rows[curr].c2name, rows[curr].c3time);
						//cb(err, 'insertStudio ok.');
					});
				}
				//insrt(curr, last);
				//cb(null,'inset ok.');
			}
		], function(err, rs) {
			if (err) throw err;
			console.log(rs);
			console.log('all task done.');
		});
	});
});

/*
createDatabase(function(err, msg) {
	if (err) throw err;
	console.log(msg);
	db.tx.series([
		dropTable,
		createTable,
		function(cb) {
			db.execute('create extension pg_jieba;', function(err) {
				cb(err, 'create extension pg_jieba ok.');
			});
		},
		insertStudioFromSqlite
	], function(err, rs) {
		if (err) throw err;
		console.log(rs);
		console.log('all task done.');
	});
});*/

/*
db.tx.series([
	//dropTable,
	//createTable,
	
	function(cb) {
		db.execute('create extension pg_jieba;', function(err) {
			cb(err);
		});
	},
	//insertStudion
], function(err, rs) {
	if (err) throw err;
	console.log('all task done.');
});*/
```





```python

```



```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import csv
import psycopg2

# Connection details:
dbname = 'sampledb'
user = 'postgres'
host = '127.0.0.1'
password = '123456789'


def get_tables_databases():
    with psycopg2.connect(dbname=dbname, user=user, host=host, password=password) as conn:
        with conn.cursor() as cur:
            cur.execute('select table_name from INFORMATION_SCHEMA.TABLES '
                        'where table_type=\'BASE TABLE\' '
                        'and table_schema not in (\'pg_catalog\', \'information_schema\');')
            return [r for (r,) in cur]


def get_column_table(table_name: str):
    with psycopg2.connect(dbname=dbname, user=user, host=host, password=password) as conn:
        with conn.cursor() as cur:
            cur.execute('select column_name from INFORMATION_SCHEMA.COLUMNS '
                        'where table_name=\'' + table_name + '\';')
            return [r for (r,) in cur]


def get_column_details_table(table_name: str):
    with psycopg2.connect(dbname=dbname, user=user, host=host, password=password) as conn:
        with conn.cursor() as cur:
            cur.execute('select column_name, data_type, character_maximum_length from INFORMATION_SCHEMA.COLUMNS '
                        'where table_name=\'' + table_name + '\';')
            return [r for r in cur]


def get_length_table(table_name: str):
    with psycopg2.connect(dbname=dbname, user=user, host=host, password=password) as conn:
        with conn.cursor() as cur:
            cur.execute('select count(*) from "' + table_name + '";')
            return cur.fetchone()[0]


def get_aprox_length_table(table_name: str):
    with psycopg2.connect(dbname=dbname, user=user, host=host, password=password) as conn:
        with conn.cursor() as cur:
            cur.execute('select reltuples as estimate from pg_class '
                        'where relname=\'' + table_name + '\';')
            return cur.fetchone()[0]


def get_size_database():
    with psycopg2.connect(dbname=dbname, user=user, host=host, password=password) as conn:
        with conn.cursor() as cur:
            cur.execute('select pg_size_pretty(pg_database_size(pg_database.datname)) as size from pg_database '
                        'where pg_database.datname=\'' + dbname + '\';')
            return cur.fetchone()[0]


def get_rows_table(table_name: str,):
    with psycopg2.connect(dbname=dbname, user=user, host=host, password=password) as conn:
        with conn.cursor() as cur:
            cur.execute('select * from ' + table_name + ';')
            return cur.fetchall()


def export_table_csv(table_name: str, file_path: str = None, with_title: bool = False):
    file_name = os.path.join(file_path if file_path else '.', table_name + '.csv')
    os.makedirs(os.path.dirname(file_name), exist_ok=True)
    with open(file_name, mode="w", encoding="UTF-8") as csvfile:
        csvwriter = csv.writer(csvfile, delimiter=' ', quotechar='|', quoting=csv.QUOTE_MINIMAL)
        with psycopg2.connect(dbname=dbname, user=user, host=host, password=password) as conn:
            # column names
            if with_title:
                with conn.cursor() as cur:
                    cur.execute('select column_name from INFORMATION_SCHEMA.COLUMNS '
                                'where table_name=\'' + table_name + '\';')
                    title = []
                    for (r,) in cur:
                        title.append(r)
                    csvwriter.writerow(title)
            # content
            with conn.cursor('server-side-cursor') as cur:
                cur.itersize = 100000  # how much records to buffer on a client
                cur.execute('select * from ' + table_name + ';')
                for r in cur:
                    csvwriter.writerow(r)


def export_database_csv(file_path: str = None, with_title: bool = False):
    file_path = file_path if file_path else dbname
    os.makedirs(file_path, exist_ok=True)
    for table in get_tables_databases():
        export_table_csv(table, file_path, with_title)


def export_table_copy(table_name: str, file_path: str = None, with_title: bool = False):
    file_name = os.path.join(file_path if file_path else '.', table_name + '.copy')
    os.makedirs(os.path.dirname(file_name), exist_ok=True)
    with open(file_name, mode="w", encoding="UTF-8") as copyfile:
        with psycopg2.connect(dbname=dbname, user=user, host=host, password=password) as conn:
            with conn.cursor() as cur:
                # column names
                if with_title:
                    cur.execute('select column_name from INFORMATION_SCHEMA.COLUMNS '
                                'where table_name=\'' + table_name + '\';')
                    title = ''
                    for (r,) in cur:
                        title += r + '|'
                    copyfile.write(title[:-1] + '\n')
                # content
                cur.copy_to(copyfile, table_name, sep="|")


def export_database_copy(file_path: str = None, with_title: bool = False):
    file_path = file_path if file_path else dbname
    os.makedirs(file_path, exist_ok=True)
    for table in get_tables_databases():
        export_table_copy(table, file_path, with_title)


def export_table_sql(table_name: str, file_path: str = None):
    file_name = os.path.join(file_path if file_path else '.', table_name + '.sql')
    os.makedirs(os.path.dirname(file_name), exist_ok=True)
    with open(file_name, mode="w", encoding="UTF-8") as sqlfile:
        with psycopg2.connect(dbname=dbname, user=user, host=host, password=password) as conn:
            # table
            with conn.cursor() as cur:
                cur.execute('select column_name, data_type, character_maximum_length from INFORMATION_SCHEMA.COLUMNS '
                            'where table_name=\'' + table_name + '\';')
                columns = []
                for r in cur:
                    (cname, ctype, clen) = r
                    if ctype in {'character varying', 'varchar', 'character', 'char', 'text'}:
                        ctype = 'varchar'
                    elif ctype == 'money':
                        ctype = 'double precision'
                    elif ctype == 'bytea':
                        ctype = 'BLOB'
                    clen = '(' + str(clen) + ')' if clen and ctype == 'varchar' else ''
                    columns.append(cname + ' ' + ctype + clen)
                sqlfile.write('create table ' + table_name + ' (' + ', '.join(columns) + ');\n')
            # rows
            with conn.cursor('server-side-cursor') as cur:
                cur.itersize = 100000  # how much records to buffer on a client
                cur.execute('select * from ' + table_name + ';')
                for r in cur:
                    data = []
                    for rd in r:
                        if rd == 'null':
                            data.append('NULL')
                        else:
                            if isinstance(rd, str):
                                rd = rd.replace('\'', '\'\'')
                            data.append(repr(rd).replace('"', '\''))
                    sqlfile.write('insert into ' + table_name + ' values (' + ', '.join(data) + ');\n')


def export_database_sql(file_path: str = None):
    file_path = file_path if file_path else dbname
    os.makedirs(file_path, exist_ok=True)
    for table in get_tables_databases():
        export_table_sql(table, file_path)


def erase_database():
    tables = get_tables_databases()
    with psycopg2.connect(dbname=dbname, user=user, host=host, password=password) as conn:
        with conn.cursor() as cur:
            for table in tables:
                cur.execute('drop table if exists ' + table + ' cascade;')
    full_vacuum()


def create_database(dbname: str):
    with psycopg2.connect(dbname='postgres', user=user, host=host, password=password) as conn:
        old_isolation_level = conn.isolation_level
        conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)
        with conn.cursor() as cur:
            cur.execute('create database ' + dbname + ';')
        conn.set_isolation_level(old_isolation_level)


def delete_database(dbname: str):
    with psycopg2.connect(dbname='postgres', user=user, host=host, password=password) as conn:
        old_isolation_level = conn.isolation_level
        conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)
        with conn.cursor() as cur:
            cur.execute('drop database ' + dbname + ';')
        conn.set_isolation_level(old_isolation_level)


def vacuum(full: bool= False, freeze: bool = False, verbose: bool = False, analyze: bool = False, table: str = None, column: str = None):
    with psycopg2.connect(dbname=dbname, user=user, host=host, password=password) as conn:
        old_isolation_level = conn.isolation_level
        conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)
        with conn.cursor() as cur:
            cur.execute('vacuum ' + ('full ' if full else '') +
                                    ('freeze ' if freeze else '') +
                                    ('verbose ' if verbose else '') +
                                    ('analyze ' if analyze else '') +
                                    (table + (' ' + column if column else '') if table else '') + ';')
        conn.set_isolation_level(old_isolation_level)


def analyze(verbose: bool = False, table: str = None, column: str = None):
    with psycopg2.connect(dbname=dbname, user=user, host=host, password=password) as conn:
        old_isolation_level = conn.isolation_level
        conn.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)
        with conn.cursor() as cur:
            cur.execute('analyze ' + ('verbose ' if verbose else '') +
                                    (table + (' ' + column if column else '') if table else '') + ';')
        conn.set_isolation_level(old_isolation_level)


def import_sql_file(file_name: str):
    with open(file_name, mode="r", encoding="UTF-8") as sqlfile:
        with psycopg2.connect(dbname=dbname, user=user, host=host, password=password) as conn:
            with conn.cursor() as cur:
                for line in sqlfile:
                    cur.execute(line)


def execute_query(query: str):
    with psycopg2.connect(dbname=dbname, user=user, host=host, password=password) as conn:
        with conn.cursor() as cur:
            cur.execute(query)
            if cur.rownumber:
                return cur.fetchall()
```







## Install PG_Jieba [u](https://github.com/jaiminpan/pg_jieba)

which pg_config



CentOS7 ç¼–è¯‘æˆåŠŸ https://github.com/jaiminpan/pg_jieba



```
yum groupinstall "Development Tools"
```


```
yum install centos-release-scl-rh && \
yum install llvm-toolset-7-clang && \
yum install postgresql13-devel
```

export PostgreSQL_ROOT=/usr/pgsql-13



submodule æ‹‰å–é”™è¯¯(git submodule update --init --recursive)


```
git submodule foreach git pull
```



cmake  -DCMAKE_PREFIX_PATH=/usr/pgsql-13  -DPostgreSQL_TYPE_INCLUDE_DIR=/usr/pgsql-13/include/server/ ..



pg_config åœ¨è¿™ä¸ªç›®å½•ï¼Œä½†æ˜¯CMAKE æ‰¾ä¸åˆ°

ls /usr/pgsql-13/bin/

```
export PATH=$PATH:/usr/pgsql-13/bin/
```

c99 é”™è¯¯

```
# åœ¨Cmakelist.txt åŠ ä¸€å¥
set(CMAKE_C_FLAGS "-std=gnu99")
```

CXXé”™è¯¯

```
# åœ¨Cmakelist.txt åŠ ä¸€å¥
set(CMAKE_CXX_FLAGS "-std=c++11")
```



cmake  -DCMAKE_PREFIX_PATH=/usr/pgsql-13  -DPostgreSQL_TYPE_INCLUDE_DIR=/usr/pgsql-13/include/server/ ..



```bash
# centos7 æˆåŠŸï¼Œæ¯”ubuntu å¤æ‚å¾ˆå¤šï¼Œä¸Šæ–¹è®¾ç½®éƒ½éœ€è¦
[root@2416f0b833b2 build]# make install
[100%] Built target pg_jieba
Install the project...
-- Install configuration: ""
-- Installing: /usr/pgsql-13/lib/pg_jieba.so
-- Installing: /usr/pgsql-13/share/extension/pg_jieba.control
-- Installing: /usr/pgsql-13/share/extension/pg_jieba--1.1.1.sql
-- Installing: /usr/pgsql-13/share/tsearch_data/jieba_base.dict
-- Installing: /usr/pgsql-13/share/tsearch_data/jieba_hmm.model
-- Installing: /usr/pgsql-13/share/tsearch_data/jieba_user.dict
-- Installing: /usr/pgsql-13/share/tsearch_data/jieba.stop
-- Installing: /usr/pgsql-13/share/tsearch_data/jieba.idf
```





```bash
# ubuntu æ¯”è¾ƒç®€å•ï¼Œä»¥ä¸‹å‡ å°±å°±å¯ä»¥æˆåŠŸ
cmake -DPostgreSQL_TYPE_INCLUDE_DIR=/usr/include/postgresql/13/server/ ..
make
make install

-- Installing: /usr/lib/postgresql/13/lib/pg_jieba.so
-- Installing: /usr/share/postgresql/13/extension/pg_jieba.control
-- Installing: /usr/share/postgresql/13/extension/pg_jieba--1.1.1.sql
-- Installing: /usr/share/postgresql/13/tsearch_data/jieba_base.dict
-- Installing: /usr/share/postgresql/13/tsearch_data/jieba_hmm.model
-- Installing: /usr/share/postgresql/13/tsearch_data/jieba_user.dict
-- Installing: /usr/share/postgresql/13/tsearch_data/jieba.stop
-- Installing: /usr/share/postgresql/13/tsearch_data/jieba.idf
```



```mysql
sudo -u postgres psql
create extension pg_jieba;
select * from to_tsquery('jiebacfg', 'æ˜¯æ‹–æ‹‰æœºå­¦é™¢æ‰‹æ‰¶æ‹–æ‹‰æœºä¸“ä¸šçš„ã€‚ä¸ç”¨å¤šä¹…ï¼Œæˆ‘å°±ä¼šå‡èŒåŠ è–ªï¼Œå½“ä¸ŠCEOï¼Œèµ°ä¸Šäººç”Ÿå·…å³°ã€‚');
select * from to_tsquery('jiebacfg', 'ç•¶äº‹æƒ…é€²è¡Œä¸å¦‚é æœŸï¼Œè®“ä½ æ„Ÿåˆ°ç„¦æ…®å¿ƒç…©æ™‚ï¼Œè‹¥èƒ½ç­è§£é€™äº›æƒ…ç·’æ˜¯ä¸å¯é¿å…çš„ï¼Œå°‡æœƒå¤§æœ‰å¹«åŠ©ã€‚');
```



æ›¿æ¢æˆåŒæ—¶æ”¯æŒç®€ç¹çš„å­—å…¸

```
proxy wget https://github.com/fxsjy/jieba/raw/master/extra_dict/dict.txt.big

# å‡ºé”™äº†ï¼Œä¸ç”¨æ›¿æ¢ä¹Ÿå¯ä»¥æŸ¥ç¹ä½“
cp  /usr/share/postgresql/13/tsearch_data/jieba_user.dict
```



## Install pgroonga

https://www.skypyb.com/2020/12/jishu/1705/  æå‰åˆ†è¯æ–¹æ¡ˆ

https://pgroonga.github.io/install/

https://groonga.org/docs/install/ubuntu.html



**TokenBigram** å°†æ–‡æœ¬æŒ‰ **äºŒå…ƒç»„ï¼ˆbigramsï¼‰** çš„æ–¹å¼è¿›è¡Œåˆ†è¯ï¼Œå³å°†ç›¸é‚»çš„ä¸¤ä¸ªå­—ç¬¦ä½œä¸ºä¸€ä¸ªè¯å…ƒè¿›è¡Œå¤„ç†ã€‚

```
CREATE INDEX idx_content ON documents USING pgroonga (content pgroonga_text_full_text_search_config('TokenBigram'));

```





```
  SELECT unnest -> 'value' AS "value" FROM unnest(
  pgroonga_tokenize('This is a pen. ã“ã‚Œã¯ãƒšãƒ³ã§ã™ã€‚ä½ ä¸ºä»€ä¹ˆå­¦ä¹ æ™®é€šè¯ï¼Ÿ',
                    'tokenizer', 'TokenMecab("include_class", true)',
                    'token_filters', 'TokenFilterNFKC100("unify_kana", true)')
  );
  
    SELECT unnest -> 'value' AS "value" FROM unnest(
  pgroonga_tokenize('This is a pen. ã“ã‚Œã¯ãƒšãƒ³ã§ã™ã€‚ä½ ä¸ºä»€ä¹ˆå­¦ä¹ æ™®é€šè¯ï¼Ÿ',
                    'tokenizer', 'TokenBigram')
  );
```





```

# see huggingface/NLPP_Audio/vector.py

proxychains4 apt install -y software-properties-common && 
proxychains4 add-apt-repository -y universe && 
proxychains4 add-apt-repository -y ppa:groonga/ppa &&
proxychains4 apt install -y wget lsb-release && 
proxychains4 wget https://packages.groonga.org/ubuntu/groonga-apt-source-latest-$(lsb_release --codename --short).deb && 
proxychains4 apt install -y -V ./groonga-apt-source-latest-$(lsb_release --codename --short).deb && 
echo "deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release --codename --short)-pgdg main" | sudo tee /etc/apt/sources.list.d/pgdg.list && 
proxychains4 wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - && 
proxychains4 apt update && 
proxychains4 apt install -y -V postgresql-17-pgdg-pgroonga && 
proxychains4 apt install -y -V groonga-tokenizer-mecab

CREATE EXTENSION pgroonga;
	# æˆåŠŸ

see https://pgroonga.github.io/tutorial/
    # ç”¨æ³•å¾ˆè¯¦ç»†
    
-- åœ¨ postgres æ•°æ®åº“é‡Œè¿è¡Œ
CREATE DATABASE nlppvector
    WITH OWNER = postgres 
    ENCODING = 'UTF8' 
    TABLESPACE = pg_default 
    CONNECTION LIMIT = -1 
    TEMPLATE template0;



CREATE EXTENSION IF NOT EXISTS rum;
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS pgroonga;
CREATE TABLE IF NOT EXISTS nlpp_vector (
    ID bigint generated always as identity (START WITH 1 INCREMENT BY 1), 
    JPMD5 CHAR(32) NOT NULL,
    S_JP text NOT NULL,
    V_JP vector(1536) NOT NULL,
    S_CN text NOT NULL,
    S_EN text NOT NULL,
    metadata jsonb NOT NULL,
    AddTime timestamp DEFAULT CURRENT_TIMESTAMP,
    UpdateTime timestamp DEFAULT NULL,
    Enabled boolean DEFAULT '1',
    UNIQUE(ID),  
    PRIMARY KEY (JPMD5) 
);
CREATE INDEX IF NOT EXISTS index_pgvector_VJP ON nlpp_vector USING hnsw (V_JP vector_cosine_ops);
CREATE INDEX IF NOT EXISTS index_pgroonga_SJP ON nlpp_vector USING pgroonga (S_JP);


```





```
    CREATE TABLE danganronpa (
        id integer primary key generated always as identity, 
        name text, 
        jp text, 
        ch text DEFAULT '', 
        en text DEFAULT '', 
        type text, 
        begintime text,
        endtime text,
        jp_ruby text,
        jp_mecab text, 
        v_jp  tsvector, 
        v_ch  tsvector, 
        v_en  tsvector, 
        seasion text DEFAULT '',
        seasionname text DEFAULT '',
        episode text DEFAULT '',
        audio bytea, 
        video bytea,
        videoname text 
      );
    create extension pgroonga;
    create extension pg_jieba;
    CREATE INDEX pgroonga_jp_index ON danganronpa USING pgroonga (jp);
    CREATE INDEX animename_index ON danganronpa (name);
    CREATE INDEX episode_index ON danganronpa (episode);
```





```
$ sudo -H yum install -y https://download.postgresql.org/pub/repos/yum/reporpms/EL-$(cut -d: -f5 /etc/system-release-cpe | cut -d. -f1)-$(rpm -qf --queryformat="%{ARCH}" /etc/redhat-release)/pgdg-redhat-repo-latest.noarch.rpm
$ sudo -H yum install -y https://packages.groonga.org/centos/groonga-release-latest.noarch.rpm
$ sudo -H yum install -y postgresql13-pgdg-pgroonga
```



```
 sudo -H yum install -y groonga-tokenizer-mecab
```



```
sudo -u postgres -H psql --command 'CREATE DATABASE pgroonga_test'

sudo -u postgres -H psql -d pgroonga_test --command 'CREATE EXTENSION pgroonga'


```



### TokenMecab + mecab-ipadic-neologd

```
apt install mecab libmecab-dev mecab-ipadic && 
git clone --depth 1 https://github.com/neologd/mecab-ipadic-neologd.git
cd mecab-ipadic-neologd && 
sudo ./bin/install-mecab-ipadic-neologd -n




```



### TokenBigramSplitSymbolAlpha ä¸­æ–‡æ¨¡ç³Šæœç´¢

é€‚ç”¨å°è§„æ¨¡åº”ç”¨

```
-- ä½¿ç”¨å‰ç¼€ç´¢å¼•æé«˜å‡†ç¡®æ€§
CREATE INDEX idx_name ON table_name 
USING pgroonga (column_name) 
WITH (tokenizer='TokenBigramSplitSymbolAlpha("report_source_location", true)');

PGroonga ä½¿ç”¨ TokenBigramSplitSymbolAlpha çš„å‡ ç§å¸¸ç”¨æŸ¥è¯¢æ–¹å¼ï¼š

åŸºç¡€åŒ¹é…æŸ¥è¯¢ (pgroonga_match)ï¼š

-- æœ€åŸºç¡€çš„å…¨æ–‡æœç´¢
SELECT * FROM table_name 
WHERE column_name @@ 'å…³é”®è¯';

-- ä½¿ç”¨ pgroonga_match
SELECT * FROM table_name 
WHERE pgroonga_match(column_name, 'å…³é”®è¯');
æ¨¡ç³ŠæŸ¥è¯¢ (pgroonga_query)ï¼š
sql

-- æ”¯æŒæŸ¥è¯¢è¯­æ³•ï¼Œå¦‚ ORã€AND ç­‰
SELECT * FROM table_name 
WHERE pgroonga_query(column_name, 'å…³é”®è¯1 OR å…³é”®è¯2');

-- ä½¿ç”¨é€šé…ç¬¦
SELECT * FROM table_name 
WHERE pgroonga_query(column_name, 'å…³*è¯');
ç›¸ä¼¼åº¦æŸ¥è¯¢ï¼š
sql

-- è¿”å›ç›¸ä¼¼åº¦åˆ†æ•°
SELECT *,
  pgroonga_score(tableoid, ctid) AS score 
FROM table_name 
WHERE column_name &@ 'å…³é”®è¯' 
ORDER BY score DESC;

-- è®¾ç½®æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼
SELECT * FROM table_name 
WHERE pgroonga_similarity_search(column_name, 'å…³é”®è¯') > 0.5;
çŸ­è¯­æœç´¢ï¼š
sql

-- ç²¾ç¡®çŸ­è¯­åŒ¹é…
SELECT * FROM table_name 
WHERE pgroonga_query(column_name, '"å®Œæ•´çŸ­è¯­"');
ç»“åˆå…¶ä»–æ¡ä»¶ï¼š
sql

-- ç»„åˆå¤šä¸ªæ¡ä»¶
SELECT * FROM table_name 
WHERE pgroonga_query(column_name, 'å…³é”®è¯')
  AND created_at > '2024-01-01'
  AND status = 'active';

```







## Install ffmpeg



```
# ffmpeg on centos7
sudo yum install epel-release && \
sudo yum localinstall --nogpgcheck https://download1.rpmfusion.org/free/el/rpmfusion-free-release-7.noarch.rpm && \
sudo yum install ffmpeg ffmpeg-devel
```



##  Install RUM

see huggingface/NLPP_Audio/vector.py

```
            """
            SELECT s_jp, v_jp <=> tsquery('ã¾ãšã¯|ã©ã†|ã—ãŸã‚‰') as distance FROM nlpp_vector ORDER BY v_jp <=> tsquery('ã¾ãšã¯|ã©ã†|ã—ãŸã‚‰') asc LIMIT 3;
                # | è¡¨ç¤ºåªè¦å‘½ä¸­å…¶ä¸­ä¸€ä¸ªå°±ç»™åˆ† (ç»“æœæ˜¯è·ç¦»)
            SELECT s_jp, v_jp <=> tsquery('ã¾ãšã¯&ã©ã†&ã—ãŸã‚‰&â—‹â—‹') as distance FROM nlpp_vector ORDER BY v_jp <=> tsquery('ã¾ãšã¯&ã©ã†&ã—ãŸã‚‰&â—‹â—‹') asc LIMIT 3;
                # & è¡¨ç¤ºå¿…é¡»å…¨éƒ¨å‘½ä¸­ï¼Œå¦åˆ™ç»™ 0 åˆ† (ç»“æœæ˜¯è·ç¦»)
            """
            q = "|".join( mmsegjp("ã¾ãšã¯ã©ã†ã—ãŸã‚‰"))
            sql = f"SELECT v_jp <=> tsquery('{q}') as distance, name, s_jp, s_zh, v_jp, v_zh, metadata, TO_CHAR(AddTime, 'YYYY-MM-DD HH24:MI:SS') AS AddTime FROM nlpp_vector WHERE enable='t' ORDER BY v_jp <=> tsquery('{q}') ASC LIMIT 20;"
            sql = f"""
                WITH tmp AS (
                SELECT s_jp, v_jp <=> tsquery('{q}') as distance
                FROM nlpp_vector WHERE name = 'nlpp_å§‰ãƒ¶å´'
                )
                SELECT * from tmp
                WHERE distance < 99999
                ORDER BY distance ASC
                LIMIT 10;
            """
```





```

# see huggingface/NLPP_Audio/vector.py

proxychains4 pip install --upgrade pip && 
proxychains4 pip install "psycopg[binary]"  


proxychains4 apt install postgresql-17-pgvector
	# å®‰è£…å‘é‡æ’ä»¶

git clone https://github.com/postgrespro/rum && 
cd rum &&
make USE_PGXS=1 PG_CONFIG=/usr/bin/pg_config &&
make USE_PGXS=1 PG_CONFIG=/usr/bin/pg_config install &&
make USE_PGXS=1 installcheck &&
$ psql DB -c "CREATE EXTENSION rum;
	# å®‰è£…  RUM æ’ä»¶

# see https://pgroonga.github.io/install/ubuntu.html
proxychains4 apt install -y software-properties-common && 
proxychains4 add-apt-repository -y universe && 
proxychains4 add-apt-repository -y ppa:groonga/ppa &&
proxychains4 apt install -y wget lsb-release && 
proxychains4 wget https://packages.groonga.org/ubuntu/groonga-apt-source-latest-$(lsb_release --codename --short).deb && 
proxychains4 apt install -y -V ./groonga-apt-source-latest-$(lsb_release --codename --short).deb && 
echo "deb http://apt.postgresql.org/pub/repos/apt/ $(lsb_release --codename --short)-pgdg main" | sudo tee /etc/apt/sources.list.d/pgdg.list && 
proxychains4 wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc | sudo apt-key add - && 
proxychains4 apt update && 
proxychains4 apt install -y -V postgresql-17-pgdg-pgroonga && 
proxychains4 apt install -y -V groonga-tokenizer-mecab

CREATE EXTENSION pgroonga;
	# æˆåŠŸ

see https://pgroonga.github.io/tutorial/
    # ç”¨æ³•å¾ˆè¯¦ç»†
    DROP DATABASE IF EXISTS nlppvector;
CREATE DATABASE nlppvector
WITH OWNER = postgres 
ENCODING = 'UTF8' 
TABLESPACE = pg_default 
CONNECTION LIMIT = -1 
TEMPLATE template0;
    # æ•´å®Œ nvcat é‡è¿ä¸€æ¬¡ï¼Œé€‰è¿™ä¸ªåº“å†è¿è¡Œä¸‹é¢çš„è¯­å¥


CREATE EXTENSION IF NOT EXISTS rum;
CREATE EXTENSION IF NOT EXISTS vector;
DROP TABLE IF EXISTS nlppvector;
CREATE TABLE IF NOT EXISTS nlpp_vector (
    ID bigint generated always as identity (START WITH 1 INCREMENT BY 1), 
    JPMD5 CHAR(32) NOT NULL,
    Name text NOT NULL,
    S_jp text NOT NULL,
    S_zh text NOT NULL,
    Embed_rwkv_jp vector(1024) NOT NULL,
    V_jp tsvector NOT NULL,
    V_zh tsvector NOT NULL,
    Metadata jsonb NOT NULL,
    AddTime timestamp DEFAULT CURRENT_TIMESTAMP,
    UpdateTime timestamp DEFAULT NULL,
    Enabled boolean DEFAULT '1',
    UNIQUE(ID),
    PRIMARY KEY (JPMD5, Name)
);
CREATE INDEX fts_rum_v_jp ON nlpp_vector USING rum (V_jp rum_tsvector_ops);
CREATE INDEX fts_rum_v_zh ON nlpp_vector USING rum (V_zh rum_tsvector_ops);





    

CREATE DATABASE nlppvector
WITH OWNER = postgres 
ENCODING = 'UTF8' 
TABLESPACE = pg_default 
CONNECTION LIMIT = -1 
TEMPLATE template0;


CREATE EXTENSION IF NOT EXISTS rum;
CREATE EXTENSION IF NOT EXISTS vector;
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS pgroonga;
CREATE TABLE IF NOT EXISTS nlpp_vector (
    ID bigint generated always as identity (START WITH 1 INCREMENT BY 1), 
    JPMD5 CHAR(32) NOT NULL,
    name text NOT NULL,
    S_JP text NOT NULL,
    S_CN text DEFAULT '' NOT NULL,
    S_EN text DEFAULT '' NOT NULL,
    Embed_gpt_jp vector(1536) NOT NULL,
    Embed_rwkv_jp vector(1024) NOT NULL,
    V_JP vector(1536) NOT NULL,
    metadata jsonb NOT NULL,
    AddTime timestamp DEFAULT CURRENT_TIMESTAMP,
    UpdateTime timestamp DEFAULT NULL,
    Enabled boolean DEFAULT '1',
    UNIQUE(ID),  
    PRIMARY KEY (JPMD5, name) 
);
CREATE INDEX IF NOT EXISTS index_pgvector_VJP ON nlpp_vector USING hnsw (V_JP vector_cosine_ops);
CREATE INDEX IF NOT EXISTS index_pgroonga_SJP ON nlpp_vector USING pgroonga (S_JP);
```





```
yum -y install https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm && \
yum -y update && \
yum search postgresql13 && \
yum -y install postgresql13 postgresql13-server && \
/usr/pgsql-13/bin/postgresql-13-setup initdb
	# æ›´å¤šå†…å®¹æ–‡æ¡£åé¢ï¼šDocker ä¸­çš„postgreql

yum groupinstall "Development Tools" && \
yum install centos-release-scl-rh && \
yum install llvm-toolset-7-clang && \
yum install postgresql13-devel && \
yum install postgresql13-contrib && \
yum install systemtap-sdt-devel

git clone https://github.com/postgrespro/rum && \
cd rum && \
export PATH=$PATH:/usr/pgsql-13/bin/ && \
make USE_PGXS=1 && \
make USE_PGXS=1 install

make USE_PGXS=1 installcheck && \
psql DB -c "CREATE EXTENSION rum;"
```





```
dnf install epel-release -y && \
dnf --enablerepo=powertools install perl-IPC-Run -y

```



```
CREATE INDEX index_rum_jp ON anime USING rum (v_jp rum_tsvector_ops);
```





## äº‹åŠ¡



PostgreSQL äº‹åŠ¡ [u](https://www.jianshu.com/p/f35d01b95a38)

> é»˜è®¤æƒ…å†µä¸‹ PostgreSQLä¼šå°†æ¯ä¸€ä¸ªSQLè¯­å¥éƒ½ä½œä¸ºä¸€ä¸ªäº‹åŠ¡æ¥æ‰§è¡Œã€‚å¦‚æœæˆ‘ä»¬æ²¡æœ‰å‘å‡ºBEGINå‘½ä»¤ï¼Œåˆ™æ¯ä¸ªç‹¬ç«‹çš„è¯­å¥éƒ½ä¼šè¢«åŠ ä¸Šä¸€ä¸ªéšå¼çš„BEGINä»¥åŠï¼ˆå¦‚æœæˆåŠŸï¼‰COMMITæ¥åŒ…å›´å®ƒã€‚ä¸€ç»„è¢«BEGINå’ŒCOMMITåŒ…å›´çš„è¯­å¥ä¹Ÿè¢«ç§°ä¸ºä¸€ä¸ªäº‹åŠ¡å—ã€‚
>
> ```sql
>BEGIN;
> UPDATE accounts SET balance = balance - 100.00
>  WHERE name = 'Alice';
> COMMIT;
>    ```



## åˆ†è¯



```
å‰è¨€  
PostgreSQL è¢«ç§°ä¸ºæ˜¯â€œæœ€é«˜çº§çš„å¼€æºæ•°æ®åº“â€ï¼Œå®ƒçš„æ•°æ®ç±»å‹éå¸¸ä¸°å¯Œï¼Œç”¨å®ƒæ¥è§£å†³ä¸€äº›æ¯”è¾ƒåé—¨çš„éœ€æ±‚éå¸¸é€‚åˆã€‚  
  
å‰äº›å¤©å°† POI ç‚¹å…³é”®è¯æŸ¥è¯¢çš„åŠŸèƒ½è¿åˆ°äº† PgSQLï¼Œæ€»ç®—å¯¹å‰æ–‡ ç©ºé—´ç´¢å¼• - å„æ•°æ®åº“ç©ºé—´ç´¢å¼•ä½¿ç”¨æŠ¥å‘Š æœ‰äº†ä¸€ä¸ªäº¤ä»£ã€‚  
  
ç”±äº PgSQL å›½å†…çš„èµ„æ–™è¾ƒå°‘ï¼Œè¿ç§»è¿‡ç¨‹è¸©äº†ä¸å°‘å‘ï¼Œè¿™é‡Œæ€»ç»“è®°å½•ä¸€ä¸‹ï¼Œå¸®åŠ©åæ¥çš„åŒå­¦èƒ½é¡ºåˆ©ä½¿ç”¨ PgSQLã€‚è€Œä¸”ç›®å‰åœ¨ç°åº¦æµ‹è¯•åˆšå¸ƒäº†ä¸€å°æœºå™¨ï¼Œåç»­å¯èƒ½è¿˜è¦æ·»åŠ æœºå™¨ï¼Œæ•´ç†ä¸€ä¸‹æµç¨‹æ€»æ˜¯å¥½çš„ã€‚  
  
æ–‡ç« ç»å¸¸è¢«äººçˆ¬ï¼Œè€Œä¸”è¿˜ä¸æ³¨æ˜åŸåœ°å€ï¼Œæˆ‘åœ¨è¿™é‡Œçš„æ›´æ–°å’Œçº é”™æ²¡æ³•åŒæ­¥ï¼Œè¿™é‡Œæ³¨æ˜ä¸€ä¸‹åŸæ–‡åœ°å€ï¼šhttp://www.cnblogs.com/zhenbianshu/p/7795247.html  
  
å¼€å§‹  
å®‰è£…  
é¦–å…ˆæ˜¯å®‰è£… PgSQLï¼Œè¿™é‡Œæˆ‘ä½¿ç”¨çš„æ˜¯ PgSQL 9.6ï¼ŒPgSQL 10 ä¹Ÿåˆšå‘å¸ƒäº†ï¼Œæœ‰å…´è¶£çš„å¯ä»¥å°ä¸‹é²œã€‚  
  
PgSQL çš„å®‰è£…å¯ä»¥è¯´éå¸¸å¤æ‚äº†ï¼Œé™¤äº†è¦å®‰è£… Server å’Œ Client å¤–ï¼Œè¿˜éœ€è¦å®‰è£… devel åŒ…ã€‚ä¸ºäº†å®ç°ç©ºé—´ç´¢å¼•åŠŸèƒ½ï¼Œæˆ‘ä»¬è¿˜è¦å®‰è£…æœ€é‡è¦çš„ PostGIS æ’ä»¶ï¼Œæ­¤æ’ä»¶éœ€è¦å¾ˆå¤šä¾èµ–ï¼Œè‡ªå·±æ‰‹åŠ¨å®‰è£…éå¸¸å¤æ‚è€Œä¸”å¾ˆå¯èƒ½å‡ºé”™ã€‚  
  
æ¨èè‡ªåŠ¨åŒ–æ–¹å¼å®‰è£…ï¼ŒYum ä¸€å®šè¦é…åˆ epel è¿™æ ·çš„ Yum æºï¼Œä¿éšœèƒ½å°†ä¾èµ–ä¸€ç½‘æ‰“å°½ã€‚å½“ç„¶æœ€å¥½çš„è¿˜æ˜¯ä½¿ç”¨ docker æ¥è¿è¡Œï¼Œæ‰¾ä¸ªé•œåƒå°±è¡Œäº†ã€‚  
  
æ’ä»¶  
ç”±äº PgSQL çš„å¾ˆå¤šåŠŸèƒ½éƒ½ç”±æ’ä»¶å®ç°ï¼Œæ‰€ä»¥è¿˜è¦å®‰è£…ä¸€äº›å¸¸ç”¨çš„æ’ä»¶ï¼Œå¦‚:  
  
postgis_topologyï¼ˆç®¡ç†é¢ã€è¾¹ã€ç‚¹ç­‰æ‹“æ‰‘å¯¹è±¡ï¼‰  
pgroutingï¼ˆè·¯å¾„è§„åˆ’ï¼‰  
postgis_sfcgalï¼ˆå®ç°3Dç›¸å…³ç®—æ³•ï¼‰  
fuzzystrmatchï¼ˆå­—ç¬¦ä¸²ç›¸ä¼¼åº¦è®¡ç®—ï¼‰  
address_standardizer/address_standardizer_data_usï¼ˆåœ°å€æ ‡å‡†åŒ–ï¼‰  
pg_trgmï¼ˆåˆ†è¯ç´¢å¼•ï¼‰  
è¿™äº›æ’ä»¶åœ¨å®‰è£…ç›®å½• /path/extensions ä¸‹ç¼–è¯‘å®Œæ¯•åï¼Œåœ¨æ•°æ®åº“ä¸­ä½¿ç”¨å‰è¦å…ˆä½¿ç”¨ create extension xxx å¯ç”¨ã€‚  
  
å¯åŠ¨  
åˆ‡æ¢åˆ°é root ç”¨æˆ·ã€‚ï¼ˆPgSQL åœ¨å®‰è£…å®Œæ¯•åä¼šåˆ›å»ºä¸€ä¸ªåä¸º postgres çš„è¶…çº§ç”¨æˆ·ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¿™ä¸ªè¶…çº§ç”¨æˆ·æ¥æ“ä½œ PgSQLï¼ŒåæœŸå»ºè®®é‡æ–°åˆ›å»ºä¸€ä¸ªæ™®é€šç”¨æˆ·ç”¨æ¥ç®¡ç†æ•°æ®ï¼‰ï¼›  
åˆ‡æ¢åˆ° /installPath/bin/ ç›®å½•ä¸‹ï¼ŒPgSQL åœ¨æ­¤ç›®å½•ä¸‹æä¾›äº†å¾ˆå¤šå‘½ä»¤ï¼Œå¦‚ createdbã€createuserã€dropdbã€pg_dump ç­‰ï¼›  
ä½¿ç”¨ createdb å‘½ä»¤åˆå§‹åŒ–ä¸€ä¸ªæ–‡ä»¶å¤¹ dir_db (æ­¤ç›®å½•ä¸èƒ½å·²å­˜åœ¨)å­˜æ”¾æ•°æ®åº“ç‰©ç†æ•°æ®ï¼Œä½¿ç”¨ -E UTF8 å‚æ•°æŒ‡å®šæ•°æ®åº“å­—ç¬¦é›†ä¸º utf-8ï¼›  
ä½¿ç”¨ pg_ctl -D dir_db æŒ‡å®šæ•°æ®åº“å¯åŠ¨åå°æœåŠ¡ï¼›  
ä½¿ç”¨ psql -d db åœ¨å‘½ä»¤è¡Œç™»é™† PgSQL;  
é…ç½®  
å®‰è£…å®Œæ¯•åè¿˜è¦é…ç½®ä¸€äº›æ¯”è¾ƒåŸºæœ¬çš„å‚æ•°æ‰èƒ½æ­£å¸¸ä½¿ç”¨ã€‚  
  
Hostæƒé™  
PgSQLéœ€è¦åœ¨ pg_hba.conf æ–‡ä»¶ä¸­é…ç½®æ•°æ®åº“ Host æƒé™ï¼Œæ‰èƒ½è¢«å…¶ä»–æœºå™¨è®¿é—®ã€‚  
  
# TYPE  DATABASE        USER            ADDRESS                 METHOD  
local   all             all                                     trust  
host    all             all             127.0.0.1/32            md5  
host    all             all             172.16.0.1/16            md5  
æ–‡ä»¶ä¸­æ³¨é‡Šéƒ¨åˆ†å¯¹è¿™å‡ ä¸ªå­—æ®µä»‹ç»å¾—æ¯”è¾ƒè¯¦ç»†ï¼Œ æˆ‘ä»¬å¾ˆå¯èƒ½éœ€è¦æ·»åŠ  host(IP) è®¿é—®é¡¹ï¼Œ ADDRESS æ˜¯æ™®é€šçš„ç½‘æ®µè¡¨ç¤ºæ³•ï¼ŒMETHOD æ¨èä½¿ç”¨ md5ï¼Œè¡¨ç¤ºä½¿ç”¨ md5 åŠ å¯†ä¼ è¾“å¯†ç ã€‚  
  
æœåŠ¡å™¨é…ç½®  
æœåŠ¡å™¨é…ç½®åœ¨ postgresql.confä¸­ï¼Œä¿®æ”¹é…ç½®åéœ€è¦ ä½¿ç”¨ pg_ctl restart -D dir_db å‘½ä»¤é‡å¯æ•°æ®åº“ï¼›  
  
æ­¤å¤–ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥åœ¨ç™»é™†æ•°æ®åº“åä¿®æ”¹é…ç½®é¡¹ï¼šä½¿ç”¨ SELECT * FROM pg_settings WHERE name = 'config'; æŸ¥è¯¢å½“å‰é…ç½®é¡¹ï¼Œå†ä½¿ç”¨ UPDATE è¯­å¥æ›´æ–°é…ç½®ã€‚ä½†æœ‰äº›é…ç½®å¦‚å†…å­˜åˆ†é…ç­–ç•¥æ˜¯åªåœ¨å½“å‰ session ç”Ÿæ•ˆçš„ï¼Œå…¨å±€ç”Ÿæ•ˆéœ€è¦åœ¨é…ç½®æ–‡ä»¶ä¸­ä¿®æ”¹ï¼Œå†é‡å¯æœåŠ¡å™¨ã€‚  
  
æˆ‘ä»¬å¯ä»¥ä¿®æ”¹é…ç½®å¹¶ç”¨å®¢æˆ·ç«¯éªŒè¯ SQL è¯­å¥çš„ä¼˜åŒ–ï¼Œä½¿ç”¨ \timing on å¼€å¯æŸ¥è¯¢è®¡æ—¶ï¼Œä½¿ç”¨ EXPLAIN ANALYSE è¯­å¥ åˆ†ææŸ¥è¯¢è¯­å¥æ•ˆç‡ã€‚ ä¸‹é¢ä»‹ç»ä¸¤ä¸ªå·²å®è·µè¿‡çš„é…ç½®å‚æ•°ï¼š  
  
shared_buffersï¼šç”¨äºæŒ‡å®šå…±äº«å†…å­˜ç¼“å†²åŒºæ‰€å ç”¨çš„å†…å­˜é‡ã€‚å®ƒåº”è¯¥è¶³å¤Ÿå¤§æ¥å­˜å‚¨å¸¸ä½¿ç”¨çš„æŸ¥è¯¢ç»“æœï¼Œä»¥å‡å°‘ç‰©ç†I/Oã€‚ä½†å®ƒä¹Ÿä¸èƒ½å¤ªå¤§ï¼Œä»¥é¿å…ç³»ç»Ÿ å†…å­˜swap çš„å‘ç”Ÿï¼Œ ä¸€èˆ¬è®¾ç½®ä¸ºç³»ç»Ÿå†…å­˜çš„ 20%ã€‚  
work_memï¼šä¸€ä¸ªè¿æ¥çš„å·¥ä½œå†…å­˜ï¼Œåœ¨æŸ¥è¯¢ç»“æœæ•°æ®é‡è¾ƒå¤§æ—¶ï¼Œæ­¤å€¼å¦‚æœè¾ƒå°çš„è¯ï¼Œä¼šå¯¼è‡´å¤§é‡ç³»ç»Ÿ I/Oï¼Œå¯¼è‡´æŸ¥è¯¢é€Ÿåº¦æ€¥å‰§ä¸‹é™ï¼Œå¦‚æœä½ çš„ explain è¯­å¥å†… buffer éƒ¨åˆ† readæ•°å€¼è¿‡å¤§ï¼Œåˆ™è¡¨ç¤ºå·¥ä½œå†…å­˜ä¸è¶³ï¼Œéœ€è¦è°ƒæ•´åŠ æ­¤å‚æ•°ã€‚ä½†æ­¤å€¼ä¹Ÿä¸èƒ½å¤ªå¤§ï¼Œéœ€è¦ä¿è¯ work_mem * max_connections + shared_buffers + ç³»ç»Ÿå†…å­˜ < RAMï¼Œä¸ç„¶åŒæ ·å¯èƒ½ä¼šå¯¼è‡´ç³»ç»Ÿ å†…å­˜swapã€‚  
è¿™æ ·ï¼ŒPgSQL å°±èƒ½ä½œä¸ºä¸€ä¸ªæ­£å¸¸çš„å…³ç³»å‹æ•°æ®ä½¿ç”¨äº†ã€‚  
  
åˆ†è¯  
å…¨æ–‡ç´¢å¼•çš„å®ç°è¦é  PgSQL çš„ gin ç´¢å¼•ã€‚åˆ†è¯åŠŸèƒ½ PgSQL å†…ç½®äº†è‹±æ–‡ã€è¥¿ç­ç‰™æ–‡ç­‰ï¼Œä½†ä¸­æ–‡åˆ†è¯éœ€è¦å€ŸåŠ©å¼€æºæ’ä»¶ zhparserï¼›  
  
SCWS  
è¦ä½¿ç”¨ zhparserï¼Œæˆ‘ä»¬é¦–å…ˆè¦å®‰è£… SCWS åˆ†è¯åº“ï¼ŒSCWS æ˜¯ Simple Chinese Word Segmentation çš„é¦–å­—æ¯ç¼©å†™ï¼ˆå³ï¼šç®€æ˜“ä¸­æ–‡åˆ†è¯ç³»ç»Ÿï¼‰ï¼Œå…¶ GitHub é¡¹ç›®åœ°å€ä¸º hightman-scwsï¼Œæˆ‘ä»¬ä¸‹è½½ä¹‹åå¯ä»¥ç›´æ¥å®‰è£…ã€‚  
  
å®‰è£…å®Œåï¼Œå°±å¯ä»¥åœ¨å‘½ä»¤è¡Œä¸­ä½¿ç”¨ scws å‘½ä»¤è¿›è¡Œæµ‹è¯•åˆ†è¯äº†ï¼Œ å…¶å‚æ•°ä¸»è¦æœ‰ï¼š  
  
-c utf8 æŒ‡å®šå­—ç¬¦é›†  
-d dict æŒ‡å®šå­—å…¸ å¯ä»¥æ˜¯ xdb æˆ– txt æ ¼å¼  
-M å¤åˆåˆ†è¯çš„çº§åˆ«ï¼Œ 1~15ï¼ŒæŒ‰ä½å¼‚æˆ–çš„ 1|2|4|8 ä¾æ¬¡è¡¨ç¤º çŸ­è¯|äºŒå…ƒ|ä¸»è¦å­—|å…¨éƒ¨å­—ï¼Œé»˜è®¤ä¸å¤åˆåˆ†è¯ï¼Œè¿™ä¸ªå‚æ•°å¯ä»¥å¸®åŠ©è°ƒæ•´åˆ°æœ€æƒ³è¦çš„åˆ†è¯æ•ˆæœã€‚  
zhpaser  
ä¸‹è½½ zhparser æºç  git clone https:github.com/amutu/zhparser.gitï¼›  
å®‰è£…å‰éœ€è¦å…ˆé…ç½®ç¯å¢ƒå˜é‡ï¼šexport PATH=$PATH:/path/to/pgsqlï¼›  
make && make installç¼–è¯‘ zhparserï¼›  
ç™»é™† PgSQL ä½¿ç”¨ CREATE EXTENSION zhparser; å¯ç”¨æ’ä»¶ï¼›  
æ·»åŠ åˆ†è¯é…ç½®  
  
CREATE TEXT SEARCH CONFIGURATION parser_name (PARSER = zhparser); // æ·»åŠ é…ç½®  
ALTER TEXT SEARCH CONFIGURATION parser_name ADD MAPPING FOR n,v,a,i,e,l,j WITH simple; // è®¾ç½®åˆ†è¯è§„åˆ™ ï¼ˆn åè¯ v åŠ¨è¯ç­‰ï¼Œè¯¦æƒ…é˜…è¯»ä¸‹é¢çš„æ–‡æ¡£ï¼‰  
ç»™æŸä¸€åˆ—çš„åˆ†è¯ç»“æœæ·»åŠ  gin ç´¢å¼• create index idx_name on table using gin(to_tsvector('parser_name', field));  
  
åœ¨å‘½ä»¤è¡Œä¸­ä½¿ç”¨ä¸Šä¸€èŠ‚ä¸­ä»‹ç»çš„ scws å‘½ä»¤æµ‹è¯•åˆ†è¯é…ç½®ï¼Œå¦‚æˆ‘è®¤ä¸ºå¤åˆç­‰çº§ä¸º 7 æ—¶åˆ†è¯ç»“æœæœ€å¥½ï¼Œåˆ™æˆ‘åœ¨ postgresql.confæ·»åŠ é…ç½®  
  
zhparser.multi_short = true #çŸ­è¯å¤åˆ: 1  
zhparser.multi_duality = true  #æ•£å­—äºŒå…ƒå¤åˆ: 2  
zhparser.multi_zmain = true  #é‡è¦å•å­—å¤åˆ: 4  
zhparser.multi_zall = false  #å…¨éƒ¨å•å­—å¤åˆ: 8  
SQL  
æŸ¥è¯¢ä¸­æˆ‘ä»¬å¯ä»¥ä½¿ç”¨æœ€ç®€å•çš„ SELECT * FROM table WHERE to_tsvector('parser_name', field) @@ 'word' æ¥æŸ¥è¯¢ field å­—æ®µåˆ†è¯ä¸­å¸¦æœ‰ word ä¸€è¯çš„æ•°æ®ï¼›  
  
ä½¿ç”¨ to_tsquery() æ–¹æ³•å°†å¥å­è§£ææˆå„ä¸ªè¯çš„ç»„åˆå‘é‡ï¼Œå¦‚ å›½å®¶å¤§å‰§é™¢ çš„è¿”å›ç»“æœä¸º 'å›½å®¶' & 'å¤§å‰§é™¢' & 'å¤§å‰§' & 'å‰§é™¢' ï¼Œå½“ç„¶æˆ‘ä»¬ä¹Ÿå¯ä»¥ä½¿ç”¨ & | ç¬¦å·æ‹¼æ¥è‡ªå·±éœ€è¦çš„å‘é‡ï¼›åœ¨æŸ¥è¯¢ é•¿å¥ æ—¶ï¼Œå¯ä»¥ä½¿ç”¨ SELECT * FROM table WHERE to_tsvector('parser_name', field) @@ to_tsquery('parser_name','words')ï¼›  
  
æœ‰æ—¶å€™æˆ‘ä»¬æƒ³åƒ MySQL çš„ SQL_CALC_FOUND_ROWS è¯­å¥ä¸€æ ·åŒæ­¥è¿”å›ç»“æœæ¡æ•°ï¼Œåˆ™å¯ä»¥ä½¿ç”¨ SELECT COUNT(*) OVER() AS score FROM table WHERE ...ï¼ŒPgSQL ä¼šåœ¨æ¯ä¸€è¡Œæ•°æ®æ·»åŠ  score å­—æ®µå­˜å‚¨æŸ¥è¯¢åˆ°çš„æ€»ç»“æœæ¡æ•°ï¼›  
  
åˆ°è¿™é‡Œï¼Œæ™®é€šçš„å…¨æ–‡æ£€ç´¢éœ€æ±‚å·²ç»å®ç°äº†ã€‚  
  
ä¼˜åŒ–  
æˆ‘ä»¬æ¥ç€å¯¹åˆ†è¯æ•ˆæœå’Œæ•ˆç‡è¿›è¡Œä¼˜åŒ–ï¼š  
  
å­˜å‚¨åˆ†è¯ç»“æœ  
æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ä¸ªå­—æ®µæ¥å­˜å‚¨åˆ†è¯å‘é‡ï¼Œå¹¶åœ¨æ­¤å­—æ®µä¸Šåˆ›å»ºç´¢å¼•æ¥æ›´ä¼˜åœ°ä½¿ç”¨åˆ†è¯ç´¢å¼•ï¼š  
  
ALTER TABLE table ADD COLUMN tsv_column tsvector;           // æ·»åŠ ä¸€ä¸ªåˆ†è¯å­—æ®µ  
UPDATE table SET tsv_column = to_tsvector('parser_name', coalesce(field,''));   // å°†å­—æ®µçš„åˆ†è¯å‘é‡æ›´æ–°åˆ°æ–°å­—æ®µä¸­  
CREATE INDEX idx_gin_zhcn ON table USING GIN(tsv_column);   // åœ¨æ–°å­—æ®µä¸Šåˆ›å»ºç´¢å¼•  
CREATE TRIGGER trigger_name BEFORE INSERT OR UPDATE  ON table FOR EACH ROW EXECUTE PROCEDURE  
tsvector_update_trigger(tsv_column, 'parser_name', field); // åˆ›å»ºä¸€ä¸ªæ›´æ–°åˆ†è¯è§¦å‘å™¨  
è¿™æ ·ï¼Œå†è¿›è¡ŒæŸ¥è¯¢æ—¶å°±å¯ä»¥ç›´æ¥ä½¿ç”¨ SELECT * FROM table WHERE tsv_column @@ 'keyword' äº†ã€‚  
  
è¿™é‡Œéœ€è¦æ³¨æ„ï¼Œè¿™æ—¶å€™åœ¨å¾€è¡¨å†…æ’å…¥æ•°æ®çš„æ—¶å€™ï¼Œå¯èƒ½ä¼šæŠ¥é”™ï¼Œæç¤ºæŒ‡å®š parser_name çš„ schemaï¼Œ è¿™æ—¶å€™å¯ä»¥ä½¿ç”¨ \dF å‘½ä»¤æŸ¥çœ‹æ‰€æœ‰ text search configuration çš„å‚æ•°ï¼š  
  
List of text search configurations  
Schema   |    Name    |              Description  
------------+------------+---------------------------------------  
pg_catalog | english    | configuration for english language  
public     | myparser   |  
æ³¨æ„ schema å‚æ•°ï¼Œåœ¨åˆ›å»º trigger æ—¶éœ€è¦æŒ‡å®š schemaï¼Œ å¦‚ä¸Šé¢ï¼Œå°±éœ€è¦ä½¿ç”¨ public.myparserã€‚  
  
æ·»åŠ è‡ªå®šä¹‰è¯å…¸  
æˆ‘ä»¬å¯ä»¥åœ¨ç½‘ä¸Šä¸‹è½½ xdb æ ¼å¼çš„è¯åº“æ¥æ›¿ä»£é»˜è®¤è¯å…¸ï¼Œè¯åº“æ”¾åœ¨ share/tsearch_data/ æ–‡ä»¶å¤¹ä¸‹æ‰èƒ½è¢« PgSQL è¯»å–åˆ°ï¼Œé»˜è®¤ä½¿ç”¨çš„è¯åº“æ˜¯ dict.utf8.xdbã€‚è¦ä½¿ç”¨è‡ªå®šä¹‰è¯åº“ï¼Œå¯ä»¥å°†è¯åº“æ”¾åœ¨è¯åº“æ–‡ä»¶å¤¹åï¼Œåœ¨ postgresql.conf é…ç½® zhparser.extra_dict="mydict.xdb" å‚æ•°ï¼›  
  
å½“æˆ‘ä»¬åªæœ‰ txt çš„è¯åº“ï¼Œæƒ³æŠŠè¿™ä¸ªè¯åº“ä½œä¸ºé»˜è®¤è¯åº“è¯¥æ€ä¹ˆåŠå‘¢ï¼Ÿä½¿ç”¨ scws å¸¦çš„scwe-gen-dict å·¥å…·æˆ–ç½‘ä¸Šæ‰¾çš„è„šæœ¬ç”Ÿæˆ xdb åæ”¾å…¥è¯åº“æ–‡ä»¶å¤¹åï¼Œåœ¨ PgSQL ä¸­åˆ†è¯ä¸€ç›´æŠ¥é”™ï¼Œè¯»å–è¯åº“æ–‡ä»¶å¤±è´¥ã€‚æˆ‘ç»è¿‡å¤šæ¬¡å®éªŒï¼Œæ€»ç»“å‡ºäº†ä¸€å¥—åˆ¶ä½œä¸€ä¸ªè¯å…¸æ–‡ä»¶çš„æ–¹æ³•ï¼š  
  
å‡†å¤‡è¯åº“æºæ–‡ä»¶ mydict.txtï¼šè¯åº“æ–‡ä»¶çš„å†…å®¹æ¯ä¸€è¡Œçš„æ ¼å¼ä¸ºè¯ TF IDF è¯æ€§ï¼Œè¯æ˜¯å¿…é¡»çš„ï¼Œè€Œ TF è¯é¢‘(Term Frequency)ã€IDF åæ–‡æ¡£é¢‘ç‡(Inverse Document Frequency) å’Œ è¯æ€§ éƒ½æ˜¯å¯é€‰çš„ï¼Œé™¤éç¡®å®šè‡ªå·±çš„è¯å…¸èµ„æ–™æ˜¯å¯¹çš„ä¸”ç¬¦åˆ scws çš„é…ç½®ï¼Œä¸ç„¶æœ€å¥½è¿˜æ˜¯ç•™ç©ºï¼Œè®© scws è‡ªå·²ç¡®å®šï¼›  
åœ¨ postgresql.conf ä¸­è®¾ç½® zhparse  
3ff7  
r.extra_dicts = "mydict.txt" åŒæ—¶è®¾ç½® zhparser.dict_in_memory = trueï¼›  
å‘½ä»¤è¡Œè¿›å…¥ PgSQLï¼Œæ‰§è¡Œä¸€æ¡åˆ†è¯è¯­å¥ select to_tsquery('parser', 'éšä¾¿ä¸€ä¸ªè¯') ï¼Œåˆ†è¯ä¼šææ…¢ï¼Œè¯·è€å¿ƒ(è¯·ä¿è¯æ­¤æ—¶åªæœ‰ä¸€ä¸ªåˆ†è¯è¯­å¥åœ¨æ‰§è¡Œ)ï¼›  
åˆ†è¯æˆåŠŸåï¼Œåœ¨/tmp/ç›®å½•ä¸‹æ‰¾åˆ°ç”Ÿæˆçš„ scws-xxxx.xdb æ›¿æ¢æ‰ share/tsearch_data/dict.utf8.xdbï¼›  
åˆ é™¤åˆšåŠ å…¥çš„ extra_dicts dict_in_memory é…ç½®ï¼Œé‡å¯æœåŠ¡å™¨ã€‚  
æ‰©å±•  
ç”±äºæŸ¥è¯¢çš„æ˜¯ POI çš„åç§°ï¼Œä¸€èˆ¬è¾ƒçŸ­ï¼Œä¸”å¾ˆå¤šè¯å¹¶æ— è¯­ä¹‰ï¼Œåˆè€ƒè™‘åˆ°ç”¨æˆ·çš„è¾“å…¥ä¹ æƒ¯ï¼Œä¸€èˆ¬ä¼šè¾“å…¥ POI åç§°çš„å‰å‡ ä¸ªå­—ç¬¦ï¼Œè€Œä¸” scws çš„åˆ†è¯å‡†ç¡®ç‡ä¹Ÿä¸èƒ½è¾¾åˆ°100%ï¼Œäºæ˜¯æˆ‘æ·»åŠ äº†åç§°çš„å‰ç¼€æŸ¥è¯¢æ¥æé«˜æŸ¥è¯¢çš„å‡†ç¡®ç‡ï¼Œå³ä½¿ç”¨ Bæ ‘ç´¢å¼• å®ç° LIKE 'å…³é”®è¯%' çš„æŸ¥è¯¢ã€‚è¿™é‡Œéœ€  
  
è¿™é‡Œè¦æ³¨æ„çš„æ˜¯ï¼Œåˆ›å»ºç´¢å¼•æ—¶è¦æ ¹æ®å­—æ®µç±»å‹é…ç½® æ“ä½œç¬¦ç±»ï¼Œä¸ç„¶ç´¢å¼•å¯èƒ½ä¼šä¸ç”Ÿæ•ˆï¼Œå¦‚åœ¨ å­—æ®µç±»å‹ä¸º varchar çš„å­—æ®µä¸Šåˆ›å»ºç´¢å¼•éœ€è¦ä½¿ç”¨è¯­å¥CREATE INDEX idx_name ON table(COLUMN varchar_pattern_ops)ï¼Œè¿™é‡Œçš„ varcharpatternops å°±æ˜¯æ“ä½œç¬¦ç±»ï¼Œæ“ä½œç¬¦ç±»çš„ä»‹ç»å’Œé€‰æ‹©å¯ä»¥æŸ¥çœ‹æ–‡æ¡£ï¼š11.9. æ“ä½œç¬¦ç±»å’Œæ“ä½œç¬¦æ—ã€‚  
  
è‡ªæ­¤ï¼Œä¸€ä¸ªè‰¯å¥½çš„å…¨æ–‡æ£€ç´¢ç³»ç»Ÿå°±å®Œæˆäº†ã€‚  
  
æ€»ç»“  
ç®€å•çš„æ•°æ®è¿ç§»å¹¶ä¸æ˜¯ç»ˆç‚¹ï¼Œåç»­è¦åšçš„è¿˜æœ‰å¾ˆå¤šï¼Œå¦‚æ•´ä¸ªç³»ç»Ÿçš„æ•°æ®åŒæ­¥ã€æŸ¥è¯¢æ•ˆç‡ä¼˜åŒ–ã€æŸ¥è¯¢åŠŸèƒ½ä¼˜åŒ–ï¼ˆæ·»åŠ æ‹¼éŸ³æœç´¢ã€æ¨¡ç³Šæœç´¢ï¼‰ç­‰ã€‚ç‰¹åˆ«æ˜¯æŸ¥è¯¢æ•ˆç‡ï¼Œä¸çŸ¥é“æ˜¯ä¸æ˜¯æˆ‘é…ç½®æœ‰é—®é¢˜ï¼Œå®Œå…¨è¾¾ä¸åˆ°é‚£ç§ Eçº§æ¯«ç§’ çš„é€Ÿåº¦ï¼Œ1kw çš„æ•°æ®æ•ˆç‡åœ¨è¿›è¡Œå¤§ç»“æœè¿”å›æ—¶å°±å¤§å¹…ä¸‹é™ï¼ˆ200msï¼‰ï¼Œåªå¥½è€è€å®å®åœ°æå‰è¿›è¡Œäº†åˆ†è¡¨ï¼Œç›®å‰ç™¾ä¸‡çº§æŸ¥è¯¢é€Ÿåº¦åœ¨ 20ms ä»¥å†…ï¼Œä¼˜åŒ–è¿˜æœ‰ä¸€æ®µè·¯è¦èµ°ã€‚  
  
ä¸è¿‡è¿™æ¬¡å€’æ˜¯å¯¹ æŠ€æœ¯çš„â€œç”Ÿæ€â€æœ‰äº†ä¸ªæ›´æ·±çš„ä½“ä¼šï¼Œè¿™æ–¹é¢ PgSQL ç¡®å®å’Œ MySQL å·®è¿œäº†ï¼Œä½¿ç”¨ MySQL æ—¶å†å¥‡è‘©çš„é—®é¢˜éƒ½èƒ½åœ¨ç½‘ä¸Šå¿«é€Ÿæ‰¾åˆ°ç­”æ¡ˆï¼Œè€Œ PgSQL å°±å°´å°¬äº†ï¼Œå…¥é—¨çº§çš„é—®é¢˜æœç´¢ stackoverflow æ¥æ¥å›å›å°±é‚£ä¹ˆå‡ ä¸ªå¯¹ä¸ä¸Šçš„å›ç­”ã€‚è™½ç„¶ä¹Ÿæœ‰é˜¿é‡Œçš„â€œå¾·å“¥â€ä¸€æ ·çš„å¤§ç¥åœ¨è¾›è‹¦å¸ƒé“ï¼Œä½†ç”¨æˆ·çš„æ•°é‡æ‰æ˜¯æ ¹æœ¬ã€‚ä¸è¿‡ï¼Œéšç€ PgSQL è¶Šæ¥è¶Šå®Œå–„ï¼Œä½¿ç”¨å®ƒçš„äººä¸€å®šä¼šè¶Šæ¥è¶Šå¤šçš„ï¼Œæˆ‘è¿™ç¯‡æ–‡ç« ä¹Ÿç®—æ˜¯ä¸º PgSQL åŠ æ¸©äº†å§ï¼Œå“ˆå“ˆ~å¸Œæœ›èƒ½å¸®åˆ°åæ¥çš„ä½¿ç”¨è€…ã€‚  
  
å…³äºæœ¬æ–‡æœ‰ä»€ä¹ˆé—®é¢˜å¯ä»¥åœ¨ä¸‹é¢ç•™è¨€äº¤æµï¼Œå¦‚æœæ‚¨è§‰å¾—æœ¬æ–‡å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œå¯ä»¥ç‚¹å‡»ä¸‹é¢çš„ æ¨è æ”¯æŒä¸€ä¸‹æˆ‘ï¼Œåšå®¢ä¸€ç›´åœ¨æ›´æ–°ï¼Œæ¬¢è¿ å…³æ³¨ ã€‚  
  
å‚è€ƒï¼š  
  
PostgreSQLç³»ç»Ÿé…ç½®ä¼˜åŒ–  
  
[PG]ä½¿ç”¨ zhparser è¿›è¡Œä¸­æ–‡åˆ†è¯å…¨æ–‡æ£€ç´¢  
  
SCWS ä¸­æ–‡åˆ†è¯  
  
Fast Search Using PostgreSQL Trigram Indexes  
  
ä½¿ç”¨é˜¿é‡Œäº‘PostgreSQL zhparseræ—¶ä¸å¯ä¸çŸ¥çš„å‡ ä¸ªå‚æ•°  
  
å¾·å“¥çš„PostgreSQLç§æˆ¿èœ - å²ä¸Šæœ€å±ŒPGèµ„æ–™åˆé›†  
```



## éšæœºæŸ¥è¯¢ && å®‰è£…æ’ä»¶

- https://github.com/digoal/blog/blob/master/202105/20210527_01.md  

  - PostgreSQL éšæœºæŸ¥è¯¢é‡‡æ · - æ—¢è¦çœŸéšæœºã€åˆè¦é«˜æ€§èƒ½

  - https://github.com/digoal/blog/blob/master/202005/20200509_01.md 

  -  PostgreSQL éšæœºé‡‡æ ·åº”ç”¨ - table sample, tsm_system_rows, tsm_system_time

    > select name from pg_available_extensions;  # æŸ¥è¯¢å¯ç”¨æ‰©å±•
    >
    > yum install postgresql13-contrib
    >
    > create extension IF NOT EXISTS tsm_system_rows;
    >
    > create extension IF NOT EXISTS tsm_system_time;
    >
    > ```
    > æœ€å¤šé‡‡æ ·10æ¯«ç§’, è¿”å›ç¬¦åˆplay_count>=2000çš„10æ¡. (å¦‚æœå¾ˆå¿«å°±æœ‰10æ¡ç¬¦åˆæ¡ä»¶, é‚£ä¹ˆä¸ä¼šç»§ç»­æ‰«æ, æ‰€ä»¥å¾ˆå¿«å¾ˆå¿«)
    > 
    > explain (analyze,verbose,timing,costs,buffers) select id,play_count from video as v1 TABLESAMPLE system_time(10)  where play_count>=2000 limit 10;  
    > 
    > 
    > æœ€å¤šé‡‡æ ·100æ¡, è¿”å›ç¬¦åˆplay_count>=2000çš„10æ¡. (å¦‚æœå¾ˆå¿«å°±æœ‰10æ¡ç¬¦åˆæ¡ä»¶, é‚£ä¹ˆä¸ä¼šç»§ç»­æ‰«æ, æ‰€ä»¥å¾ˆå¿«å¾ˆå¿«)
    > 
    > explain (analyze,verbose,timing,costs,buffers) select id,play_count from video as v1 TABLESAMPLE  system_rows (100) where play_count>=2000 limit 10;
    > 
    > SELECT id, jp_ruby as jp, zh, p.begintime as time, type, name, seasion FROM anime p  TABLESAMPLE  system_rows (10000) WHERE p.v_jp @@ to_tsquery('ã“ã“')  ORDER BY RANDOM()  LIMIT 3;
    > 
    > åœ¨æ—¶é—´å¯æ§,ä»£ä»·å¯æ§çš„æƒ…å†µä¸‹(é˜²æ­¢é‡‡æ ·é›ªå´©),ä¿è¯é‡‡æ ·éšæœºæ€§.
    > å¦‚æœwhereæ¡ä»¶çš„è®°å½•å æ¯”å¾ˆå°‘å¾ˆå°‘, å¯èƒ½è¾¾åˆ°é‡‡æ ·ä¸Šé™åæ— æ³•è¿”å›limitçš„æ¡æ•°. è¿™ç§æƒ…å†µä¸‹, å¯ä»¥é€‰æ‹©å‡ ç§æ–¹æ³•:
    > 1ã€è°ƒå¤§é‡‡æ ·ä¸Šé™, æ³¨æ„é˜²æ­¢é›ªå´©
    > 2ã€ä¿®æ”¹whereæ¡ä»¶, ä½¿å¾—è¦†ç›–ç‡å˜å¤§.
    > 3ã€åƒåœ¾å›æ”¶, ä½¿å¾—æ¯ä¸ªblockçš„ç©ºæ´å˜å°‘.
    > 4ã€åˆ†åŒº, æé«˜ç›®æ ‡é‡‡æ ·è¡¨ä¸­ where æ¡ä»¶ç¬¦åˆæ¡ä»¶è®°å½•çš„å æ¯”.                             
    > ```
    
  - [PostgreSQL ç™¾äº¿çº§æ•°æ®èŒƒå›´æŸ¥è¯¢, åˆ†ç»„æ’åºçª—å£å–å€¼ æè‡´ä¼˜åŒ– case](https://developer.aliyun.com/article/39680)
  
  - [PostgreSQL INé‡Œé¢ä¼ å…¥1w+å€¼å¦‚ä½•ä¼˜åŒ–åˆ°æè‡´ï¼Ÿ](https://zhuanlan.zhihu.com/p/342722338)
  
    - [postgres inæŸ¥è¯¢ä¼˜åŒ–](https://www.cnblogs.com/yb38156/p/11195727.html)
  
      > regexp_split_to_table å’Œ regexp_split_to_array éƒ½æ˜¯å­—ç¬¦ä¸²åˆ†éš”å‡½æ•°ï¼Œå¯é€šè¿‡æŒ‡å®šçš„è¡¨è¾¾å¼è¿›è¡Œåˆ†éš”ã€‚åŒºåˆ«æ˜¯ regexp_split_to_table å°†åˆ†å‰²å‡ºçš„æ•°æ®è½¬æˆè¡Œï¼Œregexp_split_to_array æ˜¯å°†åˆ†éš”çš„æ•°æ®è½¬æˆæ•°ç»„ã€‚
  
    > 
  
    
  
    
  
    




## FTS



PostgreSQL å…¨æ–‡æ£€ç´¢åŠ é€Ÿ å¿«åˆ°æ²¡æœ‰æœ‹å‹ - RUMç´¢å¼•æ¥å£(æ½˜å¤šæ‹‰é­”ç›’) [u](https://github.com/digoal/blog/blob/master/201610/20161019_01.md)



RUMç´¢å¼•

- å®‰è£… https://github.com/postgrespro/rum

  > ```
  > yum install -y systemtap-sdt-devel
  > ```

çŸ­è¯­æœç´¢



> create extension rum;
>
> CREATE INDEX fts_rum_anime ON anime USING rum (v_jp rum_tsvector_ops);
>
> CREATE INDEX fts_rum_studio ON studio USING rum (v_zh rum_tsvector_ops);



```
DROP DATABASE IF EXISTS nlppvector;
CREATE DATABASE nlppvector
WITH OWNER = postgres 
ENCODING = 'UTF8' 
TABLESPACE = pg_default 
CONNECTION LIMIT = -1 
TEMPLATE template0;
    # æ•´å®Œ nvcat é‡è¿ä¸€æ¬¡ï¼Œé€‰è¿™ä¸ªåº“å†è¿è¡Œä¸‹é¢çš„è¯­å¥


CREATE EXTENSION IF NOT EXISTS rum;
CREATE EXTENSION IF NOT EXISTS vector;
DROP TABLE IF EXISTS nlppvector;
CREATE TABLE IF NOT EXISTS nlpp_vector (
    ID bigint generated always as identity (START WITH 1 INCREMENT BY 1), 
    JPMD5 CHAR(32) NOT NULL,
    Name text NOT NULL,
    S_jp text NOT NULL,
    S_zh text NOT NULL,
    Embed_rwkv_jp vector(1024) NOT NULL,
    V_jp tsvector NOT NULL,
    V_zh tsvector NOT NULL,
    Metadata jsonb NOT NULL,
    AddTime timestamp DEFAULT CURRENT_TIMESTAMP,
    UpdateTime timestamp DEFAULT NULL,
    Enabled boolean DEFAULT '1',
    UNIQUE(ID),
    PRIMARY KEY (JPMD5, Name)
);
CREATE INDEX fts_rum_v_jp ON nlpp_vector USING rum (V_jp rum_tsvector_ops);
CREATE INDEX fts_rum_v_zh ON nlpp_vector USING rum (V_zh rum_tsvector_ops);

```







```python

"""
pip install xmltodict
GFW
https://www.ishells.cn/archives/linux-ssr-server-client-install
"""

import psycopg2
from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT
import sqlite3 as sqlite # Python è‡ªå¸¦çš„

from pymysql import escape_string
import glob

import json
import decimal
import datetime

import xmltodict

class DecimalEncoder(json.JSONEncoder):
    def default(self, o):
        if isinstance(o, decimal.Decimal):
            return float(o)
        elif isinstance(o, datetime.datetime):
            return str(o)
        super(DecimalEncoder, self).default(o)

def save_json(filename, dics):
    with open(filename, 'w', encoding='utf-8') as fp:
        json.dump(dics, fp, indent=4, cls=DecimalEncoder, ensure_ascii=False)
        fp.close()

def load_json(filename):
    with open(filename, encoding='utf-8') as fp:
        js = json.load(fp)
        fp.close()
        return js

#escape_string = pymysql.escape_string

#host = 'xxxxx.195'
host = '127.0.0.1'
#host = 'xxx.166'



def createDatabase_studio( host = '127.0.0.1', studiodb = './db/studioclassroom.db' ):

    with psycopg2.connect(database='postgres', user='postgres', password='postgres',host=host, port='5432') as conn:
        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)
        with conn.cursor() as cur:
            cur.execute("DROP DATABASE IF EXISTS studio;")
            cur.execute("CREATE DATABASE studio \
                WITH OWNER = postgres \
                ENCODING = 'UTF8' \
                TABLESPACE = pg_default \
                CONNECTION LIMIT = -1 \
                TEMPLATE template0;")

    with psycopg2.connect(database='studio', user='postgres', password='postgres',host=host, port='5432') as conn:

        with conn.cursor() as cur:
        
            cur.execute("DROP TABLE IF EXISTS studio;")
            cur.execute("create table studio( \
                id serial primary key, \
                en text, \
                zh text, \
                type text, \
                time text, \
                v_en  tsvector, \
                v_zh  tsvector \
            );")
            """
            éœ€è¦å®‰è£…ä¸¤ä¸ªæ‰©å±•ï¼Œä¸€ä¸ªåˆ†è¯ï¼Œä¸€ä¸ªFTS
                https://github.com/postgrespro/rum
            """
            cur.execute("create extension pg_jieba;")
            cur.execute("create extension rum;")
            cur.execute("CREATE INDEX fts_rum_studio ON studio USING rum (v_zh rum_tsvector_ops);")
        
            with sqlite.connect(studiodb) as cx: # './db/studioclassroom.db'

                cu = cx.cursor()
                cu.execute("SELECT * FROM studioclassroom_content;", [])
                rows = cu.fetchall()

                cur.execute('BEGIN;')

                for row in rows:
                    # sql è¯­å¥é‡Œæœ¬èº«æœ‰å•å¼•å·æ—¶ç”¨ä¸¤ä¸ªå•å¼•å·æ¥ä»£æ›¿
                    en = row[1].replace("'", "''").replace("\n",'')
                    zh = row[2].replace("'", "''").replace("\n",'')
                    ty = row[3].replace("'", "''").replace("\n",'')
                    ti = row[4].replace("'", "''").replace("\n",'')

                    sql = f"""insert into studio(en, zh, type, time, v_en, v_zh ) values('{en}', '{zh}', '{ty}', '{ti}', 'no', to_tsvector('jiebacfg', '{zh}'));"""

                    cur.execute( sql )
        
            cur.execute('COMMIT;')


def createDatabase_economistglobl( host = '127.0.0.1',  economistglobl= './db/economist/data/data/com.economist.hummingbird/databases/t_economics_database.db' ):
        
        with sqlite.connect(economistglobl) as cx:
            
            cu = cx.cursor()
            cu.execute("select issue_id, title as issue_time from issue_table;", [])
            rows = cu.fetchall()

            issue_time = {}

            for row in rows:
                issueid = row[0]
                issuetime = row[1]
                issue_time[ issueid ] = issuetime

            cu.execute("select article_folder as folder_id, issue_id from article_table;", [])
            rows = cu.fetchall()
            
            
            folder_id = {}
            
            for row in rows:
                folderid = row[0]
                issueid  = row[1]
                folder_id[ folderid ] = issueid


            xmls = glob.glob('./db/economist/**/article.xml', recursive=True)
            for xml in xmls:
                with open(xml, "r", encoding="utf-8") as fp:
                    data = fp.read()
                    js = xmltodict.parse(data)
                    article = {}
                    idiom = {}
                    _id = js['article']['@id']
                    pubdate = js['article']['pubdate']
                    
                    article['issue_time'] = issue_time[ folder_id[_id] ]
                    article['pubdate'] = pubdate

                    print(type( js['article']['body']['idioms'] ))
                    
                    if js['article']['body']['idioms'] != None:
                        idiom['idiom'] = js['article']['body']['idioms']['idiom']


# createDatabase_studio()
createDatabase_economistglobl()

```



### json



```
CREATE TABLE bookdata (
  id  serial NOT NULL PRIMARY KEY,
  info json NOT NULL
)

CREATE INDEX bookdata_fts ON bookdata USING gin((to_tsvector('english',info->'title')));

INSERT INTO bookdata (info)
VALUES
 ( '{ "title": "The Tattooed Duke", "items": {"product": "Diaper","qty": 24}}'),
 ( '{ "title": "She Tempts the Duke", "items": {"product": "Toy Car","qty": 1}}'),
 ( '{ "title": "The Duke Is Mine", "items": {"product": "Toy Train","qty": 2}}'),
 ( '{ "title": "What I Did For a Duke", "items": {"product": "Toy Train","qty": 2}}'),
 ('{ "title": "King Kong", "items": {"product": "Toy Train","qty": 2}}');

SELECT info -> 'title' as title FROM bookdata
WHERE to_tsvector('english',info->'title') @@ to_tsquery('Duke');
```





```
https://stackoverflow.com/questions/45680936/how-to-implement-full-text-search-on-complex-nested-jsonb-in-postgresql
```



### æŸ¥è¯¢ä¼˜åŒ–

- https://v2ex.com/t/840205#reply37
  - PostgreSQL çœŸçš„æ²¡æœ‰å®Œç¾çš„åˆ†é¡µæ–¹æ³•å—ï¼Ÿ

- https://kaifeiji.cc/post/do-i-really-know-about-pagination/
  - æˆ‘çœŸçš„ä¼šåˆ†é¡µå—

- https://github.com/digoal/blog/blob/master/201801/20180119_03.md



#### åˆ†é¡µ

ä¸è¿‡å€Ÿé‰´è¿™ä¸ªæ€è·¯ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹æŸäº›åœºæ™¯çš„åˆ†é¡µæŸ¥è¯¢è¿›è¡Œä¼˜åŒ–ã€‚
å¯¹äºæŒ‰éœ€è‡ªåŠ¨åŠ è½½ï¼ˆ*åˆ’åˆ°é¡µé¢åº•éƒ¨è‡ªåŠ¨åŠ è½½æ›´å¤šå†…å®¹*ï¼‰æˆ–è€…åªæä¾›**ä¸Šä¸€é¡µ/ä¸‹ä¸€é¡µ**æµè§ˆæ¨¡å¼çš„åœºæ™¯ï¼Œå¯ä»¥è¿›è¡Œå¦‚ä¸‹ä¼˜åŒ–ï¼š

1. æ¯æ¬¡æŸ¥è¯¢æ•°æ®æ—¶ï¼Œæˆ‘ä»¬è®°å½•æœ€åä¸€æ¡æ•°æ®çš„IDæˆ–æœ€åæ›´æ–°æ—¶é—´ï¼ˆè¿™ä¸ªä¸»è¦æ ¹æ®order byå­—æ®µæ¥ç¡®å®šï¼‰
2. åŠ è½½ä¸‹ä¸€é¡µæ•°æ®æ—¶ï¼ŒæŠŠæœ¬é¡µçš„æœ€åä¸€æ¡æ•°æ®IDä½œä¸ºè¿‡æ»¤æ¡ä»¶ã€‚
3. åŠ è½½ä¸Šä¸€é¡µæ•°æ®æ—¶ï¼Œåˆ™æŠŠæœ¬é¡µç¬¬ä¸€æ¡æ•°æ®IDä½œä¸ºè¿‡æ»¤æ¡ä»¶ã€‚

**æŸ¥è¯¢ä¸‹ä¸€é¡µ**

```n1ql
SELECT * FROM orders WHERE order_id > page_last_id ORDER BY order_id
LIMIT page_sieze OFFSET 0;
```

**æŸ¥è¯¢ä¸Šä¸€é¡µ**

```n1ql
SELECT * FROM orders WHERE order_id < page_first_id ORDER BY order_id
LIMIT page_sieze OFFSET 0;
```

å°æŠ€å·§ï¼š*æ¯æ¬¡æŸ¥è¯¢æ•°æ®æ—¶ï¼Œå¤šè¿”å›ä¸€æ¡æ•°æ®ï¼Œå³è¿”å›page_size + 1æ¡æ•°æ®ï¼Œä½†æ˜¾ç¤ºæ—¶å»æ‰æœ€åä¸€æ¡æ•°æ®ï¼Œé€šè¿‡è¿™å¤šå‡ºæ¥ä¸€æ¡æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥ç”¨æ¥åˆ¤æ–­æ•°æ®æ˜¯å¦è¿˜æœ‰ä¸‹ä¸€é¡µ*ã€‚

å¦å¤–å¯¹äºå¯ä»¥è·³è½¬åˆ°ä»»æ„é¡µé¢çš„åœºæ™¯ï¼Œä¹Ÿå¯ä»¥è¿›è¡Œä¼˜åŒ–ï¼Œè¿™ç§å¯è·³è½¬åœºæ™¯ï¼Œåˆ†é¡µæ˜¾ç¤ºä¹Ÿæ˜¯æœ‰é™çš„ï¼Œä¸€èˆ¬æ¨¡å¼æ˜¯**ç¬¬ä¸€é¡µ/ä¸Šä¸€é¡µ/å½“å‰é¡µå‰å10é¡µâ€¦â€¦/ä¸‹ä¸€é¡µ/æœ€åä¸€é¡µ**ï¼Œä¹Ÿå°±æ˜¯è¯´ï¼Œåˆ†é¡µæ—¶ï¼Œæ•°æ®æ˜¯åœ¨**ä¸€å®šèŒƒå›´å†…**ï¼ˆå‰å10é¡µï¼‰ç§»åŠ¨ï¼Œå¯ä»¥ä»¥å½“å‰é¡µæ•°æ®ä¸ºåŸºç¡€ï¼Œå¯¹æ•°æ®è¿›è¡Œè¿‡æ»¤ï¼Œå‡å°‘æ•°æ®æ‰«æèŒƒå›´ã€‚
è€ƒè™‘ordersè¡¨æœ‰10Wæ¡è®°å½•ï¼Œæ¯é¡µæ˜¾ç¤º10æ¡ï¼Œå½“å‰é¡µç ä¸º1000æ—¶çš„åœºæ™¯ï¼Œå¦‚æœæŒ‰ç…§å•ç‹¬limitå’Œoffsetæ¨¡å¼ï¼Œoffset=1Wï¼Œä¹Ÿå°±æ˜¯æ•°æ®åº“è¦æ‰«ç 1Wæ¡è®°å½•ã€‚å‡å¦‚ç°åœ¨ç¿»é¡µè¦ä»1000é¡µè·³è½¬åˆ°1005é¡µï¼Œæˆ‘ä»¬ä»¥ç¬¬1000é¡µæœ€åä¸€æ¡æ•°æ®IDä¸ºè¿‡æ»¤æ¡ä»¶ï¼Œoffsetè·³è¿‡1001-1004çš„40æ¡æ•°æ®å³å¯ã€‚

**æŸ¥è¯¢1005é¡µ**

```n1ql
SELECT * FROM orders WHERE order_id > page_1000_last_id ORDER BY order_id
LIMIT page_sieze OFFSET page_size * 4;
```

è¿™ç§æ–¹æ³•ç›¸æ¯”åŸºç¡€çš„åˆ†é¡µæ–¹å¼ï¼Œåªè¦order byå­—æ®µæ˜¯ä¸»é”®æˆ–ç´¢å¼•å­—æ®µï¼Œæ•°æ®æ‰«æçš„è¡Œæ•°ä»1Wå¤šæ¡ä¸‹é™åˆ°äº†å‡ åæ¡ï¼Œæ•ˆç‡å¤§å¤§æå‡ã€‚



### è¯»å†™åˆ†ç¦»

- https://lofter.me/2017/10/25/PostgreSQL%E9%9B%86%E7%BE%A4%E5%8F%8A%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E6%96%B9%E6%A1%88/

```
PostgreSQLé›†ç¾¤åŠè¯»å†™åˆ†ç¦»æ–¹æ¡ˆ
```



# å›¾å¼æœç´¢

- https://developer.aliyun.com/article/689151

  > å¾·å“¥PGç³»åˆ—ï¼šPostgreSQL å›¾å¼å…³ç³»æ•°æ®åº”ç”¨å®è·µ

- https://www.bilibili.com/video/BV1ff4y1b73U

  > é‡æ–°å‘ç°PostgreSQLä¹‹ç¾ - 19 å›°æ‰°å¤æƒ‘ä»”å’Œæµ·ç›—çš„æ•°å­¦éš¾é¢˜ æ£®æ—å›¾å¼åˆ†ä½£

- https://developer.aliyun.com/article/328141

- https://www.bilibili.com/video/BV1Vv4115723

  > FTS è·ç¦»

- https://developer.aliyun.com/article/72699

  > PostgreSQL é€’å½’æŸ¥è¯¢ - æ ‘å‹æ•°æ®æŒ‰è·¯å¾„åˆ†ç»„è¾“å‡º

- https://www.cnblogs.com/ricklz/p/12590618.html

  > é€šè¿‡ä½¿ç”¨RECURSIVEï¼Œä¸€ä¸ª**WITHæŸ¥è¯¢å¯ä»¥å¼•ç”¨å®ƒè‡ªå·±çš„è¾“å‡º**ã€‚
  >
  > - https://blog.csdn.net/u010251897/article/details/118515107

```
å›¾å¼æœç´¢æ˜¯PostgreSQLåœ¨ï¼ˆåŒ…æ‹¬æµè®¡ç®—ã€å…¨æ–‡æ£€ç´¢ã€å›¾å¼æœç´¢ã€K-Vå­˜å‚¨ã€å›¾åƒæœç´¢ã€æŒ‡çº¹æœç´¢ã€ç©ºé—´æ•°æ®ã€æ—¶åºæ•°æ®ã€æ¨èç­‰ï¼‰è¯¸å¤šç‰¹æ€§ä¸­çš„ä¸€ä¸ªã€‚

é‡‡ç”¨CTEè¯­æ³•ï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿çš„å®ç°å›¾å¼æœç´¢ï¼ˆNåº¦æœç´¢ã€æœ€çŸ­è·¯å¾„ã€ç‚¹ã€è¾¹å±æ€§ç­‰ï¼‰ã€‚

å…¶ä¸­å›¾å¼æœç´¢ä¸­çš„ï¼šå±‚çº§æ·±åº¦ï¼Œæ˜¯å¦å¾ªç¯ï¼Œè·¯å¾„ï¼Œéƒ½æ˜¯å¯è¡¨è¿°çš„ã€‚
```





## Docker

```
service docker status
service docker start
systemctl enable docker  # å¼€æœºè‡ªå¯åŠ¨
docker update --restart always xxxx  # å®¹å™¨éšdocker å¯åŠ¨
```



```
docker exec -it centos7PG10 /bin/bash
docker ps -a
docker inspect
exit  (quit)
CTRL + P + Q (quit)
docker inspect container_name | grep IPAddress
  --> 172.18.0.3
# éœ€è¦æ›´å¤šIP æ—¶
iptables -t nat -A  DOCKER -p tcp --dport 222 -j DNAT --to-destination 172.18.0.3:22
```





```
# https://yeasy.gitbook.io/docker_practice/image/pull
# è¿›å…¥docker
docker run -it --rm ubuntu:18.04 bash
```

```bash
åªä¹ æƒ¯ç”¨Centosç³»ç»Ÿï¼Œä½†æ˜¯æœ‰äº›è½¯ä»¶ç¼–è¯‘å®‰è£…å¾ˆéº»çƒ¦ä¸æ–¹ä¾¿ï¼Œä½†æ˜¯å‘¢åœ¨Ubuntuä¸­å°±å˜å¾—å®¹æ˜“æ–¹ä¾¿ï¼Œæ‰€ä»¥æˆ‘æ‰“ç®—ç”¨dockerè¿è¡ŒUbuntuç³»ç»Ÿå¼¥è¡¥CentosçŸ­æ¿å’Œä¸è¶³ä¹‹å¤„ï¼›

é¡¹ç›®åœ°å€ï¼šhttps://hub.docker.com/_/ubuntu/

1ã€å®‰è£…Ubuntuç³»ç»Ÿå‘½ä»¤ï¼š
docker pull ubuntu
è¿™æ˜¯ä¸€ä¸ªæåº¦ç²¾ç®€çš„ç³»ç»Ÿï¼Œè¿æœ€åŸºæœ¬çš„wgetå‘½ä»¤éƒ½æ²¡æœ‰ï¼›æ‰€ä»¥å…ˆè¦apt-get updateå‡çº§ç³»ç»Ÿå’Œå®‰è£…apt-get install wgetå‘½ä»¤ï¼›

2ã€è¿è¡Œè¿›å…¥Ubuntuç³»ç»Ÿå‘½ä»¤ï¼š
docker run -ti ubuntu bash

3ã€æ­£ç¡®é€€å‡ºç³»ç»Ÿæ–¹å¼ï¼š
å…ˆæŒ‰ï¼Œctrl+p
å†æŒ‰ï¼Œctrl+q
ç»å¯¹ä¸èƒ½ä½¿ç”¨exitæˆ–è€…ctrl+dæ¥é€€å‡ºï¼Œè¿™æ ·æ•´ä¸ªç³»ç»Ÿå°±é€€å‡ºäº†ï¼ï¼ï¼

4ã€å…±äº«å®¿ä¸»æœºç›®å½•åˆ°Ubuntuç³»ç»Ÿä¸­ï¼š
docker run -it -v /AAA:/BBB ubuntu bash
è¿™æ ·å®¿ä¸»æœºæ ¹ç›®å½•ä¸­çš„AAAæ–‡ä»¶å¤¹å°±æ˜ å°„åˆ°äº†å®¹å™¨Ubuntuä¸­å»äº†ï¼Œä¸¤è€…ä¹‹é—´èƒ½å¤Ÿå…±äº«ï¼›

5ã€ç™»é™†dockerä¸­çš„ubuntué•œåƒç³»ç»Ÿï¼š
docker run -ti ubuntu /bin/bash
#6866 æ˜¯ IMAGE ID å‰å››ä½æ•°å­—-èƒ½åŒºåˆ†å‡ºæ˜¯å“ªä¸ªimageå³å¯

6ã€é€€å‡ºå å†è¿›å…¥ubuntu
1ã€é¦–å…ˆç”¨docker ps -a æŸ¥æ‰¾åˆ°è¯¥CONTAINER IDå¯¹åº”ç¼–å·ï¼ˆæ¯”å¦‚ï¼š0a3309a3b29eï¼‰
2ã€è¿›å…¥è¯¥ç³»ç»Ÿdocker attach 0a3309a3b29e ï¼ˆæ­¤æ—¶æ²¡ååº”ï¼Œctrl+cå°±è¿›å…¥åˆ°ubuntuç³»ç»Ÿä¸­å»äº†ï¼‰

PS:æˆ‘è¿è¡Œçš„å‘½ä»¤

docker run -it -v /download:/download -p 53:53 ubuntu bash

é™„åŠ å¸¸ç”¨å‘½ä»¤ï¼š
ä¸€ã€æŸ¥çœ‹ubuntuç‰ˆæœ¬ï¼šcat /etc/issue
äºŒã€ä¿®æ”¹ubuntué•œåƒæºä¸ºubuntuï¼š
1ã€å¤‡ä»½ cp /etc/apt/sources.list /etc/apt/sources.list.backup
2ã€æ¸…ç©ºå†…å®¹åŠ å…¥ä»¥ä¸‹å†…å®¹ vi /etc/apt/sources.list

3ã€æ›´æ–°ç”Ÿæ•ˆï¼šapt-get update

ä¸‰ã€å®‰è£…å¼€å¯sshè¿è¡Œç”¨æˆ·è¿œç¨‹ç™»å½•
1ã€å®‰è£…sshdå‘½ä»¤ï¼šapt-get install openssh-server openssh-client

2ã€ç¼–è¾‘/etc/ssh/sshd_config ï¼Œæ³¨é‡Šæ‰ï¼šPermitRootLogin without-passwordï¼Œå¢åŠ PermitRootLogin yes

3ã€å¯åŠ¨å‘½ä»¤
service ssh start
service ssh stop
service ssh restart
```



### Xshellå¦‚ä½•è¿æ¥Dockerå®¹å™¨ä¸­çš„Linux

```

yum whatprovides ifconfig
yum install net-tools

# https://blog.csdn.net/u010046887/article/details/90406725

æ­¥éª¤ä¸€ï¼šé…ç½®centos:7 å®¹å™¨SSHæœåŠ¡
 
# 1ã€è·å–ç³»ç»Ÿé•œåƒ
[root@izwz9eftauv7x69f5jvi96z ~]# docker pull centos:7 
# 2ã€å¯åŠ¨ï¼ˆå¯ä»¥ä½¿ç”¨systemdç®¡ç†æœåŠ¡è¿›ç¨‹ï¼‰
[root@izwz9eftauv7x69f5jvi96z ~]# docker run -tdi --privileged centos init
# 3ã€è¿›å…¥å®¹å™¨çš„bash
[root@izwz9eftauv7x69f5jvi96z ~]# docker ps
CONTAINER ID        IMAGE                                  COMMAND                  CREATED             STATUS              PORTS                         NAMES
0d77d1bf15b3        centos                                 "init"                   8 seconds ago       Up 8 seconds                                      elegant_joliot
[root@d26c58c4f740 /]# docker exec -it 0d bash
# 4ã€ä¿®æ”¹rootå¯†ç ï¼Œåˆå§‹åŒ–å¯†ç Qwer1234
[root@d26c58c4f740 /]# passwd
Changing password for user root.
New password: 
BAD PASSWORD: The password fails the dictionary check - it is too simplistic/systematic
Retype new password: 
passwd: all authentication tokens updated successfully.
# 5ã€å®‰è£…å®¹å™¨çš„openssh-server
[root@d26c58c4f740 /]# yum install openssh-server -y
â€¦â€¦â€¦â€¦â€¦â€¦
# 6ã€ä¿®æ”¹/etc/ssh/sshd_configé…ç½®å¹¶ä¿å­˜ï¼šPermitRootLogin yes    UsePAM no
[root@d26c58c4f740 /]# vi /etc/ssh/sshd_config
 
# 7ã€å¯åŠ¨sshæœåŠ¡
[root@0d77d1bf15b3 /]# systemctl start sshd
# 8ã€é€€å‡ºå®¹å™¨
[root@0d77d1bf15b3 /]# exit
exit
æ­¥éª¤äºŒï¼šæ„å»ºå¹¶å¯åŠ¨é•œåƒ

# 1ã€æŸ¥çœ‹åˆšåˆšçš„å®¹å™¨ID
[root@izwz9eftauv7x69f5jvi96z ~]# docker ps
CONTAINER ID        IMAGE                                  COMMAND                  CREATED             STATUS              PORTS                         NAMES
0d77d1bf15b3        centos                                 "init"                   5 minutes ago       Up 5 minutes                                      elegant_joliot  
 
# 2ã€é€šè¿‡commitæ„å»ºé•œåƒ
[root@izwz9eftauv7x69f5jvi96z ~]# docker commit \
> --author "wwx<wuweixiang.alex@gmail.com>" \
> --message "å®¹å™¨centoså¼€å¯è¿œç¨‹sshæˆåŠŸ" \
> 0d \
> wuweixiang/centos7-ssh:1.0.0
sha256:983d8f4594dc6ef98d0432c34331faa307a82e85bd15ed1a6d15bfb91bc81359
 
# 3ã€å¯åŠ¨è¿™ä¸ªé•œåƒçš„å®¹å™¨ï¼Œå¹¶æ˜ å°„æœ¬åœ°çš„ä¸€ä¸ªé—²ç½®çš„ç«¯å£ï¼ˆä¾‹å¦‚10000ï¼‰åˆ°å®¹å™¨çš„22ç«¯å£
[root@izwz9eftauv7x69f5jvi96z ~]# docker images
REPOSITORY                      TAG                 IMAGE ID            CREATED             SIZE
wuweixiang/centos7-ssh          1.0.0               983d8f4594dc        2 minutes ago       302MB
[root@izwz9eftauv7x69f5jvi96z ~]# docker run -d -p 10000:22 --name wwx-centos7-ssh 983 /usr/sbin/sshd -D
9004a532ed73cee18fb804cd2e36491785b26df885fb20f226929dd4428df859
ä¸‰ã€ç”¨Xshellè¿›è¡Œsshè¿æ¥æˆåŠŸ
Connecting to 112.74.185.172:10000...
Connection established.
To escape to local shell, press 'Ctrl+Alt+]'.
 
Last login: Fri Nov 23 07:58:34 2018 from 120.42.130.201
[root@9004a532ed73 ~]#
```



docker ps -a  # å…¨éƒ¨çŠ¶æ€éƒ½åˆ—å‡ºæ¥ï¼Œå¼ºå¤§ä¸€äº›

docker start centos7



### ç§»é™¤é•œåƒ

docker images

docker rmi xxx



### ç§»é™¤å®¹å™¨

docker stop 17b3d18c1428

docker rm 17b3d18c1428









docker pull centos:7

docker run -it --rm centos:7 bash

```
# ç‰¹æƒæ¨¡å¼åˆ›å»ºå®¹å™¨
docker run -tid --name centos7 -p 222:22 --privileged=true centos:7 /sbin/init 
		# æ­¤å‘½ä»¤ä¼šè‡ªåŠ¨ä¸‹è½½é•œåƒ
		# -p 222:22 è¡¨ç¤ºå°†å®¿ä¸»çš„222ç«¯å£æ˜ å°„å®¹å™¨çš„22ç«¯å£
# è¿è¡Œ
docker exec -it centos7 /bin/bash
# å®‰è£…ssh
yum install openssh-server -y
# ä¿®æ”¹é…ç½®
vi /etc/ssh/sshd_config
PermitRootLogin yes # æ”¹æˆè¿™ä¸ª
UsePAM no # æ”¹æˆè¿™ä¸ª
# å¯åŠ¨ssh
systemctl start sshd
# é€€å‡ºå®¹å™¨
eixt

# æŸ¥çœ‹å®¹å™¨çš„IP
docker inspect centos7 | grep IPAddress
  --> "IPAddress": "172.18.0.3"

# ç™»å½•çœ‹çœ‹
ssh root@172.18.0.3
  --> æˆåŠŸ






```

https://plutoacharon.github.io/2020/02/23/Docker%E5%AE%B9%E5%99%A8%E5%87%BA%E7%8E%B0%E4%BD%BF%E7%94%A8systemctl%E9%97%AE%E9%A2%98%EF%BC%9AFailed-to-get-D-Bus-connection-Operation-not-permitted/



### ä¿å­˜é…ç½®å¥½çš„é•œåƒ



```
docker commit   --message "host 222 --> docker 22"  4ace0a92d191
```





### å¦‚æœéœ€è¦æ›´å¤šçš„ç«¯å£æ˜ å°„

```
# https://blog.opensvc.net/yun-xing-zhong-de-dockerrong-qi/

# å·²æœ‰ç«¯å£æ˜ å°„
iptables -t nat -vnL DOCKER
  --> tcp dpt:8083 to:172.18.0.2:8083
  --> tcp dpt:54322 to:172.18.0.3:5432

# è¿™ç§æ–¹æ³•æ¯æ¬¡docker é‡å¯ä¼šå¤±æ•ˆ
iptables -t nat -A DOCKER -p tcp --dport 222 -j DNAT --to-destination 172.18.0.3:22

# è·å–è§„åˆ™ç¼–å·
iptables -t nat -nL --line-number

# åˆ é™¤æŸæ¡è§„åˆ™
iptables -t nat -D DOCKER ç¼–å·

```







```
# https://www.jianshu.com/p/5c71b4f40612

docker ps -a
docker inspect çŸ­hash # ç„¶åå¾—åˆ°é•¿ID
vi /var/lib/docker/containers/2416f0b833b226332db69fe5a5664d3ce6b11adfe8956be293ff87d6995bdebc/hostconfig.json

# å·²æœ‰ç«¯å£æ˜ å°„
"PortBindings":{"5432/tcp":[{"HostIp":"","HostPort":"54322"}]}

cp /var/lib/docker/containers/2416f0b833b226332db69fe5a5664d3ce6b11adfe8956be293ff87d6995bdebc/hostconfig.json /var/lib/docker/containers/2416f0b833b226332db69fe5a5664d3ce6b11adfe8956be293ff87d6995bdebc/hostconfig.json-backup

# å¢åŠ æ–°çš„
"PortBindings":{"5432/tcp":[{"HostIp":"","HostPort":"54322"}],"22/tcp":[{"HostIp":"","HostPort":"222"}]} # è¿™é‡Œæ˜¯ç›´æ¥æ”¹

cp /var/lib/docker/containers/2416f0b833b226332db69fe5a5664d3ce6b11adfe8956be293ff87d6995bdebc/config.v2.json /var/lib/docker/containers/2416f0b833b226332db69fe5a5664d3ce6b11adfe8956be293ff87d6995bdebc/config.v2.json-backup

vi /var/lib/docker/containers/2416f0b833b226332db69fe5a5664d3ce6b11adfe8956be293ff87d6995bdebc/config.v2.json

# å·²æœ‰
"ExposedPorts":{"5432/tcp":{}}

# å¢åŠ 
"ExposedPorts":{"5432/tcp":{},"22/tcp":{}} # åŸ
"ExposedPorts":{"22/tcp":{}} # åœ¨å®ƒåé¢åŠ 

service docker restart

# æŸ¥çœ‹é…ç½®ï¼Œæ˜¯å¦ä¿®æ”¹æˆåŠŸ
docker inspect çŸ­hash

docker start xxx
```



```
 "Config": {
  "ExposedPorts": {
   // æ·»åŠ å†…éƒ¨ç«¯å£5432æ˜ å°„
   "5432/tcp": {},
   "8080/tcp": {}
  },s
  ...
 },

"PortBindings":{
  // æ·»åŠ å†…éƒ¨ç«¯å£ä»¥åŠå¤–éƒ¨ç«¯å£15432
  "5432/tcp":[
   {
    "HostIp":"",
    "HostPort":"15432"
   }
  ],
  "8080/tcp":[
   {
    "HostIp":"",
    "HostPort":"28080"
   }
  ]
 },
```







```
# å°†å®¿ä¸»æœºçš„222ç«¯å£æ˜ å°„åˆ°IPä¸º172.18.0.3å®¹å™¨çš„22ç«¯å£
# äº›æ–¹æ³•å¯ä»¥ç”¨äºå¢åŠ é¢å¤–çš„ç«¯å£ï¼Ÿï¼Ÿï¼Ÿ
iptables -t nat -A  DOCKER -p tcp --dport 222 -j DNAT --to-destination 172.18.0.3:22
```





1ã€è·å¾—å®¹å™¨IP
å°†container_name æ¢æˆå®é™…ç¯å¢ƒä¸­çš„å®¹å™¨å
docker inspect `container_name` | grep IPAddress

2ã€iptableè½¬å‘ç«¯å£
å°†å®¿ä¸»æœºçš„8888ç«¯å£æ˜ å°„åˆ°IPä¸º192.168.1.15å®¹å™¨çš„8080ç«¯å£
iptables -t nat -A  DOCKER -p tcp --dport 8888 -j DNAT --to-destination 192.168.1.15:8080



ä¸€ã€æ·»åŠ dockerå®¹å™¨ç«¯å£æ˜ å°„
ä»¥tomcatå®¹å™¨ä¸ºä¾‹ï¼š

root@localhost /]# docker run --name mytomcat -d -p 8888:8080 tomcat
1
â€“nameï¼šåˆ›å»ºçš„tomcaté•œåƒåç§°
â€dï¼šåå°è¿è¡Œ
â€pï¼šå°†ä¸»æœºçš„ç«¯å£æ˜ å°„åˆ°å®¹å™¨çš„ä¸€ä¸ªç«¯å£ï¼Œ8888:8080ä»£è¡¨ï¼šä¸»æœºç«¯å£:å®¹å™¨å†…éƒ¨çš„ç«¯å£

æ‰§è¡Œå®Œä¼šè¿”å›æ–°åˆ›å»ºçš„tomcaté•œåƒID




### Docker ä¸­çš„postgreql



<img src="postgresql summary.assets/image-20210526154947175.png" alt="image-20210526154947175" style="zoom:50%;" />



```
# å…³é—­é˜²ç«å¢™
systemctl stop firewalld

# pm2 resurrect  # pm2 save åæ¢å¤

# atuto run when reboot
chmod +x /etc/rc.d/rc.local
vi /etc/rc.d/rc.local
mount /dev/sda1 /mnt  # åŠ ä¸€å¥ï¼ŒæŒ‚è½½å­˜å‚¨å—

systemctl status postgresql-13
systemctl enable postgresql-13 # è‡ªå¯åŠ¨



# ç‰¹æƒæ¨¡å¼åˆ›å»ºå®¹å™¨
docker run -tid --name centos7PG10 -p 54322:5432 --privileged=true centos:7 /sbin/init 
		# æ­¤å‘½ä»¤ä¼šè‡ªåŠ¨ä¸‹è½½é•œåƒ
		# -p 222:22 è¡¨ç¤ºå°†å®¿ä¸»çš„222ç«¯å£æ˜ å°„å®¹å™¨çš„22ç«¯å£

# è¿è¡Œdocker çš„shell
docker exec -it centos7PG10 /bin/bash

# å®‰è£…PG13
# https://gist.github.com/coder4web/13419dbfe7c22dc5bad8bb4e135138bc # å®‰è£…è„šæœ¬
yum -y install https://download.postgresql.org/pub/repos/yum/reporpms/EL-7-x86_64/pgdg-redhat-repo-latest.noarch.rpm

yum -y update
yum search postgresql13
yum -y install postgresql13 postgresql13-server
/usr/pgsql-13/bin/postgresql-13-setup initdb
	# adduser postgres
	# chown -R postgres:postgres /mnt/psqldata
	åŠ¡å¿…çœ‹è¿™é‡Œ \doc\tech\survive.md
		åæ¥çš„æ–¹æ¡ˆï¼Œè®©linux é€‚åº”windows çš„åˆ†åŒº
		
		# https://unix.stackexchange.com/questions/491098/cannot-chown-chmod-on-mounted-ntfs-partition
			# linux mount ntfs chown æœè¿™ä¸ªï¼Œæ”¹ä¸äº†owner å±æ€§
		# cp -R /var/lib/pgsql/13/data /mnt/psqldata # åªèƒ½é€äº®æ¢æŸ±äº†
		# mv /var/lib/pgsql/13/data /var/lib/pgsql/13/data__link__to_mnt_psqldata
		# ln -s  /mnt/psqldata  /var/lib/pgsql/13/data
			# unlink å–æ¶ˆè½¯é“¾ç”¨è¿™ä¸ª
		# chown -R postgres:postgres /mnt/psqldata
	# sudo -u postgres /usr/pgsql-13/bin/initdb -D /mnt/psqldata
	# su - postgres
	# /usr/pgsql-13/bin/initdb -D /mnt/psqldata
	# /usr/pgsql-13/bin/pg_ctl -D /mnt/psqldata -l logfile -o '--config-file=/mnt/psqldata/postgresql.conf' start
	# /usr/pgsql-13/bin/pg_ctl -D /mnt/psqldata -l logfile status # æŸ¥çœ‹çŠ¶æ€
	# vi /mnt/psqldata/postgresql.conf
		listen_addresses = '*' # æ”¹æˆè¿™ä¸ª
	# vi /mnt/psqldata/pg_hba.conf
		hostnossl    all          all            0.0.0.0/0  md5
		# åŠ åœ¨æœ€åé¢ï¼Œæ¥å—æ‰€æœ‰è¿œç¨‹IP
	# psql -c "show config_file"
	# ps aux | grep /postgres
	# select name, setting from pg_Settings where name ='data_directory';
	
systemctl start postgresql-13
	# /usr/pgsql-13/bin/postmaster -D /var/lib/pgsql/13/data/
	# sudo -u postgres psql
	# SHOW data_directory;
	
systemctl status postgresql-13
systemctl enable postgresql-13 # è‡ªå¯åŠ¨

# æ”¹å¼ºå¯†ç 
su - postgres
	psql
	\password postgres
	ç„¶åè¾“å…¥å¯†ç 
	\q
			è¿™å¥ä¸æˆåŠŸ# psql -c "alter user postgres with password 'è¿™é‡Œå¡«çš„ä¸€ä¸ªå¼ºå¯†ç '"
		
# å…è®¸è¿ç¨‹è¿æ¥
vi /var/lib/pgsql/13/data/postgresql.conf
	listen_addresses = '*' # æ”¹æˆè¿™ä¸ª
vi /var/lib/pgsql/13/data/pg_hba.conf
hostnossl    all          all            0.0.0.0/0  md5  
	# hostnossl    all          all            0.0.0.0/0  trust  # ä»»ä½•å¯†ç éƒ½èƒ½è¿
	# åŠ åœ¨æœ€åé¢ï¼Œæ¥å—æ‰€æœ‰è¿œç¨‹IP

systemctl restart postgresql-13

# docker è¿æ¥æµ‹è¯•
psql -h 127.0.0.1 -p 5432 -U postgres  # æ³¨æ„ç«¯å£
  --> æˆåŠŸ
# å®¿ä¸»è¿æ¥æµ‹è¯•
psql -h 127.0.0.1 -p 54322 -U postgres # æ³¨æ„ç«¯å£
  --> æˆåŠŸ
  
```

<img src="postgresql summary.assets/image-20210330185047454.png" alt="image-20210330185047454" style="zoom:50%;" />

**navicat è¿æ¥**



#### WIN7+centos åŒå¯é—®é¢˜ 

```

åŠ¡å¿…çœ‹è¿™é‡Œ
\doc\tech\survive.md
	åæ¥çš„æ–¹æ¡ˆï¼Œè®©linux é€‚åº”windows çš„åˆ†åŒº


```



#### å¯åŠ¨å·²åœæ­¢çš„å®¹å™¨

docker start 2416f0b833b2





### ssh ä¿æŒè¿æ¥



```
vi /etc/ssh/sshd_config

TCPKeepAlive yes #è¡¨ç¤ºTCPä¿æŒè¿æ¥ä¸æ–­å¼€
ClientAliveInterval 300 #æŒ‡å®šæœåŠ¡ç«¯å‘å®¢æˆ·ç«¯è¯·æ±‚æ¶ˆæ¯çš„æ—¶é—´é—´éš”ï¼Œå•ä½æ˜¯ç§’ï¼Œé»˜è®¤æ˜¯0ï¼Œä¸å‘é€ã€‚è®¾ç½®ä¸ª300è¡¨ç¤º5åˆ†é’Ÿå‘é€ä¸€æ¬¡ï¼ˆæ³¨æ„ï¼Œè¿™é‡Œæ˜¯æœåŠ¡ç«¯ä¸»åŠ¨å‘èµ·ï¼‰ï¼Œç„¶åç­‰å¾…å®¢æˆ·ç«¯å“åº”ï¼ŒæˆåŠŸï¼Œåˆ™ä¿æŒè¿æ¥ã€‚
ClientAliveCountMax 3 #æŒ‡æœåŠ¡ç«¯å‘å‡ºè¯·æ±‚åå®¢æˆ·ç«¯æ— å“åº”åˆ™è‡ªåŠ¨æ–­å¼€çš„æœ€å¤§æ¬¡æ•°ã€‚ä½¿ç”¨é»˜è®¤ç»™çš„3å³å¯ã€‚
ï¼ˆæ³¨æ„ï¼šTCPKeepAliveå¿…é¡»æ‰“å¼€ï¼Œå¦åˆ™ç›´æ¥å½±å“åé¢çš„è®¾ç½®ã€‚ClientAliveIntervalè®¾ç½®çš„å€¼è¦å°äºå„å±‚é˜²ç«å¢™çš„æœ€å°å€¼ï¼Œä¸ç„¶ï¼Œä¹Ÿå°±æ²¡ç”¨äº†ã€‚ï¼‰
```





å¥½æ–‡

https://www.mengqingzhong.com/2020/10/01/postgresql-index-rum-8/



æˆ‘ä»¬å†ä¸€ä¸ªç›¸å¯¹å¤§ä¸€ç‚¹çš„æ•°æ®æ¯”è¾ƒGINå’ŒRUMï¼šæ‰¾å‡ºåŒ…å«helloå’Œhackersçš„åç¯‡æœ€ç›¸å…³çš„æ–‡æ¡£ã€‚

```sql
explain (costs off, analyze)
select * from mail_messages
where tsv @@ to_tsquery('hello & hackers')
order by ts_rank(tsv,to_tsquery('hello & hackers'))
limit 10;
```



select id, en, zh, type from studio where v_zh @@ to_tsquery('jiebacfg', 'æƒ…ç·’') ORDER BY RANDOM() limit 3;



SELECT id, ts_headline(body, q), rank

FROM (SELECT id, body, q, ts_rank_cd(ti, q) AS rank

   FROM apod, to_tsquery('stars') q

   WHERE ti @@ q

   ORDER BY rank DESC

   LIMIT 10) AS foo;



```
 # rise err
 sql = f"SELECT id, ts_headline(en, q) as en, zh, type \
                FROM studio, plainto_tsquery('en', '{keywd}') q \
                WHERE v_en @@ q \
                ORDER BY RANDOM() LIMIT 3 ;"
```



```sql
drop index tsv_gin;
create index tsv_rum on mail_messages using rum(tsv);
```



è¿™ä¸ªç´¢å¼•åŒ…å«äº†æ‰€æœ‰æ‰€éœ€çš„ä¿¡æ¯ï¼ŒæŸ¥è¯¢éå¸¸ç²¾ç¡®ï¼š

```sql
explain (costs off, analyze)
select * from mail_messages
where tsv @@ to_tsquery('hello <-> hackers');
```



**create index en_rum on studio using rum(en);**



SELECT id, ts_headline(en, q) as en, zh, type \

FROM studio, to_tsquery('rebell')  q

where en @@ to_tsquery('rebell')



# å›¾æ•°æ®åº“

- https://github.com/apache/age  Apache AGE

  - https://github.com/apache/age/issues/2111  pg 17 æ”¯æŒ

  - ```
    select * from cypher('graph1', $AnythingInsideDollars$
    Match(v:Persion{p_id:'safd$$bbb'}
    return v
    $AnythingInsideDollars$) as (v agtype);
    ```

  - ```
    So if you have the following in your db:
    
    (:City)-[:AirRoute]-(:City)
    (:City)-[:SeaRoute]-(:City)
    Being able to run a query and say 'Give me any Air OR Sea route between these two cities', which should be possible (in openCypher terms) via
    
    (:City { name: 'London' })-[:SeaRoute|AirRoute]-(:City { name: :'Rotterdam' })
    ```

  - ```
    issue1996=# SELECT * FROM cypher('issue1996', $$ CREATE (a:NODE {key1: "prop1", key2:"prop2"}) $$) as (a agtype);
     a 
    ---
    (0 rows)
    
    issue1996=# SELECT * FROM cypher('issue1996', $$ MATCH (a) return a$$) as (a json);
                                                 a                                              
    --------------------------------------------------------------------------------------------
     {"id": 844424930131969, "label": "NODE", "properties": {"key1": "prop1", "key2": "prop2"}}
    (1 row)
    issue1996=# SELECT cast(a as json) FROM cypher('issue1996', $$ MATCH (a) return a$$) as (a agtype);
                                                 a                                              
    --------------------------------------------------------------------------------------------
     {"id": 844424930131969, "label": "NODE", "properties": {"key1": "prop1", "key2": "prop2"}}
    (1 row)
    
    issue1996=# SELECT pg_typeof(a) FROM cypher('issue1996', $$ MATCH (a) return a$$) as (a json);
     pg_typeof 
    -----------
     json
    (1 row)
    ```

  - ```
    -- åˆ›å»ºä¸€ä¸ªåŒ…å« jsonb å±æ€§çš„èŠ‚ç‚¹
    SELECT * 
    FROM cypher('your_graph', $$
        CREATE (n:Person {name: 'Alice', attributes: '{"age": 30, "hobbies": ["reading", "hiking"]}'::jsonb})
    $$) AS (a agtype);
    
    -- GIN ç´¢å¼•ç”¨äºé€šç”¨çš„ jsonb æŸ¥è¯¢
    CREATE INDEX idx_person_attributes_gin ON your_graph.ag_catalog.v_label USING GIN ((properties -> 'attributes'));
    
    -- è¡¨è¾¾å¼ç´¢å¼•ç”¨äºä¼˜åŒ–é’ˆå¯¹ age å­—æ®µçš„æŸ¥è¯¢
    CREATE INDEX idx_person_age_expr ON your_graph.ag_catalog.v_label USING BTREE ((properties -> 'attributes' ->> 'age'));
    
    æŸ¥è¯¢ï¼šæŸ¥æ‰¾æ‰€æœ‰ hobbies åŒ…å« "reading" çš„äººå‘˜ã€‚
    SELECT *
    FROM cypher('your_graph', $$
        MATCH (n:Person)
        WHERE n.attributes @> '{"hobbies": ["reading"]}'::jsonb
        RETURN n
    $$) AS (n agtype);
    
    æŸ¥è¯¢ï¼šæŸ¥æ‰¾ age ç­‰äº 30 å²çš„äººå‘˜ã€‚
    SELECT *
    FROM cypher('your_graph', $$
        MATCH (n:Person)
        WHERE (n.attributes->>'age')::int = 30
        RETURN n
    $$) AS (n agtype);
    
    æŒ‰ age ä»å°åˆ°å¤§æ’åºäººå‘˜ã€‚
    SELECT *
    FROM cypher('your_graph', $$
        MATCH (n:Person)
        RETURN n
        ORDER BY (n.attributes->>'age')::int ASC
    $$) AS (n agtype);
    	# BTREE ç´¢å¼•æ”¯æŒé«˜æ•ˆçš„æ’åºæ“ä½œã€‚
    
    ```

  - ```
    SELECT *
    FROM cypher('your_graph', $$
        MATCH (n:Person)
        WHERE (n.attributes->>'age')::int > 25
        RETURN n
    $$) AS (n agtype);
    
    ```

  - 

- https://blog.csdn.net/qq_21090437/article/details/120292081 AgensGraph



# pg_duckdb

https://github.com/duckdb/pg_duckdb

https://github.com/abersheeran/r2-webdav  Cloudflare Workers + R2 å…ç»´æŠ¤ï¼Œ10 GB é…ç½®ç»°ç»°æœ‰ä½™



# ltree

```
CREATE TABLE test (
  path ltree,
  EXCLUDE USING HASH ((path::text) WITH =)
);
```



# JSON

```
    select t.id, array_agg(t._name) as _board
    from (
        select 
            d.id,
            jsonb_extract_path_text(jsonb_array_elements(
                case jsonb_extract_path(d.data, 'board_members') 
                    when 'null' then '[{}]'::jsonb 
                    else jsonb_extract_path(d.data, 'board_members') 
                end
            ), 'first_name') || ' ' || jsonb_extract_path_text(jsonb_array_elements(
                case jsonb_extract_path(d.data, 'board_members') 
                    when 'null' then '[{}]'::jsonb 
                    else jsonb_extract_path(d.data, 'board_members') 
                end
            ), 'last_name') as _name
        from my_table d
        group by d.id
    ) t
    group by t.id
    

1


You can use jsonb_path_query_array to get all matching array elements:

jsonb_path_query_array(data, '$.board_members[*] ? (@.ind == true)')
The above returns

[
  {"ind": true, "last_name": "Grant", "first_name": "Hugo"}, 
  {"ind": true, "last_name": "Flair", "first_name": "Rick"}
]
for your sample data.

To get the concatenated first/lastname you need to unnest the array and aggregate the names back.

select id, 
       (select jsonb_agg(concat_ws(' ', p.item ->> 'first_name', p.item ->> 'last_name'))
        from jsonb_array_elements(jsonb_path_query_array(data, '$.board_members[*] ? (@.ind == true)')) as p(item)) as names
from my_table
The above returns ["Hugo Grant", "Rick Flair"] in the names column

```

## å¸¦æœ‰å”¯ä¸€key çš„JSON

```
Another option is to use JSON or JSONB with a unique hash index on the key.

CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE TABLE key_values (
    key uuid DEFAULT uuid_generate_v4(),
    value jsonb
);
CREATE INDEX idx_key_values ON key_values USING hash (key);
postgres=# do $$
begin
for r in 1..1000 loop
INSERT INTO key_values (value)
VALUES ('{"somelarge_json": "bla"}');
end loop;
end;
$$;
DO

Some queries

SELECT * FROM key_values WHERE key = '1cfc4dbf-a1b9-46b3-8c15-a03f51dde891';
Time: 0.514 ms
postgres=# SELECT * FROM key_values WHERE key = '1cfc4dbf-a1b9-46b3-8c15-a03f51dde890';
Time: 1.747 ms


Time: 58.327 ms
```



## æ’å…¥åè¿”å› ID

```
INSERT INTO users (firstname, lastname) VALUES ('Joe', 'Cool') RETURNING id;
```



## æ™®é€šæŸ¥è¯¢è¿”å›json

```
select jsonb_agg(u) as user_data
from users u
where u.id = '1';

æˆ–ç€ï¼š
select jsonb_agg(jsonb_build_object('id', u.id, 'name', u.name)) as user_data
from users u
where u.id = '1';
```





# KVå­˜å‚¨

- https://blog.csdn.net/neweastsun/article/details/92849375

  > ```
  > CREATE EXTENSION hstore;
  > 	# å¯ç”¨å†…ç½®æ‰©å±•ï¼Œ
  > 	
  > CREATE TABLE books (
  >    id serial primary key,
  >    title VARCHAR (255),
  >    attr hstore
  > );
  > 
  > INSERT INTO books (title, attr)
  > VALUES
  >    (
  >       'PostgreSQL Tutorial',
  >       '"paperback" => "243",
  >       "publisher" => "postgresqltutorial.com",
  >       "language"  => "English",
  >       "ISBN-13"   => "978-1449370000",
  >        "weight"   => "11.2 ounces"'
  >    );
  > ```



# åˆ†å¸ƒå¼é›†ç¾¤

- https://www.xmmup.com/pggaokeyongzhicitusfenbushijiqundajianjishiyong.html  **å°éº¦è‹—DBAå®å…¸**

- https://github.com/citusdata/citus



# è¿æ¥æ± 



```python
# see huggingface/NLPP_Audio/vector.py

import aiohttp
import asyncio
import json
import psycopg
import psycopg_pool
import pandas as pd

# åˆ›å»ºä¸€ä¸ªå…¨å±€å˜é‡ï¼Œç”¨äºå­˜å‚¨è¿æ¥æ± å®ä¾‹
async_pool = None

async def pool_connect():
    global async_pool
    if async_pool is None:
        async_pool = psycopg_pool.AsyncConnectionPool(
            conninfo="postgres://postgres:post4321@127.0.0.1/nlppvector",
            min_size=1,
            max_size=32,
            open=False  # Avoid automatic opening on initialization to handle manually
        )
        # Opening the pool
        await async_pool.open()
        logging.info("Database connection pool is initialized and open.")

async def fetch_data(sql_query) -> pd.DataFrame:
    global async_pool
    await async_pool.open()

    async with async_pool.connection() as conn:
        async with conn.cursor() as cur:
            await cur.execute(sql_query)
            rows = await cur.fetchall()
            df = pd.DataFrame(rows, columns=[desc[0] for desc in cur.description])
    return df
    
async def main():
    global async_pool
    await pool_connect()


if __name__ == "__main__":
    import asyncio
    asyncio.run(main())

```





```
# æœ€å¤§è¿æ¥é…ç½®

RAM 16GB

Our configs:

/etc/sysctl.conf
kernel.shmmax=100663296

/var/lib/pgsql/13/data/postgresql.conf
max_connection=100
shared_buffer=512
```

```
# https://www.enterprisedb.com/blog/postgresql-pgpool-connection-pool-database-load

# https://stackoverflow.blog/2020/10/14/improve-database-performance-with-connection-pooling/

	pgpool-II

# https://www.cnblogs.com/wy123/p/14087274.html
	åœ¨Postgreä¸­è®¾ç½®max_connectionsæ—¶ï¼Œä¸ºä»€ä¹ˆéœ€è¦ä½¿ç”¨è¿æ¥æ±  ï¼ˆè¯‘ï¼‰

```



# æ¨¡ç³ŠæŸ¥è¯¢

https://www.cnblogs.com/xueqiuqiu/articles/10994428.html



# æ­£åˆ™æŸ¥è¯¢

https://www.cnblogs.com/xueqiuqiu/articles/10994428.html

- https://github.com/digoal/blog/blob/master/201611/20161118_01.md æ­£åˆ™



# è°ƒè¯•



```
https://gist.github.com/jhngrant/c1787346fcb4b0e3001a
https://www.techsupportpk.com/2020/12/how-to-install-pldebugger-centos.html

plugin_debugger

# GFW https://github.com/TyrantLucifer/ssr-command-client
yum install -y python3
shadowsocksr-cli --add-url https://subscription.ftwapi.com/link/xxxxxxx?sub=1
shadowsocksr-cli -u

git clone https://git.postgresql.org/git/pldebugger.git
cd pldebugger
PATH=$PATH:/usr/pgsql-13/bin
export PATH
export USE_PGXS=1
yum -y install gcc gcc-c++ kernel-devel make git nano openssl openssl-devel krb5-libs krb5-devel
make
make install
	--> '/usr/pgsql-13/lib/plugin_debugger.so'


vi /var/lib/pgsql/13/data/postgresql.conf
shared_preload_libraries = 'plugin_debugger' # æ‰¾åˆ°è¿™ä¸€å¥ï¼Œæ”¹æˆè¿™æ ·

systemctl restart postgresql-13


su postgres
psql
CREATE EXTENSION pldbgapi;
\q

```



```
http://www.postgres.cn/docs/9.4/functions-json.html

'[1,2,3]'::json->>2  # æ•°ç»„ï¼Œç´¢å¼•2
	--> 3
'{"a":1,"b":2}'::json->>'b' # json ç´¢å¼• "b"
	--> 2



```



```
regexp_split_to_array('hello world', E'\\s+')
  --> {hello,world}
```



```
with my_table(resource_name, readiops, writeiops) as (
values
('90832-00:29:3E', 3.21, 4.00),
('90833-00:30:3E', 2.12, 3.45),
('90834-00:31:3E', 2.33, 2.78),
('90832-00:29:3E', 4.21, 6.00)
)

select 
    split_part(resource_name::text, '-', 1) as array_serial,
    split_part(resource_name::text, '-', 2) as ldev,
    string_agg(readiops::text, ',') as readiops,
    string_agg(writeiops::text, ',') as writeiops
from my_table
group by 1, 2;

 array_serial |   ldev   | readiops  | writeiops 
--------------+----------+-----------+-----------
 90832        | 00:29:3E | 3.21,4.21 | 4.00,6.00
 90833        | 00:30:3E | 2.12      | 3.45
 90834        | 00:31:3E | 2.33      | 2.78
(3 rows)
```







```mysql

CREATE OR REPLACE FUNCTION ja_reading (TEXT) RETURNS TEXT AS
$func$
DECLARE
  js      JSON;
  total   TEXT[] := '{}';
  reading TEXT;
BEGIN
  FOREACH js IN ARRAY pgroonga_tokenize($1,
    'tokenizer', 'TokenMecab("use_base_form", true, "include_reading", true)')
  LOOP
    reading = (js -> 'metadata' ->> 'reading');

    IF reading IS NULL THEN
      total = total || (js ->> 'value');
    ELSE
      total = total || reading;
    END IF;
  END LOOP;

  RETURN array_to_string(total, '');
END;
$func$ LANGUAGE plpgsql IMMUTABLE;





SELECT ja_reading ('ã—ã¾ã™');
-- 

/*
{"{\"value\":\"æµ·\",\"position\":0,\"force_prefix_search\":false,\"metadata\":{\"reading\":\"ã‚¦ãƒŸ\"}}"}
{"{\"value\":\"1\",\"position\":0,\"force_prefix_search\":false}"}


SELECT pgroonga_tokenize('ã—ã¾ã™','tokenizer', 'TokenMecab("use_base_form", true, "include_reading", true)')
 --> {"{\"value\":\"ã™ã‚‹\",\"position\":0,\"force_prefix_search\":false,\"metadata\":{\"reading\":\"ã‚·\"}}","{\"value\":\"ã¾ã™\",\"position\":1,\"force_prefix_search\":true,\"metadata\":{\"reading\":\"ãƒã‚¹\"}}"}



*/
```





```
CREATE OR REPLACE FUNCTION "public"."ja_reading"(text)
  RETURNS "pg_catalog"."text" AS $BODY$
DECLARE
  js      JSON;
  total   TEXT[] := '{}';
  reading TEXT;
	s TEXT;
BEGIN
  FOREACH js IN ARRAY pgroonga_tokenize($1, 'tokenizer', 'TokenMecab("use_base_form", true, "include_reading", true)')
  LOOP
    
		FOREACH s IN ARRAY string_to_array($1, '|')
		LOOP
		
			RETURN s; 
		
		END LOOP;

		
		reading = (js -> 'metadata' ->> 'reading');

		-- total = total || (js ->> 'value');
		-- RETURN total || (js ->> 'value');
		
		-- RETURN total || (js ->> 'value');
		
		
		/*
    IF reading IS NULL THEN
      total = total || (js ->> 'value');
    ELSE
      total = total || reading;
    END IF;
		*/
  END LOOP;

  RETURN array_to_string(total, '');
END;
$BODY$
  LANGUAGE plpgsql IMMUTABLE
  COST 100
```







# JPQ



```mysql

CREATE OR REPLACE FUNCTION JPQ (TEXT) RETURNS TEXT AS
$func$
DECLARE
  js      JSON;
  total   TEXT[] := '{}';
  reading TEXT;
	s TEXT;
BEGIN
  FOREACH s IN ARRAY string_to_array($1, '|')
  LOOP
    
		FOREACH js IN ARRAY pgroonga_tokenize(s, 'tokenizer', 'TokenMecab("use_base_form", true, "include_reading", true)')
		LOOP
			reading = (js -> 'metadata' ->> 'reading');
			IF reading IS NULL THEN
					RETURN 0;
      END IF;
		
		END LOOP;
  END LOOP;
	
	RETURN 1;
	
END;
$func$ LANGUAGE plpgsql IMMUTABLE;
```





# push stream



```
# atuto run when reboot
chmod +x /etc/rc.d/rc.local
vi /etc/rc.d/rc.local
mount /dev/sda1 /mnt  # åŠ ä¸€å¥ï¼ŒæŒ‚è½½å­˜å‚¨å—
```





How to configure data directory in PostgreSQL 13

https://dsquarehelp.com/postgresql-13-data-directory/



åˆ©ç”¨Nginx WebDAVæ­å»ºè‡ªå·±çš„ç½‘ç›˜

https://www.cnblogs.com/DragonStart/p/13410090.html



è¯¦ç»†å‘½ä»¤

https://www.huaweicloud.com/articles/4a48bc251c6378d717caaf1f27acf1c4.html



NVIDIA FFmpeg è½¬ç æŒ‡å—

https://developer.nvidia.com/zh-cn/blog/nvidia-ffmpeg-transcoding-guide/



```
# ffmpeg on centos7
sudo yum install epel-release
sudo yum localinstall --nogpgcheck https://download1.rpmfusion.org/free/el/rpmfusion-free-release-7.noarch.rpm
sudo yum install ffmpeg ffmpeg-devel
```



```
# m3u8
https://yocoha.com/article/31
https://www.jianshu.com/p/e97f6555a070
https://zhuanlan.zhihu.com/p/147019759

```



```
# hls.js
https://zhuanlan.zhihu.com/p/158525554
https://segmentfault.com/a/1190000018503818 # å¹²è´§
https://blog.csdn.net/weixin_43029824/article/details/103391494 # æ›´å¹²è´§
```



```
# success
# hevc è¡¨ç¤ºä½¿ç”¨h.265 ç¼–ç 
ffmpeg -y -ss 00:01:12.960 -to 00:01:14.640  -i t.mkv  -codec:v hevc -acodec mp3 -ar 44100 -ac 2 -b:a 192k t.ts
```



```
# http://ffmpeg.org/ffmpeg-filters.html#subtitles

! ffmpeg -i t.mkv -y -ss 00:01:12.960 -to 00:01:14.640 -codec:v hevc -acodec mp3 -ar 44100 -ac 2 -b:a 192k -c:s mov_text t.ts # è½¯å­—æ…•


! ffmpeg -i t.mkv -y -ss 00:01:12.960 -to 00:01:14.640 -codec:v hevc_nvenc -acodec aac -ar 44100 -ac 2 -b:a 192k -vf subtitles=t.mkv t.ts # ç¡¬å­—å¹•


# jsmpeg.js æ­£å¸¸æ’­æ”¾
! ffmpeg -i t.mkv -y -ss 00:01:12.960 -to 00:01:14.640 -f mpegts -codec:v mpeg1video -b:v 1500k -s 960x540 -r 30 -bf 0 -codec:a mp2 -ar 44100 -ac 2 -b:a 192k -vf subtitles=t.mkv t.ts

# GPUåŠ é€Ÿ
! ffmpeg -c:v mpeg1_cuvid -i t.mkv -y -ss 00:01:12.960 -to 00:01:14.640 -f mpegts -codec:v mpeg1video -b:v 1500k -s 960x540 -r 30 -bf 0 -codec:a mp2 -ar 44100 -ac 2 -b:a 192k -vf subtitles=t.mkv t.ts
	# https://gist.github.com/garoto/54b46513fa893f48875a89bee0056d63
	! ffmpeg -decoders | grep cuvid

# showNV.sh
#/bin/bash
for i in encoders decoders filters; do
    echo $i:; ffmpeg -hide_banner -${i} | egrep -i "npp|cuvid|nvenc|cuda"
done
! chmod +x ./showNV.sh
! ./showNV.sh


# 960x540 

è¡Œ ffmpeg -i Tor_Animation_en.mp4 -i Tor_animation.zh-CN.srt Tor_Animation_subtitled.mkv çš„æ—¶å€™ï¼Œå°±ä¼šçœ‹åˆ°è¿™æ ·çš„è¾“å‡ºï¼š

Stream mapping:
  Stream #0:0 -> #0:0 (h264 (native) -> h264 (libx264))
  Stream #0:1 -> #0:1 (aac (native) -> vorbis (libvorbis))
  Stream #1:0 -> #0:2 (subrip (srt) -> ass (native))
å®ƒå¾ˆç›´è§‚åœ°å‘Šè¯‰æˆ‘ï¼Œåœ¨æœ¬æ¬¡æ“ä½œä¸­ï¼Œ 0 å·è¾“å…¥æ–‡ä»¶ï¼ˆä¹Ÿå°±æ˜¯ Tor_Animation_en.mp4 ï¼‰ä¸­çš„ 0 å·åª’ä½“æµå˜æˆäº† 0 å·è¾“å‡ºæ–‡ä»¶çš„ 0 å·åª’ä½“æµï¼Œ 0 å·è¾“å…¥æ–‡ä»¶ä¸­çš„ 1 å·åª’ä½“æµå˜æˆäº† 0 å·è¾“å‡ºæ–‡ä»¶çš„ 1 å·åª’ä½“æµï¼Œ 1 å·è¾“å…¥æ–‡ä»¶ï¼ˆä¹Ÿå°±æ˜¯ Tor_animation.zh-CN.srt ï¼‰çš„ 0 å·åª’ä½“æµå˜æˆäº† 0 å·è¾“å‡ºæ–‡ä»¶çš„ 2 å·åª’ä½“æµã€‚ç¼–ç çš„è½¬æ¢ä¹Ÿè¢«æ¸…æ™°åœ°æ˜¾ç¤ºäº†å‡ºæ¥ã€‚


å› ä¸ºå­—å¹•æµä¹Ÿæ˜¯åª’ä½“æµï¼Œä¹Ÿæœ‰å„ç§ç¼–ç ï¼Œæ‰€ä»¥ï¼Œæˆ‘ä»¬ä¹Ÿå¯ä»¥é€šè¿‡ -scodec æˆ– -c:s é€‰é¡¹æ¥æŒ‡å®šå­—å¹•æµçš„ç¼–ç ã€‚è¿™ä¸ªä¾‹å­å¯ä»¥è®© FFmpeg å¤åˆ¶è§†é¢‘æµå’ŒéŸ³é¢‘æµï¼ˆä¸ç”¨é‡æ–°ç¼–ç ï¼ŒåŠ å¿«äº†é€Ÿåº¦ï¼‰ï¼Œè€Œå°†å­—å¹•æµè½¬æ¢ä¸º ass ç¼–ç ï¼š

ffmpeg -i Tor_Animation_en.mp4 -i Tor_animation.zh-CN.srt -c:v copy -c:a copy -c:s ass Tor_Animation_subtitled.mkv
åŒæ ·çš„ï¼Œ -c é€‰é¡¹é™¤äº†ä¼šå½±å“åˆ°è§†é¢‘æµå’ŒéŸ³é¢‘æµä»¥å¤–ï¼Œä¹Ÿä¼šå½±å“åˆ°å­—å¹•æµï¼Œä¹Ÿå°±æ˜¯è¯´ï¼ŒæŒ‡å®š -c copy ä¹Ÿä¼šè®© FFmpeg ä¸å¯¹å­—å¹•æµè¿›è¡Œé‡æ–°ç¼–ç ã€‚

ä½ ç”šè‡³å¯ä»¥å°†å­—å¹•æ–‡ä»¶ä½œä¸ºå•ç‹¬çš„è¾“å…¥æ–‡ä»¶ï¼ä¹Ÿå°±æ˜¯å¯¹å­—å¹•æ–‡ä»¶è¿›è¡Œè½¬ç ï¼Œæ¯”å¦‚ ffmpeg -i Tor_animation.zh-CN.srt Tor_animation.zh-CN.ass å°±ä¼šå°† SubRip å­—å¹•è½¬æ¢ä¸º ASS å­—å¹•ã€‚ï¼ˆå› ä¸º ASS å°è£…æ ¼å¼çš„é»˜è®¤å­—å¹•ç¼–ç å°±æ˜¯ ass ï¼Œæ‰€ä»¥ä½ åœ¨è¿™æ¡å‘½ä»¤ä¸­ä¸ç”¨å†™ -c:s ass ï¼‰



åŸºäºå›¾åƒçš„å­—å¹•æ ¼å¼è¾“å…¥  ä½¿ç”¨è¦†ç›–æ»¤é•œã€‚æ­¤ç¤ºä¾‹å°†ç¬¬å››å­—å¹•æµè¦†ç›–åœ¨ç¬¬äºŒè§†é¢‘æµä¸Šï¼Œå¹¶å¤åˆ¶ç¬¬ä¸ƒéŸ³é¢‘æµï¼š
ffmpeg -i input.mkv -filter_complex "[0:v:2][0:s:3]overlay[v]" -map "[v]" -map 0:a:6 -c:a copy output.mp4

10.7 å†…åµŒå­—å¹•
åœ¨æ’­æ”¾å™¨ä¸æ”¯æŒç‹¬ç«‹å­—å¹•æµçš„åœºåˆï¼Œéœ€è¦å°†å­—å¹•æ··å…¥è§†é¢‘æµä¸­ï¼ˆå› æ­¤éœ€è¦é‡ç¼–ç ï¼‰ã€‚

ffmpeg -i input.mp4 -vf subtitles=input.srt output.mp4
å¦‚æœå­—å¹•ä»¥å­—å¹•æµçš„å½¢å¼ä½äºä¸€ä¸ªè§†é¢‘æ–‡ä»¶ä¸­ï¼Œå¯ä»¥ç›´æ¥è°ƒç”¨ï¼š
ffmpeg -i input.mkv -vf subtitles=input.mkv output.mp4

å¤„ç†æ–¹æ¡ˆ
è½¯å­—å¹•
MP4 æ ¼å¼æ”¯æŒæµæ–‡å­—æ ¼å¼å­—å¹•ï¼Œæ’­æ”¾æ—¶å¯åœ¨æ’­æ”¾å™¨ä¸­é€‰æ‹©å¯¹åº”çš„å­—å¹•ï¼Œä½†è¯¥è½¯å­—å¹•åŠŸèƒ½å¯èƒ½åœ¨æœ‰äº›æ’­æ”¾å™¨æˆ–è€…è®¾å¤‡ä¸Šä¸æ”¯æŒã€‚

1
ffmpeg -i input.mkv -map 0:v:0 -map 0:a:1 -map 0:s:34 -c:v copy -c:a copy -c:s mov_text -metadata:s:s:0 language=chs output.mp4
ç›¸å…³å‚æ•°:

-map é€‰é¡¹å¯å°†ä½ æƒ³é€‰æ‹©çš„åŸmkvæ–‡ä»¶ä¸­çš„è§†é¢‘æµ (v) /éŸ³é¢‘æµ (a) / å­—å¹•æµ (s) å¤åˆ¶åˆ°è¾“å‡ºä¸­ï¼›: åçš„æ•°å­—ä»£è¡¨åŸmkvæ–‡ä»¶ä¸­çš„ç¬¬å‡ ä¸ªæµï¼ˆmkv é‡Œæœ‰å¤šä¸ªéŸ³é¢‘æµ/å­—å¹•æµï¼‰ã€‚
æœ¬ä¾‹ä¸­é€‰æ‹©äº†ç¬¬0ä¸ªè§†é¢‘æµï¼ˆé»˜è®¤ï¼‰ï¼Œç¬¬1ä¸ªéŸ³é¢‘æµï¼Œç¬¬34ä¸ªå­—å¹•æµï¼ˆç®€ä½“ä¸­æ–‡ï¼‰ã€‚
-c é€‰é¡¹åˆ™ä»£ç¼–è§£ç å™¨åç§°ï¼Œ: åçš„ v/a/s æ„ä¹‰åŒä¸Šï¼›
åœ¨æœ¬ä¾‹ä¸­è§†é¢‘å’ŒéŸ³é¢‘çš„ç¼–è§£ç å™¨ç›´æ¥å¤åˆ¶çš„åŸè§†é¢‘éŸ³é¢‘æµçš„ç¼–ç å™¨ï¼Œæ‰€ä»¥ç¼–ç å™¨è®¾ç½®çš„ä¸º copy ã€‚
è€Œ mov_text åˆ™ä¸ºæ­¤ç±»è½¯å­—å¹•ç¼–ç å™¨
-metadata é€‰é¡¹å¯è®¾ç½®è§†é¢‘çš„å…ƒæ•°æ®ä¿¡æ¯ï¼Œä¹‹åçš„ :s:s:0 ä¸ºå¯é€‰é¡¹ï¼Œç©ºæ ¼ä¹‹åæ¥ä¸€ä¸ªè¦è®¾ç½®å…ƒä¿¡æ¯çš„é”®å€¼å¯¹ã€‚
æœ¬ä¾‹ä¸­çš„ :s:0 è¡¨ç¤ºå¯¹è¾“å‡ºæ–‡ä»¶ç¬¬0ä¸ªå­—å¹•æµè¿›è¡Œå…ƒä¿¡æ¯çš„è®¾ç½®ï¼Œå°†å­—å¹•æ ‡è¯†ä¸ºç®€ä½“ä¸­æ–‡ã€‚
å¦‚æœè¦è®¾ç½®ç¬¬0ä¸ªè§†é¢‘æµçš„å…ƒä¿¡æ¯ï¼Œåˆ™åœ¨ -metadata ä¹‹ååŠ  :s:a:0
å¤–æŒ‚å­—å¹•
å°´å°¬çš„æ˜¯ iOS ç‰ˆçš„æš´é£å½±éŸ³ä¸æ”¯æŒ mov_text ç¼–ç çš„è½¯å­—å¹•ï¼Œé‚£å°±åªèƒ½å°è¯•èƒ½ä¸èƒ½ç”¨å¤–æŒ‚å­—å¹•äº†ã€‚

ç›´æ¥é€šè¿‡ -map é€‰é¡¹å°†ç®€ä½“ä¸­æ–‡å­—å¹•æµå¯¼å‡ºåˆ° output.srt æ–‡ä»¶

1
ffmpeg -i input.mkv -map 0:s:34 output.srt
åœ¨æš´é£å½±éŸ³ä¸­é€‰æ‹©è¿™ä¸ª output.srt æ–‡ä»¶ï¼Œæ˜¾ç¤ºå‡ºæ¥å´æ˜¯ä¹±ç ï¼Œç„¶è€Œåœ¨ç”µè„‘ä¸Šçš„æ’­æ”¾å™¨ä¸Šå´ä¸€åˆ‡æ­£å¸¸ï¼Œè¿™æš´é£å½±éŸ³çœŸçš„æ˜¯ä¸è¡Œå•Šã€‚

ç¡¬å­—å¹•
å­—å¹•æ–‡ä»¶åµŒå…¥è§†é¢‘
å°†åˆšæ‰å¯¼å‡ºçš„ srt æ–‡ä»¶â€çƒ§å…¥â€åˆ°å…ˆå‰ç”Ÿæˆçš„é‚£ä¸ª output.mp4 æ–‡ä»¶ä¸­ï¼Œå› ä¸ºæ­¤å¤„è¦å¯¹æœ‰å­—å¹•çš„è§†é¢‘å¸§è¿›è¡Œå‹åˆ¶ï¼Œæ‰€ä»¥ä¼šæ¯”è¾ƒæ…¢ã€‚

1
ffmpeg -i output.mp4 -vf subtitles=output.srt output-Subtitles.mp4
-vf é€‰é¡¹ä»£è¡¨ä½¿ç”¨è§†é¢‘è¿‡æ»¤å™¨ (Video Filters)

subtitles å°±ä»£è¡¨è®¾ç½®å­—å¹•ä¸º = ä¹‹åæ¥çš„å­—å¹•æ–‡ä»¶ / æµ
å¦‚æœéœ€è¦åµŒå…¥çš„æ˜¯ ass æ ¼å¼çš„å­—å¹•ï¼Œåªéœ€è¦å°† subtitles æ›¿æ¢ä¸º ass ï¼Œç„¶å = ä¹‹åæ¥ä¸Š ass å­—å¹•æ–‡ä»¶å³å¯ï¼Œä¾‹å¦‚ ffmpeg -i output.mp4 -vf ass=subtitle.ass output-Subtitles.mp4
è¿™æ¬¡ç”Ÿæˆçš„ mp4 æ–‡ä»¶ç»ˆäºèƒ½åœ¨æš´é£å½±éŸ³é‡Œæ’­æ”¾äº†ï¼ŒçœŸæ˜¯å¤ŸæŠ˜è…¾çš„â€¦â€¦

è§†é¢‘å­—å¹•æµåµŒå…¥è§†é¢‘
ä½†æˆ‘ä¸æƒ³ç”Ÿæˆä¸­é—´çš„ srt å­—å¹•æ–‡ä»¶ï¼Œæˆ‘ä»¬å¯ä»¥ç›´æ¥å°† mkv çš„å­—å¹•æµåœ¨è½¬æˆ mp4 çš„æ—¶å€™ç›´æ¥å‹åˆ¶è¿›è§†é¢‘æ–‡ä»¶ä¸­

1
ffmpeg -i input.mkv -filter_complex "[0:v:0]subtitles=input.mkv:si=34[v]" -map "[v]" -map 0:a:0 -c:a copy output.mp4
æ­¤å¤„ä½¿ç”¨å¤æ‚å›¾åƒè¿‡æ»¤å™¨ (Complex filtergraphs) é€‰é¡¹ -filter_complex æ¥å¤„ç†è§†é¢‘ï¼Œå°†ç¬¬0ä¸ªè§†é¢‘æµåŠ ä¸Š input.mkv ä¸­çš„ç¬¬34ä¸ªå­—å¹•æµä¸€èµ·å‹åˆ¶åˆ°è§†é¢‘æµ v ä¸­ï¼ŒåŒæ—¶é€šè¿‡ -map é€‰é¡¹å°†ç¬¬0ä¸ªéŸ³é¢‘æµç›´æ¥å¯¼å‡ºåˆ° output.mp4 ä¸­ã€‚

è‡ªæ­¤ï¼Œåˆèƒ½å®Œç¾çš„åœ¨ iOS ç«¯çš„æš´é£å½±éŸ³ä¸Šæ„‰å¿«åœ°è¿½å‰§äº† d(`ï½¥âˆ€ï½¥)b

```



```
# CUDA åŠ é€Ÿ
ffmpeg -vsync 0 -hwaccel cuvid -c:v h264_cuvid -i input.mp4 -c:a copy -c:v h264_nvenc -b:v 5M output.mp4


å°†ä¸€å¼ å›¾ç‰‡å¾ªç¯20000æ¬¡ç”Ÿæˆè§†é¢‘ï¼Œä¸€ä¸ªæ˜¯ç¡¬ç¼–ç ä¸€ä¸ªæ˜¯è½¯ç¼–ç ï¼Œæ¯”è¾ƒå®ƒä»¬è¿è¡Œæ—¶é—´ã€‚
# time ./ffmpeg -f image2 -stream_loop 20000 -i 1.jpg -vcodec h264_nvenc -b:v 200k -r 10 -s 1920x1080 -y 2.mp4 
# time ./ffmpeg -f image2 -stream_loop 20000 -i 1.jpg -vcodec libx264 -b:v 200k -r 10 -s 1920x1080 -y 2.mp4 


  Duration: 00:23:30.01, start: 0.000000, bitrate: 1841 kb/s
    Stream #0:0: Video: h264 (High), yuv420p(tv, bt709, progressive), 1280x720 [SAR 1:1 DAR 16:9], 23.98 fps, 23.98 tbr, 1k tbn, 47.95 tbc (default)
    Stream #0:1(jpn): Audio: aac (LC), 48000 Hz, stereo, fltp (default)
    Stream #0:2(chi): Subtitle: ass (default)
```

```
# using libfaac on Mac OS X 10.6.8
# -vn : not copying video
# -acodec : specify codec used in flv file
# -ac : channels. 1 is for mono, 2 is for stereo
# -ab : specify bitrate for output file (note that rate is not kbps but bps)
# -ar : sampling frequency (Hz)
# -threads: number of threads for encoding
# "-strict experimental" is necessary to use libfaac

ffmpeg -y -i xxxxxxxxxxx.flv -vn -acodec aac -ac 2 -ab 128000 -ar 44100 -threads 4 -strict experimental xxxxx.m4a

# note that codec is 'libmp3lame'
ffmpeg -i xxxxxxxxxx.m4a -vn -acodec libmp3lame -ac 2 -ab 128 -ar 44100 -threads 4 -f mp3 zzzzzzzzzzz.mp3

# or you can directly convert audio track
ffmpeg -i xxxxxxxxxxx.flv -vn -acodec libmp3lame -ac 2 -ab 128000 -ar 44100 -threads 4 -f mp3  xxxxx.mp3

# for wav -acodec option is not necessary
ffmpeg -i xxxxxxxxxx.flv -vn -threads 4 -ac 1 -ar 44100 xxxxxx.wav

# for ogg
ffmpeg -i xxxxxxxxxx.flv -vn -threads 4 -acodec libvorbis -ac 2 -ar 44100 xxxxxxx.ogg

# simply extract audio without transcoding it.
ffmpeg -i xxxxxxxxxx -vn -threads 4 -acodec copy output.filename

# chop mp4 with/without transcoding
ffmpeg -ss <start.second> -i xxxxxx -t <duration.second> output.filename
ffmpeg -ss <start.second> -i xxxxxx -t <duration.second> -acodec copy -vcodec copy output.filename
```









![image-20210428171601026](postgresql summary.assets/image-20210428171601026.png)



```
ffmpeg -ss <start_time> -i video.mp4 -t <duration> -q:v 2 -vf select="eq(pict_type\,PICT_TYPE_I)" -vsync 0 frame%03d.jpg

ffmpeg -y -ss 00:01:12.960 -to 00:01:14.640 -i "F:\Downloads\[Kamigami] Danganronpa Kibou no Gakuen to Zetsubou no Koukousei The Animation [1280x720 x264 AAC MKV Sub(Chs,Jap)]\[Kamigami] Danganronpa Kibou no Gakuen to Zetsubou no ...he Animation - 01 [1280x720 x264 AAC Sub(Chs,Jap)].mkv" -r 1 -q:v 2 -f image2 -frames:v 1 snapshot.jpg




ffmpeg -y -ss 00:01:12.960 -to 00:01:14.640 -i "/Users/olnymyself/Downloads/[Kamigami] Danganronpa Kibou no Gakuen to Zetsubou no Koukousei The Animation - 01 [1280x720 x264 AAC Sub(Chs,Jap)].mkv" "frames/out-%03d.jpg"


# æˆåŠŸ
# https://www.cnblogs.com/jisongxie/p/9948845.html
ffmpeg -y -ss 00:01:12.960 -t 10 -i "/Users/olnymyself/Downloads/[Kamigami] Danganronpa Kibou no Gakuen to Zetsubou no Koukousei The Animation - 01 [1280x720 x264 AAC Sub(Chs,Jap)].mkv" -r 1 -q:v 2 -f image2 "frames/out-%03d.jpg"


```





```
ffmpeg -y -ss 00:01:12.960 -i "F:\Downloads\[Kamigami] Danganronpa Kibou no Gakuen to Zetsubou no Koukousei The Animation [1280x720 x264 AAC MKV Sub(Chs,Jap)]\[Kamigami] Danganronpa Kibou no Gakuen to Zetsubou no ...he Animation - 01 [1280x720 x264 AAC Sub(Chs,Jap)].mkv" -skip_frame nokey -frames:v 1 -q:v 2 output.jpg

For JPEG output use -q:v to control output quality. Full range is a linear scale of 1-31 where a lower value results in a higher quality. 2-5 is a good range to try.

# å‡ºé”™è§£å†³
https://www.reddit.com/r/ffmpeg/comments/lcttpl/deprecated_pixel_format_used_make_sure_you_did/ 

ffmpeg -i test.avi -y -f image2 -ss 00:00:00 -vframes 1 test.jpg
```





```
ffmpeg -i "[Kamigami] Danganronpa Kibou no Gakuen to Zetsubou no ...he Animation - 01 [1280x720 x264 AAC Sub(Chs,Jap)].mkv" -vn -ss 00:01:12.960 -to 00:01:14.640 -acodec mp3 -ar 44100 -ac 2 -b:a 192k ttttt.ts
```



```
psycopg2 returns the binary data (probably stored in a bytea column in your table) in a buffer object in Python 2, or in a memoryview in Python 3.

Both buffer and memoryview objects can be passed directly to a base64 string encoder, so this will encode the binary data in base 64:

import base64

rows = cur.fetchall()
binary_img = rows[0][0]
base64_img = base64.b64encode(binary_img)
In Python 2, if you want the binary data itself you can use str() or slice with [:] the buffer object. In Python 3 you can use the tobytes() method of the memoryview object.
```





```
# The adapter: converts from python to postgres
# note: this only works on numpy version whose arrays 
# support the buffer protocol,
# e.g. it works on 1.5.1 but not on 1.0.4 on my tests.

In [12]: def adapt_array(a):
  ....:     return psycopg2.Binary(a)
  ....:

In [13]: psycopg2.extensions.register_adapter(np.ndarray, adapt_array)


# The typecaster: from postgres to python

In [21]: def typecast_array(data, cur):
  ....:     if data is None: return None
  ....:     buf = psycopg2.BINARY(data, cur)
  ....:     return np.frombuffer(buf)
  ....:

In [24]: ARRAY = psycopg2.extensions.new_type(psycopg2.BINARY.values,
'ARRAY', typecast_array)

In [25]: psycopg2.extensions.register_type(ARRAY)


# Now it works "as expected"

In [26]: cur = cnn.cursor()

In [27]: cur.execute("select %s", (a,))

In [28]: cur.fetchone()[0]
Out[28]: array([ 1.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.])
```





```
https://my.oschina.net/u/4394125/blog/3310836

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Title</title>
    <script>
    </script>
</head>
<body>
	<audio controls="controls" autoplay="autoplay">
	<source src="http://127.0.0.1:12345/cgmedia/28181/getaudio?id=34020000001310000001@192.168.1.108:5060&format=mp3&transporttype=udp&transportport=22000" type="audio/mpeg">
	</audio>
</body>
</html>


@app.route('/audio')
def stream_mp3():
    def generate():
        path = 't.mp3'
        with open(path, 'rb') as fmp3:
            data = fmp3.read(1024)
            while data:
                yield data
                data = fmp3.read(1024)

    return Response(generate(), mimetype="audio/mpeg3")

# åœ¨audioæ ‡è®°ä¸­ï¼Œå¦‚æœä¸åŒ…å«controlså±æ€§ï¼Œåˆ™audioæ’­æ”¾å™¨å°†ä¸ä¼šå‘ˆç°åœ¨é¡µé¢ä¸Šã€‚
# <img src="{{ url_for('static', filename='foo.jpg') }}">
# åœ¨ Python è„šæœ¬é‡Œï¼Œurl_for() å‡½æ•°éœ€è¦ä» flask åŒ…ä¸­å¯¼å…¥ï¼Œè€Œåœ¨æ¨¡æ¿ä¸­åˆ™å¯ä»¥ç›´æ¥ä½¿ç”¨ï¼Œå› ä¸º Flask æŠŠä¸€äº›å¸¸ç”¨çš„å‡½æ•°å’Œå¯¹è±¡æ·»åŠ åˆ°äº†æ¨¡æ¿ä¸Šä¸‹æ–‡ï¼ˆç¯å¢ƒï¼‰é‡Œã€‚
# url_for('.static',_external=True,filename='pic/test.png') # å®Œæ•´url
# https://zhuanlan.zhihu.com/p/67747626 è®© Flask æ¨¡æ¿å¼•æ“ Jinja2 å’Œ JavaScript æ¨¡æ¿å¼•æ“å’Œå¹³å…±å­˜
{% raw %}
<div id="app">
    {{ js_var }}
</div>
{% endraw %}

{{ url_for('test',name=1) }} ç›¸å½“äºæˆ‘ä»¬ä¼ é€’çš„XXX/?name=1 
@app.route('/test/<name>', methods=['GET'])
def test(name):

URLä¸­ä¼ å‚
å¯ä»¥ä½¿ç”¨Flask requestæ–¹æ³•ï¼šrequest.args.get()ï¼Œä¾‹å¦‚ï¼Œå‰å°è¯·æ±‚URLä¸º http://localhost:5000/tk?p=1&type=1
@app.route('/tk', methods=['post','get'])
def tk():
    p = request.args.get('p')
    type = request.args.get('type')

https://www.zhangxinxu.com/wordpress/2019/07/html-audio-api-guide/
HTML audioåŸºç¡€APIå®Œå…¨ä½¿ç”¨æŒ‡å—

è¿æ¥æ± 
https://pynative.com/psycopg2-python-postgresql-connection-pooling/

Python psycopg2 mogrify
The mogrify is a psycopg2 extension to the Python DB API that returns a query string after arguments binding. The returned string is exactly the one that would be sent to the database running the execute() method or similar.
 print(cur.mogrify("SELECT name, price FROM cars WHERE id=%s", (2,)))

# Binary
https://zetcode.com/python/psycopg2/
CREATE TABLE images(id SERIAL PRIMARY KEY, data BYTEA);
create table a(a bytea);
create unique index a_bytea_unique_hash on a (md5(a)); # md5 å”¯ä¸€ç´¢å¼•


INSERT INTO test_table  
VALUES(1, pg_read_binary_file('/path/to/file')::bytea); 

    cur = con.cursor()
    data = readImage()
    binary = psycopg2.Binary(data)
    cur.execute("INSERT INTO images(data) VALUES (%s)", (binary,))

    con.commit()




CREATE TABLE btable (bvalue bytea);
INSERT INTO btable (bvalue) values(decode(â€˜%sâ€™,â€™base64â€²));
SELECT encode(bvalue,â€™base64â€²) FROM btable;


def writeImage(data):

    fout = None

    try:
        fout = open('sid2.jpg', 'wb')
        fout.write(data)

    except IOError as e:

        print(f"Error {0}")
        sys.exit(1)

    finally:

        if fout:
            fout.close()


try:
    con = psycopg2.connect(database='testdb', user='postgres',
                    password='s$cret')

    cur = con.cursor()
    cur.execute("SELECT data FROM images LIMIT 1")
    data = cur.fetchone()[0]

    writeImage(data)


<td width="15%" align="center" valign="middle" style="border:1px solid #999;"><audio id="fayint99" src="/sound/mp3/ngo5.mp3" preload="preload"> <font color="#FF0000">æ‚¨çš„æµè§ˆå™¨ä¸æ”¯æŒæ­¤å‘éŸ³ã€‚</font> </audio>
<img src="images/pc_fayin.gif" alt="ç‚¹å‡»å‘éŸ³" onclick="fyint99()" style=" cursor: pointer">
<script type="text/javascript">
<!--
var fyt99=document.getElementById("fayint99");
function fyint99()
{
if (fyt99.paused)
fyt99.play();
else
fyt99.pause();
}
//-->
</script>
</td>

```



```

# http://codingsky.com/doc/day/2018-06-10/12141.html
åŠ¨æ€JPEGæµä¼ è¾“ï¼š

    #!/usr/bin/env python
    from flask import Flask, render_template, Response
    from camera import Camera

    app = Flask(__name__)

    @app.route('/')
    def index():  
      return render_template('index.html')

    def gen(camera):
      while True:
        frame = camera.get_frame()
        yield (b'--framern'
            b'Content-Type: image/jpegrnrn' + frame + b'rn')

    @app.route('/video_feed')
    def video_feed():
      return Response(gen(Camera()),
              mimetype='multipart/x-mixed-replace; boundary=frame')

    if __name__ == '__main__':
      app.run(host='0.0.0.0', debug=True)
è¿™ä¸ªåº”ç”¨å¯¼å…¥ä¸€ä¸ªCameraç±»æ¥è´Ÿè´£æä¾›å¸§åºåˆ—ã€‚åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œå°†cameraæ§åˆ¶éƒ¨åˆ†æ”¾å…¥ä¸€ä¸ªå•ç‹¬çš„æ¨¡å—æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„ä¸»æ„ã€‚è¿™æ ·ï¼ŒWebåº”ç”¨ä¼šä¿æŒå¹²å‡€ã€ç®€å•å’Œé€šç”¨ã€‚

è¯¥åº”ç”¨æœ‰ä¸¤ä¸ªè·¯ç”±ï¼ˆrouteï¼‰ã€‚/è·¯ç”±ä¸ºä¸»é¡µæœåŠ¡ï¼Œè¢«å®šä¹‰åœ¨index.htmlæ¨¡æ¿ä¸­ã€‚ä¸‹é¢ä½ èƒ½çœ‹åˆ°è¿™ä¸ªæ¨¡æ¿æ–‡ä»¶ä¸­çš„å†…å®¹ï¼š



    <html>
     <head>
      <title>Video Streaming Demonstration</title>
     </head>
     <body>
      <h1>Video Streaming Demonstration</h1>
      <img src="{{ url_for('video_feed') }}">
     </body>
    </html>
```



```
# jquery
https://blog.csdn.net/l333f/article/details/60877276

# flask blog
https://github.com/zengxuanlin/my_blog

```



```
# auto play
<script type="text/javascript">
    window.onload = function(){
             setInterval("toggleSound()",100);
        }

    function toggleSound() {
                var music = document.getElementById("vd");//è·å–ID  
                    
                if (music.paused) { //åˆ¤è¯»æ˜¯å¦æ’­æ”¾  
                    music.paused=false;
                    music.play(); //æ²¡æœ‰å°±æ’­æ”¾ 
                }    
        }
</script>
```







```
ffmpeg -i input.wav -vn -ar 44100 -ac 2 -b:a 192k output.mp3
Explanation of the used arguments in this example:

-i - input file

-vn - Disable video, to make sure no video (including album cover image) is included if the source would be a video file

-ar - Set the audio sampling frequency. For output streams it is set by default to the frequency of the corresponding input stream. For input streams this option only makes sense for audio grabbing devices and raw demuxers and is mapped to the corresponding demuxer options.

-ac - Set the number of audio channels. For output streams it is set by default to the number of input audio channels. For input streams this option only makes sense for audio grabbing devices and raw demuxers and is mapped to the corresponding demuxer options. So used here to make sure it is stereo (2 channels)

-b:a - Converts the audio bitrate to be exact 192kbit per second
```







```
ffmpeg -i -ss 0 -t 00:01:00
```



```
with -t which specifies the duration, like -ss 60 -t 10 to capture from second 60 to 70

```



## insert bytea



```
# å·²æœ‰ç«¯å£æ˜ å°„
iptables -t nat -vnL DOCKER
```

```
yum install openssh-server -y
vi /etc/ssh/sshd_config
	é…ç½®å¹¶ä¿å­˜ï¼šPermitRootLogin yes    UsePAM no
systemctl start sshd
exit (CTRL + P, CTRL + Q)
```



```
sftp root@172.17.0.2
ls lls pwd llpwd
put t.mp3 .
exit

ssh root@172.17.0.2
```



```
cp t.mp3 /var/lib/pgsql
su - postgres
psql
CREATE TABLE audio(id SERIAL PRIMARY KEY, data BYTEA);
INSERT INTO audio(data) VALUES(pg_read_binary_file('/var/lib/pgsql/t.mp3')::bytea);
```



### insert from psycopg2

```
binary = psycopg2.Binary(data)
cur.execute("INSERT INTO images(data) VALUES (%s)", (binary,))
```



### time out

```
psycopg2.connect( dbname = databaseName, user = userName, host = hostName, port = 5432, connect_timeout = 5, options='-c statement_timeout=5000')
```

### è‡ªåŠ¨é‡è¿

```
https://github.com/psycopg/psycopg2/issues/419
```









INSERT INTO test_table  

VALUES(1, pg_read_binary_file('/path/to/file')::bytea);



### é«˜ç«¯æ“ä½œ

https://bbengfort.github.io/2017/12/psycopg2-transactions/



## Cutting small sections

To extract only a small segment in the middle of a movie, it can be used in combination with `-t` which specifies the duration, like `-ss 60 -t 10` to capture from second 60 to 70. Or you can use the `-to` option to specify an out point, like `-ss 60 -to 70` to capture from second 60 to 70. `-t` and `-to` are mutually exclusive. If you use both, `-t` will be used.

Note that if you specify `-ss` before `-i` only, the timestamps will be reset to zero, so `-t` and `-to` will have the same effect. If you want to keep the original timestamps, add the `-copyts` option.

The first command will cut from 00:01:00 to 00:03:00 (in the original), using the faster seek.
The second command will cut from 00:01:00 to 00:02:00, as intended, using the slower seek.
The third command will cut from 00:01:00 to 00:02:00, as intended, using the faster seek.

```
ffmpeg -ss 00:01:00 -i video.mp4 -to 00:02:00 -c copy cut.mp4
ffmpeg -i video.mp4 -ss 00:01:00 -to 00:02:00 -c copy cut.mp4
ffmpeg -ss 00:01:00 -i video.mp4 -to 00:02:00 -c copy -copyts cut.mp4
```

If you cut with stream copy (`-c copy`) you need to use the [-avoid_negative_ts 1](https://ffmpeg.org/ffmpeg-all.html#Format-Options) option if you want to use that segment with the [concat demuxer](https://trac.ffmpeg.org/wiki/How to concatenate (join, merge) media files#demuxer) .

Example:

```
ffmpeg -ss 00:03:00 -i video.mp4 -t 60 -c copy -avoid_negative_ts 1 cut.mp4
```

If you have to re-encode anyway, e.g., to apply filters like [afade](https://trac.ffmpeg.org/wiki/AfadeCurves), which can be very slow, make sure to use, e.g., `-ss 120 -i some.mov -to 60` to get one minute from 120s to 120+60s, not `-to 180` for three minutes starting at 120s.



```
# show info
ffprobe xxx.mp4

â€œ-anâ€ï¼ˆno audioï¼‰å’Œâ€œ-vnâ€ï¼ˆno videoï¼‰
ffmpeg -i "F:\Downloads\[Kamigami] Danganronpa Kibou no Gakuen to Zetsubou no Koukousei The Animation [1280x720 x264 AAC MKV Sub(Chs,Jap)]\[Kamigami] Danganronpa Kibou no Gakuen to Zetsubou no ...he Animation - 01 [1280x720 x264 AAC Sub(Chs,Jap)].mkv" -vn -acodec copy -ss 0 -t 00:01:00 ttttttttt.ts

ffmpeg -i "F:\Downloads\[Kamigami] Danganronpa Kibou no Gakuen to Zetsubou no Koukousei The Animation [1280x720 x264 AAC MKV Sub(Chs,Jap)]\[Kamigami] Danganronpa Kibou no Gakuen to Zetsubou no ...he Animation - 01 [1280x720 x264 AAC Sub(Chs,Jap)].mkv" -vn -acodec copy -ss 00:01:12.960 -to 00:01:14.640 ttttttttt.ts

00:01:12,960 --> 00:01:14,640


ffmpeg -i test.mp4 -codec copy -bsf h264_mp4toannexb test.ts
```





```
/usr/local/ffmpeg/bin/ffmpeg -ss START Â -t LENGTHÂ -i INPUTFILE Â -vcodec copy -acodec copy OUTFILE

00:01:00 é•¿åº¦1åˆ†é’Ÿ
/usr/local/ffmpeg/bin/ffmpeg -ss 0 -t 00:01:00 -i movie.mp4Â  -vcodec copy -acodec copy movie-1.mp4

```





```
https://it3q.com/article/59

```



```
ä»Šå¤©è€ƒè™‘ä¸€ä¸ªmcuæ··åˆçš„å®ç°ï¼Œä¹Ÿå°±æ˜¯æ¥æ”¶å¤šè·¯è¿‡æ¥çš„rtpæµï¼Œç„¶åè½¬å‘å‡ºå»ä¸€è·¯çš„rtmpæµï¼Œä½¿ç”¨ffmpegæµ‹è¯•åšçš„è®°å½•ï¼Œåˆšå¼€å§‹ä¸€ç›´é€šè¿‡ffmpegæ¨é€çš„æ–‡ä»¶æµä¸èƒ½æ»¡è¶³è¦æ±‚ï¼Œè¿˜æ˜¯å¯¹å‚æ•°é…ç½®ä¸ç†Ÿæ‚‰ï¼›



0ã€ffmpeg å‘½ä»¤æ ¼å¼ï¼š

$ ffmpeg \

-y \ # å…¨å±€å‚æ•°

-c:a libfdk_aac -c:v libx264 \ # è¾“å…¥æ–‡ä»¶å‚æ•°

-i input.mp4 \ # è¾“å…¥æ–‡ä»¶

-c:v libvpx-vp9 -c:a libvorbis \ # è¾“å‡ºæ–‡ä»¶å‚æ•°

output.webm # è¾“å‡ºæ–‡ä»¶



ä¸‹åˆ—ä¸ºè¾ƒå¸¸ä½¿ç”¨çš„å‚æ•°ï¼š

 

-iâ€”â€”è®¾ç½®è¾“å…¥æ–‡ä»¶åã€‚

-fâ€”â€”è®¾ç½®è¾“å‡ºæ ¼å¼ã€‚

-yâ€”â€”è‹¥è¾“å‡ºæ–‡ä»¶å·²å­˜åœ¨æ—¶åˆ™è¦†ç›–æ–‡ä»¶ã€‚

-fsâ€”â€”è¶…è¿‡æŒ‡å®šçš„æ–‡ä»¶å¤§å°æ—¶åˆ™ç»“æŸè½¬æ¢ã€‚

-tâ€”â€”æŒ‡å®šè¾“å‡ºæ–‡ä»¶çš„æŒç»­æ—¶é—´ï¼Œä»¥ç§’ä¸ºå•ä½ã€‚

-ssâ€”â€”ä»æŒ‡å®šæ—¶é—´å¼€å§‹è½¬æ¢ï¼Œä»¥ç§’ä¸ºå•ä½ã€‚

-tä»-ssæ—¶é—´å¼€å§‹è½¬æ¢ï¼ˆå¦‚-ss 00:00:01.00 -t 00:00:10.00å³ä»00:00:01.00å¼€å§‹åˆ°00:00:11.00ï¼‰ã€‚

-titleâ€”â€”è®¾ç½®æ ‡é¢˜ã€‚

-timestampâ€”â€”è®¾ç½®æ—¶é—´æˆ³ã€‚

-vsyncâ€”â€”å¢å‡Frameä½¿å½±éŸ³åŒæ­¥ã€‚

-câ€”â€”æŒ‡å®šè¾“å‡ºæ–‡ä»¶çš„ç¼–ç ã€‚

-metadataâ€”â€”æ›´æ”¹è¾“å‡ºæ–‡ä»¶çš„å…ƒæ•°æ®ã€‚

-helpâ€”â€”æŸ¥çœ‹å¸®åŠ©ä¿¡æ¯

å½±åƒå‚æ•°ï¼š

-b:vâ€”â€”è®¾ç½®å½±åƒæµé‡ï¼Œé»˜è®¤ä¸º200Kbit/ç§’ã€‚ï¼ˆå•ä½è¯·å¼•ç”¨ä¸‹æ–¹æ³¨æ„äº‹é¡¹ï¼‰

-râ€”â€”è®¾ç½®å¸§ç‡å€¼ï¼Œé»˜è®¤ä¸º25ã€‚

-sâ€”â€”è®¾ç½®ç”»é¢çš„å®½ä¸é«˜ã€‚

-aspectâ€”â€”è®¾ç½®ç”»é¢çš„æ¯”ä¾‹ã€‚

-vnâ€”â€”ä¸å¤„ç†å½±åƒï¼Œäºä»…é’ˆå¯¹å£°éŸ³åšå¤„ç†æ—¶ä½¿ç”¨ã€‚

-vcodec( -c:v )â€”â€”è®¾ç½®å½±åƒå½±åƒç¼–è§£ç å™¨ï¼Œæœªè®¾ç½®æ—¶åˆ™ä½¿ç”¨ä¸è¾“å…¥æ–‡ä»¶ç›¸åŒä¹‹ç¼–è§£ç å™¨ã€‚

å£°éŸ³å‚æ•°ï¼š

-b:aâ€”â€”è®¾ç½®æ¯Channelï¼ˆæœ€è¿‘çš„SVNç‰ˆä¸ºæ‰€æœ‰Channelçš„æ€»åˆï¼‰çš„æµé‡ã€‚ï¼ˆå•ä½è¯·å¼•ç”¨ä¸‹æ–¹æ³¨æ„äº‹é¡¹ï¼‰

-arâ€”â€”è®¾ç½®é‡‡æ ·ç‡ã€‚

-acâ€”â€”è®¾ç½®å£°éŸ³çš„Channelæ•°ã€‚

-acodec ( -c:a ) â€”â€”è®¾ç½®å£°éŸ³ç¼–è§£ç å™¨ï¼Œæœªè®¾ç½®æ—¶ä¸å½±åƒç›¸åŒï¼Œä½¿ç”¨ä¸è¾“å…¥æ–‡ä»¶ç›¸åŒä¹‹ç¼–è§£ç å™¨ã€‚

-anâ€”â€”ä¸å¤„ç†å£°éŸ³ï¼Œäºä»…é’ˆå¯¹å½±åƒåšå¤„ç†æ—¶ä½¿ç”¨ã€‚

-volâ€”â€”è®¾ç½®éŸ³é‡å¤§å°ï¼Œ256ä¸ºæ ‡å‡†éŸ³é‡ã€‚ï¼ˆè¦è®¾ç½®æˆä¸¤å€éŸ³é‡æ—¶åˆ™è¾“å…¥512ï¼Œä¾æ­¤ç±»æ¨ã€‚ï¼‰

-presetï¼šæŒ‡å®šè¾“å‡ºçš„è§†é¢‘è´¨é‡ï¼Œä¼šå½±å“æ–‡ä»¶çš„ç”Ÿæˆé€Ÿåº¦ï¼Œæœ‰ä»¥ä¸‹å‡ ä¸ªå¯ç”¨çš„å€¼ ultrafast, superfast, veryfast, faster, fast, medium, slow, slower, veryslowã€‚ 



1ã€udpæˆ–è€…rtpæ¨æµ

>æœ€ç®€å•æ¨¡å¼ï¼š

ffmpeg -re -i d:\videos\1080P.264 -vcodec copy -f rtp rtp://127.0.0.1:1234

ffplayæ¥æ”¶ç«¯çš„å‘½ä»¤ï¼š

ffplay -protocol_whitelist "file,udp,rtp" -i rtp://127.0.0.1:1234



>å¤æ‚æ¨¡å¼ï¼Œå†³å®šrtpåŒ…å°è£…å¤§å°ï¼Œå°è£…æ ¼å¼ï¼Œå†³å®šIå¸§é—´éš”

ffmpeg -re -i tuiliu_mp4.mp4 -vcodec libx264 -b:v 800k -s 480x320   -preset:v ultrafast -tune:v zerolatency   -an -f rtp  -profile baseline  -rtpflags h264_mode0 -pkt_size 1460 -slice-max-size 1400 -maxrate 600k -minrate 600k  -r 20 -g 20 -keyint_min 20   -an -f rtp rtp://11.12.112.42:49196

å…³é”®å‘½ä»¤å‚æ•°è¯´æ˜ï¼š

-reä¸€å®šè¦åŠ ï¼Œä»£è¡¨æŒ‰ç…§å¸§ç‡å‘é€

-i url (input)   è¾“å…¥æ–‡ä»¶è·¯å¾„æˆ–è€… url

-vcodec libx264 ï¼Œè¡¨ç¤ºä½¿ç”¨x264é‡æ–°ç¼–ç 

-b:v 800k  ç ç‡è®¾ç½®

-s 480x320   åˆ†è¾¨ç‡è®¾ç½®

-preset:v ultrafast    å¼€å¯x264çš„ -preset fast/faster/verfast/superfast/ultrafastå‚æ•°

-tune:v zerolatency   å³æ—¶ç¼–ç ï¼Œå»æ‰ç¼–ç å»¶è¿Ÿ

-profile: è®¾ç½®ç¼–ç ç­‰çº§ï¼Œbaseline, main, high 

-payload_type ï¼šrtpçš„ptå€¼

-pkt_sizeï¼šrtpå‘é€çš„æœ€å¤§é•¿åº¦

-slice-max-sizeï¼šä¸€ä¸ªnulaåŒ…æ•°æ®çš„æœ€å¤§é•¿åº¦

-rtpflags h264_mode0  rtpæ‰“åŒ…æ¨¡å¼ packetizition-mode=0ï¼Œ å½“ packetization-mode çš„å€¼ä¸º 0 æ—¶æˆ–ä¸å­˜åœ¨æ—¶, å¿…é¡»ä½¿ç”¨å•ä¸€ NALU å•å…ƒæ¨¡å¼.ï¼›å½“ packetization-mode çš„å€¼ä¸º 1 æ—¶å¿…é¡»ä½¿ç”¨éäº¤é”™(non-interleaved)å°åŒ…æ¨¡å¼.ï¼›å½“ packetization-mode çš„å€¼ä¸º 2 æ—¶å¿…é¡»ä½¿ç”¨äº¤é”™(interleaved)å°åŒ…æ¨¡å¼.

-pkt_size 1460 

-slice-max-size 1400 

-maxrate 600k 

-minrate 600k  (å¯ä»¥ä½¿ç”¨ -crf 24æ›¿æ¢ï¼Œæ§åˆ¶è§†é¢‘ç ç‡å’Œè´¨é‡çš„å‡è¡¡)

-r 20  è®¾ç½®å¸§ç‡ä¸º20å¸§/s

-g 20 GOPé—´éš”ï¼Œæ¯éš”20ä¸ªå¸§ä¸ºä¸€ä¸ªGOPï¼Œä¸¤ä¸ªå…³é”®å¸§ä¹‹é—´çš„å¸§æ•°ç§°ä¸ºä¸€ä¸ªGOPï¼Œå°†å…³é”®å¸§å¸§é—´éš”è®¾ç½®ä¸º1s,ä¹Ÿå°±æ˜¯æ¯ç§’ä¸€ä¸ªå…³é”®å¸§

-keyint_min 20   æœ€å°å…³é”®å¸§é—´éš” 

-an æ²¡æœ‰éŸ³é¢‘ï¼Œâ€œ-anâ€ï¼ˆno audioï¼‰å’Œâ€œ-vnâ€ï¼ˆno videoï¼‰åˆ†åˆ«ç”¨æ¥å•ç‹¬è¾“å‡ºè§†é¢‘å’ŒéŸ³é¢‘

-f:rtp å¼ºåˆ¶ffmpegé‡‡ç”¨æŸç§æ ¼å¼ï¼Œåè·Ÿå¯¹åº”çš„æ ¼å¼ã€‚



> ä½¿ç”¨RTPåˆ†åˆ«å‘é€éŸ³é¢‘æµå’Œè§†é¢‘æµ

FFmpegå‘½ä»¤ï¼š

ffmpeg  -re -i <media_file> -an -vcodec copy -f rtp rtp://<IP>:5004 -vn -acodec copy -f rtp rtp://<IP>:5005 > test.sdp



FFplayæ¥æ”¶çš„SDPæ–‡ä»¶ï¼š

SDP:
v=2 
m=video 5004 RTP/AVP 96
a=rtpmap:96 H264
t=0 0 
a=framerate:25
c=IN IP4 192.168.0.100
  
m=audio 5005 RTP/AVP 97
a=rtpmap:97 PCM/8000/1
a=framerate:25
c=IN IP4 192.168.0.100

2ã€rtspæ¨æµ

ffmpeg -re -i /root/mp4/1.mp4 -vcodec copy -acodec copy  -rtsp_transport tcp -f rtsp rtsp://192.168.2.161/live/rtsp_test

-rtsp_transport tcp æ ‡è¯†ä½¿ç”¨tcpä½œä¸ºrtpçš„é€šé“



3ã€rtmpæ¨æµ 

ffmpeg -re -i /root/mp4/1.flv -vcodec copy -acodec copy -f flv rtmp://192.168.2.161/live/rtsp_test



ä¿®æ”¹-iå‚æ•°ä¸ºrtspçš„åœ°å€ï¼Œå¯ä»¥æ‹‰ç›‘æ§æµç„¶åè½¬å‘ä¸ºrtmpæµï¼š

ffmpeg -f rtsp -i rtsp://admin:xdddd1998@11.12.112.249:554/h264/ch1/sub/av_stream -vcodec libx264 -b:v 800k -s 480x320 -preset:v ultrafast -tune:v zerolatency   -an -f rtp  -profile baseline  -rtpflags h264_mode0 -pkt_size 1460 -slice-max-size 1400 -maxrate 600k -minrate 600k -g 20 -keyint_min 20  -y rtp://11.12.112.42:62159



4ã€ffmpegåˆ‡ç‰‡ï¼Œå¾ˆå¤šäººä¼šé—®ï¼Œç›´æ¥æ’­æ”¾mp4ä¸å°±å¥½äº†ä¹ˆï¼Œä¸ºä»€ä¹ˆè¦åˆ‡ç‰‡å†æ’­æ”¾ï¼Ÿ

å¦‚æœæ˜¯MP4æ–‡ä»¶ï¼Œéœ€è¦å…ˆå®Œæ•´çš„ä¸‹è½½æ ¼å¼ä¸º mp4 çš„è§†é¢‘æ–‡ä»¶ï¼Œå½“è§†é¢‘æ–‡ä»¶ä¸‹è½½å®Œæˆåï¼Œç½‘ç«™æ‰å¯ä»¥æ’­æ”¾è¯¥è§†é¢‘ï¼Œè¿™å°±å¯¹äºç”¨æˆ·ä½“éªŒæ˜¯æå¤§çš„ä¸‹é™ï¼Œæ‰€ä»¥éœ€è¦åˆ‡ç‰‡ä¸ºå¤šä¸ªtsæ–‡ä»¶ï¼Œä»¥åŠm3u8æ–‡ä»¶ï¼Œm3u8æ ¼å¼çš„è§†é¢‘æ˜¯å°†æ–‡ä»¶åˆ†æˆä¸€å°æ®µä¸€å°æ®µçš„tsæ–‡ä»¶ï¼Œæ’­æ”¾å®Œä¸€ä¸ªåœ¨æ’­æ”¾ä¸‹ä¸€ä¸ªï¼Œç”±äºæ¯æ¬¡è¯·æ±‚çš„tsæ–‡ä»¶éƒ½å¾ˆå°ï¼Œæ‰€ä»¥åŸºæœ¬å¯ä»¥åšåˆ°æ— å»¶æ—¶æ’­æ”¾ï¼š

åˆ‡ç‰‡mp4è§†é¢‘æ–‡ä»¶ï¼š

ffmpeg -i ./video.mp4 -c:v libx264 -hls_time 60 -hls_list_size 0 -c:a aac -strict -2 -f hls ./video.m3u8



åˆ‡ç‰‡mp3éŸ³é¢‘æ–‡ä»¶ï¼š

ffmpeg -i ./kczfrr.mp3 -c:a libmp3lame -map 0:0 -f segment -segment_time 10 -segment_list ./kczfrr.m3u8



webé¡µé¢æ’­æ”¾m3u8ï¼Œä¸€æ–¹é¢å¯ä»¥ä½¿ç”¨è…¾è®¯çš„jsæ’ä»¶ï¼Œå¦ä¸€æ–¹é¢å°±æ˜¯ä½¿ç”¨video.jsçš„æ’ä»¶:

å¼•å…¥ç›¸å…³èµ„æº
    <link href="https://cdn.bootcss.com/video.js/6.3.3/video-js.min.css" rel="stylesheet">
    <script src="https://cdn.bootcss.com/video.js/6.3.3/video.min.js"></script>
    <script src="https://cdn.bootcss.com/videojs-contrib-hls/5.11.0/videojs-contrib-hls.js"></script>
    <!â€“[if lt IE 9]>
    <script type="text/javascript" src="http://cdn.static.runoob.com/libs/html5shiv/3.7/html5shiv.min.js"></script>
    <![endif]â€“>
è¯´æ˜ï¼š
 
video-js.min.css æ˜¯æ’­æ”¾å™¨çš„ä¸»é¢˜æ ·å¼
video.min.js æ˜¯video.jsçš„æ ¸å¿ƒä»£ç 
videojs-contrib-hls.js ç”¨äºæ”¯æŒHLSçš„åº“æ–‡ä»¶
html5shiv.min.js ç”±äºvideo.jsæ˜¯åŸºäºH5æ„å»ºçš„æ’­æ”¾å™¨ï¼Œæ‰€ä»¥åœ¨æµè§ˆå™¨ä¸æ”¯æŒH5çš„æ—¶å€™ï¼Œéœ€è¦å°†ç›¸å…³èµ„æºå¼•å…¥åˆ°æµè§ˆå™¨
æ”¾ç½®æ’­æ”¾å™¨æ§ä»¶
<video  id="myVideo"  class="video-js vjs-default-skin vjs-big-play-centered"  width="400"
        controls="controls" autoplay="autoplay"
       x-webkit-airplay="true" x5-video-player-fullscreen="true"
       preload="auto" playsinline="true" webkit-playsinline
       x5-video-player-typ="h5">
    <source type="application/x-mpegURL" src="https://cn4.creativemas.cn/ppvod/DD7AB8D25F6AD21E4291775FEAC1F710.m3u8">
</video>
è¯´æ˜ï¼š
 
è¯¥æ§ä»¶ä¸­ç”¨äºæ’­æ”¾ä¸€ä¸ªç½‘ç»œä¸Šæ‰¾çš„m3u8çš„è§†é¢‘èµ„æº
ç»™æ§ä»¶ä¸€ä¸ªidä¸»è¦æ–¹ä¾¿video.jsè·å–æ§ä»¶å¯¹è±¡
ä½¿ç”¨video.js
<script>
    // videojs ç®€å•ä½¿ç”¨
    var myVideo = videojs('myVideo',{
        bigPlayButton : true,
        textTrackDisplay : false,
        posterImage: false,
        errorDisplay : false,
    })
    myVideo.play() // è§†é¢‘æ’­æ”¾
    myVideo.pause() // è§†é¢‘æš‚åœ
</script>


5ã€åˆå¹¶éŸ³è§†é¢‘

åˆå¹¶è§†é¢‘å’ŒéŸ³é¢‘
1ã€ç›´æ¥åˆå¹¶
è§†é¢‘æ–‡ä»¶ä¸­æ²¡æœ‰éŸ³é¢‘
ffmpeg -i video.mp4 -i audio.wav -c:v copy -c:a aac -strict experimental output.mp4video.mp4,audio.wavåˆ†åˆ«æ˜¯è¦åˆå¹¶çš„è§†é¢‘å’ŒéŸ³é¢‘ï¼Œoutput.mp4æ˜¯åˆå¹¶åè¾“å‡ºçš„éŸ³è§†é¢‘æ–‡ä»¶ã€‚
 
ä¸‹é¢çš„å‘½ä»¤æ˜¯ç”¨audioéŸ³é¢‘æ›¿æ¢videoä¸­çš„éŸ³é¢‘ffmpeg -i video.mp4 -i audio.wav -c:v copy -c:a aac -strict experimental -map 0:v:0 -map 1:a:0 output.mp4
 
2ã€å…ˆæå–è§†é¢‘ä¸­çš„éŸ³é¢‘ï¼Œå°†ä¸¤ä¸ªéŸ³é¢‘åˆå¹¶æˆä¸€ä¸ªéŸ³é¢‘ï¼Œç„¶åå°†åˆå¹¶çš„éŸ³é¢‘ä¸è§†é¢‘è¿›è¡Œåˆå¹¶
#è·å–è§†é¢‘ä¸­çš„éŸ³é¢‘
ffmpeg -i input.mp4 -vn -y -acodec copy output.aac
#å»æ‰è§†é¢‘ä¸­çš„éŸ³é¢‘
ffmpeg -i input.mp4 -an output.mp4
#åˆå¹¶ä¸¤ä¸ªéŸ³é¢‘
ffmpeg -i input1.mp3 -i output.aac -filter_complex amerge -ac 2 -c:a libmp3lame -q:a 4 output.mp3
#åˆå¹¶éŸ³é¢‘å’Œè§†é¢‘
ffmpeg -i video.mp4 -i audio.wav -c:v copy -c:a aac -strict experimental output.mp4
 
 
3ã€åˆå¹¶è§†é¢‘
#æ¨ªå‘åˆå¹¶è§†é¢‘
ffmpeg -i input1.mp4 -i input2.mp4 -lavfi hstack output.mp4
 
ä¸Šé¢çš„å‘½ä»¤è™½ç„¶å¯ä»¥åˆå¹¶è§†é¢‘ï¼Œä¸¤ä¸ªè§†é¢‘å¯ä»¥æ­£å¸¸æ’­æ”¾ï¼Œä½†æ˜¯åªä¿ç•™äº†å‰é¢ä¸€ä¸ªçš„éŸ³é¢‘ã€‚
#åˆå¹¶å¤šä¸ªè§†é¢‘ï¼Œå¯ä»¥ä½¿ç”¨ä¸‹é¢å‘½ä»¤è¡Œï¼š
ffmpeg -i input1.mp4 -i input2.mp4 -i input3.mp4 -lavfi hstack=inputs=3 output.mp4
 
#çºµå‘åˆå¹¶è§†é¢‘
ffmpeg -i input1.mp4 -i input2.mp4 -lavfi vstack output.mp4
 
 
#ç½‘æ ¼åˆå¹¶è§†é¢‘ï¼Œæ¥æº:https://www.zhihu.com/question/300182407
å½“å¤šä¸ªè§†é¢‘æ—¶ï¼Œè¿˜å¯ä»¥åˆå¹¶æˆç½‘æ ¼çŠ¶ï¼Œæ¯”å¦‚2x2ï¼Œ3x3è¿™ç§ã€‚ä½†æ˜¯è§†é¢‘ä¸ªæ•°ä¸ä¸€å®šéœ€è¦æ˜¯å¶æ•°ï¼Œå¦‚æœæ˜¯å¥‡æ•°ï¼Œå¯ä»¥ç”¨é»‘è‰²å›¾ç‰‡æ¥å ä½ã€‚
 
ffmpeg -f lavfi -i color=c=black:s=1280x720 -vframes 1 black.png
è¯¥å‘½ä»¤å°†åˆ›å»ºä¸€å¼ 1280*720çš„å›¾ç‰‡
 
ç„¶åå°±å¯ä»¥ä½¿ç”¨ä¸‹é¢è¿™ä¸ªå‘½ä»¤æ¥åˆå¹¶æˆç½‘æ ¼è§†é¢‘äº†ï¼Œå¦‚æœåªæœ‰ä¸‰ä¸ªè§†é¢‘ï¼Œå¯ä»¥é€‰æ‹©ä¸Šé¢åˆ›å»ºçš„é»‘è‰²å›¾ç‰‡æ›¿ä»£ã€‚
ffmpeg -i top_left.mp4 -i top_right.mp4 -i bottom_left.mp4 -i bottom_right.mp4 \
-lavfi "[0:v][1:v]hstack[top];[2:v][3:v]hstack[bottom];[top][bottom]vstack"
-shortest 2by2grid.mp4
 
ä¸Šé¢åˆ›å»ºçš„æ˜¯æ­£è§„çš„2x2ç½‘æ ¼è§†é¢‘ã€‚æƒ³è±¡ä¸€ä¸‹ï¼Œç°åœ¨åªæœ‰ä¸‰ä¸ªè§†é¢‘ï¼Œæˆ‘æƒ³æŠŠç¬¬ä¸€ä¸ªè§†é¢‘æ‘†æ”¾åœ¨ç¬¬ä¸€è¡Œçš„ä¸­é—´ï¼Œç„¶åæŠŠç¬¬äºŒã€ä¸‰ä¸ªè§†é¢‘æ‘†æ”¾åœ¨ç¬¬äºŒè¡Œã€‚é‚£ä¹ˆå°±å¯ä»¥ä½¿ç”¨ä¸‹é¢ä¸¤ä¸ªå‘½ä»¤äº†ã€‚
 
ffmpeg -f lavfi -i color=c=black:s=640x720 -vframes 1 black.png
 
ffmpeg -i black.png -i top_center.mp4 -i bottom_left.mp4 -i bottom_right.mp4
-lavfi "[0:v][1:v][0:v]hstack=inputs=3[top];[2:v][3:v]hstack[bottom];[top][bottom]vstack"
-shortest 3_videos_2x2_grid.mp4
  
4ã€æ€ä¹ˆåˆå¹¶ä¸¤ä¸ªè§†é¢‘å¹¶ä¿ç•™ä¸¤ä¸ªè§†é¢‘ä¸­çš„éŸ³é¢‘ï¼Œæ³¨æ„è§†é¢‘çš„åˆ†è¾¨ç‡å’Œæ ¼å¼å¿…é¡»ä¸€æ ·ã€‚
#åˆå¹¶ä¸¤ä¸ªè§†é¢‘ï¼Œåªæœ‰ä¸€ä¸ªå£°éŸ³;
çºµå‘åˆå¹¶è§†é¢‘
ffmpeg -i input1.mp4 -i input2.mp4 -lavfi vstack output.mp4
 
#æŠ½å–ä¸¤ä¸ªè§†é¢‘ä¸­çš„éŸ³é¢‘ï¼Œç„¶ååˆå¹¶æˆä¸€ä¸ªéŸ³é¢‘; 
ffmpeg -i input_1.mp4 -vn -y -acodec copy output_a1.m4a
ffmpeg -i input_2.mp4 -vn -y -acodec copy output_a2.m4a
ffmpeg -i output_a1.m4a -i output_a2.m4a -filter_complex amerge -ac 2 -c:a copy -q:a 4 output_a.m4a
 
#å°†è¿™ä¸ªéŸ³é¢‘æ›¿æ¢åˆ°ä¹‹å‰çš„åˆå¹¶è§†é¢‘ä¸­;
ffmpeg -i video.mp4 -i output_a.m4a -c:v copy -c:a aac -strict experimental output.mp4
 
 
5ã€éŸ³é¢‘æ‹¼æ¥
#ä¸¤ä¸ªæ‹¼æ¥
/usr/local/ffmpeg/bin/ffmpeg -i d1.mp3 -i d2.mp3 -filter_complex '[0:0] [1:0] concat=n=2:v=0:a=1 [a]' -map [a] j5.mp3
#ä¸‰ä¸ªæ‹¼æ¥
/usr/local/ffmpeg/bin/ffmpeg -i ç‰‡å¤´.wav -i å†…å®¹.WAV -i ç‰‡å°¾.wav -filter_complex '[0:0] [1:0] [2:0] concat=n=3:v=0:a=1 [a]' -map [a] åˆæˆ.wav
 
#å¤šæ–‡ä»¶æ‹¼æ¥
ffmpeg -f concat -ilist.txt -c copycutebaby.mp3
list.txtæ–‡ä»¶å†…å®¹:Ã æŒ‰é¡ºåºè¿æ¥cutebaby_1.mp3, football.mp3,cutebaby_2.mp3,cutebaby_3.mp3
 
#æ‹¼æ¥ä¸åŒæ ¼å¼çš„æ–‡ä»¶ï¼Œä¸‹é¢çš„å‘½ä»¤åˆå¹¶äº†ä¸‰ç§ä¸åŒæ ¼å¼çš„æ–‡ä»¶ï¼ŒFFmpeg concat è¿‡æ»¤å™¨ä¼šé‡æ–°ç¼–ç å®ƒä»¬ã€‚æ³¨æ„è¿™æ˜¯æœ‰æŸå‹ç¼©ã€‚
[0:0] [0:1] [1:0] [1:1] [2:0] [2:1] åˆ†åˆ«è¡¨ç¤ºç¬¬ä¸€ä¸ªè¾“å…¥æ–‡ä»¶çš„è§†é¢‘ã€éŸ³é¢‘ã€ç¬¬äºŒä¸ªè¾“å…¥æ–‡ä»¶çš„è§†é¢‘ã€éŸ³é¢‘ã€ç¬¬ä¸‰ä¸ªè¾“å…¥æ–‡ä»¶çš„è§†é¢‘ã€éŸ³é¢‘ã€‚concat=n=3:v=1:a=1 è¡¨ç¤ºæœ‰ä¸‰ä¸ªè¾“å…¥æ–‡ä»¶ï¼Œè¾“å‡ºä¸€æ¡è§†é¢‘æµå’Œä¸€æ¡éŸ³é¢‘æµã€‚[v] [a] å°±æ˜¯å¾—åˆ°çš„è§†é¢‘æµå’ŒéŸ³é¢‘æµçš„åå­—ï¼Œæ³¨æ„åœ¨ bash ç­‰ shell ä¸­éœ€è¦ç”¨å¼•å·ï¼Œé˜²æ­¢é€šé…ç¬¦æ‰©å±•ã€‚ 
 
ffmpeg -i input1.mp4 -i input2.webm -i input3.avi -filter_complex '[0:0] [0:1] [1:0] [1:1] [2:0] [2:1] concat=n=3:v=1:a=1 [v] [a]' -map '[v]' -map '[a]' <ç¼–ç å™¨é€‰é¡¹> output.mkv
```



```
m3u8æ ¼å¼çš„è§†é¢‘æ˜¯å°†æ–‡ä»¶åˆ†æˆä¸€å°æ®µä¸€å°æ®µçš„tsæ–‡ä»¶ï¼Œæ’­æ”¾å®Œä¸€ä¸ªåœ¨æ’­æ”¾ä¸‹ä¸€ä¸ªï¼Œç”±äºæ¯æ¬¡è¯·æ±‚çš„tsæ–‡ä»¶éƒ½å¾ˆå°ï¼Œæ‰€ä»¥åŸºæœ¬å¯ä»¥åšåˆ°æ— å»¶æ—¶æ’­æ”¾ã€‚ç›®å‰WEBä¸Šä¸»æµçš„ç›´æ’­æ–¹æ¡ˆä¸»è¦æ˜¯HLSå’ŒRTMPï¼Œç§»åŠ¨ç«¯ä¸»è¦æ˜¯HLSï¼ŒPCç«¯ä¸»è¦æ˜¯RTMPã€‚

HLSæ˜¯è‹¹æœæ¨å‡ºçš„ï¼Œç§»åŠ¨ç«¯ä¸ç®¡æ˜¯IOSè¿˜æ˜¯Androidéƒ½å¤©ç„¶æ”¯æŒHLSåè®®ï¼Œç›´æ¥åœ¨h5é¡µé¢ç›´æ¥é…ç½®å³å¯ä½¿ç”¨ï¼›PCç«¯åªæœ‰safariæµè§ˆå™¨æ”¯æŒï¼Œå…¶ä»–æµè§ˆå™¨å‡ä¸æ”¯æŒã€‚

å¯ä»¥ç”¨video.jså’Œvideojs-contrib-hls.jsã€‚video.jsæ˜¯éå¸¸å¥½ç”¨çš„æ’ä»¶ï¼Œå…³äºå®ƒå¦‚ä½•ä½¿ç”¨è¿™é‡Œå°±ä¸ä¸€ä¸€ä»‹ç»äº†ã€‚

```



```
æµåª’ä½“ï¼šffmpegç”ŸæˆHLSçš„m3u8ä¸tsç‰‡æ®µ
 

è½¬æ¢æ–¹å¼ä¸€
1.ç›´æ¥æŠŠåª’ä½“æ–‡ä»¶è½¬ä¸ºts

ffmpeg -i cat.mp4 -c copy -bsf h264_mp4toannexb cat.ts
2.ä½¿ç”¨segmentå‚æ•°è¿›è¡Œåˆ‡ç‰‡

ffmpeg -i cat.ts -c copy -map 0 -f segment -segment_list playlist.m3u8 -segment_time 2 cat_output%03d.ts
 

 

è½¬æ¢æ–¹å¼äºŒ
1.ffmpegåˆ‡ç‰‡å‘½ä»¤ï¼Œä»¥H264å’ŒAACçš„å½¢å¼å¯¹è§†é¢‘è¿›è¡Œè¾“å‡º

ffmpeg -i input.mp4 -c:v libx264 -c:a aac -strict -2 -f hls output.m3u8
2.ffmpegè½¬åŒ–æˆHLSæ—¶é™„å¸¦çš„æŒ‡ä»¤

-hls_time n: è®¾ç½®æ¯ç‰‡çš„é•¿åº¦ï¼Œé»˜è®¤å€¼ä¸º2ã€‚å•ä½ä¸ºç§’

-hls_list_size n:è®¾ç½®æ’­æ”¾åˆ—è¡¨ä¿å­˜çš„æœ€å¤šæ¡ç›®ï¼Œè®¾ç½®ä¸º0ä¼šä¿å­˜æœ‰æ‰€ç‰‡ä¿¡æ¯ï¼Œé»˜è®¤å€¼ä¸º5

-hls_wrap n:è®¾ç½®å¤šå°‘ç‰‡ä¹‹åå¼€å§‹è¦†ç›–ï¼Œå¦‚æœè®¾ç½®ä¸º0åˆ™ä¸ä¼šè¦†ç›–ï¼Œé»˜è®¤å€¼ä¸º0.è¿™ä¸ªé€‰é¡¹èƒ½å¤Ÿé¿å…åœ¨ç£ç›˜ä¸Šå­˜å‚¨è¿‡å¤šçš„ç‰‡ï¼Œè€Œä¸”èƒ½å¤Ÿé™åˆ¶å†™å…¥ç£ç›˜çš„æœ€å¤šçš„ç‰‡çš„æ•°é‡

-hls_start_number n:è®¾ç½®æ’­æ”¾åˆ—è¡¨ä¸­sequence numberçš„å€¼ä¸ºnumberï¼Œé»˜è®¤å€¼ä¸º0

3.å¯¹ffmpegåˆ‡ç‰‡æŒ‡ä»¤çš„ä½¿ç”¨

ffmpeg -i output.mp4 -c:v libx264 -c:a aac -strict -2 -f hls -hls_list_size 0 -hls_time 5 data/output.m3u8 
å‚æ•°:

-hls_base_url   m3u8æ’­æ”¾åœ°å€å‰ç¼€

-segment_list_entry_prefix  m3u8æ’­æ”¾åœ°å€å‰ç¼€

-s 1280x720    :  720påˆ†è¾¨ç‡
-b 1500k  æ¯”ç‰¹ç‡
-r è®¾å®šå¸§é€Ÿç‡ï¼Œé»˜è®¤ä¸º25
-aspect è®¾å®šç”»é¢çš„æ¯”ä¾‹
```



# graphql

- https://github.com/graphile/postgraphile

  > nodejs

- https://ruby-china.org/topics/40334

  > PostGraphileï¼šå°† Postgres æ•°æ®åº“å˜æˆå…¨åŠŸèƒ½ GraphQL åç«¯
  >
  > è¿™ä¸ªå·¥å…·å¯ä»¥ç›´æ¥æŠŠä¸€ä¸ª postgres æ•°æ®åº“ç”Ÿæˆä¸ºä¸€ä¸ª graphql åç«¯ï¼Œå†…ç½®äº†å¯¹æ¯ä¸ªè¡¨æ ¼çš„ crud query åŠ mutationã€‚
  >
  > ä¸ºä»€ä¹ˆè¯´æ˜¯å…¨åŠŸèƒ½çš„å‘¢ï¼Ÿå› ä¸ºä»…ä»…é€šè¿‡ graphile å’Œ pg å¯ä»¥åšåˆ°ä¼ ç»Ÿåç«¯éœ€è¦çš„ä»»ä½•äº‹ï¼Œè€Œä¸”æ‰€æœ‰éœ€è¦å†™çš„ä»£ç å’Œé…ç½®éƒ½åœ¨ postgres é‡Œï¼Œè¿ç§»çš„æ—¶å€™ç›´æ¥å¯¼å‡º postgres æ•°æ®åº“ï¼Œå°±èƒ½å¤‡ä»½æ•´ä¸ªåç«¯ã€‚
  >
  > é™¤äº†ç”Ÿæˆçš„ crudï¼Œç”¨æˆ·å¯ä»¥ç”¨ pl/sql å†™ä¸šåŠ¡é€»è¾‘çš„å‡½æ•°ï¼Œä¸€ä¸ªæœ‰å‰¯ä½œç”¨ï¼ˆcudï¼‰çš„å‡½æ•°ä¼šç›´æ¥æŒ‚è½½ä¸º graphql çš„ mutationï¼Œæ— å‰¯ä½œç”¨çš„åˆ™ä¼šæŒ‚è½½ä¸º queryã€‚
  >
  > graphile å¯¹æ•°æ®åº“çš„æ›´æ–°é‰´æƒæ˜¯ä½¿ç”¨ pg å†…ç½®çš„ role å’Œ row level security å®ç°çš„ã€‚ä¸€èˆ¬åº”ç”¨éœ€è¦ä¸¤ä¸ª roleï¼šç™»é™†å‰çš„ anonymous å’Œç™»é™†åçš„ userã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ grant æ¥å¯¹ä¸åŒ role é…ç½®ä»–ä»¬èƒ½å¯¹è¡¨è¿›è¡Œçš„æ“ä½œï¼Œè€Œ row level security åˆ™å…è®¸æˆ‘ä»¬é…ç½®ä¸€ä¸ª session å¯¹è¡Œçš„æƒé™ï¼Œåœ¨ cud è¡Œçš„æ—¶å€™ï¼Œå¯ä»¥æ‰§è¡Œä¸€äº› checkï¼Œä¾‹å¦‚æ£€æŸ¥å½“å‰ç”¨æˆ· id æ˜¯ä¸æ˜¯å’Œè¦ä¿®æ”¹çš„æ•°æ®ä¸€æ ·ã€‚
  >
  > å’Œ hasura å¯¹æ¯”çš„å¥½å¤„ï¼š
  >
  > - graphile ä»¥ postgres ä¸ºä¸­å¿ƒï¼Œæ²¡æœ‰è‡ªå·±çš„ metadataã€‚hasura æŠŠå…³è”çš„é…ç½®ä¿å­˜ä¸ºä¸€ä»½è‡ªå·±çš„é…ç½®ï¼Œè¿™æ ·åœ¨è¿ç§»çš„æ—¶å€™é™¤äº†å¯¼å‡ºæ•°æ®åº“ï¼Œè¿˜éœ€è¦å¯¼å‡º hasura çš„é…ç½®ã€‚è€Œ graphile çš„å…³è”ä¿¡æ¯æ˜¯å®Œå…¨é€šè¿‡ pg å†…çš„å¤–é”®å…³è”æ¨å¯¼å‡ºæ¥çš„ã€‚
  > - hasura å®ç°ç™»é™†é‰´æƒåŠŸèƒ½çš„æ—¶å€™éœ€è¦ä¸€ä¸ªå¤–éƒ¨æœåŠ¡å™¨ã€‚graphile ä¸éœ€è¦ä¸€ä¸ªé¢å¤–çš„æœåŠ¡å™¨ï¼Œå‡­å€Ÿè‡ªèº«å°±å¯ä»¥å®ç°ç™»é™†æ³¨å†Œï¼Œç­¾ç½² jwtã€‚
  > - graphile ä½¿ç”¨ pg å†…ç½®çš„ row level security æ¥å¤„ç†æƒé™ï¼Œè€Œ hasura æ˜¯ç”¨ä¸€å¥—è‡ªå·±çš„é‰´æƒæœºåˆ¶æ¥å¤„ç†çš„ã€‚

- https://www.jianshu.com/p/a300a964c797

  

# nginx



```
æœ‰æ²¡æœ‰äººé‡åˆ° Nginx åšåä»£ https ç™»é™†é¡µé¢å‡ºç°é—®é¢˜

æ— èŠåšäº†ä¸ªåä»£ä¸Šdmm
ç»“æœdmmçš„httpsç™»é™†é¡µé¢ä¸€ç›´ä¸å¤ªå¯¹
é¦–å…ˆå“åº”çš„æ—¶é—´å°±éå¸¸é•¿ï¼Œç»å¸¸è¶…æ—¶
ç„¶åä¹Ÿæ— æ³•æ­£å¸¸ç™»é™†,ä¸€ç›´æç¤ºå¯†ç é”™è¯¯

ç„¶è€Œç”¨squidæ­£ä»£å°±æ²¡æœ‰ä»»ä½•é—®é¢˜
åŸºæœ¬å¯ä»¥ç¡®å®šè‚¯å®šæ˜¯nginxå“ªé‡Œé”™äº†

ç ”ç©¶äº†åŠå¤©è¿˜æ˜¯æ²¡ä»€ä¹ˆæˆæœã€‚ã€‚ã€‚æ‰€ä»¥æˆ‘å°±æƒ³é—®é—®æˆ‘ç©¶ç«Ÿåœ¨å“ªé‡Œæ‰å‘é‡Œäº†

è´´éƒ¨åˆ†é…ç½®ï¼š
server {
listen server_ip:443 ssl;
server_name www.dmmm.com;

ssl_certificate     /usr/local/nginx/conf/server.crt;
    ssl_certificate_key  /usr/local/nginx/conf/server.key;

    ssl_session_cache    shared:SSL:1m;
    ssl_session_timeout  5m;

    ssl_ciphers  HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers  on;

    location / {
        proxy_pass https://www.dmm.com;

        proxy_set_header Host $http_host;

        proxy_max_temp_file_size     0k;
        proxy_connect_timeout       60;
        proxy_send_timeout         60;
        proxy_read_timeout         60;
        proxy_buffers             256 4k;
        proxy_busy_buffers_size      64k;
        proxy_redirect            off;
    }
}
ç¬¬ 1 æ¡é™„è¨€  Â·  2015-03-31 22:08:05 +08:00
ä»Šå¤©å·²ç»å®Œæˆæ’é”™ä»»åŠ¡åŸå› ä¸º:
[kQBYS09a1******@********* ~]$ cat /usr/local/nginx/logs/error.log | grep invalid
2015/03/31 16:15:46 [info] 11637#0: *73 client sent invalid header line: "DMM_TOKEN: b909db2e73f6d2c9ab1a6**********" while reading client request headers, client: ********, server: www.dmm.com, request: "POST /my/-/login/ajax-get-token/ HTTP/1.1", host: "www.dmm.com"
ç»è¿‡æŸ¥é˜…æ–‡æ¡£nginxå¯¹äº"DMM_TOKEN"è¿™ç±»å¸¦æœ‰ä¸‹åˆ’çº¿çš„headerè®¤ä¸ºä¸åˆæ³•è‡ªåŠ¨å¿½ç•¥
nginxä½œè€…å’Œä¸‹åˆ’çº¿åˆ°åº•æœ‰å¤šå¤§ä»‡~~~~~
è§£å†³æ–¹æ³•ä¹Ÿå¾ˆç®€å•:
underscores_in_headers on
```



# acg power ä»£ç†



```
http://127.0.0.1:8123/proxy.pac  # å®ƒå®šä¹‰çš„ipã€ç½‘å€è§„åˆ™ï¼Œæ”¹å®ƒ(for dmm game player)
```







# è§£å¯†



```
https://www.v2ex.com/t/311275

æ±‚å¸®å¿™ç ´è§£ AES-128 åŠ å¯†çš„ m3u8+ts+key è§†é¢‘
     gushengren Â· 2016-10-09 01:21:20 +08:00 Â· 18439 æ¬¡ç‚¹å‡»  
è¿™æ˜¯ä¸€ä¸ªåˆ›å»ºäº 1859 å¤©å‰çš„ä¸»é¢˜ï¼Œå…¶ä¸­çš„ä¿¡æ¯å¯èƒ½å·²ç»æœ‰æ‰€å‘å±•æˆ–æ˜¯å‘ç”Ÿæ”¹å˜ã€‚
æŠŠæµè§ˆå™¨ç¼“å­˜çš„ä¸œè¥¿éƒ½å¤åˆ¶å‡ºæ¥äº†,é™¤äº† m3u8 å’Œ key,å…¶ä»–çš„éƒ½æ˜¯ ts æ–‡ä»¶,å“ªä½å¤§ç¥èƒ½å¸®å¿™ç ´è§£ä¸€ä¸‹,æƒ³æŠŠè¿™ä¸ªè§†é¢‘ä¸‹ä¸‹æ¥å•Š.ç”Ÿæˆä¸€ä¸ªå¯ä»¥æ’­æ”¾çš„è§†é¢‘
é“¾æ¥ï¼š http://pan.baidu.com/s/1nvvZCSh å¯†ç ï¼š hoqf
18439 æ¬¡ç‚¹å‡»  âˆ™  12 äººæ”¶è—  åŠ å…¥æ”¶è—  Tweet  å¿½ç•¥ä¸»é¢˜  æ„Ÿè°¢
 M3U8 key ç ´è§£ å¸®å¿™32 æ¡å›å¤  â€¢  2017-05-18 17:51:15 +08:00
gushengren		        Reply    1
gushengren   2016-10-09 02:49:26 +08:00
æ±‚å¤§ç¥æ¥å¸®å¿™
annielong		        Reply    2
annielong   2016-10-09 09:21:47 +08:00
ts æ–‡ä»¶ä¹ŸåŠ å¯†äº†å—ï¼Ÿå…ˆçœ‹çœ‹ ts æ–‡ä»¶èƒ½ä¸èƒ½ç›´æ¥æ’­æ”¾ï¼Œå¦‚æœå¯ä»¥ç›´æ¥æ’­æ”¾å°±æ˜¯æ²¡æœ‰åŠ å¯†ï¼Œç›´æ¥åˆå¹¶å°±è¡Œäº†
xxxyyy		        Reply    3
xxxyyy   2016-10-09 09:43:19 +08:00 via Android
av æ¥çš„å‘€ï¼Œä¸è¿‡åˆ†è¾¨ç‡ä¹Ÿå¤ªå°äº†ï¼Œåªæœ‰ 320x180 ï¼Œè€Œä¸”è¿˜æ‰“ç äº†
Ellison		        Reply    4
Ellison   2016-10-09 11:25:49 +08:00
@xxxyyy æ¨èæ¥¼ä¸»ç›´æ¥é—®è€å¸æœºè¦ç•ªå·
gushengren		        Reply    5
gushengren   2016-10-09 12:39:37 +08:00
@annielong TS å¦‚æœä¸åŠ å¯†,æˆ‘å°±ä¸ç”¨åœ¨è¿™é—®äº†
gushengren		        Reply    6
gushengren   2016-10-09 12:40:10 +08:00
@xxxyyy ç¥äºº,ä½ ç ´äº†å—?
xxxyyy		        Reply    7
xxxyyy   2016-10-09 12:50:56 +08:00 via Android
@gushengren ä½ ä¸çŸ¥é“é‡Œé¢çš„å†…å®¹çš„å—ï¼Ÿ
gushengren		        Reply    8
gushengren   2016-10-09 12:56:05 +08:00
@xxxyyy æˆ‘çŸ¥é“å•Š,æˆ‘çœ‹ä½ å±…ç„¶çŸ¥é“é‡Œé¢çš„å†…å®¹,ä½ æ˜¯ç ´è§£äº†å—?å…„å¼Ÿ,è·ªæ±‚æ–¹æ³•å•Š
gushengren		        Reply    9
gushengren   2016-10-09 12:57:23 +08:00
@xxxyyy å¯ä»¥ç•™ä¸ªè”ç³»æ–¹å¼å—?
gushengren		        Reply    10
gushengren   2016-10-09 14:12:33 +08:00
å“ªä½å¤§ç¥ç¥å¸®å¸®æˆ‘å•Š.555555555555555555
xxxyyy		        Reply    11
xxxyyy   2016-10-09 14:50:15 +08:00 via Android
æœ‰ telegram å—ï¼Ÿ
gushengren		        Reply    12
gushengren   2016-10-09 14:55:47 +08:00
@xxxyyy æ²¡æœ‰å‘¢,æœ‰æ²¡æœ‰æ¯”è¾ƒä½ç«¯çš„è”ç³»æ–¹å¼å•Š,å‘µå‘µ
likuku		        Reply    13
likuku   2016-10-09 15:10:01 +08:00
æš´åŠ›ç©·ä¸¾çŒœå¯†ç çš„è¯ï¼Œå°±æ”¾å¼ƒå§ï¼Œå½“å‰åœ°çƒäººçš„è®¡ç®—è®¾å¤‡è¿˜ä¸å¤Ÿå¼ºã€‚

åç­‰é‡å­è¶…çº§ç”µè„‘ã€‚
xxxyyy		        Reply    14
xxxyyy   2016-10-09 15:20:13 +08:00
@gushengren QQ ï¼š(æŒ)361(é›¶)992(å£¹)
v2014		        Reply    15
v2014   2016-10-09 15:47:29 +08:00
è´¹äº†æ´ªè’ä¹‹åŠ›ç»ˆäºçœ‹åˆ°é‚£å¥³çš„ç©¿çš„æ˜¯æ¡çº¹è¡£æœ
gushengren		        Reply    16
gushengren   2016-10-09 15:55:23 +08:00
@v2014 å“ˆå“ˆ,ä½ èƒ½ä¹Ÿç ´?è·ªæ±‚æŒ‡å¯¼
v2014		        Reply    17
v2014   2016-10-09 16:02:33 +08:00
@gushengren æ¥¼ä¸Šä¸æ˜¯æœ‰ QQ ä¹ˆï¼Œä½ æ‹¿ key å’Œè§†é¢‘ç”¨ aes128 ç®—æ³•è§£å¯†å°±å¯ä»¥äº†
gushengren		        Reply    18
gushengren   2016-10-09 16:04:12 +08:00
å°±æ˜¯ä¸çŸ¥é“æ€ä¹ˆè§£å¯†å•Š,å…„å¼Ÿ,åŸç†æˆ‘éƒ½æ‡‚çš„,ä¸ç„¶æˆ‘ä¹Ÿä¸ä¼šæä¾›å‡ºè§£å¯†éœ€è¦çš„ä¸œè¥¿å•Š,èƒ½æä¾›ä¸‹ QQ æŒ‡å¯¼ä¸€ä¸‹ä¹ˆ,ä¸èƒœæ„Ÿæ¿€
gushengren		        Reply    19
gushengren   2016-10-09 16:06:20 +08:00
@v2014 æˆ‘ç”¨ ffmpeg æ¥æ”¶ å®ƒæŠ¥ä¸ªæœªçŸ¥æ ¼å¼çš„é”™è¯¯,æˆ‘ TM å°± SB äº†,ä¸çŸ¥é“å’‹åŠäº†
v2014		        Reply    20
v2014   2016-10-09 16:15:39 +08:00
@gushengren æˆ‘ä¸ä¼š ffmpeg ï¼Œåªæ˜¯ç”¨ python è§£äº†ä¸ªè§†é¢‘ã€‚ä½ å¯ä»¥çœ‹çœ‹è¿™ä¸ª http://dola.xinfan.org/?p=549
monkeygo		        Reply    21
monkeygo   2016-10-09 16:20:03 +08:00 via iPhone
éƒ½æ˜¯è€å¸æœº
gushengren		        Reply    22
gushengren   2016-10-09 16:22:18 +08:00
@v2014 è¿™ä¸ªæˆ‘çœ‹äº†,æ ¹æœ¬ä¸çŸ¥é“å¦‚ä½•æ“ä½œ,æåˆ°å‘½ä»¤è¡Œçš„æ—¶å€™,å‘µå‘µ
tinyproxy		        Reply    23
tinyproxy   2016-10-09 17:09:44 +08:00   â¤ï¸ 2
è¿™ä¸ªä¸å«ç ´è§£ã€‚ã€‚ã€‚ AES çš„ mode å°±é‚£ä¹ˆå‡ ä¸ªï¼Œä½ çŸ¥é“æ˜¯ AES-128 ï¼Œè¯•ä¸€ä¸‹ä¸å°±å¥½äº†ã€‚

æˆ‘éšä¾¿ä¸‹äº†ä¸€ä¸ªæ–‡ä»¶ï¼Œè¿™ä¸ªæ˜¯æˆ‘çš„ä»£ç ï¼Œå…¶å®ƒçš„ä½ è‡ªå·±å¤„ç†å§ã€‚
#!/usr/bin/env python
# -*- coding: utf8 -*-
from Crypto.Cipher import AES

raw = file('dyVuoO%2BiKIqY%2B3Ebf3CavNpB5RKlXfGtInP31znaGCfYnVkrSsAF46r2hg-1', 'rb').read()
iv = raw[0:16]
data = raw[16:]
key = file('key', 'rb').read()

plain_data = AES.new(key, AES.MODE_CBC, iv).decrypt(data)
file('fuck.mp4', 'wb').write(plain_data)
VYSE		        Reply    24
VYSE   2016-10-09 17:39:32 +08:00
http://www.dmm.co.jp
æå–ç•ªå·ä¸å°±è¡Œäº†,è¿™éƒ½æ˜¯é¢„è§ˆå§?
21grams		        Reply    25
21grams   2016-10-09 17:48:50 +08:00
key éƒ½æœ‰äº†è¿˜ä¸ä¼šè§£å—ï¼Ÿ
gushengren		        Reply    26
gushengren   2016-10-09 17:54:17 +08:00
@21grams ä¸ä¼š,æˆ‘æ˜¯å°ç™½
Jat001		        Reply    27
Jat001   2016-10-09 17:58:28 +08:00
@tinyproxy ä¸‡ä¸€æ˜¯ gcm æ€ä¹ˆåŠï¼Ÿä½ æ€ä¹ˆçŸ¥é“ iv æ˜¯å‰ 16 å­—èŠ‚ï¼Ÿ
tinyproxy		        Reply    28
tinyproxy   2016-10-09 18:48:49 +08:00   â¤ï¸ 1
@Jat001
1. æ¥¼ä¸Šå‡ ä½éƒ½æ˜ç¡®æš—ç¤ºè§£å¯†æˆåŠŸäº†ï¼Œæ‰€ä»¥æˆ‘ä¹Ÿå°±æ˜¯éšä¾¿æ‹¿ä¸€ç§ mode æ¥çŒœçš„ï¼Œå½“æ—¶ç¬¬ä¸€ååº”æ˜¯ CBC ã€‚è‡³äº GCM å’‹åŠï¼Œå› ä¸ºæ²¡ç”¨è¿‡è¿™ç§ mode ï¼Œæ‰€ä»¥æš‚æ—¶ä¸äº†è§£åŠ è§£å¯†æ“ä½œï¼Œä¸å›å¤ã€‚
2. iv æ˜¯å‰ 16 å­—èŠ‚è¿™ä¸ªé—®é¢˜ï¼Œè¿™ä¸ªæ˜¯ä¸ªäººç»éªŒã€‚æˆ‘ç›®å‰ä¸ºæ­¢çœ‹è¿‡çš„æ‰€æœ‰ä»£ç éƒ½æ˜¯ç›´æ¥æŠŠ iv æ·»åŠ åˆ°å¯†æ–‡å‰é¢å»ï¼Œæ‰€ä»¥ä¹Ÿå°±éšæ‰‹è¯•è¯•ï¼Œä½ çœ‹æˆ‘çš„ä»£ç ä¹Ÿæ²¡å‡ è¡Œï¼Œä¸æˆåŠŸå°±ç®—äº†å‘—ã€‚
Jat001		        Reply    29
Jat001   2016-10-09 19:08:57 +08:00
@tinyproxy gcm åŠ å¯†æ—¶è¿˜éœ€è¦ associated data ï¼ŒåŠ å¯†å®Œè¿˜ä¼šç”Ÿæˆ tag ç”¨ä½œæ ¡éªŒï¼Œå…·ä½“å®ç°å¯ä»¥å‚è€ƒã€‚
https://cryptography.io/en/latest/hazmat/primitives/symmetric-encryption/#cryptography.hazmat.primitives.ciphers.modes.GCM
crab		        Reply    30
crab   2016-10-09 19:13:56 +08:00
dmm è¿™ç½‘ç«™çš„ï¼Ÿ
hwsdien		        Reply    31
hwsdien   2016-10-09 19:16:54 +08:00
key éƒ½æœ‰äº†ã€‚ã€‚ã€‚
```







# hira2kata



```
pip install jaconv
```



```
import jaconv

# Hiragana to Katakana å¹³å‡å ===> ç‰‡å‡å
jaconv.hira2kata(u'ã¨ã‚‚ãˆã¾ã¿')
# => u'ãƒˆãƒ¢ã‚¨ãƒãƒŸ'

# Hiragana to half-width Katakana å¹³å‡å ===> åŠè§’ç‰‡å‡å
jaconv.hira2hkata(u'ã¨ã‚‚ãˆã¾ã¿')
# => u'ï¾„ï¾“ï½´ï¾ï¾'

# Katakana to Hiragana ç‰‡å‡å ====> å¹³å‡å
jaconv.kata2hira(u'å·´ãƒãƒŸ')
# => u'å·´ã¾ã¿'

# half-width character to full-width character åŠè§’ ===> å…¨è§’
jaconv.h2z(u'ï¾ƒï½¨ï¾›ï½¥ï¾Œï½¨ï¾…ï½°ï¾š')
# => u'ãƒ†ã‚£ãƒ­ï½¥ãƒ•ã‚£ãƒŠãƒ¼ãƒ¬'

# half-width character to full-width character
# but only ascii characters åªé™asciiå­—ç¬¦
jaconv.h2z(u'abc', ascii=True)
# => u'ï½ï½‚ï½ƒ'

# half-width character to full-width character
# but only digit characters
jaconv.h2z(u'123', digit=True)
# => u'ï¼‘ï¼’ï¼“'

# half-width character to full-width character
# except half-width Katakana é™¤åŠè§’ç‰‡å‡å
jaconv.h2z(u'ï½±abc123', kana=False, digit=True, ascii=True)
# => u'ï½±ï½ï½‚ï½ƒï¼‘ï¼’ï¼“'

# full-width character to half-width character å…¨è§’ ===> åŠè§’
jaconv.z2h(u'ãƒ†ã‚£ãƒ­ãƒ»ãƒ•ã‚£ãƒŠãƒ¼ãƒ¬')
# => u'ï¾ƒï½¨ï¾›ãƒ»ï¾Œï½¨ï¾…ï½°ï¾š'

# full-width character to half-width character
# but only ascii characters åªé™asciiå­—ç¬¦
jaconv.z2h(u'ï½ï½‚ï½ƒ', ascii=True)
# => u'abc'

# full-width character to half-width character
# but only digit characters åªé™æ•°å­—
jaconv.z2h(u'ï¼‘ï¼’ï¼“', digit=True)
# => u'123'

# full-width character to half-width character
# except full-width Katakana é™¤å…¨è§’ç‰‡å‡å
jaconv.z2h(u'ã‚¢ï½ï½‚ï½ƒï¼‘ï¼’ï¼“', kana=False, digit=True, ascii=True)
# => u'ã‚¢abc123'

# normalize
jaconv.normalize(u'ãƒ†ã‚£ãƒ­ï½¥ãƒ•ã‚£ãƒŠã€œãƒ¬', 'NFKC')
# => u'ãƒ†ã‚£ãƒ­ãƒ»ãƒ•ã‚£ãƒŠãƒ¼ãƒ¬'

# Hiragana to alphabet å¹³å‡å===>ç½—é©¬å­—
jaconv.kana2alphabet(u'ã˜ã‚ƒã±ã‚“')
# => japan

# Alphabet to Hiragana ç½—é©¬å­—===>å¹³å‡å
jaconv.alphabet2kana(u'japan')
# => ã˜ã‚ƒã±ã‚“
```



# CentOS è¿œç¨‹

```
https://www.51sec.org/2020/07/06/install-configure-xfce-and-vnc-server-on-centos7/
	# æˆåŠŸ
	# æ³¨æ„vncserver çš„å¯†ç å’Œlinux è´¦å·çš„å¯†ç æ˜¯åˆ†å¼€çš„
	# è¦å¾—è®¾å¯†ç å…ˆåˆ‡æ¢æŸä¸ªlinux è´¦å·ï¼Œç„¶å rm ~/.vnc/passwd
	# vncserver # æç¤ºè¾“å…¥å¯†ç ï¼Œåé¢å†é—®è®¾ç½® view only å¯†ç ï¼Œé€‰æ‹©ä¸è®¾ç½®
# https://vitux.com/centos-vnc-server/
# https://serverspace.io/support/help/installing-and-configuring-a-vnc-server-on-centos-7/

VNC è¿æ¥å®¢æˆ·ç«¯ç”¨ Royal TSXï¼Œå…è´¹ç‰ˆå°±å¯ä»¥ã€‚åªèƒ½å»ºä¸€ä¸ªdocument
```



```
# https://www.getpagespeed.com/server-setup/clear-disk-space-centos
	æ¸…ç†ç©ºé—´
```





```
yum install -y epel-release && systemctl start xrdp && \
systemctl start xrdp && \
systemctl enable xrdp


firewall-cmd --zone=public  --add-port=3389/tcp --permanent
systemctl restart firewalld.service
```



```
# https://serverok.in/install-xfce-vnc-remote-desktop-on-centos-7

yum -y install epel-release & \
yum -y update

yum -y groupinstall "Server with GUI"
yum -y groupinstall "Xfce"
systemctl get-default
systemctl set-default graphical.target
systemctl isolate graphical.target
# yum groupremove "Xfce"
reboot


yum install -y tigervnc-server
vi ~/.vnc/xstartup
#!/bin/sh

unset SESSION_MANAGER
unset DBUS_SESSION_BUS_ADDRESS
/etc/X11/xinit/xinitrc
/bin/startxfce4
# æ›¿æ¢æˆä¸Šé¢


vncserver
vncserver -kill :1


https://www.realvnc.com/en/connect/download/viewer/windows/
# VNC Viewer è¿æ¥
209.141.34.77:1
```



```
# æŸ¥çœ‹ç«¯å£
netstat -lntp | grep vnc
```



## ä¸­æ–‡



```
locale -a |grep "zh_CN"
	yum groupinstall "fonts" -y # æ²¡æœ‰è¾“å‡ºåˆ™å®‰è£…

vi /etc/locale.conf
LANG="zh_CN.uft8"  # æ”¹æˆè¿™æ ·

source   /etc/locale.conf
echo $LANG 
date # æ˜¯å¦æˆåŠŸ

```



```
# æˆåŠŸï¼Œåªè¦å®‰è£…è¿™ä¸ª VNC å°±æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡äº†
wget http://mirror.centos.org/centos/7/os/x86_64/Packages/google-noto-sans-cjk-fonts-20141117-5.el7.noarch.rpm

yum install google-noto-sans-cjk-fonts-20141117-5.el7.noarch.rpm -y
```



# Syncthing  åŒæ­¥

```
# https://www.cnblogs.com/jackadam/p/8568833.html

sed 's/127.0.0.1/0.0.0.0/g' /root/.config/syncthing/config.xml
	# é»˜è®¤ç›‘å¬ç½‘ç»œæ˜¯127.0.0.1ï¼Œè¿œç¨‹ä¸èƒ½è®¿é—®

```





# FRP



```
frps.ini
[common]
bind_port = 7000

./frps -c frps.ini 
```



```
frpc.ini
[common]
server_addr = 209.141.34.77
server_port = 7000

[tcp_port]
type = tcp
local_ip = 127.0.0.1
local_port = 8085
remote_port = 7075

frpc.exe -c frpc.ini
```



```
209.141.34.77:7075 --> ä¼šè½¬åˆ°å†…ç½‘çš„8085
```









# NAS



```
linuxä½¿ç”¨LVMåˆå¹¶ç¡¬ç›˜
FreeNAS11.0-U4é…ç½®iSCSIï¼Œç»™ä½ ç”µè„‘å®‰è£…ä¸€ä¸ªè¿œç¨‹ç¡¬ç›˜
ISCSIå®ç°ç£ç›˜ç½‘ç»œå…±äº«ä»¥åŠLVMæ–¹å¼å…±äº«æ‹“å±•
ç”¨LVMï¼ŒæŠŠå››ä¸ªç›˜åœ¨é€»è¾‘ä¸Šé›†åˆæˆä¸€ä¸ªå¤§ç›˜ç»„ï¼Œå†åˆ†åŒºã€‚
```



```
ä»¥ FreeNAS ä¸¾ä¾‹ï¼Œåˆ›å»º iSCSI å­˜å‚¨çš„æ•°é‡æ²¡æœ‰é™åˆ¶ï¼Œè¿˜å¯ä»¥å¯¹å·²åˆ›å»ºçš„ iSCSI å­˜å‚¨æ‰§è¡ŒåŠ¨æ€æ‰©å®¹ï¼Œç»™ç”µè„‘æŒ‚è½½ä¸€å—æ— é™å®¹é‡çš„ç¡¬ç›˜ï¼Œå¾ˆç¾å¦™å§ã€‚
```



# Colab

```
# star()å¼€å§‹
# stop()ç»“æŸ

function getElementByXpath(path) {
       return document.evaluate(path, document, null, 
       XPathResult.FIRST_ORDERED_NODE_TYPE, null).singleNodeValue;
}
 
function reconnect(){
	  console.log('working')
	  getElementByXpath("//div[@id='top-toolbar']/colab-connect-button").click()
}
var a = setInterval(reconnect, 1*60*1000);
function stop(){
	 clearInterval(a)
}
function start(){
	 a = setInterval(reconnect, 1*60*1000);
}
```



# VMWare





# NTFS



```
yum install ntfsprogs  # for mkfs.ntfs
```





https://www.51ittech.com/knowledge-base/centos-7-install-vmware-workstation-15/



```
https://download3.vmware.com/software/wkst/file/VMware-Workstation-Full-15.1.0-13591040.x86_64.bundle
YG5H2-ANZ0H-M8ERY-TXZZZ-YKRV8
UG5J2-0ME12-M89WY-NPWXX-WQH88
UA5DR-2ZD4H-089FY-6YQ5T-YPRX6
GA590-86Y05-4806Y-X4PEE-ZV8E0
ZF582-0NW5N-H8D2P-0XZEE-Z22VA
YA18K-0WY8P-H85DY-L4NZG-X7RAD
```

```
# ä¿„ç½—æ–¯ç²¾ç®€ç‹‚äºº è¶…çº§ç²¾ç®€ç‰ˆé›†åˆ 
# http://y-os.net/?p=770

Windows7æ——èˆ°ç‰ˆ32ä½ ed2k://|file|cn_windows_7_ultimate_x86_dvd_x15-65907.iso|2604238848|D6F139D7A45E81B76199DDCCDDC4B509|/

Windows7æ——èˆ°ç‰ˆ64ä½ ed2k://|file|cn_windows_7_ultimate_x64_dvd_x15-66043.iso|3341268992|7DD7FA757CE6D2DB78B6901F81A6907A|/

Windows7ä¼ä¸šç‰ˆ32ä½ ed2k://|file|cn_windows_7_enterprise_x86_dvd_x15-70737.iso|2465783808|41ABFA74E57353B2F35BC33E56BD5202|/

Windows7ä¼ä¸šç‰ˆ64ä½ ed2k://|file|cn_windows_7_enterprise_x64_dvd_x15-70741.iso|3203516416|876DCF115C2EE28D74B178BE1A84AB3B|/

Windows7ä¸“ä¸šç‰ˆ32ä½ ed2k://|file|cn_windows_7_professional_x86_dvd_x15-65790.iso|2604238848|E812FBE758F05B485C5A858C22060785|/

Windows7ä¸“ä¸šç‰ˆ64ä½ ed2k://|file|cn_windows_7_professional_x64_dvd_x15-65791.iso|3341268992|3474800521D169FBF3F5E527CD835156|/

Windows7å®¶åº­é«˜çº§ç‰ˆ32ä½ ed2k://|file|cn_windows_7_home_premium_x86_dvd_x15-65717.iso|2604238848|98E1EB474F92343B06737F227665DF1C|/

Windows7å®¶åº­é«˜çº§ç‰ˆ64ä½ ed2k://|file|cn_windows_7_home_premium_x64_dvd_x15-65718.iso|3341268992|9F976045631A6A2162ABE32FC77C8ACC|/

Windows7å®¶åº­åˆçº§ç‰ˆ32ä½ ed2k://|file|cn_windows_7_home_basic_x86_dvd_x15-65975.iso|2604238848|AF82993DCF8F3D7AA08D54693691BB48|/

Windows7ç®€æ˜“ç‰ˆ32ä½ ed2k://|file|cn_windows_7_starter_x86_dvd_x15-69303.iso|2604238848|5A6796B2B6A97B3E372F7C37D3A42AA4|/

---------------------------------

Windows7è‹±æ–‡æ——èˆ°ç‰ˆ32ä½ ed2k://|file|en_windows_7_ultimate_x86_dvd_X15-65921.iso|2501894144|09902C7687C9CA86BD935BD0EFB61D3A|/

Windows7è‹±æ–‡æ——èˆ°ç‰ˆ64ä½ ed2k://|file|en_windows_7_ultimate_x64_dvd_X15-65922.iso|3224686592|6719AFC5486F38BE75F2DF39C8527113|/

Windows7ç¹ä½“ï¼ˆå°ï¼‰æ——èˆ°ç‰ˆ32ä½ ed2k://|file|tw_windows_7_ultimate_x86_dvd_x15-65908.iso|2578382848|D3570ECAED1D132724FCD399B523DB23|/

Windows7ç¹ä½“ï¼ˆå°ï¼‰æ——èˆ°ç‰ˆ64ä½ ed2k://|file|tw_windows_7_ultimate_x64_dvd_x15-65909.iso|3317223424|E6C906D22060285BE18929FADBA37F48|/

Windows7ç¹ä½“ï¼ˆæ¸¯ï¼‰æ——èˆ°ç‰ˆ32ä½ ed2k://|file|hk_windows_7_ultimate_x86_dvd_x15-65912.iso|2574176256|4AA63D85BEA48F5742BD22B8655363B2|/

Windows7ç¹ä½“ï¼ˆæ¸¯ï¼‰æ——èˆ°ç‰ˆ64ä½ ed2k://|file|hk_windows_7_ultimate_x64_dvd_x15-65911.iso|3313936384|917F16D04FBBFDE763A35E2A32595AD9|/

Windows7æ—¥æ–‡æ——èˆ°ç‰ˆ32ä½  ed2k://|file|ja_windows_7_ultimate_x86_dvd_x15-65939.iso|2503079936|B02221E9B203CD065155D395B8C56E7F|/

Windows7æ—¥æ–‡æ——èˆ°ç‰ˆ64ä½  ed2k://|file|ja_windows_7_ultimate_x64_dvd_x15-65940.iso|3241390080|826D4EF10382972267E39ECC011B81BA|/

Windows7å¤šå›½è¯­è¨€åŒ…32ä½  ed2k://|file|mu_windows_7_language_pack_x86_dvd_x15-73272.iso|1936062464|A5FB4917B281929F30256924D8D0715E|/

Windows7å¤šå›½è¯­è¨€åŒ…64ä½  ed2k://|file|mu_windows_7_language_pack_x64_dvd_x15-73276.iso|2306793472|21D6652E82D87305525366D5824AAFA2|/

---------------------------------

Windows Vista SP2ç®€ä½“ä¸­æ–‡32ä½  ed2k://|file|cn_windows_vista_with_sp2_x86_dvd_x15-36285.iso|3078893568|F50709974F03C63BB41B5CA0D406160D|/

Windows Vista SP2ç®€ä½“ä¸­æ–‡64ä½  ed2k://|file|cn_windows_vista_with_sp2_x64_dvd_x15-36322.iso|3817512960|3719CEC49ECC2D73FCF7AF152A42049A|/

Windows 2008 ä¼ä¸šç‰ˆ&æ ‡å‡†ç‰ˆ ç®€ä½“ä¸­æ–‡32ä½ ed2k://|file|cn_windows_server_standard_enterprise_and_datacenter_with_sp2_x86_dvd_x15-41045.iso|2190057472|E93B029C442F19024AA9EF8FB02AC90B|/

Windows 2008 ä¼ä¸šç‰ˆ&æ ‡å‡†ç‰ˆ ç®€ä½“ä¸­æ–‡64ä½ ed2k://|file|cn_windows_server_2008_standard_enterprise_and_datacenter_with_sp2_x64_dvd_x15-41319.iso|2952992768|5F2CA73C9DA296CB05E7C0319F7D0E62|/

Windows 2008 R2 ä¼ä¸šç‰ˆ&æ ‡å‡†ç‰ˆ ç®€ä½“ä¸­æ–‡64ä½ ed2k://|file|cn_windows_server_2008_r2_standard_enterprise_datacenter_web_vl_build_x64_dvd_x15-59777.iso|3270465536|1C7FDB37C0CEC1765A52CD49B2227CBE|/

==============================================
```


# whistle æŠ“åŒ…



https://wproxy.org/whistle/

https://github.com/whistle-plugins/examples



```
C:\Users\i\AppData\Roaming\npm
```





## 1. å¯åŠ¨ whistleï¼š 

```shell
npm run start
```

## 2. å®‰è£…æ’ä»¶ 

```shell
# npm å…¨å±€å®‰è£…ï¼Œè·Ÿæ™®é€š npm åŒ…å…¨å±€å®‰è£…ä¸€æ ·ï¼š
npm i -g whistle.autosave
```

## 3.å¯åŠ¨å‰ç«¯

```shell
# å‰ç«¯åœ¨æ’ä»¶æ ¹ç›®å½•ä¸‹çš„ publicæ–‡ä»¶å¤¹é‡Œè¾¹ï¼Œ \public\catchjsonã€‚ä¹Ÿæ˜¯å®‰è£…äº†ä¾èµ–çš„ã€‚
npm run serve
```

## å­˜åœ¨çš„é—®é¢˜

1. socket æ²¡æœ‰åšè¶…æ—¶éªŒè¯
2. è¿‡äºå¤æ‚





# BM25é«˜æ€§èƒ½å…¨æ–‡æ£€ç´¢

https://help.aliyun.com/zh/analyticdb/analyticdb-for-postgresql/user-guide/usage-guide  BM25é«˜æ€§èƒ½å…¨æ–‡æ£€ç´¢



https://www.v2ex.com/t/1146080

- https://blog.hiripple.com/zh

  åç«¯ supabase ï¼Œå‰ç«¯éƒ¨ç½²åœ¨ Vercel 



# CURL 



```
# æµåª’ä½“æµ‹è¯•
	# https://github.com/CoiaPrant/MediaUnlock_Test/edit/main/check.sh
		ç”±äºå›½å†…å¤–æµåª’ä½“å¹³å°å¯¹ä¸IPçš„é™åˆ¶ï¼Œå³ä½¿è´­ä¹°äº†å¯¹åº”åŒºåŸŸçš„VPSï¼Œä¸è¿›è¡Œä¸å¯æè¿°æ“ä½œçš„æƒ…å†µä¸‹æ˜¯æ— æ³•å¾—çŸ¥è¯¥VPSçš„IPæ˜¯å¦è§£é”æƒ³è¦æŸ¥è¯¢çš„æµåª’ä½“å¹³å°çš„ã€‚
	# https://hostloc.com/forum.php?mod=viewthread&tid=895976&extra=&highlight=buyvm&page=1
		buyvmæ˜¯frantechçš„åˆ†é”€å•†ï¼Œæœ€è¿‘æ­£å¼æ¨å‡ºäº†å…¨æ–°è§£é”å¤šæµåª’ä½“çš„VPSï¼Œä¸€æ¬¡æ€§å¸®ä½ æå®šå¾ˆå¤šå¾ˆå¤šå¹³æ—¶å¯¹IPè¦æ±‚ä¸¥æ ¼çš„å¹³å°

	# buyvmå®˜æ–¹æµåª’ä½“ä¼˜åŒ–æœºå™¨ä¸­å›½ç‰¹æ®Šç‰ˆChina Special - STREAM RYZEN
		ä½¿ç”¨æ³¨æ„ï¼š
		1ï¼Œè‡ªè¡ŒæŠŠæµåª’ä½“IPç»‘å®šåˆ°ç½‘å¡ï¼Œæ³¨æ„é¿å…å†²çªï¼Œæ¯”å¦‚eth0:1
		2ï¼Œåå°è®¾ç½®å‡ºç«™IPä¸ºæµåª’ä½“è§£é”IP
		3ï¼Œç›¸å…³ç¨‹åº å¯èƒ½ ä¹Ÿè¦ä¿®æ”¹å‡ºç«™IP
	
	# AbemaTV ä¸èƒ½çœ‹ï¼å°ç£èˆ‡é¦™æ¸¯è§£é™¤åœ°å€é™åˆ¶æ‡¶äººåŒ…
	

		ä½¿ç”¨çš„è¯ï¼Œéœ€è¦æœ‰æ—¥æœ¬çš„ipï¼Œè‡ªå·±vpsæˆ–é£æœºåœºéƒ½è¡Œ
		DNSè®¾ç½®ä¸º153.128.30.88

		ä»…æä¾›AbemaTV

		å¦‚æœæ— æ³•è§‚çœ‹ï¼Œå»è¿™é‡Œæµ‹è¯•
		www.dnsleaktest.com
		
		https://www.ablenet.jp/
			ablenet.jpä¹‹å‰ç”¨è¿‡ï¼Œæœºå™¨å·²ç»è¿‡æœŸåœæ‰äº†ï¼Œæ²¡æ³•ç»™ä½ åšæµ‹è¯•ï¼Œä½†æˆ‘çš„ä½¿ç”¨ç»éªŒéƒ½æ˜¯äº²èº«ä½“éªŒï¼Œæœ‰ä¸ª2ä¸ªIPæ®µç»™ä½ ä½œå‚è€ƒï¼š	128.22.141.Xã€128.22.130.Xï¼Œæ—¥æœ¬å¤§é˜ªåŸç”ŸIP
Netflixåªèƒ½çœ‹è‡ªåˆ¶å‰§ï¼Œç‰ˆæƒå‰§çœ‹ä¸äº†ï¼Œå¯ä»¥è§£é”å…¬ä¸»è¿ç»“æ—¥æœã€AbemaTVã€DMMè¿™äº›æ—¥æœ¬æœ¬åœ°æ¸¸æˆã€æµåª’ä½“æœåŠ¡ï¼Œç½‘ç»œæ ‡ç§°200Må¸¦å®½å…±äº«ï¼Œæµé‡ä¸é™ï¼Œå®é™…speedtestèƒ½è·‘å‡º100å¤šMè¿™æ ·ï¼Œå›å¤§é™†éæ™šé«˜å³°æœ€é«˜å¸¦å®½åªèƒ½å†æ‰“ä¸ªå¯¹æŠ˜ï¼Œç”šè‡³æ›´æ…¢ï¼Œä¸€æ—¦çŸ­æ—¶é—´å‡ºç°é«˜å¸¦å®½å ç”¨ï¼Œæ— è®ºæ˜¯è¿›ç½‘è¿˜æ˜¯å‡ºç½‘ï¼Œæ¯”å¦‚è¿è¡Œæµ‹è¯•è„šæœ¬ä¸‹è½½å…¨ä¸–ç•Œå¤šåœ°åŒºæµ‹è¯•èŠ‚ç‚¹1GBå¤§å°çš„æµ‹è¯•æ–‡ä»¶ï¼Œå°±ä¼šè¢«é™é€Ÿåˆ°10Mä»¥ä¸‹

		https://www.daehub.com/archives/9611.html
			

	    kagoya.jp
            ä½ å¯ä»¥è¯•è¯•kagoya.jpï¼ŒæŒ‰å¤©è®¡è´¹ï¼Œæœ€ä½é…æœˆä»˜ä»·æ ¼å’Œablenetå·®ä¸å¤šï¼Œå†…å­˜1Gï¼Œæ¯”ablenetæœ€ä½é…é«˜ä¸€å€ï¼Œæ¯”cloudsigmaæ—¥æœ¬æœ€ä½é…è¿˜ä¾¿å®œä¸€äº›

	
#!/bin/bash
shell_version="1.4.1";
UA_Browser="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.87 Safari/537.36";
UA_Dalvik="Dalvik/2.1.0 (Linux; U; Android 9; ALP-AL00 Build/HUAWEIALP-AL00)";
DisneyAuth="grant_type=urn%3Aietf%3Aparams%3Aoauth%3Agrant-type%3Atoken-exchange&latitude=0&longitude=0&platform=browser&subject_token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJiNDAzMjU0NS0yYmE2LTRiZGMtOGFlOS04ZWI3YTY2NzBjMTIiLCJhdWQiOiJ1cm46YmFtdGVjaDpzZXJ2aWNlOnRva2VuIiwibmJmIjoxNjIyNjM3OTE2LCJpc3MiOiJ1cm46YmFtdGVjaDpzZXJ2aWNlOmRldmljZSIsImV4cCI6MjQ4NjYzNzkxNiwiaWF0IjoxNjIyNjM3OTE2LCJqdGkiOiI0ZDUzMTIxMS0zMDJmLTQyNDctOWQ0ZC1lNDQ3MTFmMzNlZjkifQ.g-QUcXNzMJ8DwC9JqZbbkYUSKkB1p4JGW77OON5IwNUcTGTNRLyVIiR8mO6HFyShovsR38HRQGVa51b15iAmXg&subject_token_type=urn%3Abamtech%3Aparams%3Aoauth%3Atoken-type%3Adevice"
DisneyHeader="authorization: Bearer ZGlzbmV5JmJyb3dzZXImMS4wLjA.Cu56AgSfBTDag5NiRA81oLHkDZfu5L3CKadnefEAY84"
Font_Black="\033[30m";
Font_Red="\033[31m";
Font_Green="\033[32m";
Font_Yellow="\033[33m";
Font_Blue="\033[34m";
Font_Purple="\033[35m";
Font_SkyBlue="\033[36m";
Font_White="\033[37m";
Font_Suffix="\033[0m";
LOG_FILE="check.log";

clear;
echo -e "æµåª’ä½“è§£é”æµ‹è¯• MediaUnlock_Test" && echo -e "æµåª’ä½“è§£é”æµ‹è¯• MediaUnlock_Test" > ${LOG_FILE};
echo -e "${Font_Purple}é¡¹ç›®åœ°å€ https://github.com/CoiaPrant/MediaUnlock_Test ${Font_Suffix}" && echo -e "é¡¹ç›®åœ°å€ https://github.com/CoiaPrant/MediaUnlock_Test" >> ${LOG_FILE};
echo -e "${Font_Purple}BUGåé¦ˆ https://github.com/CoiaPrant/MediaUnlock_Test/issues${Font_Suffix}" && echo -e "BUGåé¦ˆ https://github.com/CoiaPrant/MediaUnlock_Test/issues" >> ${LOG_FILE};
echo -e "${Font_Purple}è”ç³»ä½œè€… https://t.me/CoiaPrant${Font_Suffix}" && echo -e "è”ç³»ä½œè€… https://t.me/CoiaPrant" >> ${LOG_FILE};
echo -e "${Font_Purple}ä¸ªäººé¢‘é“ https://t.me/CoiaPrant_Blog${Font_Suffix}" && echo -e "ä¸ªäººé¢‘é“ https://t.me/CoiaPrant_Blog" >> ${LOG_FILE};
echo -e "${Font_Purple}å£°æ˜ æœ¬æµ‹è¯•å·¥å…·æ ¹æ®GPL V3åè®®å¼€æºï¼Œä¸¥ç¦å€’å–${Font_Suffix}" && echo -e "å£°æ˜ æœ¬æµ‹è¯•å·¥å…·æ ¹æ®GPL V3åè®®å¼€æºï¼Œä¸¥ç¦å€’å–" >> ${LOG_FILE};
echo -e "${Font_Purple}æç¤º æœ¬å·¥å…·æµ‹è¯•ç»“æœä»…ä¾›å‚è€ƒï¼Œè¯·ä»¥å®é™…ä½¿ç”¨ä¸ºå‡†${Font_Suffix}" && echo -e "æç¤º æœ¬å·¥å…·æµ‹è¯•ç»“æœä»…ä¾›å‚è€ƒï¼Œè¯·ä»¥å®é™…ä½¿ç”¨ä¸ºå‡†" >> ${LOG_FILE};
echo -e "${Font_Purple}å›½å®¶ä»£ç  http://www.loglogo.com/front/countryCode/${Font_Suffix}" && echo -e "å›½å®¶ä»£ç  http://www.loglogo.com/front/countryCode/" >> ${LOG_FILE};
echo -e " ** å½“å‰ç‰ˆæœ¬: v${shell_version}" && echo -e " ** å½“å‰ç‰ˆæœ¬: v${shell_version}" >> ${LOG_FILE};
echo -e " ** ç³»ç»Ÿæ—¶é—´: $(date)" && echo -e " ** ç³»ç»Ÿæ—¶é—´: $(date)" >> ${LOG_FILE};

export LANG="en_US";
export LANGUAGE="en_US";
export LC_ALL="en_US";

function InstallJQ() {
    #å®‰è£…JQ
    if [ -e "/etc/redhat-release" ];then
        echo -e "${Font_Green}æ­£åœ¨å®‰è£…ä¾èµ–: epel-release${Font_Suffix}";
        yum install epel-release -y -q > /dev/null;
        echo -e "${Font_Green}æ­£åœ¨å®‰è£…ä¾èµ–: jq${Font_Suffix}";
        yum install jq -y -q > /dev/null;
        elif [[ $(cat /etc/os-release | grep '^ID=') =~ ubuntu ]] || [[ $(cat /etc/os-release | grep '^ID=') =~ debian ]];then
        echo -e "${Font_Green}æ­£åœ¨æ›´æ–°è½¯ä»¶åŒ…åˆ—è¡¨...${Font_Suffix}";
        apt-get update -y > /dev/null;
        echo -e "${Font_Green}æ­£åœ¨å®‰è£…ä¾èµ–: jq${Font_Suffix}";
        apt-get install jq -y > /dev/null;
        elif [[ $(cat /etc/issue | grep '^ID=') =~ alpine ]];then
        apk update > /dev/null;
        echo -e "${Font_Green}æ­£åœ¨å®‰è£…ä¾èµ–: jq${Font_Suffix}";
        apk add jq > /dev/null;
    else
        echo -e "${Font_Red}è¯·æ‰‹åŠ¨å®‰è£…jq${Font_Suffix}";
        exit;
    fi
}

function PharseJSON() {
    # ä½¿ç”¨æ–¹æ³•: PharseJSON "è¦è§£æçš„åŸJSONæ–‡æœ¬" "è¦è§£æçš„é”®å€¼"
    # Example: PharseJSON ""Value":"123456"" "Value" [è¿”å›ç»“æœ: 123456]
    echo -n $1 | jq -r .$2;
}

function PasteBin_Upload() {
    local uploadresult="$(curl -fsL -X POST \
        --url https://paste.ubuntu.com \
        --output /dev/null \
        --write-out "%{url_effective}\n" \
        --data-urlencode "content@${PASTEBIN_CONTENT:-/dev/stdin}" \
        --data "poster=${PASTEBIN_POSTER:-MediaUnlock_Test_By_CoiaPrant}" \
        --data "expiration=${PASTEBIN_EXPIRATION:-}" \
    --data "syntax=${PASTEBIN_SYNTAX:-text}")"
    if [ "$?" = "0" ]; then
        echo -e "${Font_Green}å·²ç”ŸæˆæŠ¥å‘Š ${uploadresult} ${Font_Suffix}";
    else
        echo -e "${Font_Red}ç”ŸæˆæŠ¥å‘Šå¤±è´¥ ${Font_Suffix}";
    fi
}

function GameTest_Steam(){
    echo -n -e " Steam Currency:\t\t\t->\c";
    local result=`curl --user-agent "${UA_Browser}" -${1} -fsSL --max-time 30 https://store.steampowered.com/app/761830 2>&1 | grep priceCurrency | cut -d '"' -f4`;
    
    if [ ! -n "$result" ]; then
        echo -n -e "\r Steam Currency:\t\t\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " Steam Currency:\t\t\tFailed (Network Connection)" >> ${LOG_FILE};
    else
        echo -n -e "\r Steam Currency:\t\t\t${Font_Green}${result}${Font_Suffix}\n" && echo -e " Steam Currency:\t\t\t${result}" >> ${LOG_FILE};
    fi
}

function MediaUnlockTest_HBONow() {
    echo -n -e " HBO Now:\t\t\t\t->\c";
    # å°è¯•è·å–æˆåŠŸçš„ç»“æœ
    local result=`curl --user-agent "${UA_Browser}" -${1} -fsSL --max-time 30 --write-out "%{url_effective}\n" --output /dev/null https://play.hbonow.com/ 2>&1`;
    if [[ "$result" != "curl"* ]]; then
        # ä¸‹è½½é¡µé¢æˆåŠŸï¼Œå¼€å§‹è§£æè·³è½¬
        if [ "${result}" = "https://play.hbonow.com" ] || [ "${result}" = "https://play.hbonow.com/" ]; then
            echo -n -e "\r HBO Now:\t\t\t\t${Font_Green}Yes${Font_Suffix}\n" && echo " HBO Now:\t\t\t\tYes" >> ${LOG_FILE};
            elif [ "${result}" = "http://hbogeo.cust.footprint.net/hbonow/geo.html" ] || [ "${result}" = "http://geocust.hbonow.com/hbonow/geo.html" ]; then
            echo -n -e "\r HBO Now:\t\t\t\t${Font_Red}No${Font_Suffix}\n" && echo -e " HBO Now:\t\t\t\tNo" >> ${LOG_FILE};
        else
            echo -n -e "\r HBO Now:\t\t\t\t${Font_Yellow}Failed (Parse Json)${Font_Suffix}\n" && echo -e " HBO Now:\t\t\t\tFailed (Parse Json)" >> ${LOG_FILE};
        fi
    else
        # ä¸‹è½½é¡µé¢å¤±è´¥ï¼Œè¿”å›é”™è¯¯ä»£ç 
        echo -n -e "\r HBO Now:\t\t\t\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " HBO Now:\t\t\t\tFailed (Network Connection)" >> ${LOG_FILE};
    fi
}

# æµåª’ä½“è§£é”æµ‹è¯•-åŠ¨ç”»ç–¯
function MediaUnlockTest_BahamutAnime() {
    echo -n -e " Bahamut Anime:\t\t\t\t->\c";
    local tmpresult=`curl -${1} --user-agent "${UA_Browser}" --max-time 30 -fsSL 'https://ani.gamer.com.tw/ajax/token.php?adID=89422&sn=14667' 2>&1`;
    if [[ "$tmpresult" == "curl"* ]]; then
        echo -n -e "\r Bahamut Anime:\t\t\t\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " Bahamut Anime:\t\t\t\tFailed (Network Connection)" >> ${LOG_FILE};
        return;
    fi
    
    local result="$(PharseJSON "$tmpresult" "animeSn")";
    
    if [ "$result" != "null" ]; then
        resultverify="$(echo $result | grep -oE '[0-9]{1,}')";
        if [ "$?" = "0" ]; then
            echo -n -e "\r Bahamut Anime:\t\t\t\t${Font_Green}Yes${Font_Suffix}\n" && echo -e " Bahamut Anime:\t\t\t\tYes" >> ${LOG_FILE};
        else
            echo -n -e "\r Bahamut Anime:\t\t\t\t${Font_Red}Failed (Parse Json)${Font_Suffix}\n" && echo -e " Bahamut Anime:\t\t\t\tFailed (Parse Json)" >> ${LOG_FILE};
        fi
    else
        local result="$(PharseJSON "$tmpresult" "error.code")";
        if [ "$result" != "null" ]; then
            resultverify="$(echo $result | grep -oE '[0-9]{1,}')";
            if [ "$?" = "0" ]; then
                echo -n -e "\r Bahamut Anime:\t\t\t\t${Font_Red}No${Font_Suffix}\n" && echo -e " Bahamut Anime:\t\t\t\tNo" >> ${LOG_FILE};
            else
                echo -n -e "\r Bahamut Anime:\t\t\t\t${Font_Red}Failed (Parse Json)${Font_Suffix}\n" && echo -e " Bahamut Anime:\t\t\t\tFailed (Parse Json)" >> ${LOG_FILE};
            fi
        else
            echo -n -e "\r Bahamut Anime:\t\t\t\t${Font_Red}Failed (Parse Json)${Font_Suffix}\n" && echo -e " Bahamut Anime:\t\t\t\tFailed (Parse Json)" >> ${LOG_FILE};
        fi
    fi
}

# æµåª’ä½“è§£é”æµ‹è¯•-å“”å“©å“”å“©å¤§é™†é™å®š
function MediaUnlockTest_BilibiliChinaMainland() {
    echo -n -e " BiliBili China Mainland Only:\t\t->\c";
    local randsession="$(cat /dev/urandom | head -n 32 | md5sum | head -c 32)";
    # å°è¯•è·å–æˆåŠŸçš„ç»“æœ
    local result=`curl --user-agent "${UA_Browser}" -${1} -fsSL --max-time 30 "https://api.bilibili.com/pgc/player/web/playurl?avid=82846771&qn=0&type=&otype=json&ep_id=307247&fourk=1&fnver=0&fnval=16&session=${randsession}&module=bangumi" 2>&1`;
    if [[ "$result" == "curl"* ]]; then
        echo -n -e "\r BiliBili China Mainland Only:\t\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " BiliBili China Mainland Only:\t\tFailed (Network Connection)" >> ${LOG_FILE};
        return;
    fi
    
    local result="$(PharseJSON "${result}" "code")";
    if [ "$?" -ne "0" ]; then
        echo -n -e "\r BiliBili China Mainland Only:\t\t${Font_Red}Failed (Parse Json)${Font_Suffix}\n" && echo -e " BiliBili China Mainland Only:\t\tFailed (Parse Json)" >> ${LOG_FILE};
        return;
    fi
    
    case ${result} in
        0)
            echo -n -e "\r BiliBili China Mainland Only:\t\t${Font_Green}Yes${Font_Suffix}\n" && echo -e " BiliBili China Mainland Only:\t\tYes" >> ${LOG_FILE};
        ;;
        -10403)
            echo -n -e "\r BiliBili China Mainland Only:\t\t${Font_Red}No${Font_Suffix}\n" && echo -e " BiliBili China Mainland Only:\t\tNo" >> ${LOG_FILE};
        ;;
        *)
            echo -n -e "\r BiliBili China Mainland Only:\t\t${Font_Red}Failed${Font_Suffix} ${Font_SkyBlue}(${result})${Font_Suffix}\n" && echo -e " BiliBili China Mainland Only:\t\tFailed (${result})" >> ${LOG_FILE};
        ;;
    esac
}

# æµåª’ä½“è§£é”æµ‹è¯•-å“”å“©å“”å“©æ¸¯æ¾³å°é™å®š
function MediaUnlockTest_BilibiliHKMCTW() {
    echo -n -e " BiliBili Hongkong/Macau/Taiwan:\t->\c";
    local randsession="$(cat /dev/urandom | head -n 32 | md5sum | head -c 32)";
    # å°è¯•è·å–æˆåŠŸçš„ç»“æœ
    local result=`curl --user-agent "${UA_Browser}" -${1} -fsSL --max-time 30 "https://api.bilibili.com/pgc/player/web/playurl?avid=18281381&cid=29892777&qn=0&type=&otype=json&ep_id=183799&fourk=1&fnver=0&fnval=16&session=${randsession}&module=bangumi" 2>&1`;
    if [[ "$result" == "curl"* ]]; then
        echo -n -e "\r BiliBili Hongkong/Macau/Taiwan:\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " BiliBili Hongkong/Macau/Taiwan:\tFailed (Network Connection)" >> ${LOG_FILE};
        return
    fi
    
    local result="$(PharseJSON "${result}" "code")";
    if [ "$?" -ne "0" ]; then
        echo -n -e "\r BiliBili Hongkong/Macau/Taiwan:\t${Font_Red}Failed (Parse Json)${Font_Suffix}\n" && echo -e " BiliBili Hongkong/Macau/Taiwan:\tFailed (Parse Json)" >> ${LOG_FILE};
        return;
    fi
    case ${result} in
        0)
            echo -n -e "\r BiliBili Hongkong/Macau/Taiwan:\t${Font_Green}Yes${Font_Suffix}\n" && echo -e " BiliBili Hongkong/Macau/Taiwan:\tYes" >> ${LOG_FILE};
        ;;
        -10403)
            echo -n -e "\r BiliBili Hongkong/Macau/Taiwan:\t${Font_Red}No${Font_Suffix}\n" && echo -e " BiliBili Hongkong/Macau/Taiwan:\tNo" >> ${LOG_FILE};
        ;;
        *)
            echo -n -e "\r BiliBili Hongkong/Macau/Taiwan:\t${Font_Red}Failed${Font_Suffix} ${Font_SkyBlue}(${result})${Font_Suffix}\n" && echo -e " BiliBili Hongkong/Macau/Taiwan:\tFailed (${result})" >> ${LOG_FILE};
        ;;
    esac
}

# æµåª’ä½“è§£é”æµ‹è¯•-å“”å“©å“”å“©å°æ¹¾é™å®š
function MediaUnlockTest_BilibiliTW() {
    echo -n -e " Bilibili Taiwan Only:\t\t\t->\c";
    local randsession="$(cat /dev/urandom | head -n 32 | md5sum | head -c 32)";
    # å°è¯•è·å–æˆåŠŸçš„ç»“æœ
    local result=`curl --user-agent "${UA_Browser}" -${1} -fsSL --max-time 30 "https://api.bilibili.com/pgc/player/web/playurl?avid=50762638&cid=100279344&qn=0&type=&otype=json&ep_id=268176&fourk=1&fnver=0&fnval=16&session=${randsession}&module=bangumi" 2>&1`;
    if [[ "$result" == "curl"* ]]; then
        echo -n -e "\r Bilibili Taiwan Only:\t\t\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " Bilibili Taiwan Only:Failed (Network Connection)" >> ${LOG_FILE};
        return;
    fi
    
    local result="$(PharseJSON "${result}" "code")";
    if [ "$?" -ne "0" ]; then
        echo -n -e "\r Bilibili Taiwan Only:\t\t\t${Font_Red}Failed (Parse Json)${Font_Suffix}\n" && echo -e " Bilibili Taiwan Only:Failed (Parse Json)" >> ${LOG_FILE};
        return;
    fi
    
    case ${result} in
        0)
            echo -n -e "\r Bilibili Taiwan Only:\t\t\t${Font_Green}Yes${Font_Suffix}\n" && echo -e " Bilibili Taiwan Only:\t\t\tYes" >> ${LOG_FILE};
        ;;
        -10403)
            echo -n -e "\r Bilibili Taiwan Only:\t\t\t${Font_Red}No${Font_Suffix}\n" && echo -e " Bilibili Taiwan Only:\t\t\tNo" >> ${LOG_FILE};
        ;;
        *)
            echo -n -e "\r Bilibili Taiwan Only:\t\t\t${Font_Red}Failed (${result})${Font_Suffix}\n" && echo " Bilibili Taiwan Only:Failed (${result})" >> ${LOG_FILE};
        ;;
    esac
}

# æµåª’ä½“è§£é”æµ‹è¯•-Abema.TV
#
function MediaUnlockTest_AbemaTV_IPTest() {
    echo -n -e " Abema.TV:\t\t\t\t->\c";
    #
    local result=`curl --user-agent "${UA_Dalvik}" -${1} -fsL --write-out %{http_code} --max-time 30 "https://api.abema.io/v1/ip/check?device=android" 2>&1`;
    if [[ "${result}" == "000" ]]; then
        echo -n -e "\r Abema.TV:\t\t\t\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " Abema.TV:\t\t\t\tFailed (Network Connection)" >> ${LOG_FILE};
        return;
    fi
    
    local result=`curl --user-agent "${UA_Dalvik}" -${1} -fsL --max-time 30 "https://api.abema.io/v1/ip/check?device=android" 2>&1`;
    if [ ! -n "$result" ]; then
        echo -n -e "\r Abema.TV:\t\t\t\t${Font_Red}No${Font_Suffix}\n" && echo -e " Abema.TV:\t\t\t\tNo" >> ${LOG_FILE};
        return;
    fi

    local result=$(PharseJSON "${result}" "isoCountryCode");
    if [[ "${result}" == "JP" ]];then
        echo -n -e "\r Abema.TV:\t\t\t\t${Font_Green}Yes${Font_Suffix}\n" && echo -e " Abema.TV:\t\t\t\tYes" >> ${LOG_FILE};
        return;
    fi
    echo -n -e "\r Abema.TV:\t\t\t\t${Font_Yellow}Oversea Only${Font_Suffix}\n" && echo -e " Abema.TV:\t\t\t\tOversea Only" >> ${LOG_FILE};
}

function MediaUnlockTest_PCRJP() {
    echo -n -e " Princess Connect Re:Dive Japan:\t->\c";
    local result=`curl --user-agent "${UA_Dalvik}" -${1} -fsL --write-out %{http_code} --output /dev/null --max-time 30 https://api-priconne-redive.cygames.jp/ 2>&1`;
    case $result in
        000)
            echo -n -e "\r Princess Connect Re:Dive Japan:\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " Princess Connect Re:Dive Japan:\tFailed (Network Connection)" >> ${LOG_FILE};
        ;;
        404)
            echo -n -e "\r Princess Connect Re:Dive Japan:\t${Font_Green}Yes${Font_Suffix}\n" && echo -e " Princess Connect Re:Dive Japan:\tYes" >> ${LOG_FILE};
        ;;
        403)
            echo -n -e "\r Princess Connect Re:Dive Japan:\t${Font_Red}No${Font_Suffix}\n" && echo -e " Princess Connect Re:Dive Japan:\tNo" >> ${LOG_FILE};
        ;;
        *)
            echo -n -e "\r Princess Connect Re:Dive Japan:\t${Font_Red}Failed (Unexpected Result: $result)${Font_Suffix}\n" && echo -e " Princess Connect Re:Dive Japan:\tFailed (Unexpected Result: $result)" >> ${LOG_FILE};
        ;;
    esac
}

function MediaUnlockTest_UMAJP() {
    echo -n -e " Pretty Derby Japan:\t\t\t->\c";
    local result=`curl --user-agent "${UA_Dalvik}" -${1} -fsL --write-out %{http_code} --output /dev/null --max-time 30 https://api-umamusume.cygames.jp/`;
    case ${result} in
        000)
            echo -n -e "\r Pretty Derby Japan:\t\t\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " Pretty Derby Japan:\t\t\tFailed (Network Connection)" >> ${LOG_FILE};
        ;;
        404)
            echo -n -e "\r Pretty Derby Japan:\t\t\t${Font_Green}Yes${Font_Suffix}\n" && echo -e " Pretty Derby Japan:\t\t\tYes" >> ${LOG_FILE};
        ;;
        403)
            echo -n -e "\r Pretty Derby Japan:\t\t\t${Font_Red}No${Font_Suffix}\n" && echo -e " Pretty Derby Japan:\t\t\tNo" >> ${LOG_FILE};
        ;;
        *)
            echo -n -e "\r Pretty Derby Japan:\t\t\t${Font_Red}Failed (Unexpected Result: $result)${Font_Suffix}\n" && echo -e " Pretty Derby Japan:\t\t\tFailed (Unexpected Result: $result)" >> ${LOG_FILE};
        ;;
    esac
}

function MediaUnlockTest_Kancolle() {
    echo -n -e " Kancolle Japan:\t\t\t->\c";
    local result=`curl --user-agent "${UA_Dalvik}" -${1} -fsL --write-out %{http_code} --output /dev/null --max-time 30 http://203.104.209.7/kcscontents/ 2>&1`;
    case ${result} in
        000)
            echo -n -e "\r Kancolle Japan:\t\t\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " Kancolle Japan:\t\t\tFailed (Network Connection)" >> ${LOG_FILE};
        ;;
        200)
            echo -n -e "\r Kancolle Japan:\t\t\t${Font_Green}Yes${Font_Suffix}\n" && echo -e " Kancolle Japan:\t\t\tYes" >> ${LOG_FILE};
        ;;
        403)
            echo -n -e "\r Kancolle Japan:\t\t\t${Font_Red}No${Font_Suffix}\n" && echo -e " Kancolle Japan:\t\t\tNo" >> ${LOG_FILE};
        ;;
        *)
            echo -n -e "\r Kancolle Japan:\t\t\t${Font_Red}Failed (Unexpected Result: $result)${Font_Suffix}\n" && echo -e " Kancolle Japan:\t\t\tFailed (Unexpected Result: $result)" >> ${LOG_FILE};
        ;;
    esac
}

function MediaUnlockTest_BBC() {
    echo -n -e " BBC:\t\t\t\t\t->\c";
    local result=`curl --user-agent "${UA_Browser}" -${1} -fsL --write-out %{http_code} --output /dev/null --max-time 30 http://ve-dash-uk.live.cf.md.bbci.co.uk/`;
    if [ "${result}" = "000" ]; then
        echo -n -e "\r BBC:\t\t\t\t\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " BBC:\t\t\t\t\tFailed (Network Connection)" >> ${LOG_FILE};
        elif [ "${result}" = "403" ]; then
        echo -n -e "\r BBC:\t\t\t\t\t${Font_Red}No${Font_Suffix}\n" && echo -e " BBC:\t\t\t\t\tNo" >> ${LOG_FILE};
        elif [ "${result}" = "404" ]; then
        echo -n -e "\r BBC:\t\t\t\t\t${Font_Green}Yes${Font_Suffix}\n" && echo -e " BBC:\t\t\t\t\tYes" >> ${LOG_FILE};
    else
        echo -n -e "\r BBC:\t\t\t\t\t${Font_Red}Failed (Unexpected Result: $result)${Font_Suffix}\n" && echo -e " BBC:\t\t\t\t\tFailed (Unexpected Result: $result)" >> ${LOG_FILE};
    fi
}

function MediaUnlockTest_Netflix() {
    echo -n -e " Netflix:\t\t\t\t->\c";
    local result=`curl -${1} --user-agent "${UA_Browser}" -sSL "https://www.netflix.com/" 2>&1`;
    if [ "$result" == "Not Available" ];then
        echo -n -e "\r Netflix:\t\t\t\t${Font_Red}Unsupport${Font_Suffix}\n" && echo -e " Netflix:\t\t\t\tUnsupport" >> ${LOG_FILE};
        return;
    fi
    
    if [[ "$result" == "curl"* ]];then
        echo -n -e "\r Netflix:\t\t\t\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " Netflix:\t\t\t\tFailed (Network Connection)" >> ${LOG_FILE};
        return;
    fi
    
    local result=`curl -${1} --user-agent "${UA_Browser}" -sL "https://www.netflix.com/title/80018499" 2>&1`;
    if [[ "$result" == *"page-404"* ]] || [[ "$result" == *"NSEZ-403"* ]];then
        echo -n -e "\r Netflix:\t\t\t\t${Font_Red}No${Font_Suffix}\n" && echo -e " Netflix:\t\t\t\tNo" >> ${LOG_FILE};
        return;
    fi
    
    local result1=`curl -${1} --user-agent "${UA_Browser}" -sL "https://www.netflix.com/title/70143836" 2>&1`;
    local result2=`curl -${1} --user-agent "${UA_Browser}" -sL "https://www.netflix.com/title/80027042" 2>&1`;
    local result3=`curl -${1} --user-agent "${UA_Browser}" -sL "https://www.netflix.com/title/70140425" 2>&1`;
    local result4=`curl -${1} --user-agent "${UA_Browser}" -sL "https://www.netflix.com/title/70283261" 2>&1`;
    local result5=`curl -${1} --user-agent "${UA_Browser}"-sL "https://www.netflix.com/title/70143860" 2>&1`;
    local result6=`curl -${1} --user-agent "${UA_Browser}" -sL "https://www.netflix.com/title/70202589" 2>&1`;
    
    if [[ "$result1" == *"page-404"* ]] && [[ "$result2" == *"page-404"* ]] && [[ "$result3" == *"page-404"* ]] && [[ "$result4" == *"page-404"* ]] && [[ "$result5" == *"page-404"* ]] && [[ "$result6" == *"page-404"* ]];then
        echo -n -e "\r Netflix:\t\t\t\t${Font_Yellow}Only Homemade${Font_Suffix}\n" && echo -e " Netflix:\t\t\t\tOnly Homemade" >> ${LOG_FILE};
        return;
    fi
    
    local region=`tr [:lower:] [:upper:] <<< $(curl -${1} --user-agent "${UA_Browser}" -fs --write-out %{redirect_url} --output /dev/null "https://www.netflix.com/title/80018499" | cut -d '/' -f4 | cut -d '-' -f1)` ;
    
    if [[ ! -n "$region" ]];then
        region="US";
    fi
    echo -n -e "\r Netflix:\t\t\t\t${Font_Green}Yes(Region: ${region})${Font_Suffix}\n" && echo -e " Netflix:\t\t\t\tYes(Region: ${region})" >> ${LOG_FILE};
    return;
}

function MediaUnlockTest_YouTube_Region() {
    echo -n -e " YouTube Region:\t\t\t->\c";
    local result=`curl --user-agent "${UA_Browser}" -${1} -sSL "https://www.youtube.com/" 2>&1`;
    
    if [[ "$result" == "curl"* ]];then
        echo -n -e "\r YouTube Region:\t\t\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " YouTube Region:\t\t\tFailed (Network Connection)" >> ${LOG_FILE};
        return;
    fi
    
    local result=`curl --user-agent "${UA_Browser}" -${1} -sL "https://www.youtube.com/red" | sed 's/,/\n/g' | grep "countryCode" | cut -d '"' -f4`;
    if [ -n "$result" ]; then
        echo -n -e "\r YouTube Region:\t\t\t${Font_Green}${result}${Font_Suffix}\n" && echo -e " YouTube Region:\t\t\t${result}" >> ${LOG_FILE};
        return;
    fi
    
    echo -n -e "\r YouTube Region:\t\t\t${Font_Red}No${Font_Suffix}\n" && echo -e " YouTube Region:\t\t\tNo" >> ${LOG_FILE};
    return;
}

function MediaUnlockTest_DisneyPlus() {
    echo -n -e " DisneyPlus:\t\t\t\t->\c";
    local result=`curl -${1} --user-agent "${UA_Browser}" -sSL "https://global.edge.bamgrid.com/token" 2>&1`;
    
    if [[ "$result" == "curl"* ]];then
        echo -n -e "\r DisneyPlus:\t\t\t\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " DisneyPlus:\t\t\t\tFailed (Network Connection)" >> ${LOG_FILE};
        return;
    fi
    
    local previewcheck=`curl -sSL -o /dev/null -L --max-time 30 -w '%{url_effective}\n' "https://disneyplus.com" 2>&1`;
    if [[ "${previewcheck}" == "curl"* ]];then
        echo -n -e "\r DisneyPlus:\t\t\t\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " DisneyPlus:\t\t\t\tFailed (Network Connection)" >> ${LOG_FILE};
        return;
    fi
    
    if [[ "${previewcheck}" == *"preview"* ]];then
        echo -n -e "\r DisneyPlus:\t\t\t\t${Font_Red}No${Font_Suffix}\n" && echo -e " DisneyPlus:\t\t\t\tNo" >> ${LOG_FILE};
        return;
    fi
    
    local result=`curl -${1} --user-agent "${UA_Browser}" -fs --write-out '%{redirect_url}\n' --output /dev/null "https://www.disneyplus.com" 2>&1`;
    if [[ "${website}" == "https://disneyplus.disney.co.jp/" ]];then
        echo -n -e "\r DisneyPlus:\t\t\t\t${Font_Green}Yes(Region: JP)${Font_Suffix}\n" && echo -e " DisneyPlus:\t\t\t\tYes(Region: JP)" >> ${LOG_FILE};
        return;
    fi
    
    local result=`curl -${1} -sSL --user-agent "$UA_Browser" -H "Content-Type: application/x-www-form-urlencoded" -H "${DisneyHeader}" -d "${DisneyAuth}" -X POST  "https://global.edge.bamgrid.com/token" 2>&1`;
    PharseJSON "${result}" "access_token" 2>&1 > /dev/null;
    if [[ "$?" -eq 0 ]]; then
        local region=$(curl -${1} -sSL https://www.disneyplus.com | grep 'region: ' | awk '{print $2}')
        if [ -n "$region" ];then
            echo -n -e "\r DisneyPlus:\t\t\t\t${Font_Green}Yes(Region: $region)${Font_Suffix}\n" && echo -e " DisneyPlus:\t\t\t\tYes(Region: $region)" >> ${LOG_FILE};
            return;
        fi
        echo -n -e "\r DisneyPlus:\t\t\t\t${Font_Green}Yes${Font_Suffix}\n" && echo -e " DisneyPlus:\t\t\t\tNo" >> ${LOG_FILE};
        return;
    fi
    echo -n -e "\r DisneyPlus:\t\t\t\t${Font_Red}No${Font_Suffix}\n" && echo -e " DisneyPlus:\t\t\t\tNo" >> ${LOG_FILE};
}

function MediaUnlockTest_Dazn() {
    echo -n -e " Dazn:\t\t\t\t\t->\c";
    local result=`curl -${1} -sSL --max-time 30 -X POST -H "Content-Type: application/json" -d '{"LandingPageKey":"generic","Languages":"zh-CN,zh,en","Platform":"web","PlatformAttributes":{},"Manufacturer":"","PromoCode":"","Version":"2"}' "https://startup.core.indazn.com/misl/v5/Startup" 2>&1`;
    if [[ "$result" == "curl"* ]];then
        echo -n -e "\r Dazn:\t\t\t\t\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " Dazn:\t\t\t\t\tFailed (Network Connection)" >> ${LOG_FILE};
        return;
    fi

    local region=`tr [:lower:] [:upper:] <<<$(PharseJSON "${result}" "Region.GeolocatedCountry")`;
    if [ ! -n "${result}" ]; then
        echo -n -e "\r Dazn:\t\t\t\t\t${Font_Red}Unsupport${Font_Suffix}\n" && echo -e " Dazn:\t\t\t\t\tUnsupport" >> ${LOG_FILE};
        return;
    fi

    if [[ "${region}" == "NULL" ]];then
        echo -n -e "\r Dazn:\t\t\t\t\t${Font_Red}No${Font_Suffix}\n" && echo -e " Dazn:\t\t\t\t\tNo" >> ${LOG_FILE}
        return;
    fi
    echo -n -e "\r Dazn:\t\t\t\t\t${Font_Green}Yes(Region: ${region})${Font_Suffix}\n" && echo -e " Dazn:\t\t\t\t\tYes(Region: ${region})" >> ${LOG_FILE}
}

function MediaUnlockTest_HuluJP() {
    echo -n -e " Hulu Japan:\t\t\t\t->\c";
    local result=`curl -${1} -sSL -o /dev/null --max-time 30 -w '%{url_effective}\n' "https://id.hulu.jp" 2>&1`;
    if [[ "$result" == "curl"* ]];then
        echo -n -e "\r Hulu Japan:\t\t\t\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " Hulu Japan:\t\t\t\tFailed (Network Connection)" >> ${LOG_FILE};
        return;
    fi
    
    if [[ "$result" == *"login"* ]];then
        echo -n -e "\r Hulu Japan:\t\t\t\t${Font_Green}Yes${Font_Suffix}\n" && echo -e " Hulu Japan:\t\t\t\tYes" >> ${LOG_FILE};
        return;
    fi
    echo -n -e "\r Hulu Japan:\t\t\t\t${Font_Red}No${Font_Suffix}\n" && echo -e " Hulu Japan:\t\t\t\tNo" >> ${LOG_FILE};
}

function MediaUnlockTest_MyTVSuper() {
    echo -n -e " MyTVSuper:\t\t\t\t->\c";
    local result=`curl -sSL -${1} --max-time 30 "https://www.mytvsuper.com/iptest.php" 2>&1`;
    
    if [[ "$result" == "curl"* ]];then
        echo -n -e "\r MyTVSuper:\t\t\t\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " MyTVSuper:\t\t\t\tFailed (Network Connection)" >> ${LOG_FILE};
        return;
    fi
    
    if [[ "$result" == *"HK"* ]];then
        echo -n -e "\r MyTVSuper:\t\t\t\t${Font_Green}Yes${Font_Suffix}\n" && echo -e " MyTVSuper:\t\t\t\tYes" >> ${LOG_FILE};
        return;
    fi
    echo -n -e "\r MyTVSuper:\t\t\t\t${Font_Red}No${Font_Suffix}\n" && echo -e " MyTVSuper:\t\t\t\tNo" >> ${LOG_FILE};
}

function MediaUnlockTest_NowE() {
    echo -n -e " Now E:\t\t\t\t\t->\c";
    local result=`curl -${1} -sSLk --max-time 30 -X POST -H "Content-Type: application/json" -d '{"contentId":"202105121370235","contentType":"Vod","pin":"","deviceId":"W-60b8d30a-9294-d251-617b-c12f9d0c","deviceType":"WEB"}' "https://webtvapi.nowe.com/16/1/getVodURL" 2>&1`;
    if [[ "${result}" == "curl"* ]];then
        echo -n -e "\r Now E:\t\t\t\t\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " Now E:\t\t\t\t\tFailed (Network Connection)" >> ${LOG_FILE};
        return;
    fi
    
    local result=$(PharseJSON "${result}" "responseCode");
    case ${result} in
        SUCCESS)
            echo -n -e "\r Now E:\t\t\t\t\t${Font_Green}Yes${Font_Suffix}\n" && echo -e " Now E:\t\t\t\t\tYes" >> ${LOG_FILE};
        ;;
        GEO_CHECK_FAIL)
            echo -n -e "\r Now E:\t\t\t\t\t${Font_Red}No${Font_Suffix}\n" && echo -e " Now E:\t\t\t\t\tNo" >> ${LOG_FILE};
        ;;
        *)
            echo -n -e "\r Now E:\t\t\t\t\t${Font_Red}Failed (Unexpected Result: $result)${Font_Suffix}\n" && echo -e " Now E:\t\t\t\t\tFailed (Unexpected Result: $result)" >> ${LOG_FILE};
        ;;
    esac
}

function MediaUnlockTest_ViuTV() {
    echo -n -e " Viu TV:\t\t\t\t->\c";
    local result=`curl -${1} -sSLk --max-time 30 -X POST -H "Content-Type: application/json" -d '{"callerReferenceNo":"20210603233037","productId":"202009041154906","contentId":"202009041154906","contentType":"Vod","mode":"prod","PIN":"password","cookie":"3c2c4eafe3b0d644b8","deviceId":"U5f1bf2bd8ff2ee000","deviceType":"ANDROID_WEB","format":"HLS"}' "https://api.viu.now.com/p8/3/getVodURL" 2>&1`;
    if [[ "${result}" == "curl"* ]];then
        echo -n -e "\r Viu TV:\t\t\t\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " Viu TV:\t\t\t\tFailed (Network Connection)" >> ${LOG_FILE};
        return;
    fi
    
    local result=$(PharseJSON "${result}" "responseCode");
    if [[ "$result" == "SUCCESS" ]]; then
        echo -n -e "\r Viu TV:\t\t\t\t${Font_Green}Yes${Font_Suffix}\n" && echo -e " Viu TV:\t\t\t\tYes" >> ${LOG_FILE};
        return
    fi
    
    if [[ "$result" == "GEO_CHECK_FAIL" ]]; then
        echo -n -e "\r Viu TV:\t\t\t\t${Font_Red}No${Font_Suffix}\n" && echo -e " Viu TV:\t\t\t\tNo" >> ${LOG_FILE};
        return;
    fi
    
    echo -n -e "\r Viu.TV:\t\t\t\t${Font_Red}Failed (Unexpected Result: $result)${Font_Suffix}\n" && echo -e " Viu TV:\t\t\t\tFailed (Unexpected Result: $result)" >> ${LOG_FILE};
}

function MediaUnlockTest_UNext() {
    echo -n -e " U Next:\t\t\t\t->\c";
    local result=`curl -${1} -sSL --max-time 30 "https://video-api.unext.jp/api/1/player?entity%5B%5D=playlist_url&episode_code=ED00148814&title_code=SID0028118&keyonly_flg=0&play_mode=caption&bitrate_low=1500" 2>&1`;
    if [[ "${result}" == "curl"* ]];then
        echo -n -e "\r U Next:\t\t\t\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " U Next:\t\t\t\tFailed (Network Connection)" >> ${LOG_FILE};
        return;
    fi
    
    local result=$(PharseJSON "${result}" "data.entities_data.playlist_url.result_status");
    if [[ "${result}" == "475" || "${result}" == "200" ]]; then
        echo -n -e "\r U Next:\t\t\t\t${Font_Green}Yes${Font_Suffix}\n" && echo -e " U Next:\t\t\t\tYes" >> ${LOG_FILE};
        return;
    fi
    
    if [[ "${result}" == "467" ]]; then
        echo -n -e "\r U Next:\t\t\t\t${Font_Red}No${Font_Suffix}\n" && echo -e " U Next:\t\t\t\tNo" >> ${LOG_FILE};
        return;
    fi
    echo -n -e "\r U Next:\t\t\t\t${Font_Red}Failed (Unexpected Result: ${result})${Font_Suffix}\n" && echo -e " U Next:\t\t\t\tFailed (Unexpected Result: ${result})" >> ${LOG_FILE};
}

function MediaUnlockTest_Paravi() {
    echo -n -e " Paravi:\t\t\t\t->\c";
    local result=`curl -${1} -sSL --max-time 30 -H "Content-Type: application/json" -d '{"meta_id":71885,"vuid":"3b64a775a4e38d90cc43ea4c7214702b","device_code":1,"app_id":1}' "https://api.paravi.jp/api/v1/playback/auth" 2>&1`;
    if [[ "$result" == "curl"* ]];then
        echo -n -e "\r Paravi:\t\t\t\t${Font_Red}Failed (Network Connection)${Font_Suffix}\n" && echo -e " Paravi:\t\t\t\tFailed (Network Connection)" >> ${LOG_FILE};
        return;
    fi
    
    if [[ "$(PharseJSON "${result}" "error.code" | awk '{print $2}' | cut -d ',' -f1)" == "2055" ]]; then
        echo -n -e "\r Paravi:\t\t\t\t${Font_Red}No${Font_Suffix}\n" && echo -e " Paravi:\t\t\t\tNo" >> ${LOG_FILE};
        return;
    fi
    
    local result=$(PharseJSON "${result}" "playback_validity_end_at");
    if [[ "${result}" != "null" ]]; then
        echo -n -e "\r Paravi:\t\t\t\t${Font_Green}Yes${Font_Suffix}\n" && echo -e " Paravi:\t\t\t\tYes" >> ${LOG_FILE};
        return;
    fi
    echo -n -e "\r Paravi:\t\t\t\t${Font_Red}No${Font_Suffix}\n" && echo -e " Paravi:\t\t\t\tNo" >> ${LOG_FILE};
}

function ISP(){
    local result=`curl -sSL -${1} "https://api.ip.sb/geoip" 2>&1`;
    if [[ "$result" == "curl"* ]];then
        return
    fi
    local ip=$(PharseJSON "${result}" "ip" 2>&1)
    local isp="$(PharseJSON "${result}" "isp" 2>&1) [$(PharseJSON "${result}" "country" 2>&1) $(PharseJSON "${result}" "city" 2>&1)]";
    if [ $? -eq 0 ];then
        echo " ** IP: ${ip}"
        echo " ** ISP: ${isp}" && echo " ** ISP: ${isp}" >> ${LOG_FILE};
    fi
}

function MediaUnlockTest() {
    ISP ${1};
    MediaUnlockTest_HBONow ${1};
    MediaUnlockTest_BBC ${1};
    
    MediaUnlockTest_MyTVSuper ${1};
    MediaUnlockTest_NowE ${1};
    MediaUnlockTest_ViuTV ${1};
    MediaUnlockTest_BahamutAnime ${1};
    MediaUnlockTest_BilibiliChinaMainland ${1};
    MediaUnlockTest_BilibiliHKMCTW ${1};
    MediaUnlockTest_BilibiliTW ${1};
    
    MediaUnlockTest_AbemaTV_IPTest ${1};
    MediaUnlockTest_Paravi ${1};
    MediaUnlockTest_UNext ${1};
    MediaUnlockTest_HuluJP ${1};
    MediaUnlockTest_PCRJP ${1};
    MediaUnlockTest_UMAJP ${1};
    MediaUnlockTest_Kancolle ${1};
    
    MediaUnlockTest_Dazn ${1};
    MediaUnlockTest_Netflix ${1};
    MediaUnlockTest_YouTube_Region ${1};
    MediaUnlockTest_DisneyPlus ${1};
    GameTest_Steam ${1};
}

curl -V > /dev/null 2>&1;
if [ $? -ne 0 ];then
    echo -e "${Font_Red}Please install curl${Font_Suffix}";
    exit;
fi

jq -V > /dev/null 2>&1;
if [ $? -ne 0 ];then
    InstallJQ;
fi
echo " ** æ­£åœ¨æµ‹è¯•IPv4è§£é”æƒ…å†µ" && echo " ** æ­£åœ¨æµ‹è¯•IPv4è§£é”æƒ…å†µ" >> ${LOG_FILE};
check4=`ping 1.1.1.1 -c 1 2>&1`;
if [[ "$check4" != *"unreachable"* ]] && [[ "$check4" != *"Unreachable"* ]];then
    MediaUnlockTest 4;
else
    echo -e "${Font_SkyBlue}å½“å‰ä¸»æœºä¸æ”¯æŒIPv4,è·³è¿‡...${Font_Suffix}" && echo "å½“å‰ä¸»æœºä¸æ”¯æŒIPv4,è·³è¿‡..." >> ${LOG_FILE};
fi

echo " ** æ­£åœ¨æµ‹è¯•IPv6è§£é”æƒ…å†µ" && echo " ** æ­£åœ¨æµ‹è¯•IPv6è§£é”æƒ…å†µ" >> ${LOG_FILE};
check6=`ping6 240c::6666 -c 1 2>&1`;
if [[ "$check6" != *"unreachable"* ]] && [[ "$check6" != *"Unreachable"* ]];then
    MediaUnlockTest 6;
else
    echo -e "${Font_SkyBlue}å½“å‰ä¸»æœºä¸æ”¯æŒIPv6,è·³è¿‡...${Font_Suffix}" && echo "å½“å‰ä¸»æœºä¸æ”¯æŒIPv6,è·³è¿‡..." >> ${LOG_FILE};
fi
echo -e "";
echo -e "${Font_Green}æœ¬æ¬¡æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ° ${LOG_FILE} ${Font_Suffix}";
cat ${LOG_FILE} | PasteBin_Upload;

```





# YY

```
https://github.com/tgbot-collection/YYeTsBot
https://github.com/ffffffff0x/Dork-Admin  # hack
https://github.com/hudunkey/Red-Team-links # hack
```



