{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "iAttention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "o64AZhvX7B6f"
      },
      "source": [
        "# https://github.com/foamliu/Transformer-v2  真大佬"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-oMo1nlO3U3",
        "outputId": "072fe563-187b-49b4-a306-149e4112e7c0"
      },
      "source": [
        "! git clone https://github.com/dlxj/NTU_MachineLearning.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NTU_MachineLearning'...\n",
            "remote: Enumerating objects: 1094, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 1094 (delta 11), reused 28 (delta 8), pack-reused 1059\u001b[K\n",
            "Receiving objects: 100% (1094/1094), 290.81 MiB | 37.41 MiB/s, done.\n",
            "Resolving deltas: 100% (221/221), done.\n",
            "Checking out files: 100% (774/774), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "md4Qb6Q2LXTz",
        "outputId": "1bfa00b2-358f-4d40-a7f3-5eb7b908a383"
      },
      "source": [
        "# ! git clone https://github.com/dlxj/NTU_MachineLearning.git\n",
        "\n",
        "import os\n",
        "os.chdir('/content/NTU_MachineLearning/') # HW8_Seq2Seq\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as torch_data\n",
        "import torch.utils.data.sampler as sampler\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# import nltk\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "# from nltk.translate.bleu_score import SmoothingFunction\n",
        "\n",
        "import numpy as np\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "import json\n",
        "import heapq as pq\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # 判斷是用 CPU 還是 GPU 執行運算\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def get_dictionary(data_path, language):\n",
        "    # 載入字典\n",
        "    with open(os.path.join(data_path, f'word2int_{language}.json'), \"r\", encoding='UTF-8') as f:\n",
        "      word2int = json.load(f)\n",
        "    with open(os.path.join(data_path, f'int2word_{language}.json'), \"r\", encoding='UTF-8') as f:\n",
        "      int2word = json.load(f)\n",
        "    return word2int, int2word\n",
        "\n",
        "def Data(data_path, type='training'):\n",
        "    data = []\n",
        "    with open(os.path.join(data_path, f'{type}.txt'), \"r\", encoding='UTF-8') as f:\n",
        "      for line in f:\n",
        "        data.append(line)\n",
        "    print (f'{type} dataset size: {len(data)}')\n",
        "    return data\n",
        "\n",
        "class LabelTransform(object):\n",
        "  def __init__(self, size, pad):\n",
        "    self.size = size\n",
        "    self.pad = pad\n",
        "\n",
        "  def __call__(self, label):\n",
        "    label = np.pad(label, (0, (self.size - label.shape[0])), mode='constant', constant_values=self.pad)\n",
        "    return label\n",
        "\n",
        "import re\n",
        "class TorchDataset(torch_data.Dataset):\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "        \n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  def __getitem__(self, Index):\n",
        "    # 先將中英文分開\n",
        "    sentences = self.data[Index]\n",
        "    sentences = re.split('[\\t\\n]', sentences)\n",
        "    sentences = list(filter(None, sentences))\n",
        "    #print (sentences)\n",
        "    assert len(sentences) == 2\n",
        "\n",
        "    # 預備特殊字元\n",
        "    BOS = word2int_en['<BOS>']\n",
        "    EOS = word2int_en['<EOS>']\n",
        "    UNK = word2int_en['<UNK>']\n",
        "\n",
        "    # 在開頭添加 <BOS>，在結尾添加 <EOS> ，不在字典的 subword (詞) 用 <UNK> 取代\n",
        "    en, cn = [BOS], [BOS]\n",
        "    # 將句子拆解為 subword 並轉為整數\n",
        "    sentence = re.split(' ', sentences[0])\n",
        "    sentence = list(filter(None, sentence))\n",
        "    #print (f'en: {sentence}')\n",
        "    for word in sentence:\n",
        "      en.append(word2int_en.get(word, UNK))\n",
        "    en.append(EOS)\n",
        "\n",
        "    # 將句子拆解為單詞並轉為整數\n",
        "    # e.g. < BOS >, we, are, friends, < EOS > --> 1, 28, 29, 205, 2\n",
        "    sentence = re.split(' ', sentences[1])\n",
        "    sentence = list(filter(None, sentence))\n",
        "    #print (f'cn: {sentence}')\n",
        "    for word in sentence:\n",
        "      cn.append(word2int_cn.get(word, UNK))\n",
        "    cn.append(EOS)\n",
        "\n",
        "    en, cn = np.asarray(en), np.asarray(cn)\n",
        "\n",
        "    # 用 <PAD> 將句子補到相同長度\n",
        "    en, cn = transform(en), transform(cn)\n",
        "    en, cn = torch.LongTensor(en), torch.LongTensor(cn)\n",
        "\n",
        "    return en, cn\n",
        "\n",
        "def infinite_iter(data_loader):\n",
        "  it = iter(data_loader)\n",
        "  while True:\n",
        "    try:\n",
        "      ret = next(it)\n",
        "      yield ret\n",
        "    except StopIteration:\n",
        "      it = iter(data_loader)\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, en_vocab_size, emb_dim, hid_dim, n_layers, dropout):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(en_vocab_size, emb_dim)  # 所有单词转换成向量表示，单词总数为en_vocab_size，每个单词用emb_dim 维向量表示\n",
        "    self.hid_dim = hid_dim\n",
        "    self.n_layers = n_layers\n",
        "    self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout, batch_first=True, bidirectional=True)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, input):\n",
        "    # input = [batch size, sequence len, vocab size]\n",
        "    embedding = self.embedding(input)\n",
        "    outputs, hidden = self.rnn(self.dropout(embedding))\n",
        "    # outputs = [batch size, sequence len, hid dim * directions]\n",
        "    # hidden =  [num_layers * directions, batch size  , hid dim]\n",
        "    # outputs 是最上層RNN的輸出\n",
        "        \n",
        "    return outputs, hidden\n",
        "\n",
        "class Attention(nn.Module):\n",
        "  def __init__(self, hid_dim):\n",
        "    super(Attention, self).__init__()\n",
        "    self.hid_dim = hid_dim\n",
        "    self.attn = nn.Linear((hid_dim * 2) + (hid_dim * 2), hid_dim)\n",
        "    self.v = nn.Linear(hid_dim, 1, bias = False)\n",
        "  \n",
        "  def forward(self, encoder_outputs, decoder_hidden):\n",
        "    # encoder_outputs = [batch size, sequence len, hid dim * directions]\n",
        "    # decoder_hidden = [num_layers, batch size, hid dim]\n",
        "    # 一般來說是取 Encoder 最後一層的 hidden state 來做 attention\n",
        "    # num_layers = 3\n",
        "    # TODO\n",
        "    src_len = encoder_outputs.shape[1]\n",
        "    decoder_hidden = decoder_hidden[0] + decoder_hidden[1] + decoder_hidden[2]\n",
        "    decoder_hidden = decoder_hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
        "\n",
        "    energy = torch.tanh(self.attn(torch.cat((encoder_outputs, decoder_hidden), dim = 2)))\n",
        "    attention = self.v(energy).squeeze(2)\n",
        "    \n",
        "    return F.softmax(attention, dim = 1)\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, cn_vocab_size, emb_dim, hid_dim, n_layers, dropout, isatt):\n",
        "    super().__init__()\n",
        "    self.cn_vocab_size = cn_vocab_size\n",
        "    self.hid_dim = hid_dim * 2\n",
        "    self.n_layers = n_layers\n",
        "    self.embedding = nn.Embedding(cn_vocab_size, emb_dim)\n",
        "    self.isatt = isatt\n",
        "    self.attention = Attention(hid_dim)\n",
        "    # 如果使用 Attention Mechanism 會使得輸入維度變化，請在這裡修改\n",
        "    # e.g. Attention 接在輸入後面會使得維度變化，所以輸入維度改為\n",
        "    # self.input_dim = emb_dim + hid_dim * 2 if isatt else emb_dim\n",
        "    self.input_dim = emb_dim\n",
        "    if isatt == False:\n",
        "        self.rnn = nn.GRU(self.input_dim, self.hid_dim, self.n_layers, dropout = dropout, batch_first=True)\n",
        "    else:\n",
        "        self.rnn = nn.GRU((emb_dim + hid_dim*2), self.hid_dim, n_layers, dropout= dropout, batch_first=True)\n",
        "\n",
        "    self.embedding2vocab1 = nn.Linear(self.hid_dim, self.hid_dim * 2)\n",
        "    self.embedding2vocab2 = nn.Linear(self.hid_dim * 2, self.hid_dim * 4)\n",
        "    self.embedding2vocab3 = nn.Linear(self.hid_dim * 4, self.cn_vocab_size)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, input, hidden, encoder_outputs):\n",
        "    # input = [batch size, vocab size]\n",
        "    # hidden = [batch size, n layers * directions, hid dim]\n",
        "    # Decoder 只會是單向，所以 directions=1\n",
        "    input = input.unsqueeze(1)\n",
        "    embedded = self.dropout(self.embedding(input))\n",
        "    # embedded = [batch size, 1, emb dim]\n",
        "    if self.isatt:\n",
        "        # TODO: 在這裡決定如何使用 Attention，e.g. 相加 或是 接在後面， 請注意維度變化\n",
        "        attn = self.attention(encoder_outputs, hidden)\n",
        "        attn = attn.unsqueeze(1)\n",
        "        weighted = torch.bmm(attn, encoder_outputs)\n",
        "        rnn_input = torch.cat((embedded, weighted), dim=2)\n",
        "        output, hidden = self.rnn(rnn_input, hidden)\n",
        "\n",
        "    else:\n",
        "        output, hidden = self.rnn(embedded, hidden)\n",
        "    # output = [batch size, 1, hid dim]\n",
        "    # hidden = [num_layers, batch size, hid dim]\n",
        "\n",
        "    # 將 RNN 的輸出轉為每個詞出現的機率\n",
        "    output = self.embedding2vocab1(output.squeeze(1))\n",
        "    output = self.embedding2vocab2(output)\n",
        "    prediction = self.embedding2vocab3(output)\n",
        "    # prediction = [batch size, vocab size]\n",
        "    return prediction, hidden\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder, decoder, device):\n",
        "    super().__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.device = device\n",
        "    assert encoder.n_layers == decoder.n_layers, \\\n",
        "            \"Encoder and decoder must have equal number of layers!\"\n",
        "            \n",
        "  def forward(self, input, target, teacher_forcing_ratio):\n",
        "    # input  = [batch size, input len, vocab size]\n",
        "    # target = [batch size, target len, vocab size]\n",
        "    # teacher_forcing_ratio 是有多少機率使用正確答案來訓練\n",
        "    batch_size = target.shape[0]\n",
        "    target_len = target.shape[1]\n",
        "    vocab_size = self.decoder.cn_vocab_size\n",
        "\n",
        "    # 準備一個儲存空間來儲存輸出\n",
        "    outputs = torch.zeros(batch_size, target_len, vocab_size).to(self.device)\n",
        "    # 將輸入放入 Encoder\n",
        "    encoder_outputs, hidden = self.encoder(input)\n",
        "    # Encoder 最後的隱藏層(hidden state) 用來初始化 Decoder\n",
        "    # encoder_outputs 主要是使用在 Attention\n",
        "    # 因為 Encoder 是雙向的RNN，所以需要將同一層兩個方向的 hidden state 接在一起\n",
        "    # hidden =  [num_layers * directions, batch size  , hid dim]  --> [num_layers, directions, batch size  , hid dim]\n",
        "    hidden = hidden.view(self.encoder.n_layers, 2, batch_size, -1)\n",
        "    hidden = torch.cat((hidden[:, -2, :, :], hidden[:, -1, :, :]), dim=2)\n",
        "    # 取的 <BOS> token\n",
        "    input = target[:, 0]\n",
        "    preds = []\n",
        "    for t in range(1, target_len):\n",
        "      output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
        "      outputs[:, t] = output\n",
        "      # 決定是否用正確答案來做訓練\n",
        "      teacher_force = random.random() <= teacher_forcing_ratio\n",
        "      # 取出機率最大的單詞\n",
        "      top1 = output.argmax(1)\n",
        "      # 如果是 teacher force 則用正解訓練，反之用自己預測的單詞做預測\n",
        "      input = target[:, t] if teacher_force and t < target_len else top1\n",
        "      preds.append(top1.unsqueeze(1))\n",
        "    preds = torch.cat(preds, 1)\n",
        "    return outputs, preds\n",
        "\n",
        "  def inference(self, input, target):\n",
        "    ########\n",
        "    # TODO #\n",
        "    ########\n",
        "    # 在這裡實施 Beam Search\n",
        "    # 此函式的 batch size = 1  \n",
        "    # input  = [batch size, input len, vocab size]\n",
        "    # target = [batch size, target len, vocab size]\n",
        "    batch_size = input.shape[0]\n",
        "    input_len = input.shape[1]        # 取得最大字數\n",
        "    vocab_size = self.decoder.cn_vocab_size\n",
        "\n",
        "    # 準備一個儲存空間來儲存輸出\n",
        "    outputs = torch.zeros(batch_size, input_len, vocab_size).to(self.device)\n",
        "    # 將輸入放入 Encoder\n",
        "    encoder_outputs, hidden = self.encoder(input)\n",
        "    # Encoder 最後的隱藏層(hidden state) 用來初始化 Decoder\n",
        "    # encoder_outputs 主要是使用在 Attention\n",
        "    # 因為 Encoder 是雙向的RNN，所以需要將同一層兩個方向的 hidden state 接在一起\n",
        "    # hidden =  [num_layers * directions, batch size  , hid dim]  --> [num_layers, directions, batch size  , hid dim]\n",
        "    hidden = hidden.view(self.encoder.n_layers, 2, batch_size, -1)\n",
        "    hidden = torch.cat((hidden[:, -2, :, :], hidden[:, -1, :, :]), dim=2)\n",
        "    # 取的 <BOS> token\n",
        "    input = target[:, 0]\n",
        "    if BEAM_SEARCH == False:\n",
        "      preds = []\n",
        "      for t in range(1, input_len):\n",
        "        output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
        "        # 將預測結果存起來\n",
        "        outputs[:, t] = output\n",
        "        # 取出機率最大的單詞\n",
        "        top1 = output.argmax(1)\n",
        "        input = top1\n",
        "        preds.append(top1.unsqueeze(1))\n",
        "      preds = torch.cat(preds, 1)\n",
        "      return outputs, preds\n",
        "    else:\n",
        "      if BEAM_WIDTH <= 1:\n",
        "        print('BEAM_WIDTH <= 1 !!')\n",
        "      \n",
        "      preds = []\n",
        "      for t in range(1, input_len):\n",
        "        if t == 1:\n",
        "          # first\n",
        "          output, hidden = self.decoder(input, hidden, encoder_outputs)\n",
        "          outputs[:,t] = output\n",
        "          output = F.log_softmax(output, dim = 1)\n",
        "          log_prob, indexs = torch.topk(output, BEAM_WIDTH)\n",
        "\n",
        "          for k, (log_p, idx) in enumerate(zip(log_prob[0], indexs[0])):\n",
        "            idx = idx.view(1)\n",
        "            pq.heappush(preds, [-log_p.clone().item(), [idx], hidden.clone(), outputs.clone()])\n",
        "        \n",
        "        else:\n",
        "          temp = []\n",
        "          for i in range(BEAM_WIDTH):\n",
        "            cur_p, cur_tokens, cur_hidden, cur_outputs = preds[i]\n",
        "            input = cur_tokens[-1]\n",
        "            output, cur_hidden = self.decoder(input, cur_hidden, encoder_outputs)\n",
        "            cur_outputs[:,t] = output\n",
        "            output = F.log_softmax(output, dim = 1)\n",
        "            log_prob, indexs = torch.topk(output, BEAM_WIDTH)\n",
        "            # print(log_prob)\n",
        "\n",
        "            for j, (log_p, idx) in enumerate(zip(log_prob[0], indexs[0])):\n",
        "              temp_p = cur_p\n",
        "              idx = idx.view(1)\n",
        "              tmp_token = cur_tokens + [idx]\n",
        "              temp_p -= log_p.item()\n",
        "              pq.heappush(temp, [temp_p, tmp_token, cur_hidden.clone(), cur_outputs.clone()])\n",
        "\n",
        "          preds = [pq.heappop(temp) for i in range(BEAM_WIDTH)]\n",
        "          # print(len(preds))\n",
        "          # print(len(preds[0]))\n",
        "          del temp\n",
        "      \n",
        "      preds = pq.heappop(preds)\n",
        "      _, preds, _, outputs= preds\n",
        "      preds = torch.LongTensor(preds).view(1, len(preds))\n",
        "      return outputs, preds\n",
        "\n",
        "def schedule_sampling(step, t_step, mode):\n",
        "    ########\n",
        "    # TODO #\n",
        "    ########\n",
        "    # teach force\n",
        "    # 請在這裡直接 return 0 來取消 Teacher Forcing\n",
        "    # 請在這裡實作 schedule_sampling 的策略\n",
        "    try:\n",
        "      mode, h_para = mode\n",
        "    except:\n",
        "      mode = MODE[0]\n",
        "    \n",
        "    if mode == 'Naive':\n",
        "      return TEACHER_FORCE_RATE\n",
        "    elif mode == 'Linear':\n",
        "      decrement = 1/t_step\n",
        "      return 1- decrement * step\n",
        "    elif mode == 'Exponential': # 0.999 \n",
        "      return h_para**step\n",
        "    elif mode == 'Inverse_Sigmoid':\n",
        "      return h_para / (h_para + np.exp(step/h_para)) # 800\n",
        "\n",
        "def train(model, optimizer, train_iter, loss_function, total_steps, summary_steps, train_dataset):\n",
        "  model.train()\n",
        "  model.zero_grad()\n",
        "  losses = []\n",
        "  loss_sum = 0.0\n",
        "\n",
        "  for step in range(summary_steps):\n",
        "    now_tf = schedule_sampling(total_steps + step, num_steps, MODE)\n",
        "    sources, targets = next(train_iter)\n",
        "    sources, targets = sources.to(device), targets.to(device)\n",
        "    outputs, preds = model(sources, targets, now_tf)\n",
        "    # targets 的第一個 token 是 <BOS> 所以忽略\n",
        "    outputs = outputs[:, 1:].reshape(-1, outputs.size(2))\n",
        "    targets = targets[:, 1:].reshape(-1)\n",
        "    loss = loss_function(outputs, targets)\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_sum += loss.item()\n",
        "    if (step + 1) % 5 == 0:\n",
        "      loss_sum = loss_sum / 5\n",
        "      print (\"\\r\", \"train [{}] loss: {:.3f}, Perplexity: {:.3f}, teach: {:.3f}      \".format(total_steps + step + 1, loss_sum, np.exp(loss_sum), now_tf), end=\" \")\n",
        "      losses.append(loss_sum)\n",
        "      loss_sum = 0.0\n",
        "\n",
        "  return model, optimizer, losses\n",
        "\n",
        "def tokens2sentence(outputs, int2word):\n",
        "  sentences = []\n",
        "  for tokens in outputs:\n",
        "    sentence = []\n",
        "    for token in tokens:\n",
        "      word = int2word[str(int(token))]\n",
        "      if word == '<EOS>':\n",
        "        break\n",
        "      sentence.append(word)\n",
        "    sentences.append(sentence)\n",
        "  \n",
        "  return sentences\n",
        "\n",
        "\n",
        "\n",
        "def computebleu(sentences, targets):\n",
        "  score = 0 \n",
        "  assert (len(sentences) == len(targets))\n",
        "\n",
        "  def cut_token(sentence):\n",
        "    tmp = []\n",
        "    for token in sentence:\n",
        "      if token == '<UNK>' or token.isdigit() or len(bytes(token[0], encoding='utf-8')) == 1:\n",
        "        tmp.append(token)\n",
        "      else:\n",
        "        tmp += [word for word in token]\n",
        "    return tmp \n",
        "\n",
        "  for sentence, target in zip(sentences, targets):\n",
        "    sentence = cut_token(sentence)\n",
        "    target = cut_token(target)\n",
        "    score += sentence_bleu([target], sentence, weights=(1, 0, 0, 0))                                                                                          \n",
        "  \n",
        "  return score\n",
        "\n",
        "def test(model, dataloader, loss_function):\n",
        "  model.eval()\n",
        "  loss_sum, bleu_score= 0.0, 0.0\n",
        "  n = 0\n",
        "  result = []\n",
        "  for sources, targets in dataloader:\n",
        "    sources, targets = sources.to(device), targets.to(device)\n",
        "    batch_size = sources.size(0)\n",
        "    outputs, preds = model.inference(sources, targets)\n",
        "    # targets 的第一個 token 是 <BOS> 所以忽略\n",
        "    outputs = outputs[:, 1:].reshape(-1, outputs.size(2))\n",
        "    targets = targets[:, 1:].reshape(-1)\n",
        "\n",
        "    loss = loss_function(outputs, targets)\n",
        "    loss_sum += loss.item()\n",
        "\n",
        "    # 將預測結果轉為文字\n",
        "    targets = targets.view(sources.size(0), -1)\n",
        "    preds = tokens2sentence(preds, int2word_cn)\n",
        "    sources = tokens2sentence(sources, int2word_en)\n",
        "    targets = tokens2sentence(targets, int2word_cn)\n",
        "    for source, pred, target in zip(sources, preds, targets):\n",
        "      result.append((source, pred, target))\n",
        "    # 計算 Bleu Score\n",
        "    bleu_score += computebleu(preds, targets)\n",
        "\n",
        "    n += batch_size\n",
        "\n",
        "  return loss_sum / len(dataloader), bleu_score / n, result\n",
        "\n",
        "\n",
        "def save_model(model, optimizer, store_model_path, step):\n",
        "  torch.save(model.state_dict(), f'{store_model_path}/model_{step}.ckpt')\n",
        "  return\n",
        "\n",
        "def Load_Model(model, load_model_path):\n",
        "  print(f'Load model from {load_model_path}')\n",
        "  model.load_state_dict(torch.load(f'{load_model_path}.ckpt'))\n",
        "  return model\n",
        "\n",
        "if  __name__ == \"__main__\": \n",
        "\n",
        "    input_path = './HW8_Seq2Seq/cmn-eng'\n",
        "    batch_size = 60\n",
        "    emb_dim = 256                    # 嵌入向量的维度，即用多少维来表示一个单词\n",
        "    hid_dim = 512                    # RNN 輸出和隱藏狀態的維度\n",
        "    n_layers = 3                     # RNN 要疊多少層\n",
        "    dropout = 0.5                    # dropout 是決定有多少的機率會將某個節點變為 0，主要是為了防止 overfitting ，一般來說是在訓練時使用，測試時則不使用\n",
        "    learning_rate = 0.00005\n",
        "    max_output_len = 50              # 最後輸出句子的最大長度\n",
        "    num_steps =  12000                # 總訓練次數\n",
        "    store_steps = 300                # 訓練多少次後須儲存模型\n",
        "    summary_steps = 300              # 訓練多少次後須檢驗是否有overfitting\n",
        "    load_model = False               # 是否需載入模型\n",
        "    store_model_path = \"./\"          # 儲存模型的位置\n",
        "    load_model_path = None           # 載入模型的位置 e.g. \"./ckpt/model_{step}\" \n",
        "    data_path = input_path           # 資料存放的位置\n",
        "    attention = True                 # 是否使用 Attention Mechanism\n",
        "\n",
        "\n",
        "    BEAM_SEARCH = False\n",
        "    BEAM_WIDTH = 3\n",
        "    TEACHER_FORCE_RATE = 0.5\n",
        "    # MODE = ['Linear']\n",
        "    # MODE = ['Exponential', 0.999]\n",
        "    MODE = ['Inverse_Sigmoid', 800]\n",
        "    \n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # 載入字典\n",
        "    word2int_en, int2word_en = get_dictionary(data_path, 'en')\n",
        "    word2int_cn, int2word_cn = get_dictionary(data_path, 'cn')\n",
        "    \n",
        "    en_vocab_size = len(word2int_en)\n",
        "    cn_vocab_size = len(word2int_cn)\n",
        "\n",
        "    # 加载训练数据\n",
        "\n",
        "\n",
        "    transform = LabelTransform(max_output_len, word2int_en['<PAD>'])\n",
        "    \n",
        "\n",
        "    train_dataset = TorchDataset(Data(data_path, type='training'))\n",
        "    train_loader = torch_data.DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
        "    train_iter = infinite_iter(train_loader)\n",
        "\n",
        "    val_dataset = TorchDataset(Data(data_path, type='validation'))\n",
        "    val_loader = torch_data.DataLoader(val_dataset, batch_size = 1, shuffle=False)\n",
        "    \n",
        "    # 建構模型\n",
        "    encoder = Encoder(en_vocab_size, emb_dim, hid_dim, n_layers, dropout)\n",
        "    decoder = Decoder(cn_vocab_size, emb_dim, hid_dim, n_layers, dropout, attention)\n",
        "\n",
        "    model = Seq2Seq(encoder, decoder, device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    if load_model:\n",
        "      model = load_model(model, load_model_path)\n",
        "    model = model.to(device)\n",
        "\n",
        "    loss_function = nn.CrossEntropyLoss(ignore_index=0)\n",
        "\n",
        "    train_losses, val_losses, bleu_scores = [], [], []\n",
        "    total_steps = 0\n",
        "\n",
        "    # show the teacher forcing scope for current setting by plot\n",
        "    tf = []\n",
        "    print('Now teacher forcing setting plot')\n",
        "    for i in range(num_steps):\n",
        "      tf.append(schedule_sampling(i, num_steps, MODE))\n",
        "    plt.plot(range(num_steps), tf)\n",
        "    plt.title('teacher forcing schedule')\n",
        "    plt.show()\n",
        "\n",
        "    #embedding = nn.Embedding(en_vocab_size, emb_dim)\n",
        "\n",
        "    while (total_steps < num_steps):\n",
        "      # 訓練模型\n",
        "      model, optimizer, loss = train(model, optimizer, train_iter, loss_function, total_steps, summary_steps, train_dataset)\n",
        "      train_losses += loss\n",
        "      # 檢驗模型\n",
        "      val_loss, bleu_score, result = test(model, val_loader, loss_function)\n",
        "      val_losses.append(val_loss)\n",
        "      bleu_scores.append(bleu_score)\n",
        "\n",
        "      total_steps += summary_steps\n",
        "      print (\"\\r\", \"val [{}] loss: {:.3f}, Perplexity: {:.3f}, blue score: {:.3f}       \".format(total_steps, val_loss, np.exp(val_loss), bleu_score))\n",
        "    \n",
        "      # 儲存模型和結果\n",
        "      if total_steps % store_steps == 0 or total_steps >= num_steps:\n",
        "        print(1)\n",
        "        save_model(model, optimizer, store_model_path, total_steps)\n",
        "        with open(f'{store_model_path}/output_{total_steps}.txt', 'w', encoding='UTF-8') as f:\n",
        "          for line in result:\n",
        "            print (line, file=f)\n",
        "    \n",
        "\n",
        "    load_model_path = f'{store_model_path}/model_{total_steps}'\n",
        "    print( load_model_path )\n",
        "    Load_Model(model, load_model_path)\n",
        "     \n",
        "\n",
        "    print(2)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training dataset size: 18000\n",
            "validation dataset size: 500\n",
            "Now teacher forcing setting plot\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXwV9b3/8dfnnOwJJAECQlZAsIKCYMriAvRaLdoKrVavK1q1aFtbb+3y0NvlWu9tf7be2l5vadVWrWCFWutCW3utte6CEERAQCDsiSxhC0kg+/f3xxnwmGYDTjJneT8fj/PImZnvmfl8zyTvzJmZM2POOUREJPYF/C5AREQiQ4EuIhInFOgiInFCgS4iEicU6CIicUKBLiISJxTo0iPM7BUzu6kH53+Kmb1rZjVm9rUIzrfIzGrNLBipeZ6ISL6PZnaXmT0e6bYSPRToCcbMtpjZJ/2uIwK+DbzsnOvjnLs/UjN1zm1zzmU551oiNU+R3qJAl6hmIe39nhYDq49znkknVpVIdFKgJxAzmwcUAX/ydit82xs/yczeMrMDZrbCzKaFveYLZrbW27WxycxubjPPmd6uj4NmttHMpodNLjazN73X/s3MBoS9rrNlvmJmPzSzN4FDwLA2y/wH8AngF14/RppZtpnNNbMqM9tqZt898o/AzK736viZme0F7jKzdDP7qde22sze8MaVmJk7EvpeLf/ZST9mefPYa2bf6+wTkJldZGZrvPlUmtk3e/h9HGpmr3qvexEIf900M6toU19ntXe4HIkizjk9EugBbAE+GTacD+wFLiL0D/58bzjPm/5pYDhgwFRCATvemzYBqPZeE/Dm9TFv2ivARmAkkO4N39PNZb4CbANGA0lAcjv9eAW4KWx4LvAc0AcoAdYDN3rTrgeaga9680sH5njzyAeCwFlAqvdaByR1ox+jgFrgHCAF+G+gKfz9bVPzDuBc73luL7yPi4D7vH5NAWqAx71p04CKjn43gLvC2na6HD2i56EtdLkGeN4597xzrtU59yJQRuiPF+fcX5xzG13Iq8DfgHO9194IPOKce9F7baVz7v2weT/qnFvvnDsMPAmc0Z1len7rnFvtnGt2zjV11gHvAOYVwJ3OuRrn3Bbgp8C1Yc0+cM79r3OuGWgAbgBu82pucc695Zxr6GARHfXj88CfnHNvOOcage8T+mfQkSZglJn1dc7td869442P+PtoZkXAx4HvOecanHOvAX/q7H3sRHfWl0QBBboUA5d5H6UPmNkBQlucgwHM7EIzW2xm+7xpF/HhR/dCQluPHdkZ9vwQkNWdZXq2H0MfBgDJwNawcVsJbVm2N78BQFoXtYfrqB9DwufrnDtEaMu1I5cSev+2ertCJnvje+J9HALsd87Vhb02/P05Ft1ZXxIFdHAo8bTdgtwOzHPOfbFtQzNLBf4IzAKec841mdmzhHa/HHnt8OOoocNldlJnZ/YQ2votBtZ444qAyg7mtweoJ1T7imNYTls7gFOODJhZOtC/o8bOuaXATDNLBm4ltLVdSA+8j2ZWDOSaWWZYqBfx4ftQB2SEtQ8Cece6HIku2kJPPLv46EHGx4GLzexTZhY0szTvgFkBof3CqUAV0GxmFwIXhL32YeALZnaemQXMLN/MPtaNGjpb5jFzoVMMnwR+aGZ9vDC73VtOe+1bgUeA+8xsiFfDZO8f2LF4yuvHWWaWQmi/s7XX0MxSzOxqM8v2diEdBFq9yRF/H51zWwntFvmBt+xzgIvDXrseSDOzT3v/YL5LaF0f03K6UaP0IgV64vl/wHe9j87fdM5tB2YC/04ouLcD3wICzrka4GuEwnI/cBWw8MiMnHNLgC8APyN0UO9VQlvJnepsmSfQr68S2urcBLwBPEEotDvyTWAVsBTYB/z4WJfvnFvtLXcBoa31WmA3oX307bkW2GJmB4FbgKu9+fTU+3gVMNHr338QOnB85LXVwJeB3xD6JFMHfOSsl2NYjkQJc043uBCJBDPLAg4AI5xzm/2uRxKP/sOKnAAzu9jMMswsk9Bpi6sInf4n0usU6CInZibwgfcYAVzh9LFXfKJdLiIicUJb6CIiccK389AHDBjgSkpK/Fq8iEhMWrZs2R7nXLvfGfAt0EtKSigrK/Nr8SIiMcnMOvzGr3a5iIjECQW6iEicUKCLiMQJBbqISJxQoIuIxIkuA93MHjGz3Wb2XgfTzczuN7NyM1tpZuMjX6aIiHSlO1vovwWmdzL9QkJfeR4BzAZ+deJliYjIseryPHTn3GtmVtJJk5nAXO/6FYvNLMfMBjvndkSoxo9YumUfr2/YQ1LASAoayYEASUEjKRggOWAEA0Zy0BsXCJAcDBsX8NoFjZSkAOnJQdKOPgKkBAOYtXs5axGRqBeJLxbl89Hbe1V44/4p0M1sNqGteIqKio5rYe9s3c/9L204rtd2xYyjIZ+eHCQ1ORT66clBstKS6JuWTN/0JPqkJbd5nkTf9GQGZKYyoE8KGSm6EZSI9L5eTR7n3EPAQwClpaXHdVWwm6cOZ/aUYbS0OppbHU0trTS3OJpaQz9bjowLm9bceuTnh+MaW1o53NhCfXMLhxtbaGj2hpuOjGulvrmF+sYWDje1sLe2kS176jhY38zBw000t3ZcfkZKkAFZqQzISiGvTyoDslIZnJ1GQW4GBbnpFORmMLBPKoGAPg2ISOREItArCd0X8YgCPnovx4gzM283C6QlB3tyUe1yzlHf1MrB+iZq6puoPhwK+T21DeypbWRPbQNVNQ3sqW1g8546lmzex/5DH71xfUowwJCcNIr6ZzJiYFboMagPJw/MIjs9udf7JCKxLxKBvhC41cwWELrdVXVP7T+PFmZGekqQ9JQgg/qmdes1hxtbqDxwmIr9h6jYf9h7HPICfy/1Ta1H2w7qm8rp+dmcUZjD2MIcxuTnkJ2hkBeRznUZ6GY2H5gGDDCzCkL3JkwGcM49ADwPXASUA4cI3RtR2khPCXLywCxOHpj1T9NaWh2V+w+zYXcN63fVsn5XDSsqDvD3tbuPthmWl8mkYf05e/gAJg/vT7/MlN4sX0RigG83uCgtLXW62mLnqg83saqimhUVB1i2dT9LNu+jtqEZMzj1pL584mN5TB89mNPy++rsHJEEYWbLnHOl7U5ToMeOppZWVlZU81b5Hl4v38OyrftpaXXk56RzwehBXDx2COMKcxTuInFMgR6n9tU18ve1u/jb6p28tmEPjc2tDM/L5LLSQi4Zl8/Abu7fF5HYoUBPADX1TTy/agd/KKugbOt+ggFj+uiTuOncoYwryvW7PBGJEAV6gtlYVcvvl25n/pJt1NQ3U1qcy+wpwzh/1CDtjhGJcQr0BFXb0MwfyrbzyJub2b7vMGMLsvnGBadw7ogBCnaRGKVAT3DNLa08s7ySn/99A5UHDjNxaD++95lRnJaf7XdpInKMOgt0XQ89ASQFA1xWWsg/vjmVu2eOZmNVLTN+8Qbfe/Y9qtt8g1VEYpcCPYGkJgWZNbmEl74xjVmTS/jd21v5xE9f4bl3K/Hrk5qIRI4CPQFlpydz14zR/OVr51LcP4PbFrzLrU8sZ19do9+licgJUKAnsFMH9+WpW87i29NP4W9rdnLBz17jtfVVfpclIsdJgZ7gggHjy9NO5rmvnEP/zBSue3QJ//P3DbR2cnlgEYlOCnQBYNSQvjzzlbP47Bn5/Ozv67nhsaUcOKRdMCKxRIEuR2WkJHHf5WP5r8+exlvle7nkV2+xbe8hv8sSkW5SoMtHmBnXTCpm3o0T2FvbyCW/epN3tx/wuywR6QYFurRr4rD+/PFLZ5GeEuSKhxbx8rrdXb9IRHylQJcOnTwwi6e/dDbD87K4ee4yXlyzy++SRKQTCnTpVF6fVJ64aRKnDu7Dlx5fxl9XxfXdBUVimgJdupSdkcy8myYytjCHW+cv54XVO/0uSUTaoUCXbumblsxjN0zg9Pxsvjp/OYs27vW7JBFpQ4Eu3ZaVmsSj13+c4n4ZfHFuGe9VVvtdkoiEUaDLMcnNTGHejRPJTk/mukeWsH2fzlMXiRYKdDlmJ2WnMffGCTS1tHLTY2XUNjT7XZKIoECX4zQ8L4tfXn0m5VW13DZ/OS269ouI7xToctzOGTGA/7h4FC+9v5uf/N/7fpcjkvCS/C5AYtusySWs21nDg69tYlxRLtNPO8nvkkQSlrbQ5YR9/+JRjC3I5ltPrdDFvER8pECXE5aaFOQXV43HgK888Q4NzS1+lySSkBToEhGF/TL46eVnsKqymh/9Za3f5YgkJAW6RMz5owZxw9lDeWzRVl7VrexEep0CXSLq29NPYcTALL791AqqDzX5XY5IQulWoJvZdDNbZ2blZnZHO9OLzOxlM1tuZivN7KLIlyqxIC05yH2Xn8He2ka+v/A9v8sRSShdBrqZBYE5wIXAKOBKMxvVptl3gSedc+OAK4BfRrpQiR2nF2TztfNG8Ny7H/DnlR/4XY5IwujOFvoEoNw5t8k51wgsAGa2aeOAvt7zbEB/xQnuy9OGM7Ygm/94brVuNi3SS7oT6PnA9rDhCm9cuLuAa8ysAnge+GpEqpOYlRQMcM+lYzhwuIkfPa+zXkR6Q6QOil4J/NY5VwBcBMwzs3+at5nNNrMyMyurqtJZEPHu1MF9uencoTxZVsHiTbp+ukhP606gVwKFYcMF3rhwNwJPAjjnFgFpwIC2M3LOPeScK3XOlebl5R1fxRJT/u28kRT2S+ffn1lFfZO+cCTSk7oT6EuBEWY21MxSCB30XNimzTbgPAAzO5VQoGsTXEhPCfJfnz2dTVV1/OqVjX6XIxLXugx051wzcCvwArCW0Nksq83sbjOb4TX7BvBFM1sBzAeud87peqoCwNSReXxmzGAeeHUjFft1rReRnmJ+5W5paakrKyvzZdnS+yoPHOa8n77CeacOYs5V4/0uRyRmmdky51xpe9P0TVHpFfk56dwydTh/WblDB0hFeogCXXrNzVOGMyQ7jR/8aY3ucCTSAxTo0mvSU4LcedGprN1xkAVLt/ldjkjcUaBLr/rMmMF8vCSXn724gTrdXFokohTo0qvMjDsuPJU9tQ088sZmv8sRiSsKdOl1Zxbncv6oQTz42ib21ek6LyKRokAXX3z7U6dwqLGZOS+X+12KSNxQoIsvRgzqw6XjC5i3aKu+bCQSIQp08c3Xzx8JBj97cYPfpYjEBQW6+GZITjqzJhXzzPIKNlXV+l2OSMxToIuvbp46nJSkAL/4h/ali5woBbr4Kq9PKtdMLObZdyvZvKfO73JEYpoCXXw3e+owkoPaShc5UQp08d3APmlcMym0lb5FW+kix02BLlHh5qnDSAoYv9B56SLHTYEuUWFgnzSunljMM8sr2bZX56WLHA8FukSNW6YOI2jGQ6/rVnUix0OBLlFjYN80Lhmfzx/KKqiqafC7HJGYo0CXqDJ7yjAaW1r57Vu6EqPIsVKgS1QZlpfF9NEnMW/RVmp1vXSRY6JAl6hzy9ThHKxvZv7buquRyLFQoEvUGVuYw+Rh/Xn4jc00Nrf6XY5IzFCgS1S6Zdpwdh6s59l3K/0uRSRmKNAlKk0ZMYBRg/vy4KsbaW11fpcjEhMU6BKVzIzZU4axsaqOVzdU+V2OSExQoEvUuuj0wQzqm6qbSYt0kwJdolZKUoBZk0t4fcMe1u+q8bsckainQJeodtWEIlKTAjz6prbSRbqiQJeolpuZwiXjC3j6nUr21TX6XY5IVFOgS9S74ewSGppbeeLtrX6XIhLVFOgS9UYM6sOUkXnMXbRVXzQS6US3At3MppvZOjMrN7M7OmhzuZmtMbPVZvZEZMuURHfD2SXsrmngL6s+8LsUkajVZaCbWRCYA1wIjAKuNLNRbdqMAO4EznbOjQb+rQdqlQQ2dWQeJw/M4uE3NuOcvmgk0p7ubKFPAMqdc5ucc43AAmBmmzZfBOY45/YDOOd2R7ZMSXRmxhfOLuG9yoOUbd3vdzkiUak7gZ4PbA8brvDGhRsJjDSzN81ssZlNb29GZjbbzMrMrKyqSt/+k2PzuXH59ElLYu4iHRwVaU+kDoomASOAacCVwK/NLKdtI+fcQ865UudcaV5eXoQWLYkiIyWJy84s5K+rdrD7YL3f5YhEne4EeiVQGDZc4I0LVwEsdM41Oec2A+sJBbxIRF07uZjmVsf8Jdu7biySYLoT6EuBEWY21MxSgCuAhW3aPEto6xwzG0BoF8ymCNYpAsDQAZlMGZnHE0u20tSiUxhFwnUZ6M65ZuBW4AVgLfCkc261md1tZjO8Zi8Ae81sDfAy8C3n3N6eKloS26xJxew62MCLa3b5XYpIVDG/TgErLS11ZWVlvixbYltLq2PKT16msF86C2ZP9rsckV5lZsucc6XtTdM3RSXmBAPGtZOLWbxpH+t26iqMIkco0CUmXV5aSEpSgHmLt/hdikjUUKBLTOqXmcLFY4bwzDuV1NQ3+V2OSFRQoEvMuu6sYuoaW3j6Hd1IWgQU6BLDxhTkMLYwh7mLtuj6LiIo0CXGzZpUzMaqOt7aqLNkRRToEtM+PWYw/TJTmLtoi9+liPhOgS4xLS05yOWlhby4ZhcfHDjsdzkivlKgS8y7emIRDpi/ZJvfpYj4SoEuMa+wXwb/cspA5i/ZrlvUSUJToEtcuHZyMXtqG/i/1Tv9LkXENwp0iQtTRuRR3D+DeYu2+F2KiG8U6BIXAgHjmonFLN2yn7U7DvpdjogvFOgSNy4rLSA1KcC8xbpFnSQmBbrEjZyMFGaMHcKzyys5qOu7SAJSoEtcmTW5hEONLTy9rMLvUkR6nQJd4srpBdmMLcxh3uKtur6LJBwFusSdI9d3WaTru0iCUaBL3Pn0mMHkZiTr4KgkHAW6xJ205CCXf7yQv63ZxY5qXd9FEocCXeLSNROLaXWO+Uu2+12KSK9RoEtcKuyXwSdOGcj8Jdt0fRdJGAp0iVvXTi6mqqaBF3R9F0kQCnSJW1NH5FHUL0MHRyVhKNAlbgUCxjWTiliyeR/v79T1XST+KdAlrl12ZiGpSQEe11a6JAAFusS13MwULh47hGfeqaRG13eROKdAl7h37aRi6hpbeGZ5pd+liPQoBbrEvbGFOYwtyGbuIl3fReKbAl0SwjWTiinfXcviTfv8LkWkxyjQJSFcPHYIORnJzFu8xe9SRHpMtwLdzKab2TozKzezOzppd6mZOTMrjVyJIicuLTnI5aWFvLB6F7sO1vtdjkiP6DLQzSwIzAEuBEYBV5rZqHba9QFuA96OdJEikXDk+i5PvL3N71JEekR3ttAnAOXOuU3OuUZgATCznXb/CfwY0OaPRKWi/hlMG5nH/CXbaGrR9V0k/nQn0POB8EvWVXjjjjKz8UChc+4vnc3IzGabWZmZlVVVVR1zsSIn6trJxeyuaeBvq3f5XYpIxJ3wQVEzCwD3Ad/oqq1z7iHnXKlzrjQvL+9EFy1yzKaOHEhhv3QdHJW41J1ArwQKw4YLvHFH9AFOA14xsy3AJGChDoxKNAoGjKsnFrN40z7W76rxuxyRiOpOoC8FRpjZUDNLAa4AFh6Z6Jyrds4NcM6VOOdKgMXADOdcWY9ULHKCLi8tJCUpwG/f2uJ3KSIR1WWgO+eagVuBF4C1wJPOudVmdreZzejpAkUirV9mCpeOz+ePyyrYV9fodzkiEdOtfejOueedcyOdc8Odcz/0xn3fObewnbbTtHUu0e7Gc4bS0NyqqzBKXNE3RSUhnTywD584JY+5i7ZQ39TidzkiEaFAl4R107nD2FPbyMIVH/hdikhEKNAlYZ01vD+nDu7Lw69v1lUYJS4o0CVhmRk3nTOUdbtqeH3DHr/LETlhCnRJaBePHcLAPqn8+vVNfpcicsIU6JLQUpICXHdWCa9v2MO6nfqikcQ2BbokvKsnFpGeHOQ32kqXGKdAl4SXk5HC5aUFPPtuJR8cOOx3OSLHTYEuAnxxyjCcQ/vSJaYp0EWAgtwMPjsun/lLtrG3tsHvckSOiwJdxHPL1OE0NLfy6Jtb/C5F5Lgo0EU8Jw/M4sLTTuKxRVs4WN/kdzkix0yBLhLmy9NOpqa+WRftkpikQBcJc1p+NlNH5vHw65s53KiLdklsUaCLtPGVT5zM3rpGFizd5ncpIsdEgS7SxoSh/Zg4tB+/fGWjttIlpijQRdrxjQtOoaqmQfvSJaYo0EXaMWFoP84dMYBfvbqRuoZmv8sR6RYFukgHbj9/JPvqGnUzaYkZCnSRDowryuW8jw3kwVc3Un1Y56VL9FOgi3Ti6+eP5GB9Mw+/sdnvUkS6pEAX6cRp+dlceNpJPPLGZvboGi8S5RToIl34xgWncLiphftf2uB3KSKdUqCLdOHkgVlcNaGI3729jY1VtX6XI9IhBbpIN9z2yRGkJwe556/v+12KSIcU6CLdMCArlS9NG86La3axeNNev8sRaZcCXaSbbjxnKEOy0/jR82tpbXV+lyPyTxToIt2UlhzkW9NPYWVFNX98p8LvckT+iQJd5BjMHJvPmcW53PPX96k+pC8bSXRRoIscg0DAuHvmaPYfauTev+kAqUSXbgW6mU03s3VmVm5md7Qz/XYzW2NmK83sJTMrjnypItFh9JBsZk0u4Xdvb2NVRbXf5Ygc1WWgm1kQmANcCIwCrjSzUW2aLQdKnXNjgKeAn0S6UJFocvsFI+mfmcp3n3tPB0glanRnC30CUO6c2+ScawQWADPDGzjnXnbOHfIGFwMFkS1TJLr0TUvmO5/+GCu2H+Dxt3XNdIkO3Qn0fGB72HCFN64jNwJ/bW+Cmc02szIzK6uqqup+lSJR6LNn5HPuiAHc89f32b7vUNcvEOlhET0oambXAKXAve1Nd8495Jwrdc6V5uXlRXLRIr3OzLjn0jEYcOfTq3BOu17EX90J9EqgMGy4wBv3EWb2SeA7wAznnC5LJwkhPyedOy86lTfK97Bg6fauXyDSg7oT6EuBEWY21MxSgCuAheENzGwc8CChMN8d+TJFotdVE4qYPKw/P/zLWioPHPa7HElgXQa6c64ZuBV4AVgLPOmcW21md5vZDK/ZvUAW8Acze9fMFnYwO5G4EwgYP750DM45vv77d2nRWS/iE/Nrv19paakrKyvzZdkiPeHpdyq4/ckV3H7+SL523gi/y5E4ZWbLnHOl7U3TN0VFIuSS8QV8blw+P//7esq27PO7HElACnSRCLp75mgKcjO4bcG7utaL9DoFukgE9UlL5v4rx7G7pp6vLViu/enSqxToIhF2RmEOd80Yzavrq7jvxXV+lyMJJMnvAkTi0dUTi3mvspo5L2/ktCHZXHj6YL9LkgSgLXSRHnLXjNGMK8rhG39YweoPdFVG6XkKdJEekpoU5IFrziQ7PZkvPLqUiv263ov0LAW6SA8a1DeNx26YwOGmFq5/dCkHDjX6XZLEMQW6SA8bOagPv55Vyra9h/ji3DION7b4XZLEKQW6SC+YNKw/9/3rWMq27ueLc8uob1KoS+Qp0EV6yWfGDOHez4/lzY17mD1vmUJdIk6BLtKLPn9mAT++ZAyvra/ilseXafeLRJQCXaSXXf7xQu655HReXV/FNQ+/rQOlEjEKdBEfXDGhiDlXjWdVRTWXPbCIHdW6jrqcOAW6iE8uOn0wv73h4+yorudzc95iZcUBv0uSGKdAF/HRWcMH8OTNkwkGjM8/sIin36nwuySJYQp0EZ+NGtKXhbeezfiiHG5/cgU/+NNqGpp1sFSOnQJdJAr0z0pl3o0Tuf6sEh59cwufm/MW5btr/S5LYowCXSRKJAcD3DVjNL+eVcrOg/V85n9fZ96iLbTqmurSTQp0kShz/qhB/N9t5/Lxkn5877nVXP7gItbvqvG7LIkBCnSRKDSwbxpzb5jAvZ8fQ3lVLZ++/3XufeF96hqa/S5NopgCXSRKmRmXlRby0u1TuXjsEOa8vJGp977C44u30tTS6nd5EoUU6CJRrn9WKvddfgbPfPkshg7I4LvPvsenfv4azyyvoFnBLmEU6CIxYlxRLk/ePJlfzyolKWB8/fcrmPbfrzBv0RZd6EsAMOf8OYJeWlrqysrKfFm2SKxrbXW89P5ufvlKOcu3HSAnI5nPjy/gyolFDM/L8rs86UFmtsw5V9ruNAW6SOxyzvH25n3MW7SVF1bvpLnVMWlYPy4ZX8CnRp9Ednqy3yVKhCnQRRLA7pp6/lBWwe+XbmfbvkMkB42pI/P49JjBTBs5kNzMFL9LlAhQoIskEOccKyuq+fPKD/jzyh3sqK4nYDC2MIepI/OYdspAThvSl6SgDqHFIgW6SIJqbXWsqDjAK+uqeHV9FSsqDuAcZKYEGVeUy5nFuZSW5HJGYQ590rR7JhYo0EUEgH11jbxRvoeyLftYumU/7+88yJEIKO6fwakn9eXUwX05dXAfPnZSX/Jz0wkGzN+i5SM6C/Sk3i5GRPzTLzOFGWOHMGPsEABq6ptYvu0AKysOsGbHQdbuqOGFNTuPhnxy0Cjsl8HQ/pmUDAg9CnLSGdQ3jcHZaeRkJGOmwI8W3Qp0M5sO/A8QBH7jnLunzfRUYC5wJrAX+Ffn3JbIlioikdYnLZkpI/OYMjLv6Li6hmbe31lD+e4aNu85xJY9dWzZW8ebG/dQ3/TRLzKlJgU4KTuNk/qmMbBvGv0yksnNTKFfZgq5Gd4jM5l+mSlkpSaRmZJEQFv8PabLQDezIDAHOB+oAJaa2ULn3JqwZjcC+51zJ5vZFcCPgX/tiYJFpGdlpiZxZnFo/3q41lbH7poGPqg+zM7q+tDjYD07quvZVV3PqooD7D/URPXhps7nnxIkMzWJrNQkstJCIR8aDpKeEiQ1KUhqUiD0SA57nhQkNfnD5ylJAYIBIylgJAUDJAXs6HAwYCQHAx8ZTgoESAp+2CZghhlx9QmjO1voE4By59wmADNbAMwEwgN9JnCX9/wp4BdmZs6vHfQiEnGBgIW2xrPTOm3X3NLKgcNN7K9rZF9dI/sPNbH/UCO19c3UNoQedW1+Vh44TF1DM/VNLTQ0t9LQHPrZGwliBgYELBTyGAQsNHxk/JHgD7T5+eHrvGELa8+HbUIL+nDc184bcXS3VyR1J9Dzge1hw6C68/IAAAZwSURBVBXAxI7aOOeazawa6A/sCW9kZrOB2QBFRUXHWbKIRLOkYIABWakMyEo9ofk452hqcUfDvaG5lQYv8OubWmhsbqXFOZpbHC2tjuZWR0trK01thptbQ23aDrc6R6sDvJ+O0M9W58D72erAec+dcziOPMeb5o5OPzKPD9uDC+uLg6MjcnroC1+9elDUOfcQ8BCEznLpzWWLSGwxM1KSjJSkAH38LiZGdOebBZVAYdhwgTeu3TZmlgRkEzo4KiIivaQ7gb4UGGFmQ80sBbgCWNimzULgOu/554F/aP+5iEjv6nKXi7dP/FbgBUKnLT7inFttZncDZc65hcDDwDwzKwf2EQp9ERHpRd3ah+6cex54vs2474c9rwcui2xpIiJyLHR1HhGROKFAFxGJEwp0EZE4oUAXEYkTvl0+18yqgK3H+fIBtPkWagxTX6JPvPQD1JdodSJ9KXbO5bU3wbdAPxFmVtbR9YBjjfoSfeKlH6C+RKue6ot2uYiIxAkFuohInIjVQH/I7wIiSH2JPvHSD1BfolWP9CUm96GLiMg/i9UtdBERaUOBLiISJ2Iu0M1supmtM7NyM7vD73raMrNCM3vZzNaY2Wozu80b38/MXjSzDd7PXG+8mdn9Xn9Wmtn4sHld57XfYGbXdbTMXuhT0MyWm9mfveGhZva2V/PvvcsqY2ap3nC5N70kbB53euPXmdmnfOpHjpk9ZWbvm9laM5sci+vFzL7u/W69Z2bzzSwtVtaJmT1iZrvN7L2wcRFbB2Z2ppmt8l5zv1nP3TC0g77c6/1+rTSzZ8wsJ2xau+93R5nW0TrtlDtya6UYeBC6fO9GYBiQAqwARvldV5saBwPjved9gPXAKOAnwB3e+DuAH3vPLwL+Suh2g5OAt73x/YBN3s9c73muT326HXgC+LM3/CRwhff8AeBL3vMvAw94z68Afu89H+Wtq1RgqLcOgz704zHgJu95CpATa+uF0O0eNwPpYevi+lhZJ8AUYDzwXti4iK0DYInX1rzXXtjLfbkASPKe/zisL+2+33SSaR2t005r6s0/qAi8gZOBF8KG7wTu9LuuLmp+DjgfWAcM9sYNBtZ5zx8Ergxrv86bfiXwYNj4j7TrxfoLgJeAfwH+7P2h7An7pT26TghdM3+y9zzJa2dt11N4u17sRzahILQ242NqvfDh/Xv7ee/xn4FPxdI6AUrahGBE1oE37f2w8R9p1xt9aTPtc8DvvOftvt90kGmd/Z119oi1XS7t3bA636dauuR9vB0HvA0Mcs7t8CbtBAZ5zzvqU7T09efAt4FWb7g/cMA519xOXR+5WThw5Gbh0dCXoUAV8Ki3++g3ZpZJjK0X51wl8N/ANmAHofd4GbG5To6I1DrI9563He+XGwh9SoBj70tnf2cdirVAjxlmlgX8Efg359zB8Gku9C836s8XNbPPALudc8v8riUCkgh9PP6Vc24cUEfo4/1RsbBevP3LMwn9gxoCZALTfS0qgmJhHXSHmX0HaAZ+15vLjbVA784Nq31nZsmEwvx3zrmnvdG7zGywN30wsNsb31GfoqGvZwMzzGwLsIDQbpf/AXIsdDPwtnV1dLPwaOhLBVDhnHvbG36KUMDH2nr5JLDZOVflnGsCnia0nmJxnRwRqXVQ6T1vO75Xmdn1wGeAq71/UHDsfdlLx+u0Q7EW6N25YbWvvKPqDwNrnXP3hU0Kv5H2dYT2rR8ZP8s7oj8JqPY+fr4AXGBmud5W2QXeuF7jnLvTOVfgnCsh9F7/wzl3NfAyoZuBt9eX9m4WvhC4wjvjYigwgtDBq17jnNsJbDezU7xR5wFriL31sg2YZGYZ3u/akX7E3DoJE5F14E07aGaTvPdmVti8eoWZTSe0i3KGc+5Q2KSO3u92M81bRx2t0471xkGQCB+EuIjQmSMbge/4XU879Z1D6CPjSuBd73ERoX1iLwEbgL8D/bz2Bszx+rMKKA2b1w1Auff4gs/9msaHZ7kM834Zy4E/AKne+DRvuNybPizs9d/x+riOHjzzoIs+nAGUeevmWUJnSMTcegF+ALwPvAfMI3TmREysE2A+oX3/TYQ+Nd0YyXUAlHrvy0bgF7Q5CN4LfSkntE/8yN/+A12933SQaR2t084e+uq/iEiciLVdLiIi0gEFuohInFCgi4jECQW6iEicUKCLiMQJBbqISJxQoIuIxIn/D3Ed8luKQAbvAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            " train [300] loss: 4.347, Perplexity: 77.236, teach: 0.998       "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " val [300] loss: 6.155, Perplexity: 470.836, blue score: 0.208       \n",
            "1\n",
            " val [600] loss: 6.257, Perplexity: 521.492, blue score: 0.251       \n",
            "1\n",
            " val [900] loss: 5.567, Perplexity: 261.715, blue score: 0.290       \n",
            "1\n",
            " val [1200] loss: 5.474, Perplexity: 238.419, blue score: 0.300       \n",
            "1\n",
            " val [1500] loss: 5.251, Perplexity: 190.827, blue score: 0.320       \n",
            "1\n",
            " val [1800] loss: 5.089, Perplexity: 162.165, blue score: 0.330       \n",
            "1\n",
            " val [2100] loss: 5.043, Perplexity: 154.877, blue score: 0.340       \n",
            "1\n",
            " val [2400] loss: 5.040, Perplexity: 154.480, blue score: 0.342       \n",
            "1\n",
            " val [2700] loss: 4.755, Perplexity: 116.113, blue score: 0.352       \n",
            "1\n",
            " val [3000] loss: 4.836, Perplexity: 125.924, blue score: 0.368       \n",
            "1\n",
            " val [3300] loss: 4.446, Perplexity: 85.263, blue score: 0.377       \n",
            "1\n",
            " val [3600] loss: 4.272, Perplexity: 71.685, blue score: 0.373       \n",
            "1\n",
            " val [3900] loss: 4.251, Perplexity: 70.149, blue score: 0.387       \n",
            "1\n",
            " val [4200] loss: 3.992, Perplexity: 54.166, blue score: 0.394       \n",
            "1\n",
            " val [4500] loss: 3.848, Perplexity: 46.886, blue score: 0.396       \n",
            "1\n",
            " val [4800] loss: 3.725, Perplexity: 41.455, blue score: 0.408       \n",
            "1\n",
            " val [5100] loss: 3.722, Perplexity: 41.357, blue score: 0.403       \n",
            "1\n",
            " val [5400] loss: 3.594, Perplexity: 36.378, blue score: 0.421       \n",
            "1\n",
            " val [5700] loss: 3.540, Perplexity: 34.470, blue score: 0.414       \n",
            "1\n",
            " val [6000] loss: 3.464, Perplexity: 31.938, blue score: 0.418       \n",
            "1\n",
            " val [6300] loss: 3.432, Perplexity: 30.953, blue score: 0.419       \n",
            "1\n",
            " val [6600] loss: 3.404, Perplexity: 30.072, blue score: 0.428       \n",
            "1\n",
            " val [6900] loss: 3.384, Perplexity: 29.481, blue score: 0.435       \n",
            "1\n",
            " val [7200] loss: 3.325, Perplexity: 27.786, blue score: 0.436       \n",
            "1\n",
            " val [7500] loss: 3.338, Perplexity: 28.160, blue score: 0.433       \n",
            "1\n",
            " val [7800] loss: 3.302, Perplexity: 27.157, blue score: 0.442       \n",
            "1\n",
            " val [8100] loss: 3.301, Perplexity: 27.147, blue score: 0.439       \n",
            "1\n",
            " val [8400] loss: 3.273, Perplexity: 26.390, blue score: 0.447       \n",
            "1\n",
            " val [8700] loss: 3.269, Perplexity: 26.284, blue score: 0.444       \n",
            "1\n",
            " val [9000] loss: 3.279, Perplexity: 26.541, blue score: 0.445       \n",
            "1\n",
            " val [9300] loss: 3.286, Perplexity: 26.729, blue score: 0.443       \n",
            "1\n",
            " val [9600] loss: 3.243, Perplexity: 25.613, blue score: 0.442       \n",
            "1\n",
            " val [9900] loss: 3.259, Perplexity: 26.028, blue score: 0.455       \n",
            "1\n",
            " val [10200] loss: 3.269, Perplexity: 26.273, blue score: 0.450       \n",
            "1\n",
            " val [10500] loss: 3.261, Perplexity: 26.073, blue score: 0.456       \n",
            "1\n",
            " val [10800] loss: 3.297, Perplexity: 27.018, blue score: 0.450       \n",
            "1\n",
            " val [11100] loss: 3.281, Perplexity: 26.604, blue score: 0.456       \n",
            "1\n",
            " val [11400] loss: 3.272, Perplexity: 26.375, blue score: 0.459       \n",
            "1\n",
            " val [11700] loss: 3.249, Perplexity: 25.754, blue score: 0.464       \n",
            "1\n",
            " val [12000] loss: 3.269, Perplexity: 26.294, blue score: 0.462       \n",
            "1\n",
            ".//model_12000\n",
            "Load model from .//model_12000\n",
            "2\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}