{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenNMT-py  Quickstart",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wdk5PfJiW8KU"
      },
      "source": [
        "Check Nvidia Drivers, make sure you have chosen GPU runtime from Runtime > Change runtime type > GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHvEf7ZMW_oj",
        "outputId": "a0422f46-2e77-4340-fa04-9878582bac75"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Apr 13 00:14:59 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KDu3mEZjRA1D"
      },
      "source": [
        "**Step 0: Install OpenNMT-py**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RLOWbG_RDgD"
      },
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install OpenNMT-py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdqojW07XGVb"
      },
      "source": [
        "**Step 1: Prepare the data**\n",
        "\n",
        "To get started, we propose to download a toy English-German dataset for machine translation containing 10k tokenized sentences:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1aSKimtzXNpr"
      },
      "source": [
        "!wget https://s3.amazonaws.com/opennmt-trainingdata/toy-ende.tar.gz\n",
        "!tar xf toy-ende.tar.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7DTfTcc7XjId"
      },
      "source": [
        "The data consists of parallel source (src) and target (tgt) data containing one sentence per line with tokens separated by a space:\n",
        "\n",
        "src-train.txt\n",
        "\n",
        "tgt-train.txt\n",
        "\n",
        "src-val.txt\n",
        "\n",
        "tgt-val.txt\n",
        "\n",
        "Validation files are used to evaluate the convergence of the training. It usually contains no more than 5k sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlkRq9_oXnB0"
      },
      "source": [
        "!head -n 3 toy-ende/src-train.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyFBYn8WcBn3"
      },
      "source": [
        "We need to build a YAML configuration file to specify the data that will be used:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaazqR27cDa8"
      },
      "source": [
        "%%bash\n",
        "cat <<EOF > toy_en_de.yaml\n",
        "# toy_en_de.yaml\n",
        "\n",
        "## Where the samples will be written\n",
        "save_data: toy-ende/run/example\n",
        "## Where the vocab(s) will be written\n",
        "src_vocab: toy-ende/run/example.vocab.src\n",
        "tgt_vocab: toy-ende/run/example.vocab.tgt\n",
        "# Prevent overwriting existing files in the folder\n",
        "overwrite: False\n",
        "\n",
        "# Corpus opts:\n",
        "data:\n",
        "    corpus_1:\n",
        "        path_src: toy-ende/src-train.txt\n",
        "        path_tgt: toy-ende/tgt-train.txt\n",
        "    valid:\n",
        "        path_src: toy-ende/src-val.txt\n",
        "        path_tgt: toy-ende/tgt-val.txt\n",
        "\n",
        "EOF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAbZHee4coKb"
      },
      "source": [
        "From this configuration, we can build the vocab(s), that will be necessary to train the model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMCXdJT2co93"
      },
      "source": [
        "!onmt_build_vocab -config toy_en_de.yaml -n_sample 10000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4wLeBKBctEs"
      },
      "source": [
        "Notes:\n",
        "\n",
        "-n_sample is required here â€“ it represents the number of lines sampled from each corpus to build the vocab.\n",
        "\n",
        "This configuration is the simplest possible, without any tokenization or other transforms. See other example configurations for more complex pipelines."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvfiYDE2cvOl"
      },
      "source": [
        "**Step 2: Train the model**\n",
        "\n",
        "To train a model, we need to add the following to the YAML configuration file:\n",
        "\n",
        "the vocabulary path(s) that will be used: can be that generated by onmt_build_vocab;\n",
        "\n",
        "training specific parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_k1CJ0WdLlm"
      },
      "source": [
        "%%bash \n",
        "cat <<EOF >> toy_en_de.yaml\n",
        "# Vocabulary files that were just created\n",
        "src_vocab: toy-ende/run/example.vocab.src\n",
        "tgt_vocab: toy-ende/run/example.vocab.tgt\n",
        "\n",
        "# Train on a single GPU\n",
        "world_size: 1\n",
        "gpu_ranks: [0]\n",
        "\n",
        "# Where to save the checkpoints\n",
        "save_model: toy-ende/run/model\n",
        "save_checkpoint_steps: 500\n",
        "train_steps: 1000\n",
        "valid_steps: 500\n",
        "EOF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgjyeEyVdcAR"
      },
      "source": [
        "Then you can simply run:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnWQpabuddc9"
      },
      "source": [
        "!onmt_train -config toy_en_de.yaml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Y4lltv_dfQk"
      },
      "source": [
        "This configuration will run the default model, which consists of a 2-layer LSTM with 500 hidden units on both the encoder and decoder. It will run on a single GPU (world_size 1 & gpu_ranks [0]).\n",
        "\n",
        "Before the training process actually starts, the *.vocab.pt together with *.transforms.pt can be dumped to -save_data with configurations specified in -config yaml file by enabling the -dump_fields and -dump_transforms flags. It is also possible to generate transformed samples to simplify any potentially required visual inspection. The number of sample lines to dump per corpus is set with the -n_sample flag.\n",
        "\n",
        "For more advanded models and parameters, see other example configurations or the FAQ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_iIzy_-dqsR"
      },
      "source": [
        "**Step 3: Translate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kWMdbILdvTP"
      },
      "source": [
        "!onmt_translate -model toy-ende/run/model_step_1000.pt -src toy-ende/src-test.txt -output toy-ende/pred_1000.txt -gpu 0 -verbose"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLz4AJ74erb9"
      },
      "source": [
        "Now you have a model which you can use to predict on new data. We do this by running beam search. This will output predictions into toy-ende/pred_1000.txt.\n",
        "\n",
        "Note:\n",
        "\n",
        "The predictions are going to be quite terrible, as the demo dataset is small. Try running on some larger datasets! For example you can download millions of parallel sentences for translation or summarization."
      ]
    }
  ]
}