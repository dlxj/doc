{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "- https://willylan.medium.com/how-to-install-cuda-11-1-and-cudnn-v8-05-on-ubuntu-20-1-with-rtx3090-8e0b768faaa2"
      ],
      "metadata": {
        "id": "ND9QQm3VIa7h"
      },
      "id": "ND9QQm3VIa7h"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install CUDA 11.1"
      ],
      "metadata": {
        "id": "0aZ6XKyV220x"
      },
      "id": "0aZ6XKyV220x"
    },
    {
      "cell_type": "code",
      "source": [
        "!lsb_release -a"
      ],
      "metadata": {
        "id": "KrGEirDAXv1c"
      },
      "id": "KrGEirDAXv1c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!lsmod | grep -i nvidia"
      ],
      "metadata": {
        "id": "hBxaZcdYjO4D"
      },
      "id": "hBxaZcdYjO4D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo rmmod nvidia-drm"
      ],
      "metadata": {
        "id": "H0UPVUSdlZaw"
      },
      "id": "H0UPVUSdlZaw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo rmmod nvidia_uvm"
      ],
      "metadata": {
        "id": "Cv22-KTGld2-"
      },
      "id": "Cv22-KTGld2-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!modprobe -r nvidia_uvm"
      ],
      "metadata": {
        "id": "emVR11zhkOmc"
      },
      "id": "emVR11zhkOmc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill -9 962560  "
      ],
      "metadata": {
        "id": "10scqNvxjoRV"
      },
      "id": "10scqNvxjoRV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ubuntu-drivers autoinstall"
      ],
      "metadata": {
        "id": "eLygv3VsaZ7d"
      },
      "id": "eLygv3VsaZ7d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "#Uninstall the current CUDA version\n",
        "apt-get --purge remove cuda nvidia* libnvidia-*\n",
        "dpkg -l | grep cuda- | awk '{print $2}' | xargs -n1 dpkg --purge\n",
        "apt-get remove cuda-*\n",
        "apt autoremove\n",
        "apt-get update"
      ],
      "metadata": {
        "id": "l_WnZrNl26So"
      },
      "id": "l_WnZrNl26So",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "apt-get --purge -y remove 'cuda*'\n",
        "apt-get --purge -y remove 'nvidia*'\n",
        "apt-get --purge -y remove 'libnvidia*'\n",
        "apt-get --purge -y remove 'libnccl*'\n",
        "apt-get remove --auto-remove nvidia-cuda-toolkit\n",
        "apt autoremove -y\n",
        "apt-get clean\n",
        "apt update -qq;"
      ],
      "metadata": {
        "id": "HtZ4Ud1S2_2y"
      },
      "id": "HtZ4Ud1S2_2y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "sudo apt-get purge *nvidia*\n",
        "sudo apt remove --autoremove nvidia-*\n",
        "sudo rm /etc/apt/sources.list.d/cuda*\n",
        "sudo apt remove --autoremove nvidia-cuda-toolkit\n",
        "sudo apt-get autoremove && sudo apt-get autoclean\n",
        "sudo rm -rf /usr/local/cuda*"
      ],
      "metadata": {
        "id": "QSC9QqewY72u"
      },
      "id": "QSC9QqewY72u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "apt-get update\n",
        "apt-get upgrade"
      ],
      "metadata": {
        "id": "2coIsMTUZW4h"
      },
      "id": "2coIsMTUZW4h",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!lspci | grep -i nvidia"
      ],
      "metadata": {
        "id": "6IAAh7-kZP6y"
      },
      "id": "6IAAh7-kZP6y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dpkg -l | grep -i nvidia"
      ],
      "metadata": {
        "id": "No-Mt4XYW-Pl"
      },
      "id": "No-Mt4XYW-Pl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat ~/.profile"
      ],
      "metadata": {
        "id": "iwwEeBGuXbJh"
      },
      "id": "iwwEeBGuXbJh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://developer.download.nvidia.com/compute/cuda/11.1.1/local_installers/cuda_11.1.1_455.32.00_linux.run\n"
      ],
      "metadata": {
        "id": "VWrduGG2Vfy4"
      },
      "id": "VWrduGG2Vfy4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sh cuda_11.1.1_455.32.00_linux.run --silent"
      ],
      "metadata": {
        "id": "E22AQvvxVo_4"
      },
      "id": "E22AQvvxVo_4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id '14oKDza_dJBTL7qJdpraneSDPdSZ_RZ9U'\n",
        "!gdown --id '1Ij3jiT4BKXEFd9uJUmD60CDNm1FbhjcX'\n",
        "!gdown --id '1jXDHhmTAyKdqeceBv7CANTmQzINHEvo-'\n",
        "!gdown --id '1GJWAjM6EfcdjfZEHfLJG6BIIexn3yayh'"
      ],
      "metadata": {
        "id": "3erAShWi3QZj"
      },
      "id": "3erAShWi3QZj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dpkg -i libcudnn8_8.0.5.39-1+cuda11.1_amd64.deb\n",
        "!dpkg -i libcudnn8-dev_8.0.5.39-1+cuda11.1_amd64.deb\n",
        "!dpkg -i libcudnn8-samples_8.0.5.39-1+cuda11.1_amd64.deb"
      ],
      "metadata": {
        "id": "rnSN266z3SFz"
      },
      "id": "rnSN266z3SFz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!/usr/local/cuda/bin/nvcc --version"
      ],
      "metadata": {
        "id": "jkyotpwy3CYB"
      },
      "id": "jkyotpwy3CYB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ldconfig -p | grep cuda"
      ],
      "metadata": {
        "id": "Dz2RToiD3EuC"
      },
      "id": "Dz2RToiD3EuC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version\n",
        "!ldconfig -p | grep cuda"
      ],
      "metadata": {
        "id": "Qz7AbtdH9Rte"
      },
      "id": "Qz7AbtdH9Rte",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /usr/src/cudnn_samples_v8/ ."
      ],
      "metadata": {
        "id": "NQztjVld0UQO"
      },
      "id": "NQztjVld0UQO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "cd cudnn_samples_v8/mnistCUDNN\n",
        "make\n",
        "./mnistCUDNN"
      ],
      "metadata": {
        "id": "80bJqHt50Z9X"
      },
      "id": "80bJqHt50Z9X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install cudnn"
      ],
      "metadata": {
        "id": "dZVWXAxgUbOh"
      },
      "id": "dZVWXAxgUbOh"
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --id '14oKDza_dJBTL7qJdpraneSDPdSZ_RZ9U'\n",
        "!gdown --id '1Ij3jiT4BKXEFd9uJUmD60CDNm1FbhjcX'\n",
        "!gdown --id '1jXDHhmTAyKdqeceBv7CANTmQzINHEvo-'\n",
        "!gdown --id '1GJWAjM6EfcdjfZEHfLJG6BIIexn3yayh'"
      ],
      "metadata": {
        "id": "xD3Zl5BOU36m"
      },
      "id": "xD3Zl5BOU36m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!dpkg -i libcudnn8_8.0.5.39-1+cuda11.1_amd64.deb\n",
        "!dpkg -i libcudnn8-dev_8.0.5.39-1+cuda11.1_amd64.deb\n",
        "!dpkg -i libcudnn8-samples_8.0.5.39-1+cuda11.1_amd64.deb"
      ],
      "metadata": {
        "id": "IRD78LKgU4sG"
      },
      "id": "IRD78LKgU4sG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install jax"
      ],
      "metadata": {
        "id": "iUMnJr2Z3pXW"
      },
      "id": "iUMnJr2Z3pXW"
    },
    {
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "pip install --upgrade pip && \\\n",
        "pip install \"jax[cuda11_cudnn805]\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html && \\\n",
        "pip install flax diffrax equinox einops optax && \\\n",
        "apt-cache policy libcudnn8"
      ],
      "metadata": {
        "id": "J-UHDqnPXTZT"
      },
      "id": "J-UHDqnPXTZT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pip"
      ],
      "metadata": {
        "id": "MI-x2AbT-Ute"
      },
      "id": "MI-x2AbT-Ute",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffrax"
      ],
      "metadata": {
        "id": "QFU2zz6ICLVp"
      },
      "id": "QFU2zz6ICLVp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install equinox"
      ],
      "metadata": {
        "id": "mLs6mVXkCYQS"
      },
      "id": "mLs6mVXkCYQS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "id": "-8dIG1EXCh4F"
      },
      "id": "-8dIG1EXCh4F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optax"
      ],
      "metadata": {
        "id": "48IFXXLCCuZg"
      },
      "id": "48IFXXLCCuZg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test"
      ],
      "metadata": {
        "id": "8TOgPiIIv-4h"
      },
      "id": "8TOgPiIIv-4h"
    },
    {
      "cell_type": "code",
      "source": [
        "# Check libcudnn8 version\n",
        "!apt-cache policy libcudnn8"
      ],
      "metadata": {
        "id": "gwaGjPUhy6ja"
      },
      "id": "gwaGjPUhy6ja",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import flax.linen as nn\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    @nn.compact\n",
        "    def __call__(self, x):\n",
        "        x = nn.Conv(features=32, kernel_size=(3, 3))(x)\n",
        "        x = nn.relu(x)\n",
        "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "        x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
        "        x = nn.relu(x)\n",
        "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
        "        x = x.reshape((x.shape[0], -1))  # flatten\n",
        "        x = nn.Dense(features=256)(x)\n",
        "        x = nn.relu(x)\n",
        "        x = nn.Dense(features=10)(x)\n",
        "        x = nn.log_softmax(x)\n",
        "        return x\n",
        "\n",
        "model = CNN()\n",
        "batch = jnp.ones((32, 64, 64, 10))  # (N, H, W, C) format\n",
        "variables = model.init(jax.random.PRNGKey(0), batch)\n",
        "output = model.apply(variables, batch)"
      ],
      "metadata": {
        "id": "9xUKFzbPwLIb"
      },
      "id": "9xUKFzbPwLIb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f725bf21-971f-40f9-b195-f4ada22c6d8f",
      "metadata": {
        "id": "f725bf21-971f-40f9-b195-f4ada22c6d8f"
      },
      "source": [
        "# Generative score-based diffusion\n",
        "\n",
        "In this example we train a [score-based diffusion](https://arxiv.org/abs/2011.13456) as a generative model for MNIST digits.\n",
        "\n",
        "![samples](https://github.com/patrick-kidger/equinox/blob/main/imgs/score_based_diffusion_samples.png?raw=1)\n",
        "\n",
        "This example:\n",
        "\n",
        "- Uses the variance-preserving SDE to corrupt the data:\n",
        "\n",
        "$y(0) \\sim \\mathrm{data}\\qquad\\mathrm{d}y(t) = -\\frac{1}{2} β(t)y(t)\\mathrm{d}t + \\sqrt{β(t)}\\mathrm{d}w(t) \\qquad\\text{for }t \\in [0, T].$\n",
        "\n",
        "- Trains a score model $s_\\theta$ according to the denoising objective:\n",
        "\n",
        "$\\arg\\min_\\theta \\mathbb{E}_{t \\sim \\mathrm{Uniform}[0, T]}\\mathbb{E}_{y(0) \\sim \\mathrm{data}}\\mathbb{E}_{(y(t)|y(0)) \\sim \\mathrm{SDE}} \\lambda(t) \\| s_\\theta(t, y(t)) - \\nabla_y \\log p(y(t)|y(0)) \\|_2^2$\n",
        "\n",
        "- Uses the equivalent ODE for sampling (solved using the [Diffrax](https://github.com/patrick-kidger/diffrax) library):\n",
        "\n",
        "$y(1) \\sim \\mathcal{N}(0, I)\\qquad\\mathrm{d}y(t) = -\\frac{1}{2}β(t) (y(t) + s_\\theta(t, y(t)))\\mathrm{d}t \\qquad\\text{for }t \\in [0, T].$\n",
        "\n",
        "- Uses an [MLP-Mixer](https://arxiv.org/abs/2105.01601) to parameterise the score model $s_\\theta$.\n",
        "\n",
        "\n",
        "!!! warning\n",
        "\n",
        "    This example will take a short while to run on a GPU.\n",
        "\n",
        "!!! cite \"Reference\"\n",
        "\n",
        "    [arXiv link](https://arxiv.org/abs/2011.13456)\n",
        "\n",
        "    ```bibtex\n",
        "    @inproceedings{song2021scorebased,\n",
        "    title={Score-Based Generative Modeling through Stochastic Differential\n",
        "           Equations},\n",
        "    author={Yang Song and Jascha Sohl-Dickstein and Diederik P Kingma and\n",
        "            Abhishek Kumar and Stefano Ermon and Ben Poole},\n",
        "    booktitle={International Conference on Learning Representations},\n",
        "    year={2021},\n",
        "    }\n",
        "    ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6032df21-c88f-4a59-b7f8-c4859cc18b7b",
      "metadata": {
        "id": "6032df21-c88f-4a59-b7f8-c4859cc18b7b"
      },
      "outputs": [],
      "source": [
        "import array\n",
        "import functools as ft\n",
        "import gzip\n",
        "import os\n",
        "import struct\n",
        "import urllib.request\n",
        "\n",
        "import diffrax as dfx  # https://github.com/patrick-kidger/diffrax\n",
        "import einops  # https://github.com/arogozhnikov/einops\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.random as jr\n",
        "import matplotlib.pyplot as plt\n",
        "import optax  # https://github.com/deepmind/optax\n",
        "\n",
        "import equinox as eqx"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "71616372-0cc8-41e7-a0f3-f784c107eb7e",
      "metadata": {
        "id": "71616372-0cc8-41e7-a0f3-f784c107eb7e"
      },
      "source": [
        "First let's specify our score-based model $s_\\theta$, as an MLP-Mixer. We'll use many of the pre-built `equinox.nn` layers here.\n",
        "\n",
        "We encode time-dependence in a simple way, by just concatenating it as another channel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b29fa3a-19a7-467a-bb99-497150038727",
      "metadata": {
        "id": "1b29fa3a-19a7-467a-bb99-497150038727"
      },
      "outputs": [],
      "source": [
        "class MixerBlock(eqx.Module):\n",
        "    patch_mixer: eqx.nn.MLP\n",
        "    hidden_mixer: eqx.nn.MLP\n",
        "    norm1: eqx.nn.LayerNorm\n",
        "    norm2: eqx.nn.LayerNorm\n",
        "\n",
        "    def __init__(\n",
        "        self, num_patches, hidden_size, mix_patch_size, mix_hidden_size, *, key\n",
        "    ):\n",
        "        tkey, ckey = jr.split(key, 2)\n",
        "        self.patch_mixer = eqx.nn.MLP(\n",
        "            num_patches, num_patches, mix_patch_size, depth=1, key=tkey\n",
        "        )\n",
        "        self.hidden_mixer = eqx.nn.MLP(\n",
        "            hidden_size, hidden_size, mix_hidden_size, depth=1, key=ckey\n",
        "        )\n",
        "        self.norm1 = eqx.nn.LayerNorm((hidden_size, num_patches))\n",
        "        self.norm2 = eqx.nn.LayerNorm((num_patches, hidden_size))\n",
        "\n",
        "    def __call__(self, y):\n",
        "        y = y + jax.vmap(self.patch_mixer)(self.norm1(y))\n",
        "        y = einops.rearrange(y, \"c p -> p c\")\n",
        "        y = y + jax.vmap(self.hidden_mixer)(self.norm2(y))\n",
        "        y = einops.rearrange(y, \"p c -> c p\")\n",
        "        return y\n",
        "\n",
        "\n",
        "class Mixer2d(eqx.Module):\n",
        "    conv_in: eqx.nn.Conv2d\n",
        "    conv_out: eqx.nn.ConvTranspose2d\n",
        "    blocks: list\n",
        "    norm: eqx.nn.LayerNorm\n",
        "    t1: float\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        img_size,\n",
        "        patch_size,\n",
        "        hidden_size,\n",
        "        mix_patch_size,\n",
        "        mix_hidden_size,\n",
        "        num_blocks,\n",
        "        t1,\n",
        "        *,\n",
        "        key,\n",
        "    ):\n",
        "        input_size, height, width = img_size\n",
        "        assert (height % patch_size) == 0\n",
        "        assert (width % patch_size) == 0\n",
        "        num_patches = (height // patch_size) * (width // patch_size)\n",
        "        inkey, outkey, *bkeys = jr.split(key, 2 + num_blocks)\n",
        "\n",
        "        self.conv_in = eqx.nn.Conv2d(\n",
        "            input_size + 1, hidden_size, patch_size, stride=patch_size, key=inkey\n",
        "        )\n",
        "        self.conv_out = eqx.nn.ConvTranspose2d(\n",
        "            hidden_size, input_size, patch_size, stride=patch_size, key=outkey\n",
        "        )\n",
        "        self.blocks = [\n",
        "            MixerBlock(\n",
        "                num_patches, hidden_size, mix_patch_size, mix_hidden_size, key=bkey\n",
        "            )\n",
        "            for bkey in bkeys\n",
        "        ]\n",
        "        self.norm = eqx.nn.LayerNorm((hidden_size, num_patches))\n",
        "        self.t1 = t1\n",
        "\n",
        "    def __call__(self, t, y):\n",
        "        t = t / self.t1\n",
        "        _, height, width = y.shape\n",
        "        t = einops.repeat(t, \"-> 1 h w\", h=height, w=width)\n",
        "        y = jnp.concatenate([y, t])\n",
        "        y = self.conv_in(y)\n",
        "        _, patch_height, patch_width = y.shape\n",
        "        y = einops.rearrange(y, \"c h w -> c (h w)\")\n",
        "        for block in self.blocks:\n",
        "            y = block(y)\n",
        "        y = self.norm(y)\n",
        "        y = einops.rearrange(y, \"c (h w) -> c h w\", h=patch_height, w=patch_width)\n",
        "        return self.conv_out(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "939246fa-2e6a-4849-9ba2-4aea1af049fd",
      "metadata": {
        "id": "939246fa-2e6a-4849-9ba2-4aea1af049fd"
      },
      "source": [
        "Now set up our loss and sampling functions. Note that the variance-preserving SDE is parameterised by some function $β$. The value $\\nabla_y \\log p(y(t)|y(0))$ is computed analytically, in which $\\int_0^t β(s) \\mathrm{d}s$ appears.\n",
        "\n",
        "As such our functions are parameterised by a function `int_beta`, and where necessary we obtain $β$ through autodifferentiation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "817c3713-f96f-418f-9e9c-629d86c4033b",
      "metadata": {
        "id": "817c3713-f96f-418f-9e9c-629d86c4033b"
      },
      "outputs": [],
      "source": [
        "def single_loss_fn(model, weight, int_beta, data, t, key):\n",
        "    mean = data * jnp.exp(-0.5 * int_beta(t))\n",
        "    var = jnp.maximum(1 - jnp.exp(-int_beta(t)), 1e-5)\n",
        "    std = jnp.sqrt(var)\n",
        "    noise = jr.normal(key, data.shape)\n",
        "    y = mean + std * noise\n",
        "    pred = model(t, y)\n",
        "    return weight(t) * jnp.mean((pred + noise / std) ** 2)\n",
        "\n",
        "\n",
        "def batch_loss_fn(model, weight, int_beta, data, t1, key):\n",
        "    batch_size = data.shape[0]\n",
        "    tkey, losskey = jr.split(key)\n",
        "    losskey = jr.split(losskey, batch_size)\n",
        "    # Low-discrepancy sampling over t to reduce variance\n",
        "    t = jr.uniform(tkey, (batch_size,), minval=0, maxval=t1 / batch_size)\n",
        "    t = t + (t1 / batch_size) * jnp.arange(batch_size)\n",
        "    loss_fn = ft.partial(single_loss_fn, model, weight, int_beta)\n",
        "    loss_fn = jax.vmap(loss_fn)\n",
        "    return jnp.mean(loss_fn(data, t, losskey))\n",
        "\n",
        "\n",
        "@eqx.filter_jit\n",
        "def single_sample_fn(model, int_beta, data_shape, dt0, t1, key):\n",
        "    def drift(t, y, args):\n",
        "        _, beta = jax.jvp(int_beta, (t,), (jnp.ones_like(t),))\n",
        "        return -0.5 * beta * (y + model(t, y))\n",
        "\n",
        "    term = dfx.ODETerm(drift)\n",
        "    solver = dfx.Tsit5()\n",
        "    t0 = 0\n",
        "    y1 = jr.normal(key, data_shape)\n",
        "    # reverse time, solve from t1 to t0\n",
        "    sol = dfx.diffeqsolve(term, solver, t1, t0, -dt0, y1, adjoint=dfx.NoAdjoint())\n",
        "    return sol.ys[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d33ec46e-fc9d-41ea-b0aa-92d876010dc0",
      "metadata": {
        "id": "d33ec46e-fc9d-41ea-b0aa-92d876010dc0"
      },
      "source": [
        "Now get the data, i.e. the MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58d108bd-4702-4c92-a939-4ef235d77cb0",
      "metadata": {
        "id": "58d108bd-4702-4c92-a939-4ef235d77cb0"
      },
      "outputs": [],
      "source": [
        "def mnist():\n",
        "    filename = \"train-images-idx3-ubyte.gz\"\n",
        "    url_dir = \"https://storage.googleapis.com/cvdf-datasets/mnist\"\n",
        "    target_dir = os.getcwd() + \"/data/mnist\"\n",
        "    url = f\"{url_dir}/{filename}\"\n",
        "    target = f\"{target_dir}/{filename}\"\n",
        "\n",
        "    if not os.path.exists(target):\n",
        "        os.makedirs(target_dir, exist_ok=True)\n",
        "        urllib.request.urlretrieve(url, target)\n",
        "        print(f\"Downloaded {url} to {target}\")\n",
        "\n",
        "    with gzip.open(target, \"rb\") as fh:\n",
        "        _, batch, rows, cols = struct.unpack(\">IIII\", fh.read(16))\n",
        "        shape = (batch, 1, rows, cols)\n",
        "        return jnp.array(array.array(\"B\", fh.read()), dtype=jnp.uint8).reshape(shape)\n",
        "\n",
        "\n",
        "def dataloader(data, batch_size, *, key):\n",
        "    dataset_size = data.shape[0]\n",
        "    indices = jnp.arange(dataset_size)\n",
        "    while True:\n",
        "        perm = jr.permutation(key, indices)\n",
        "        (key,) = jr.split(key, 1)\n",
        "        start = 0\n",
        "        end = batch_size\n",
        "        while end < dataset_size:\n",
        "            batch_perm = perm[start:end]\n",
        "            yield data[batch_perm]\n",
        "            start = end\n",
        "            end = start + batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61656665-f539-4cce-a4aa-cb9196dde4e9",
      "metadata": {
        "id": "61656665-f539-4cce-a4aa-cb9196dde4e9"
      },
      "source": [
        "And now we have the main training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce5003dd-7b1b-4eb3-96ca-852df0dd1b85",
      "metadata": {
        "id": "ce5003dd-7b1b-4eb3-96ca-852df0dd1b85"
      },
      "outputs": [],
      "source": [
        "@eqx.filter_jit\n",
        "def make_step(model, weight, int_beta, data, t1, key, opt_state, opt_update):\n",
        "    loss_fn = eqx.filter_value_and_grad(batch_loss_fn)\n",
        "    loss, grads = loss_fn(model, weight, int_beta, data, t1, key)\n",
        "    updates, opt_state = opt_update(grads, opt_state)\n",
        "    model = eqx.apply_updates(model, updates)\n",
        "    key = jr.split(key, 1)[0]\n",
        "    return loss, model, key, opt_state\n",
        "\n",
        "\n",
        "def main(\n",
        "    # Model hyperparameters\n",
        "    patch_size=4,\n",
        "    hidden_size=64,\n",
        "    mix_patch_size=512,\n",
        "    mix_hidden_size=512,\n",
        "    num_blocks=4,\n",
        "    t1=10.0,\n",
        "    # Optimisation hyperparameters\n",
        "    num_steps=1_000_000,\n",
        "    lr=3e-4,\n",
        "    batch_size=256,\n",
        "    print_every=10_000,\n",
        "    # Sampling hyperparameters\n",
        "    dt0=0.1,\n",
        "    sample_size=10,\n",
        "    # Seed\n",
        "    seed=5678,\n",
        "):\n",
        "    key = jr.PRNGKey(seed)\n",
        "    model_key, train_key, loader_key, sample_key = jr.split(key, 4)\n",
        "    data = mnist()\n",
        "    data_mean = jnp.mean(data)\n",
        "    data_std = jnp.std(data)\n",
        "    data_max = jnp.max(data)\n",
        "    data_min = jnp.min(data)\n",
        "    data_shape = data.shape[1:]\n",
        "    data = (data - data_mean) / data_std\n",
        "\n",
        "    model = Mixer2d(\n",
        "        data_shape,\n",
        "        patch_size,\n",
        "        hidden_size,\n",
        "        mix_patch_size,\n",
        "        mix_hidden_size,\n",
        "        num_blocks,\n",
        "        t1,\n",
        "        key=model_key,\n",
        "    )\n",
        "    int_beta = lambda t: t  # Try experimenting with other options here!\n",
        "    weight = lambda t: 1 - jnp.exp(\n",
        "        -int_beta(t)\n",
        "    )  # Just chosen to upweight the region near t=0.\n",
        "\n",
        "    opt = optax.adabelief(lr)\n",
        "    # Optax will update the floating-point JAX arrays in the model.\n",
        "    opt_state = opt.init(eqx.filter(model, eqx.is_inexact_array))\n",
        "\n",
        "    total_value = 0\n",
        "    total_size = 0\n",
        "    for step, data in zip(\n",
        "        range(num_steps), dataloader(data, batch_size, key=loader_key)\n",
        "    ):\n",
        "        value, model, train_key, opt_state = make_step(\n",
        "            model, weight, int_beta, data, t1, train_key, opt_state, opt.update\n",
        "        )\n",
        "        total_value += value.item()\n",
        "        total_size += 1\n",
        "        if (step % print_every) == 0 or step == num_steps - 1:\n",
        "            print(f\"Step={step} Loss={total_value / total_size}\")\n",
        "            total_value = 0\n",
        "            total_size = 0\n",
        "\n",
        "    sample_key = jr.split(sample_key, sample_size**2)\n",
        "    sample_fn = ft.partial(single_sample_fn, model, int_beta, data_shape, dt0, t1)\n",
        "    sample = jax.vmap(sample_fn)(sample_key)\n",
        "    sample = data_mean + data_std * sample\n",
        "    sample = jnp.clip(sample, data_min, data_max)\n",
        "    sample = einops.rearrange(\n",
        "        sample, \"(n1 n2) 1 h w -> (n1 h) (n2 w)\", n1=sample_size, n2=sample_size\n",
        "    )\n",
        "    plt.imshow(sample, cmap=\"Greys\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adb83b98-6e24-4d2d-8dd1-9b2a81595120",
      "metadata": {
        "id": "adb83b98-6e24-4d2d-8dd1-9b2a81595120"
      },
      "outputs": [],
      "source": [
        "main()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "name": "jax_MNIST.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "0aZ6XKyV220x",
        "dZVWXAxgUbOh",
        "iUMnJr2Z3pXW",
        "8TOgPiIIv-4h"
      ],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}