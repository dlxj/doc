{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFQM12Qy2scn"
      },
      "outputs": [],
      "source": [
        "!unzip MNIST.zip_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLwb4iUY3uNH",
        "outputId": "df268e64-070d-44d2-9253-c46b44d008ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(28, 28, 3)\n"
          ]
        }
      ],
      "source": [
        "import cv2 # pip install opencv-python # win10要编译很久的\n",
        "\n",
        "im = cv2.imread(\"./MNIST/0_0_10.jpg\")\n",
        "print(im.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "sHbfOT2E4My7",
        "outputId": "fdf7eaf7-b6da-4334-aa71-765720919b3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name:  0_0_10.jpg\n",
            "<class 'numpy.ndarray'>\n",
            "(28, 28)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "# from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "#import numpy as np\n",
        "\n",
        "rootdir = './MNIST'\n",
        "names = os.listdir(rootdir)\n",
        "\n",
        "for name in names:\n",
        "  print(\"name: \", name)\n",
        "  path = os.path.join(rootdir, name)\n",
        "  im = cv2.imread(path)\n",
        "  im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  print(type(im))\n",
        "  print(im.shape)\n",
        "\n",
        "  cv2.imshow('image', im) # BUG: crash the colab kernel\n",
        "  # cv2_imshow(im)\n",
        "  plt.imshow(im.squeeze(), cmap='gray_r'); \n",
        "  \n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "v30zot4W7BRU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([[6.],\n",
            "        [0.],\n",
            "        [5.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [5.],\n",
            "        [7.],\n",
            "        [8.],\n",
            "        [6.],\n",
            "        [4.],\n",
            "        [1.],\n",
            "        [3.],\n",
            "        [4.],\n",
            "        [3.],\n",
            "        [8.],\n",
            "        [4.],\n",
            "        [8.],\n",
            "        [1.],\n",
            "        [9.],\n",
            "        [9.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [9.],\n",
            "        [2.],\n",
            "        [6.],\n",
            "        [4.],\n",
            "        [1.],\n",
            "        [7.],\n",
            "        [7.],\n",
            "        [6.],\n",
            "        [5.],\n",
            "        [3.],\n",
            "        [5.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [4.],\n",
            "        [3.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [3.],\n",
            "        [3.],\n",
            "        [7.],\n",
            "        [2.],\n",
            "        [5.],\n",
            "        [7.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [8.],\n",
            "        [8.],\n",
            "        [6.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [7.],\n",
            "        [4.],\n",
            "        [6.],\n",
            "        [0.],\n",
            "        [7.],\n",
            "        [0.]])\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "手写数字识别 pytorch 实现\n",
        "\n",
        "reference:\n",
        "    https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627\n",
        "    doc\\lang\\programming\\pytorch\\李宏毅2020机器翻译\\iAttention.py\n",
        "    doc\\lang\\programming\\pytorch\\数字识别\\ihandwritten_digit_recognition_GPU.ipynb\n",
        "    https://gist.github.com/user01/68514db1127eb007f24d28bfd11dd60e\n",
        "\n",
        "\n",
        "MNIST 图片的导出（）\n",
        "# import cv2\n",
        "\n",
        "# print( images.shape[0] )\n",
        "\n",
        "# for j in range(30):\n",
        "  \n",
        "#   images, labels = next(dataiter)\n",
        "\n",
        "#   for i in range(images.shape[0]):\n",
        "#     a = ((images[i].numpy().squeeze() + 1) / 2) * 255  # 原来的数值范围是 -1.0 ~ +1.0 ，规范为 0 ~ 255\n",
        "#     b = np.rint(a)  # Round elements of the array to the nearest integer.\n",
        "#     #plt.imshow(b, cmap='gray_r')\n",
        "#     #b\n",
        "#     label = labels.numpy()[i]\n",
        "#     #print(label)\n",
        "#     #cv2.imshow('Binary Threshold', b)\n",
        "#     cv2.imwrite(f'./out/{label}_{j}_{i}.jpg',b)\n",
        "\n",
        "\"\"\"\n",
        "import torch\n",
        "from torch.types import Number\n",
        "import torch.utils.data as torch_data\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "from time import time\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "# from google.colab.patches import cv2_imshow\n",
        "\n",
        "def Data(type='training'):\n",
        "\n",
        "    #currDir = os.getcwd() # jupyter is ok\n",
        "    #currDir = os.path.dirname(os.path.abspath(__file__)) # jupyter not ok\n",
        "\n",
        "    data = []\n",
        "\n",
        "\n",
        "    currDir = \".\" # \"/content\" # jupyter not ok\n",
        "\n",
        "    root = os.path.join(currDir, \"MNIST\")\n",
        "\n",
        "    names = os.listdir(root)\n",
        "\n",
        "    for name in names:\n",
        "\n",
        "        #print(\"name: \", name)\n",
        "\n",
        "        num = name.split('_')[0]  # number in fname already \n",
        "        num = int(num)\n",
        "\n",
        "        #print( \"label: \", num )\n",
        "\n",
        "        #num = num / 10  # normalize number to 0.0 ~ 1.0\n",
        "\n",
        "        path = os.path.join(root, name)\n",
        "        im = cv2.imread(path)\n",
        "        im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        \"\"\"\n",
        "        输入：im.shape，  可以看到维度是 (28, 28)\n",
        "              im，       可以看到数值范围是 0 ~ 255\n",
        "              im/255     可以看到数值范围变成了 0.0 ~ 1.0\n",
        "        \"\"\"\n",
        "        # import pdb; pdb.set_trace() # 调试， exit 退出\n",
        "\n",
        "        im = im / 255\n",
        "\n",
        "        im_sq = im.reshape(28*28) # (28*28) 的图片降维成一维数组\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        输入：im_sq.shape 可以看到维度是 (784,)\n",
        "        \"\"\"\n",
        "\n",
        "        #import pdb; pdb.set_trace()\n",
        "\n",
        "\n",
        "        #print(im.shape)\n",
        "\n",
        "        #print( type(im) )\n",
        "        #print(im.shape)\n",
        "        #print(im)\n",
        "\n",
        "        # cv2.imshow('image', im) # BUG: crash the colab kernel\n",
        "        #cv2_imshow(im)\n",
        "        #plt.imshow(im.squeeze(), cmap='gray_r');\n",
        "\n",
        "        data.append( [ torch.Tensor(im_sq), torch.Tensor([num]) ] )\n",
        "\n",
        "        #break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return data\n",
        "\n",
        "class TorchDataset(torch_data.Dataset):\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "        \n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  def __getitem__(self, Index):\n",
        "    item = self.data[Index]\n",
        "\n",
        "    return item[0], item[1]\n",
        "\n",
        "def infinite_iter(data_loader):\n",
        "  it = iter(data_loader)\n",
        "  while True:\n",
        "    try:\n",
        "      item_in , item_out = next(it)\n",
        "      yield item_in, item_out\n",
        "    except StopIteration:\n",
        "      it = iter(data_loader)\n",
        "\n",
        "#Data();\n",
        "\n",
        "\n",
        "train_dataset = TorchDataset(Data(type='training'))\n",
        "train_loader = torch_data.DataLoader(train_dataset, batch_size = 64, shuffle=True)  # 每个输入是维度是(2) 的一维数组，每一批总共输入2 组，维度既是：(2, 2)\n",
        "train_iter = infinite_iter(train_loader)\n",
        "\n",
        "sources, targets = next(train_iter)\n",
        "\n",
        "print( sources, targets )\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn0Uxx9hgQx-",
        "outputId": "fdfc7297-d997-4635-d189-9243af53b69e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (5): LogSoftmax(dim=1)\n",
            ")\n",
            "cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 - Training loss: 0.00011264593922533095\n",
            "\n",
            "Training Time (in minutes) = 0.25551716883977255\n",
            "Epoch 1 - Training loss: 1.376107320538722e-05\n",
            "\n",
            "Training Time (in minutes) = 0.5136989275614421\n",
            "Epoch 2 - Training loss: 8.917024388210848e-06\n",
            "\n",
            "Training Time (in minutes) = 0.769320539633433\n"
          ]
        }
      ],
      "source": [
        "# 训练\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "# Layer details for the neural network\n",
        "input_size = 784\n",
        "hidden_sizes = [128, 64]\n",
        "output_size = 10\n",
        "\n",
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1], output_size),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "print(model)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "\n",
        "time0 = time()\n",
        "epochs = 3\n",
        "for e in range(epochs):\n",
        "\n",
        "    for i in range(10000):\n",
        "\n",
        "        running_loss = 0\n",
        "    \n",
        "        images, labels = next(train_iter)\n",
        "    \n",
        "        labels = labels.reshape(64)\n",
        "        labels = torch.tensor(labels, dtype=torch.long) \n",
        "    \n",
        "        # Training pass\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(  images.cuda() if torch.cuda.is_available() else images.cpu() )\n",
        "\n",
        "        #import pdb; pdb.set_trace() # 调试， exit 退出\n",
        "\n",
        "        loss = criterion(output, labels.cuda() if torch.cuda.is_available() else labels.cpu())\n",
        "        \n",
        "        #This is where the model learns by backpropagating\n",
        "        loss.backward()\n",
        "        \n",
        "        #And optimizes its weights here\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "\n",
        "\n",
        "    print(\"Epoch {} - Training loss: {}\".format(e, running_loss/64))\n",
        "    print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "BYlOAl-zGLYC",
        "outputId": "5febf2df-8c69-42ff-a14b-d127e81f0827"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \"\"\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "3\n",
            "Number Of Images Tested = 1\n",
            "\n",
            "Model Accuracy = 1.0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "image/png": {
              "height": 248,
              "width": 251
            },
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "correct_count, all_count = 0, 0\n",
        "\n",
        "images, labels = next(train_iter)\n",
        "labels = labels.reshape(64)\n",
        "labels = torch.tensor(labels, dtype=torch.long) \n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i in range(1):\n",
        "    img = images[i].reshape(1, 784)\n",
        "    logps = model(img.cuda())\n",
        "\n",
        "    # Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.cpu().numpy()[0])\n",
        "    pred_label = probab.index(max(probab))\n",
        "\n",
        "\n",
        "    img_to_show = images[i].reshape(28,28)\n",
        "    img_to_show = img_to_show * 255\n",
        "\n",
        "    plt.imshow(img_to_show, cmap='gray_r'); \n",
        "\n",
        "    print(pred_label)  # 预测的数字\n",
        "\n",
        "    true_label = labels.numpy()[i]\n",
        "\n",
        "    print(true_label)  # 真实的数字\n",
        "\n",
        "    if(true_label == pred_label):\n",
        "      correct_count += 1\n",
        "    all_count += 1\n",
        "\n",
        "\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"\\nModel Accuracy =\", (correct_count/all_count))  # 预测的正确率"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVLao9GxqErS"
      },
      "outputs": [],
      "source": [
        "# 准备数据\n",
        "import torch\n",
        "from google.colab import drive\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('./mnist/MNIST_data/', download=True, train=True, transform=transform)\n",
        "valset = datasets.MNIST('./mnist/MNIST_data/', download=True, train=False, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPVS6m1wXsu5"
      },
      "outputs": [],
      "source": [
        "# 观察数据\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)  # images [64, 1, 28, 28]，64 张，1 通道，28 宽，28 高 的图片  # labels [64] 64个标签\n",
        "  # 28*28 = 784 个像素点，每张图片作为输入是[768] 的一维数组，每一批总共输入64 张，既是：[64, 784]\n",
        "  # so, 输入层共784 个神经元结点，每个结点得到图片的其中一个像素作为输入\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r');  # squeeze 将 [1, 28, 28] 降维成 [28, 28]\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "输入： images[0].numpy().squeeze()\n",
        "可以看到数值范围是：-1.0 ~ +1.0\n",
        "\"\"\"\n",
        "# import pdb; pdb.set_trace() # 调试， exit 退出\n",
        "\n",
        "\n",
        "figure = plt.figure()\n",
        "num_of_images = 60\n",
        "for index in range(1, num_of_images + 1):\n",
        "    plt.subplot(6, 10, index)  # 绘制  6 行，10 列 个对象\n",
        "    plt.axis('off')            # 关闭坐标轴显示\n",
        "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "iov7ufvQqPhG",
        "outputId": "5506360c-8c35-4280-8979-c1f89dacdff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (5): LogSoftmax(dim=1)\n",
            ")\n",
            "cpu\n",
            "> <ipython-input-10-32d940273697>(76)<module>()\n",
            "-> loss.backward()\n",
            "(Pdb) label.shape\n",
            "*** NameError: name 'label' is not defined\n",
            "(Pdb) labels.shape\n",
            "torch.Size([64])\n",
            "(Pdb) exit\n"
          ]
        },
        {
          "ename": "BdbQuit",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-32d940273697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m#This is where the model learns by backpropagating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m#And optimizes its weights here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-32d940273697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m#This is where the model learns by backpropagating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m#And optimizes its weights here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBdbQuit\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 训练\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "# Layer details for the neural network\n",
        "input_size = 784\n",
        "hidden_sizes = [128, 64]\n",
        "output_size = 10\n",
        "\n",
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1], output_size),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "print(model)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "\n",
        "time0 = time()\n",
        "epochs = 15\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)  # 元素的总数不变，对维度重新进行解释，相当于 reshape  # 64 行，列数自适应(-1 的作用)  \n",
        "          # 28*28 = 784 个像素点，每张图片作为输入是[784] 的一维数组，每一批总共输入64 张，既是：[64, 784]\n",
        "    \n",
        "        \"\"\"\n",
        "        输入： \n",
        "            images[0] 可以看到是张量 tensor，数值范围是：-1.0 ~ +1.0\n",
        "            images[0].shape，可以看到维度是 784，是一维数组\n",
        "            ((images[0]+1)/2)*255 ，数值范围规范为：0 ~ 255\n",
        "        \"\"\"\n",
        "        #import pdb; pdb.set_trace() # 调试， exit 退出\n",
        "\n",
        "\n",
        "        for i in range(len(images)):\n",
        "          images[i] = ( (images[i]+1) / 2 ) # 原来的数值范围是 -1.0 ~ +1.0 ，规范为 0 ~ +1.0\n",
        "        \n",
        "\n",
        "        # Training pass\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "\n",
        "\n",
        "        output = model(  images.cuda() if torch.cuda.is_available() else images.cpu() )\n",
        "        loss = criterion(output, labels.cuda() if torch.cuda.is_available() else  labels.cpu())\n",
        "\n",
        "        import pdb; pdb.set_trace() # 调试， exit 退出\n",
        "        \n",
        "        #This is where the model learns by backpropagating\n",
        "        loss.backward()\n",
        "        \n",
        "        #And optimizes its weights here\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\n",
        "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7NcRWeYambN"
      },
      "outputs": [],
      "source": [
        "# 验证模型精度\n",
        "correct_count, all_count = 0, 0\n",
        "for images,labels in valloader:\n",
        "  for i in range(len(labels)):\n",
        "    img = images[i].view(1, 784)\n",
        "    img = ( (img+1) / 2 ) # 原来的数值范围是 -1.0 ~ +1.0 ，规范为 0 ~ +1.0\n",
        "    # Turn off gradients to speed up this part\n",
        "    with torch.no_grad():\n",
        "        logps = model(img.cuda())\n",
        "\n",
        "    # Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.cpu().numpy()[0])\n",
        "    pred_label = probab.index(max(probab))\n",
        "    true_label = labels.numpy()[i]\n",
        "    if(true_label == pred_label):\n",
        "      correct_count += 1\n",
        "    all_count += 1\n",
        "\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bdAmw1v7DHq"
      },
      "outputs": [],
      "source": [
        "# 预测\n",
        "def view_classify(img, ps):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.cpu().data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    ax2.set_yticklabels(np.arange(10))\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "    plt.tight_layout()\n",
        "\n",
        "images, labels = next(iter(valloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "img = ( (img+1) / 2 ) # 原来的数值范围是 -1.0 ~ +1.0 ，规范为 0 ~ +1.0\n",
        "\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img.cuda())\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = torch.exp(logps)\n",
        "probab = list(ps.cpu().numpy()[0])\n",
        "print(\"Predicted Digit =\", probab.index(max(probab)))\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "digit_torch_version2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
