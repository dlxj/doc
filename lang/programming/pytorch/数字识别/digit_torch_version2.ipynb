{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFQM12Qy2scn"
      },
      "outputs": [],
      "source": [
        "!unzip MNIST.zip_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLwb4iUY3uNH",
        "outputId": "df268e64-070d-44d2-9253-c46b44d008ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(28, 28, 3)\n"
          ]
        }
      ],
      "source": [
        "import cv2 # pip install opencv-python # win10要编译很久的\n",
        "\n",
        "im = cv2.imread(\"./MNIST/0_0_10.jpg\")\n",
        "print(im.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "sHbfOT2E4My7",
        "outputId": "fdf7eaf7-b6da-4334-aa71-765720919b3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "name:  0_0_10.jpg\n",
            "<class 'numpy.ndarray'>\n",
            "(28, 28)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "# from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "#import numpy as np\n",
        "\n",
        "rootdir = './MNIST'\n",
        "names = os.listdir(rootdir)\n",
        "\n",
        "for name in names:\n",
        "  print(\"name: \", name)\n",
        "  path = os.path.join(rootdir, name)\n",
        "  im = cv2.imread(path)\n",
        "  im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  print(type(im))\n",
        "  print(im.shape)\n",
        "\n",
        "  cv2.imshow('image', im) # BUG: crash the colab kernel\n",
        "  # cv2_imshow(im)\n",
        "  plt.imshow(im.squeeze(), cmap='gray_r'); \n",
        "  \n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "v30zot4W7BRU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]]) tensor([[6.],\n",
            "        [0.],\n",
            "        [5.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [5.],\n",
            "        [7.],\n",
            "        [8.],\n",
            "        [6.],\n",
            "        [4.],\n",
            "        [1.],\n",
            "        [3.],\n",
            "        [4.],\n",
            "        [3.],\n",
            "        [8.],\n",
            "        [4.],\n",
            "        [8.],\n",
            "        [1.],\n",
            "        [9.],\n",
            "        [9.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [9.],\n",
            "        [2.],\n",
            "        [6.],\n",
            "        [4.],\n",
            "        [1.],\n",
            "        [7.],\n",
            "        [7.],\n",
            "        [6.],\n",
            "        [5.],\n",
            "        [3.],\n",
            "        [5.],\n",
            "        [2.],\n",
            "        [2.],\n",
            "        [4.],\n",
            "        [3.],\n",
            "        [0.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [3.],\n",
            "        [3.],\n",
            "        [7.],\n",
            "        [2.],\n",
            "        [5.],\n",
            "        [7.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [1.],\n",
            "        [8.],\n",
            "        [8.],\n",
            "        [6.],\n",
            "        [1.],\n",
            "        [0.],\n",
            "        [7.],\n",
            "        [4.],\n",
            "        [6.],\n",
            "        [0.],\n",
            "        [7.],\n",
            "        [0.]])\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "手写数字识别 pytorch 实现\n",
        "\n",
        "reference:\n",
        "    https://towardsdatascience.com/handwritten-digit-mnist-pytorch-977b5338e627\n",
        "    doc\\lang\\programming\\pytorch\\李宏毅2020机器翻译\\iAttention.py\n",
        "    doc\\lang\\programming\\pytorch\\数字识别\\ihandwritten_digit_recognition_GPU.ipynb\n",
        "    https://gist.github.com/user01/68514db1127eb007f24d28bfd11dd60e\n",
        "\n",
        "\n",
        "MNIST 图片的导出（）\n",
        "# import cv2\n",
        "\n",
        "# print( images.shape[0] )\n",
        "\n",
        "# for j in range(30):\n",
        "  \n",
        "#   images, labels = next(dataiter)\n",
        "\n",
        "#   for i in range(images.shape[0]):\n",
        "#     a = ((images[i].numpy().squeeze() + 1) / 2) * 255  # 原来的数值范围是 -1.0 ~ +1.0 ，规范为 0 ~ 255\n",
        "#     b = np.rint(a)  # Round elements of the array to the nearest integer.\n",
        "#     #plt.imshow(b, cmap='gray_r')\n",
        "#     #b\n",
        "#     label = labels.numpy()[i]\n",
        "#     #print(label)\n",
        "#     #cv2.imshow('Binary Threshold', b)\n",
        "#     cv2.imwrite(f'./out/{label}_{j}_{i}.jpg',b)\n",
        "\n",
        "\"\"\"\n",
        "import torch\n",
        "from torch.types import Number\n",
        "import torch.utils.data as torch_data\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "from time import time\n",
        "import os\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "# from google.colab.patches import cv2_imshow\n",
        "\n",
        "def Data(type='training'):\n",
        "\n",
        "    #currDir = os.getcwd() # jupyter is ok\n",
        "    #currDir = os.path.dirname(os.path.abspath(__file__)) # jupyter not ok\n",
        "\n",
        "    data = []\n",
        "\n",
        "\n",
        "    currDir = \".\" # \"/content\" # jupyter not ok\n",
        "\n",
        "    root = os.path.join(currDir, \"MNIST\")\n",
        "\n",
        "    names = os.listdir(root)\n",
        "\n",
        "    for name in names:\n",
        "\n",
        "        #print(\"name: \", name)\n",
        "\n",
        "        num = name.split('_')[0]  # number in fname already \n",
        "        num = int(num)\n",
        "\n",
        "        #print( \"label: \", num )\n",
        "\n",
        "        #num = num / 10  # normalize number to 0.0 ~ 1.0\n",
        "\n",
        "        path = os.path.join(root, name)\n",
        "        im = cv2.imread(path)\n",
        "        im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        \"\"\"\n",
        "        输入：im.shape，  可以看到维度是 (28, 28)\n",
        "              im，       可以看到数值范围是 0 ~ 255\n",
        "              im/255     可以看到数值范围变成了 0.0 ~ 1.0\n",
        "        \"\"\"\n",
        "        # import pdb; pdb.set_trace() # 调试， exit 退出\n",
        "\n",
        "        im = im / 255\n",
        "\n",
        "        im_sq = im.reshape(28*28) # (28*28) 的图片降维成一维数组\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        输入：im_sq.shape 可以看到维度是 (784,)\n",
        "        \"\"\"\n",
        "\n",
        "        #import pdb; pdb.set_trace()\n",
        "\n",
        "\n",
        "        #print(im.shape)\n",
        "\n",
        "        #print( type(im) )\n",
        "        #print(im.shape)\n",
        "        #print(im)\n",
        "\n",
        "        # cv2.imshow('image', im) # BUG: crash the colab kernel\n",
        "        #cv2_imshow(im)\n",
        "        #plt.imshow(im.squeeze(), cmap='gray_r');\n",
        "\n",
        "        data.append( [ torch.Tensor(im_sq), torch.Tensor([num]) ] )\n",
        "\n",
        "        #break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return data\n",
        "\n",
        "class TorchDataset(torch_data.Dataset):\n",
        "  def __init__(self, data):\n",
        "    self.data = data\n",
        "        \n",
        "  def __len__(self):\n",
        "    return len(self.data)\n",
        "  def __getitem__(self, Index):\n",
        "    item = self.data[Index]\n",
        "\n",
        "    return item[0], item[1]\n",
        "\n",
        "def infinite_iter(data_loader):\n",
        "  it = iter(data_loader)\n",
        "  while True:\n",
        "    try:\n",
        "      item_in , item_out = next(it)\n",
        "      yield item_in, item_out\n",
        "    except StopIteration:\n",
        "      it = iter(data_loader)\n",
        "\n",
        "#Data();\n",
        "\n",
        "\n",
        "train_dataset = TorchDataset(Data(type='training'))\n",
        "train_loader = torch_data.DataLoader(train_dataset, batch_size = 64, shuffle=True)  # 每个输入是维度是(2) 的一维数组，每一批总共输入2 组，维度既是：(2, 2)\n",
        "train_iter = infinite_iter(train_loader)\n",
        "\n",
        "sources, targets = next(train_iter)\n",
        "\n",
        "print( sources, targets )\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn0Uxx9hgQx-",
        "outputId": "fdfc7297-d997-4635-d189-9243af53b69e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (5): LogSoftmax(dim=1)\n",
            ")\n",
            "cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_13348\\2659634111.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(labels, dtype=torch.long)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 - Training loss: 7.890174310887232e-05\n",
            "\n",
            "Training Time (in minutes) = 0.7793349663416544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_13348\\2659634111.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(labels, dtype=torch.long)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Training loss: 1.3753730854659807e-05\n",
            "\n",
            "Training Time (in minutes) = 1.7248555302619935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_13348\\2659634111.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(labels, dtype=torch.long)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 - Training loss: 6.151569778012345e-06\n",
            "\n",
            "Training Time (in minutes) = 2.317987871170044\n"
          ]
        }
      ],
      "source": [
        "# 训练\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "# import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "\n",
        "import os\n",
        "# from google.colab import drive\n",
        "\n",
        "\n",
        "# from torchvision import datasets, transforms\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "# Layer details for the neural network\n",
        "input_size = 784\n",
        "hidden_sizes = [128, 64]\n",
        "output_size = 10\n",
        "\n",
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1], output_size),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "print(model)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "\n",
        "time0 = time()\n",
        "epochs = 3\n",
        "for e in range(epochs):\n",
        "\n",
        "    for i in range(10000):\n",
        "\n",
        "        running_loss = 0\n",
        "    \n",
        "        images, labels = next(train_iter)\n",
        "    \n",
        "        labels = labels.reshape(64)\n",
        "        labels = torch.tensor(labels, dtype=torch.long) \n",
        "    \n",
        "        # Training pass\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(  images.cuda() if torch.cuda.is_available() else images.cpu() )\n",
        "\n",
        "        #import pdb; pdb.set_trace() # 调试， exit 退出\n",
        "\n",
        "        loss = criterion(output, labels.cuda() if torch.cuda.is_available() else labels.cpu())\n",
        "        \n",
        "        #This is where the model learns by backpropagating\n",
        "        loss.backward()\n",
        "        \n",
        "        #And optimizes its weights here\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "\n",
        "\n",
        "    print(\"Epoch {} - Training loss: {}\".format(e, running_loss/64))\n",
        "    print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "BYlOAl-zGLYC",
        "outputId": "5febf2df-8c69-42ff-a14b-d127e81f0827"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_13348\\414890312.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  labels = torch.tensor(labels, dtype=torch.long)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "3\n",
            "Number Of Images Tested = 1\n",
            "\n",
            "Model Accuracy = 1.0\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {
            "image/png": {
              "height": 413,
              "width": 417
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "correct_count, all_count = 0, 0\n",
        "\n",
        "images, labels = next(train_iter)\n",
        "labels = labels.reshape(64)\n",
        "labels = torch.tensor(labels, dtype=torch.long) \n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i in range(1):\n",
        "    img = images[i].reshape(1, 784)\n",
        "    logps = model(images.cuda() if torch.cuda.is_available() else images.cpu())\n",
        "\n",
        "    # Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.cpu().numpy()[0])\n",
        "    pred_label = probab.index(max(probab))\n",
        "\n",
        "\n",
        "    img_to_show = images[i].reshape(28,28)\n",
        "    img_to_show = img_to_show * 255\n",
        "\n",
        "    plt.imshow(img_to_show, cmap='gray_r'); \n",
        "\n",
        "    print(pred_label)  # 预测的数字\n",
        "\n",
        "    true_label = labels.numpy()[i]\n",
        "\n",
        "    print(true_label)  # 真实的数字\n",
        "\n",
        "    if(true_label == pred_label):\n",
        "      correct_count += 1\n",
        "    all_count += 1\n",
        "\n",
        "\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"\\nModel Accuracy =\", (correct_count/all_count))  # 预测的正确率"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVLao9GxqErS"
      },
      "outputs": [],
      "source": [
        "# 准备数据\n",
        "import torch\n",
        "from google.colab import drive\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('./mnist/MNIST_data/', download=True, train=True, transform=transform)\n",
        "valset = datasets.MNIST('./mnist/MNIST_data/', download=True, train=False, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPVS6m1wXsu5"
      },
      "outputs": [],
      "source": [
        "# 观察数据\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)  # images [64, 1, 28, 28]，64 张，1 通道，28 宽，28 高 的图片  # labels [64] 64个标签\n",
        "  # 28*28 = 784 个像素点，每张图片作为输入是[768] 的一维数组，每一批总共输入64 张，既是：[64, 784]\n",
        "  # so, 输入层共784 个神经元结点，每个结点得到图片的其中一个像素作为输入\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r');  # squeeze 将 [1, 28, 28] 降维成 [28, 28]\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "输入： images[0].numpy().squeeze()\n",
        "可以看到数值范围是：-1.0 ~ +1.0\n",
        "\"\"\"\n",
        "# import pdb; pdb.set_trace() # 调试， exit 退出\n",
        "\n",
        "\n",
        "figure = plt.figure()\n",
        "num_of_images = 60\n",
        "for index in range(1, num_of_images + 1):\n",
        "    plt.subplot(6, 10, index)  # 绘制  6 行，10 列 个对象\n",
        "    plt.axis('off')            # 关闭坐标轴显示\n",
        "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "iov7ufvQqPhG",
        "outputId": "5506360c-8c35-4280-8979-c1f89dacdff4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (1): ReLU()\n",
            "  (2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (3): ReLU()\n",
            "  (4): Linear(in_features=64, out_features=10, bias=True)\n",
            "  (5): LogSoftmax(dim=1)\n",
            ")\n",
            "cpu\n",
            "> <ipython-input-10-32d940273697>(76)<module>()\n",
            "-> loss.backward()\n",
            "(Pdb) label.shape\n",
            "*** NameError: name 'label' is not defined\n",
            "(Pdb) labels.shape\n",
            "torch.Size([64])\n",
            "(Pdb) exit\n"
          ]
        },
        {
          "ename": "BdbQuit",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-32d940273697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m#This is where the model learns by backpropagating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m#And optimizes its weights here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-32d940273697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m#This is where the model learns by backpropagating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;31m#And optimizes its weights here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBdbQuit\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# 训练\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "# Layer details for the neural network\n",
        "input_size = 784\n",
        "hidden_sizes = [128, 64]\n",
        "output_size = 10\n",
        "\n",
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1], output_size),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "print(model)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "\n",
        "time0 = time()\n",
        "epochs = 15\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)  # 元素的总数不变，对维度重新进行解释，相当于 reshape  # 64 行，列数自适应(-1 的作用)  \n",
        "          # 28*28 = 784 个像素点，每张图片作为输入是[784] 的一维数组，每一批总共输入64 张，既是：[64, 784]\n",
        "    \n",
        "        \"\"\"\n",
        "        输入： \n",
        "            images[0] 可以看到是张量 tensor，数值范围是：-1.0 ~ +1.0\n",
        "            images[0].shape，可以看到维度是 784，是一维数组\n",
        "            ((images[0]+1)/2)*255 ，数值范围规范为：0 ~ 255\n",
        "        \"\"\"\n",
        "        #import pdb; pdb.set_trace() # 调试， exit 退出\n",
        "\n",
        "\n",
        "        for i in range(len(images)):\n",
        "          images[i] = ( (images[i]+1) / 2 ) # 原来的数值范围是 -1.0 ~ +1.0 ，规范为 0 ~ +1.0\n",
        "        \n",
        "\n",
        "        # Training pass\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "\n",
        "\n",
        "        output = model(  images.cuda() if torch.cuda.is_available() else images.cpu() )\n",
        "        loss = criterion(output, labels.cuda() if torch.cuda.is_available() else  labels.cpu())\n",
        "\n",
        "        import pdb; pdb.set_trace() # 调试， exit 退出\n",
        "        \n",
        "        #This is where the model learns by backpropagating\n",
        "        loss.backward()\n",
        "        \n",
        "        #And optimizes its weights here\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\n",
        "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7NcRWeYambN"
      },
      "outputs": [],
      "source": [
        "# 验证模型精度\n",
        "correct_count, all_count = 0, 0\n",
        "for images,labels in valloader:\n",
        "  for i in range(len(labels)):\n",
        "    img = images[i].view(1, 784)\n",
        "    img = ( (img+1) / 2 ) # 原来的数值范围是 -1.0 ~ +1.0 ，规范为 0 ~ +1.0\n",
        "    # Turn off gradients to speed up this part\n",
        "    with torch.no_grad():\n",
        "        logps = model(img.cuda())\n",
        "\n",
        "    # Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.cpu().numpy()[0])\n",
        "    pred_label = probab.index(max(probab))\n",
        "    true_label = labels.numpy()[i]\n",
        "    if(true_label == pred_label):\n",
        "      correct_count += 1\n",
        "    all_count += 1\n",
        "\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bdAmw1v7DHq"
      },
      "outputs": [],
      "source": [
        "# 预测\n",
        "def view_classify(img, ps):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.cpu().data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    ax2.set_yticklabels(np.arange(10))\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "    plt.tight_layout()\n",
        "\n",
        "images, labels = next(iter(valloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "img = ( (img+1) / 2 ) # 原来的数值范围是 -1.0 ~ +1.0 ，规范为 0 ~ +1.0\n",
        "\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img.cuda())\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = torch.exp(logps)\n",
        "probab = list(ps.cpu().numpy()[0])\n",
        "print(\"Predicted Digit =\", probab.index(max(probab)))\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "digit_torch_version2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
