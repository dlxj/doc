{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "digit_torch_version2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFQM12Qy2scn"
      },
      "source": [
        "!unzip MNIST.zip_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLwb4iUY3uNH",
        "outputId": "87ae1214-c392-42eb-e5ed-87524628383f"
      },
      "source": [
        "import cv2\n",
        "\n",
        "im = cv2.imread(\"./MNIST/0_0_10.jpg\")\n",
        "print(im.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "id": "sHbfOT2E4My7",
        "outputId": "a919d29a-2f91-46c9-9073-257eb1a8004d"
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "#import numpy as np\n",
        "\n",
        "rootdir = './MNIST'\n",
        "names = os.listdir(rootdir)\n",
        "\n",
        "for name in names:\n",
        "  print(\"name: \", name)\n",
        "  path = os.path.join(rootdir, name)\n",
        "  im = cv2.imread(path)\n",
        "  im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "  print(type(im))\n",
        "  print(im.shape)\n",
        "\n",
        "  # cv2.imshow('image', im) # BUG: crash the colab kernel\n",
        "  cv2_imshow(im)\n",
        "  plt.imshow(im.squeeze(), cmap='gray_r'); \n",
        "  \n",
        "  break"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "name:  7_5_53.jpg\n",
            "<class 'numpy.ndarray'>\n",
            "(28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABXUlEQVR4nHWSvUtcQRTFf/fO7IKNyKIiS7SIIagIYqNiJensrAT/AutAiAQbi2BhIVhYhDRpUii2NordNluINvaCIiILIqjJ482Hxa4PffveqWY4c+49586FDIKAUALBlDCKGNBSlkqZVEQ7T4phKTckXbo316isx/G8S8QAwtTvS7/3a3L540imMQKI2KGvzoc0Bu/83UZP1slgYGbXxaR5dO+idy58eiUVYfnsOab/D/v4Njt9Gt3VgL46Mmw9hZCGxzmoV76HxO23E2lQ8fRVY0g3+5voTVqL9u9atFk+sx19q94u8+Vf2pDMrQjSe3DxGRVQfga/0j0nEUAGW/HmQ9EQFTj2yWon3DvGAiPX/qHzP13K4XOfLgmiubrGQnUhiY12CJsTWuQkuEWw+Zag6I8QLmraPr9PgvAnpBMULqgy33JhrMAoIOwk7qRawsng+e1o8fYZEMn5eAEh+2vtYxKYhgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=28x28 at 0x7FC8A837C410>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "oVLao9GxqErS"
      },
      "source": [
        "# 准备数据\n",
        "import torch\n",
        "from google.colab import drive\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform to normalize the data\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                              transforms.Normalize((0.5,), (0.5,)),\n",
        "                              ])\n",
        "\n",
        "# Download and load the training data\n",
        "trainset = datasets.MNIST('./mnist/MNIST_data/', download=True, train=True, transform=transform)\n",
        "valset = datasets.MNIST('./mnist/MNIST_data/', download=True, train=False, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=True)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wPVS6m1wXsu5"
      },
      "source": [
        "# 观察数据\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = next(dataiter)  # images [64, 1, 28, 28]，64 张，1 通道，28 宽，28 高 的图片  # labels [64] 64个标签\n",
        "  # 28*28 = 784 个像素点，每张图片作为输入是[768] 的一维数组，每一批总共输入64 张，既是：[64, 784]\n",
        "  # so, 输入层共784 个神经元结点，每个结点得到图片的其中一个像素作为输入\n",
        "print(type(images))\n",
        "print(images.shape)\n",
        "print(labels.shape)\n",
        "\n",
        "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r');  # squeeze 将 [1, 28, 28] 降维成 [28, 28]\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "输入： images[0].numpy().squeeze()\n",
        "可以看到数值范围是：-1.0 ~ +1.0\n",
        "\"\"\"\n",
        "# import pdb; pdb.set_trace() # 调试， exit 退出\n",
        "\n",
        "\n",
        "figure = plt.figure()\n",
        "num_of_images = 60\n",
        "for index in range(1, num_of_images + 1):\n",
        "    plt.subplot(6, 10, index)  # 绘制  6 行，10 列 个对象\n",
        "    plt.axis('off')            # 关闭坐标轴显示\n",
        "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iov7ufvQqPhG"
      },
      "source": [
        "# 训练\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "# Layer details for the neural network\n",
        "input_size = 784\n",
        "hidden_sizes = [128, 64]\n",
        "output_size = 10\n",
        "\n",
        "# Build a feed-forward network\n",
        "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
        "                      nn.ReLU(),\n",
        "                      nn.Linear(hidden_sizes[1], output_size),\n",
        "                      nn.LogSoftmax(dim=1))\n",
        "print(model)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.NLLLoss()\n",
        "\n",
        "\n",
        "time0 = time()\n",
        "epochs = 15\n",
        "for e in range(epochs):\n",
        "    running_loss = 0\n",
        "    for images, labels in trainloader:\n",
        "        # Flatten MNIST images into a 784 long vector\n",
        "        images = images.view(images.shape[0], -1)  # 元素的总数不变，对维度重新进行解释，相当于 reshape  # 64 行，列数自适应(-1 的作用)  \n",
        "          # 28*28 = 784 个像素点，每张图片作为输入是[784] 的一维数组，每一批总共输入64 张，既是：[64, 784]\n",
        "    \n",
        "        \"\"\"\n",
        "        输入： \n",
        "            images[0] 可以看到是张量 tensor，数值范围是：-1.0 ~ +1.0\n",
        "            images[0].shape，可以看到维度是 784，是一维数组\n",
        "            ((images[0]+1)/2)*255 ，数值范围规范为：0 ~ 255\n",
        "        \"\"\"\n",
        "        #import pdb; pdb.set_trace() # 调试， exit 退出\n",
        "\n",
        "\n",
        "        for i in range(len(images)):\n",
        "          images[i] = ( (images[i]+1) / 2 ) # 原来的数值范围是 -1.0 ~ +1.0 ，规范为 0 ~ +1.0\n",
        "        \n",
        "\n",
        "        # Training pass\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        output = model(  images.cuda() if torch.cuda.is_available() else images.cpu() )\n",
        "        loss = criterion(output, labels.cuda())\n",
        "        \n",
        "        #This is where the model learns by backpropagating\n",
        "        loss.backward()\n",
        "        \n",
        "        #And optimizes its weights here\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    else:\n",
        "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\n",
        "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7NcRWeYambN"
      },
      "source": [
        "# 验证模型精度\n",
        "correct_count, all_count = 0, 0\n",
        "for images,labels in valloader:\n",
        "  for i in range(len(labels)):\n",
        "    img = images[i].view(1, 784)\n",
        "    img = ( (img+1) / 2 ) # 原来的数值范围是 -1.0 ~ +1.0 ，规范为 0 ~ +1.0\n",
        "    # Turn off gradients to speed up this part\n",
        "    with torch.no_grad():\n",
        "        logps = model(img.cuda())\n",
        "\n",
        "    # Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "    ps = torch.exp(logps)\n",
        "    probab = list(ps.cpu().numpy()[0])\n",
        "    pred_label = probab.index(max(probab))\n",
        "    true_label = labels.numpy()[i]\n",
        "    if(true_label == pred_label):\n",
        "      correct_count += 1\n",
        "    all_count += 1\n",
        "\n",
        "print(\"Number Of Images Tested =\", all_count)\n",
        "print(\"\\nModel Accuracy =\", (correct_count/all_count))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bdAmw1v7DHq"
      },
      "source": [
        "# 预测\n",
        "def view_classify(img, ps):\n",
        "    ''' Function for viewing an image and it's predicted classes.\n",
        "    '''\n",
        "    ps = ps.cpu().data.numpy().squeeze()\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
        "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
        "    ax1.axis('off')\n",
        "    ax2.barh(np.arange(10), ps)\n",
        "    ax2.set_aspect(0.1)\n",
        "    ax2.set_yticks(np.arange(10))\n",
        "    ax2.set_yticklabels(np.arange(10))\n",
        "    ax2.set_title('Class Probability')\n",
        "    ax2.set_xlim(0, 1.1)\n",
        "    plt.tight_layout()\n",
        "\n",
        "images, labels = next(iter(valloader))\n",
        "\n",
        "img = images[0].view(1, 784)\n",
        "img = ( (img+1) / 2 ) # 原来的数值范围是 -1.0 ~ +1.0 ，规范为 0 ~ +1.0\n",
        "\n",
        "# Turn off gradients to speed up this part\n",
        "with torch.no_grad():\n",
        "    logps = model(img.cuda())\n",
        "\n",
        "# Output of the network are log-probabilities, need to take exponential for probabilities\n",
        "ps = torch.exp(logps)\n",
        "probab = list(ps.cpu().numpy()[0])\n",
        "print(\"Predicted Digit =\", probab.index(max(probab)))\n",
        "view_classify(img.view(1, 28, 28), ps)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}