从初音ミク到歌声合成
===

受[疾风月影](http://bbs.ivocaloid.com/space-uid-104749.html)之邀，写了这篇歌声合成研究领域的入门指南。因篇幅限制只能给出大体方向的指引。作者本人不能确保内容完整不含偏见，故暂且发布在Github上，恳请日后各位帮助修改、完善。
本指南所推荐的学习方向仅是作者个人在不断摸索和碰壁中总结出的经验，不清楚是否对所有人都合适，希望对你多少能有些帮助。

前言
---

四年多前我曾试图编写一个像Vocaloid一样的歌声合成软件，在对相关技术一无所知的情况下，花了一年半瞎胡摸索写了个勉强能发声的合成器。当我开始接触到一些歌声合成领域的学术文献时，才后悔当初没先了解别人的研究成果就盲目动手。

走上这条研究道路的有两种人：从学院走出来遇上了虚拟歌姬，和遇上虚拟歌姬后有感而发步入学院。
绝大多数人属于前者，即在歌声合成或相关领域的学术研究上钻研多年，偶然发现初音竟和自己的研究有关。然而这篇文章是写给后者的：或许你是个程序员或者废宅，看到初音这么萌的孩子后突然对歌声合成产生了兴趣，希望自己也能创造出歌姬，于是走上学术研究路线。

对于第二类人，我们若没有教育机会就只能靠自学，但自学的路线是艰辛无比的。歌声合成属于语音合成的子领域，又属于信号处理和机器学习(甚至还带点语音学)的交叉领域。如果要把所有涉及到的学科和领域列出来的话，这代表你恐怕要从数学开始恶补起来了：

<p align="center"><img src="https://cloud.githubusercontent.com/assets/4531595/8493088/83af543e-2187-11e5-8af3-1d5d51aab5fb.png" width="450" /></p>

是不是很害怕？大概50岁前把这些领域全精通是不太可能了(世界上的确有几个大牛是全才，跪)……但是你至少还是可以**选定一个子领域、一个方向甚至仅仅一个课题去专攻**，过程中你会不可避免地多少接触些其它领域的东西，时间久了就积累起来了。

总体学习方案
---

综上所述，我推荐自学者分两个步骤学习：

1.  自下而上：打基础，先学点不管什么领域都会用到的数学、信号处理和机器学习的常用简单技巧。(约500-1000小时)
2.  自上而下：找准了一个目标，啃论文，遇到不懂的再往下学，若还不懂就继续往下学，直到搞懂为止。(时间无上限)

没错，“简单技巧”也要千把小时才能学完，所以愿你在接下来的日子里始终记着：

*   你的初衷是想落实你对虚拟歌姬的喜爱
*   只要有希望，一切都好说
*   如果你坚持下去，日子会一天一天变好的

把第一阶段完成了，你就拿到了歌声合成游乐场的门票，但是里面的游乐项目还是单独收费的。这时候你可以挑一个具体点的目标来专心研究(我是指先学习，再自己动手研究)。

**歌声合成所研究的问题远远不止“如何生成自然的歌声”**，还包括如何从乐谱生成韵律、如何对语音建模、如何进行音高时长修改、如何对语音进行自动标注、如何提取语音的基频和频谱特征等等……但无论最终走那条路，数学、信号处理和机器学习基础都多少会用到，这就是下一节要详细说明的。

自下而上
---

这个阶段是打基础用的。虽然直接自上而下(理论上)是可以，但你始终会遇到困难一层层被打回来学数学和信号处理，还不如直接学些常用的技能，总体会省时。
这是个有点求快但不求好的教程，这么做可以相对快地把你引入时下最前沿的研究，但终归学得不扎实。所以若时间充裕，**请务必回头多巩固基础**。

### 数学

基本上什么领域的论文都会用到些代数、微积分之类，所以首要工作是找本高中数学、大学数学教材，最起码把单变量微积分弄熟了；概率和统计也是推荐学习的，主要在第二阶段读一些机器学习相关论文时常会用到；线性代数和多元微积分可以开始看起来，但相对不那么迫切。另外学信号处理和机器学习的时候也会顺带学些数学。
如果觉得在线视频看起来比较舒服，可以去看[可汗学院](https://www.khanacademy.org/)的数学课。个人感觉在线课程有个坏处就是容易走神，不过关键还是看个人。

### 数字信号处理

数字信号处理(Digital Signal Processing)是用数学方法研究信号、处理信号的学科。“信号”可以是数字图像、音频甚至各种传感器数据，而这门学科是关于处理各类信号的一系列通用方法。在歌声合成领域，数字信号处理主要用于人声的底层建模和修改(例如变调、时间伸缩等)。

A.V. Oppenheim教授的《离散时间信号处理》在业界被称为圣经，但完全自学看起难度略高，这里不推荐作为第一本数字信号处理书(但入门后推荐看一遍)。

这里推荐两个视频教程：

*   Coursera上[EPFL的数字信号处理课](https://www.coursera.org/course/dsp)
*   Coursera上[UPF的音乐音频信号处理课](https://www.coursera.org/course/audio)

内容上稍有区别，从名字也能看出来。难度上前者偏难一点。另外前者偏理论，后者偏应用。
两个视频看完你就算是入门啦，然后推荐(但不是必须)看Julius. O. Smith教授的[频谱音频信号处理](https://ccrma.stanford.edu/~jos/sasp/)一书来巩固补缺，若还愿意找虐，就去过遍圣经吧。

### 机器学习

机器学习属于人工智能下的一个子领域(也有说法是从人工智能演变而来)。它主要研究如何通过计算机程序，从已有数据中学习、发掘规律，用于对未知数据进行预测。
举个例子：唱歌或说话时，爆破音(如p, t, k)前往往有停顿，但具体停顿时间和语境有很大关系。我们可以录制几分钟真人唱歌/说话的语音，使用机器学习算法学习语境和停顿时间的关系，从而实现给定曲谱/句子，让机器估计出听起来自然的停顿时间。

个人强烈推荐Andrew Ng教授的[Coursera机器学习公开课](https://class.coursera.org/ml-006)。对数学基础要求较少又很实用，一般人应该都能顺利学完。
机器学习领域的资料都很公开，这对自学者来说是极好的。

自上而下
---

你慢慢会注意到窝在家里啃论文其实是一场环球旅行，你将逐渐了解到世界各地研究者的动向，进而浮现出歌声/语音合成领域的全貌，这个过程其实挺有意思的。

语音合成是歌声合成的“爹爹”，后者用的很多技术都是从前者带过来的。在介绍研究方向前有必要先普及一下语音合成领域中两种主流的技术路线：拼接合成(Concatenative Synthesis)和统计参数合成(Statistical Parametric Synthesis)。

* 拼接合成： 事先录制好大量语音/歌声，根据文本/曲谱把录制好的语音拼接起来，视情况对语音片段进行时长和音高等修正。
* 统计参数语音合成：同样也是事先录制好大量语音/歌声，然后建立数学模型，把相似的语音片段归类、统计出共同特征。合成时根据文本/曲谱重新组合统计信息，生成语音/歌声。

<p align="center"><img src="https://cloud.githubusercontent.com/assets/4531595/8493957/b38b2d08-2192-11e5-9746-56463f787f8a.png" width="350" /></p>

历史上，这两种方法分别起源于双音子拼接合成(Diphone Synthesis)和基于隐马尔科夫模型(HMM-based)的统计参数合成。

前者涉及到的事先录制好的语音样本均只包含两个音素，比如"ka", "la", "ai", "ua"这样，这样实现起来十分简单。在90年代中期这种技术发展成了基元选择(Unit Selection)拼接合成，一般录制的语音样本为连续的句子，拼接单元长度没有硬性规定，例如可以是双音素、多音素、多音节等，且合成过程中选择拼接用到的语音样本时会结合上下文信息对数据库(在本领域称为“语料库(Corpus)”)进行筛选。Vocaloid和苹果的Siri等即是采用了拼接合成技术路线。

基于隐马尔科夫模型的语音合成方法相对拼接合成比较复杂。这里我写过一个[概念性的简介](http://www.zhihu.com/question/21350325/answer/38139770)。目前该技术路线最新的进展是将深度学习(Deep Learning)技术，如深度置信网络(Deep Belief Network)、深度神经网络(Deep Neural Network)等引入统计参数合成框架。这种技术路线的优点是在合成语音的韵律控制上相比拼接合成更自然。缺点是由于语音是被精简成统计信息再合成，而不是像拼接合成一样直接把原始语料库用作拼接，合成的语音多少会变得有些模糊(Muffled)。前面提到的深度学习技术的引入，也主要是为了缓解这种发音模糊的问题。CeVIO歌声合成软件和Google翻译的语音朗读采用了统计参数合成技术。

这里给出几个常见的研究方向，其中大多数无论在拼接合成还是统计参数合成中都会用到，你可以选择感兴趣的进行深入学习。

* 不论何种技术路线，都需要语音数据的储备。如何录制尽量少的数据来覆盖尽量多的语境组合，涉及到语料库设计(Corpus Design)的问题；
* 语料库录制好以后，为了能够选取样本进行拼接，或者训练一个统计参数模型，必须实现标注好语料库里每个音素的起始和结束时间。这个问题叫做自动语音分段(Automatic Speech Segmentation)或文语对齐(Text-to-Speech Alignment)；
* 直接以波形存储的语音数据并不适合音高和时长修改，因此需要将语音转换成某种中间参数的形式，对中间参数进行变换后，再转换回波形数据。这称作分析-合成(Analysis-Synthesis)，应用这种分析-合成技术对语音进行编码和解码的装置叫声码器(Vocoder)；
* 也有不需要转换中间参数直接对语音进行音高、时长修改的方法，广义上就是语音时长/音高修改(关键字：Speech Duration/Pitch Modification)；
* 许多语音修改算法或分析算法需要事先知道语音的基频曲线，这就涉及到基频提取(Fundamental Frequency Estimation/F0 Estimation)。许多基频提取算法不仅适用于语音，也适用于其它音频信号例如各种乐器；
* 如何从文本/曲谱生成出各个音节音素的时长和基频的变化曲线，即韵律生成/建模(Prosody Generation/Modelling)，在歌声合成方面主要集中于基频曲线生成(F0 Contour Generation)。研究这一课题往往会用到机器学习手段；
* 如何将文本转换成一串音标或分割成一串音节、如何把语音中的阿拉伯数字、日期、货币符号等等转换成单词的形式、如何判断重音(Stress)的位置……这一系列我们一般划入语音合成前端(Front End)的工作，称作文本分析(Textual Analysis)。一般用到自然语言处理等机器学习手段(这里面水很深)；
* 语音转换(Voice Conversion)：把一个人说话的声音转换成另一个人说话的声音，有时还包括说话风格(比如语调、停顿)的转换。在统计参数合成的框架里这一般被称作Speaker Adaption。
* 广义上整个语音合成系统的设计。无论拼接合成还是统计参数语音合成，往往都是若干技术的组合(从上面提到的语料库设计到文本分析到分析-合成到基元选择算法等等)。选择哪些技术进行组合、怎么组合这些技术当然也是门学问。

有时很难硬性地把某些研究归类，因为很多研究同时包含了上述多个课题。像统计参数语音合成一般会顺带着把韵律建模问题解决掉。

### 从什么论文读起比较好

选定一个研究方向后，就可以开始进入啃论文的阶段了。从哪些论文开始读起比较好让人接受呢？其实并没有固定的顺序。我个人常用的一些方法是：

* 读这个领域里总结性的论文 (当一个领域或研究方向流行一段时间后，往往就会有人写总结性文章。15年前的古董文就不要了)
* 读引用量最高的论文 (虽然很多人说引用量不能直接反映论文的质量，但多数情况是管用的)
* 在阅读论文时，把Introduction章节里引用到的文献标记出来，这里面往往会总结很多先前的研究。若有兴趣可以阅读这些引用文献。

接下来举几个例子：

* 总结性论文：Schwarz, Diemo. "Corpus-based concatenative synthesis." Signal Processing Magazine, IEEE 24.2 (2007): 92-104. 概括了语音/音乐拼接合成系统的大致结构，涉及几个有待研究的方向，引用了不少有参考价值的文献。
* 高引用量论文：Hunt, Andrew J., and Alan W. Black. "Unit selection in a concatenative speech synthesis system using a large speech database." Acoustics, Speech, and Signal Processing, 1996. ICASSP-96. Conference Proceedings., 1996 IEEE International Conference on. Vol. 1. IEEE, 1996. 使用动态规划进行大语料库拼接合成，将基元选择看作状态转移网络，提出误差权重的自动预测方法，引用量目前已超过1100。

### 从哪找论文

大约80%以上的论文都可以从[Google Scholar](http://scholar.google.com/)检索到。如果国内上不去，可以访问这个[镜像](http://www.jwss.com/scholar)。

在歌声合成和机器学习领域，过半数的论文是直接在网上公开pdf的。至于如何找到和下载pdf版本，Google Scholar上一清二楚，这里就不赘述。
可惜不是所有作者/出版社都愿意在网上公开文献资料，这种情况下有如下几个解决途径：

0. 有时[CiteSeerX](http://citeseerx.ist.psu.edu/)上的论文明明提供了下载地址，但Google Scholar没显示出来；
1. 有时Google的通用搜索能检索出Scholar都找不到的论文；
2. 寻找内容类似并公开pdf的论文以代替；
3. 寻找引用该论文的文献，看看它的Introduction里是不是介绍了这篇论文使用的方法；
4. 去[Research Gate](http://researchgate.net/)看看作者是不是把pdf投到这儿了(不过一般Google的检索结果会包含Research Gate)；
5. 如果上述方法都不管用，那么向作者发封邮件问问能不能把pdf发给你，记得用语一定要礼貌；
6. 如果上述方法都不管用，那么只好向出版社氪金了。

### 怎么读论文

请参见[Robert Siegel. "Reading Scientific Papers"](http://web.stanford.edu/~siegelr/readingsci.htm)。
没必要刻版地按着步骤来，读多了会找到适合自己的方法。

### 读不懂怎么办

别害怕，这是常有的事。这种情况90%是由于你缺乏背景知识。请保持**耐心**，试试以下方法：

1. 上Google查你看不懂的关键词；
2. 去引用文献里找，看看有没有介绍你看不懂的部分的文章；
3. 如果引用文献也看不懂，用Google Scholar找内容近似的文献学习；
4. 如果还看不懂，你应该是缺乏相关领域的基本常识(虽说在相关领域里是“基本”但实际上可能真的很有深度)。这种情况建议看本书或教程；
5. 如果还看不懂，向作者发邮件提问吧。同样，注意礼貌用语。很多作者会发给你几篇论文供参考。

将研究结合实践
---

一直磕论文磕书本但不自己亲手写代码实现文献里讲的方法，个人认为是不好的。很多时候你不自己动手就不会发现，其实论文里有很多没交待清楚的地方(因为很多期刊有页数限制)，不自己试试根本就学不到。久而久之你的知识会离实际应用越来越遥远……

这又是一个自学者很不讨好的地方。一般大学里教授做研究，把公式推出来以后扔给手下的学生写代码实现出来。学生好歹还能找几个帮手一起赶代码，而我们不得不自己从头到尾做完所有工作。

本领域做研究常用的编程语言是Matlab。Mathematica目前看到用的较少，(听说)设计滤波器时可以省不少事。Matlab在做某些工作(比如很多基于动态规划的算法)时效率非常坑爹，所以最好掌握使用C/C++写Matlab扩展的技能。另一个常用的编程语言是Python，使用Scipy库基本可以替代Matlab。说起来Python最近越来越流行了。

同样，在实现算法时请保持耐心。实现一篇论文里的算法所耗时间，短的只要几小时，长的要几星期甚至几个月。为节省时间我们一般不会从零开始，而是先去找有没有现成的库。比如当你尝试用HMM合成语音时，应该先去找找有没有供Matlab/Python使用的HMM库，如果有的话就不用自己去实现HMM相关的一大套算法了。(不过可惜的是并没有这样一个库，目前唯一能用的是剑桥大学的HTK，但不提供Matlab/Python接口。这只是个例子)